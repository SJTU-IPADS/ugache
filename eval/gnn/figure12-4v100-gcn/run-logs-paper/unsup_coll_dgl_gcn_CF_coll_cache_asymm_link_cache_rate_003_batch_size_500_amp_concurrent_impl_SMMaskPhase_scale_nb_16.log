succeed=True
[CUDA] cuda: usage: 5.47 GB
0 :  {link #0 : 1}, {link #1 : 2}, {link #2 : 3},
1 :  {link #0 : 2}, {link #1 : 3}, {link #2 : 0},
2 :  {link #0 : 3}, {link #1 : 0}, {link #2 : 1},
3 :  {link #0 : 0}, {link #1 : 1}, {link #2 : 2},
0 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g2 24}, {link #2 : g3 24},
1 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g3 24}, {link #2 : g0 24},
2 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g0 24}, {link #2 : g1 24},
3 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g1 24}, {link #2 : g2 24},
0 :  {link #0 : 1}, {link #1 : 2}, {link #2 : 3},
1 :  {link #0 : 2}, {link #1 : 3}, {link #2 : 0},
2 :  {link #0 : 3}, {link #1 : 0}, {link #2 : 1},
3 :  {link #0 : 0}, {link #1 : 1}, {link #2 : 2},
0 :  {link #0 : 1}, {link #1 : 2}, {link #2 : 3},
1 :  {link #0 : 2}, {link #1 : 3}, {link #2 : 0},
2 :  {link #0 : 3}, {link #1 : 0}, {link #2 : 1},
3 :  {link #0 : 0}, {link #1 : 1}, {link #2 : 2},
0 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g2 24}, {link #2 : g3 24},
1 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g3 24}, {link #2 : g0 24},
2 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g0 24}, {link #2 : g1 24},
3 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g1 24}, {link #2 : g2 24},
0 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g2 24}, {link #2 : g3 24},
1 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g3 24}, {link #2 : g0 24},
2 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g0 24}, {link #2 : g1 24},
3 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g1 24}, {link #2 : g2 24},
0 :  {link #0 : 1}, {link #1 : 2}, {link #2 : 3},
1 :  {link #0 : 2}, {link #1 : 3}, {link #2 : 0},
2 :  {link #0 : 3}, {link #1 : 0}, {link #2 : 1},
3 :  {link #0 : 0}, {link #1 : 1}, {link #2 : 2},
0 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g2 24}, {link #2 : g3 24},
1 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g3 24}, {link #2 : g0 24},
2 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g0 24}, {link #2 : g1 24},
3 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g1 24}, {link #2 : g2 24},
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID
Set parameter TimeLimit to value 200
Set parameter MIPGap to value 0.05
Set parameter LogFile to value "cppsolver.log"
Set parameter Threads to value 40
Academic license - for non-commercial use only - registered to xiaoniu.sxn@sjtu.edu.cn
Gurobi Optimizer version 9.5.1 build v9.5.1rc2 (linux64)
Thread count: 40 physical cores, 80 logical processors, using up to 40 threads
Academic license - for non-commercial use only - registered to xiaoniu.sxn@sjtu.edu.cn
Optimize a model with 11156 rows, 3643 columns and 34264 nonzeros
Model fingerprint: 0x0ef8b47d
Variable types: 5 continuous, 3638 integer (3638 binary)
Coefficient statistics:
  Matrix range     [2e-09, 4e+04]
  Objective range  [1e+00, 1e+00]
  Bounds range     [1e+00, 1e+00]
  RHS range        [1e+00, 2e+04]
Warning: Model contains large matrix coefficient range
         Consider reformulating model or setting NumericFocus parameter
         to avoid numerical issues.
Found heuristic solution: objective 2.000000e+09
Presolve removed 7838 rows and 139 columns
Presolve time: 0.05s
Presolved: 3318 rows, 3504 columns, 16149 nonzeros
Found heuristic solution: objective 84564.262962
Variable types: 1 continuous, 3503 integer (3502 binary)

Root relaxation: objective 3.881163e+04, 3104 iterations, 0.04 seconds (0.02 work units)

    Nodes    |    Current Node    |     Objective Bounds      |     Work
 Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time

     0     0 38811.6345    0   25 84564.2630 38811.6345  54.1%     -    0s
H    0     0                    40899.312713 38811.6345  5.10%     -    0s
H    0     0                    39530.731249 38811.6345  1.82%     -    0s

Cutting planes:
  Gomory: 4
  Cover: 1
  MIR: 1
  RLT: 3

Explored 1 nodes (4448 simplex iterations) in 0.18 seconds (0.11 work units)
Thread count was 40 (of 80 available processors)

Solution count 4: 39530.7 40899.3 84564.3 2e+09 

Optimal solution found (tolerance 5.00e-02)
Best objective 3.953073124866e+04, best bound 3.881163587492e+04, gap 1.8191%
coll_cache:optimal_local_rate=0.131075,0.183343,0.171692,0.175414,
coll_cache:optimal_remote_rate=0.523217,0.47095,0.4826,0.478879,
coll_cache:optimal_cpu_rate=0.345707,0.345707,0.345707,0.345707,
z=39530.7
test_result:init:feat_nbytes=67182966784
test_result:init:cache_nbytes=2082671616
test_result:init:feat_nbytes=67182966784
test_result:init:cache_nbytes=2082671616
test_result:init:feat_nbytes=67182966784
test_result:init:cache_nbytes=2082671616
test_result:init:feat_nbytes=67182966784
test_result:init:cache_nbytes=2082671616
worker 0 running with pid=32098
config:eval_tsp="2023-08-06 08:31:46"
config:num_worker=4
config:num_intra_size=4
config:root_dir=/datasets_gnn/wholegraph
config:graph_name=com-friendster
config:epochs=4
config:batchsize=500
config:skip_epoch=2
config:local_step=250
config:presc_epoch=2
config:neighbors=15,10,5
config:hiddensize=256
config:num_layer=3
config:model=gcn
config:framework=dgl
config:dataloaderworkers=0
config:dropout=0.5
config:weight_decay=0.0005
config:lr=0.003
config:use_nccl=False
config:use_amp=True
config:use_collcache=True
config:cache_percentage=0.03
config:cache_policy=coll_cache_asymm_link
config:omp_thread_num=40
config:unsupervised=True
config:classnum=100
config:global_barrier=<multiprocessing.synchronize.Barrier object at 0x7f869efbe880>
config:worker_id=0
creating_intra_node_communicator root=0, local_size=4, world_size=4
loading train edge idx from disk
loading train edge idx from disk done
tensor([ 312558501,  165303846,  382592436, 3465360478, 1289294319, 1055724137,
        3392581687,  213217736, 3047409731, 2134151289, 2553067370, 2969120916,
        2293768477, 1618302669,  184738216, 1829492105, 1438364301,  143975391,
        3488855025, 1525393396,  484788782, 1824160758, 3278914432, 1791042494,
        2531399103, 1976393697,  267524578, 1415973226, 3055112374, 2304304850,
        2970740983,  463733153,  470323953,  172504368,  314487920,  565768019,
        1325206124,    3902063, 2558324563, 2631782915, 3561616031, 2061569113,
        1776804911, 3574237973,  226132407,  361666075, 1514025674, 2274739441,
         125808586,  613763319, 1680587044,   50300193, 1625798297, 1321548596,
        3372445782, 1162803676, 1779255988, 2824765390, 1859433431, 2244623276,
        2673542557, 2014397343,  787107922, 1470797842,  653592026, 3063416664,
        2396187549,   39784734,  782941200, 2597902117, 1950931722,  539301441,
         881167165, 2566715114, 1143946729, 1063252333,  374533248, 2050371892,
        3306915207,  552684244, 1631811769,  588251379,  562506265,   42541411,
        1864901246, 2976754698, 1822251476,  641961590,  819864454, 3489874270,
        3553458922, 3534464258, 1694742715, 1593217661,  209704235, 1093043746,
        2390506997,   76009729,   77103172, 2606303238])
Rank=0, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.010139, per step: 0.000041
epoch=4 total_steps=1000
presamping
presamping takes 15.620014667510986
start training...
[Epoch 0][Step 0], time=1.207380771636963, ext_time=0.03931856155395508, train_time=1.159081220626831
[Epoch 0][Step 1], time=0.06702542304992676, ext_time=0.03380632400512695, train_time=0.025765180587768555
[Epoch 0][Step 2], time=0.06171822547912598, ext_time=0.03345894813537598, train_time=0.02231574058532715
[Epoch 0][Step 3], time=0.06357359886169434, ext_time=0.0332341194152832, train_time=0.024524450302124023
[Epoch 0][Step 4], time=0.06101870536804199, ext_time=0.03336143493652344, train_time=0.021863698959350586
[Epoch 0][Step 5], time=0.06240224838256836, ext_time=0.033235788345336914, train_time=0.023473739624023438
[Epoch 0][Step 6], time=0.060970306396484375, ext_time=0.03338479995727539, train_time=0.021883726119995117
[Epoch 0][Step 7], time=0.06398367881774902, ext_time=0.03341221809387207, train_time=0.024820804595947266
[Epoch 0][Step 8], time=0.06103825569152832, ext_time=0.03316688537597656, train_time=0.022104978561401367
[Epoch 0][Step 9], time=0.060945749282836914, ext_time=0.03376269340515137, train_time=0.021440982818603516
[Epoch 0][Step 10], time=0.06406497955322266, ext_time=0.03331303596496582, train_time=0.025043010711669922
[Epoch 0][Step 11], time=0.06305456161499023, ext_time=0.03309130668640137, train_time=0.02174091339111328
[Epoch 0][Step 12], time=0.06264042854309082, ext_time=0.03364753723144531, train_time=0.022589921951293945
[Epoch 0][Step 13], time=0.0629572868347168, ext_time=0.033852338790893555, train_time=0.023283004760742188
[Epoch 0][Step 14], time=0.06299805641174316, ext_time=0.03306174278259277, train_time=0.024220943450927734
[Epoch 0][Step 15], time=0.06316494941711426, ext_time=0.0337827205657959, train_time=0.023408174514770508
[Epoch 0][Step 16], time=0.06224489212036133, ext_time=0.03343033790588379, train_time=0.02274632453918457
[Epoch 0][Step 17], time=0.06211280822753906, ext_time=0.032796382904052734, train_time=0.023401975631713867
[Epoch 0][Step 18], time=0.061156272888183594, ext_time=0.033448219299316406, train_time=0.021762371063232422
[Epoch 0][Step 19], time=0.06109356880187988, ext_time=0.03333592414855957, train_time=0.021821260452270508
[Epoch 0][Step 20], time=0.06212759017944336, ext_time=0.03366446495056152, train_time=0.02246546745300293
[Epoch 0][Step 21], time=0.06150507926940918, ext_time=0.03352618217468262, train_time=0.021992206573486328
[Epoch 0][Step 22], time=0.06120944023132324, ext_time=0.03325033187866211, train_time=0.022072553634643555
[Epoch 0][Step 23], time=0.061850786209106445, ext_time=0.033455610275268555, train_time=0.0224611759185791
[Epoch 0][Step 24], time=0.061594486236572266, ext_time=0.03339195251464844, train_time=0.022249460220336914
[Epoch 0][Step 25], time=0.060980796813964844, ext_time=0.033177852630615234, train_time=0.021879196166992188
[Epoch 0][Step 26], time=0.061562538146972656, ext_time=0.03367900848388672, train_time=0.021990299224853516
[Epoch 0][Step 27], time=0.06232190132141113, ext_time=0.03363966941833496, train_time=0.02275991439819336
[Epoch 0][Step 28], time=0.06146550178527832, ext_time=0.03358745574951172, train_time=0.021737337112426758
[Epoch 0][Step 29], time=0.06332635879516602, ext_time=0.03449845314025879, train_time=0.0228884220123291
[Epoch 0][Step 30], time=0.06166529655456543, ext_time=0.03307533264160156, train_time=0.022617578506469727
[Epoch 0][Step 31], time=0.061226844787597656, ext_time=0.033353567123413086, train_time=0.021888017654418945
[Epoch 0][Step 32], time=0.05977606773376465, ext_time=0.03258776664733887, train_time=0.02128005027770996
[Epoch 0][Step 33], time=0.06182146072387695, ext_time=0.033855438232421875, train_time=0.02219676971435547
[Epoch 0][Step 34], time=0.060457468032836914, ext_time=0.03343558311462402, train_time=0.021225452423095703
[Epoch 0][Step 35], time=0.061202287673950195, ext_time=0.033316612243652344, train_time=0.022170305252075195
[Epoch 0][Step 36], time=0.060979366302490234, ext_time=0.03314614295959473, train_time=0.022065401077270508
[Epoch 0][Step 37], time=0.06176638603210449, ext_time=0.0334169864654541, train_time=0.02256631851196289
[Epoch 0][Step 38], time=0.06070113182067871, ext_time=0.033155202865600586, train_time=0.021859169006347656
[Epoch 0][Step 39], time=0.062020063400268555, ext_time=0.03343987464904785, train_time=0.022800445556640625
[Epoch 0][Step 40], time=0.06367349624633789, ext_time=0.034085750579833984, train_time=0.023694515228271484
[Epoch 0][Step 41], time=0.06623673439025879, ext_time=0.03346657752990723, train_time=0.026991844177246094
[Epoch 0][Step 42], time=0.0612640380859375, ext_time=0.033426523208618164, train_time=0.02209949493408203
[Epoch 0][Step 43], time=0.06373095512390137, ext_time=0.03366374969482422, train_time=0.02419304847717285
[Epoch 0][Step 44], time=0.06206250190734863, ext_time=0.03343343734741211, train_time=0.022928237915039062
[Epoch 0][Step 45], time=0.061136484146118164, ext_time=0.033110618591308594, train_time=0.022270917892456055
[Epoch 0][Step 46], time=0.06142473220825195, ext_time=0.03356504440307617, train_time=0.022133350372314453
[Epoch 0][Step 47], time=0.06035780906677246, ext_time=0.03353571891784668, train_time=0.020995140075683594
[Epoch 0][Step 48], time=0.0615537166595459, ext_time=0.033596038818359375, train_time=0.022140979766845703
[Epoch 0][Step 49], time=0.06277990341186523, ext_time=0.03335380554199219, train_time=0.023600339889526367
[Epoch 0][Step 50], time=0.061420440673828125, ext_time=0.0335540771484375, train_time=0.022114038467407227
[Epoch 0][Step 51], time=0.06068158149719238, ext_time=0.03360748291015625, train_time=0.021353483200073242
[Epoch 0][Step 52], time=0.06150031089782715, ext_time=0.03304338455200195, train_time=0.022733688354492188
[Epoch 0][Step 53], time=0.06099724769592285, ext_time=0.03382468223571777, train_time=0.021411418914794922
[Epoch 0][Step 54], time=0.06064581871032715, ext_time=0.03365206718444824, train_time=0.021247386932373047
[Epoch 0][Step 55], time=0.0614476203918457, ext_time=0.03363466262817383, train_time=0.022096633911132812
[Epoch 0][Step 56], time=0.06093168258666992, ext_time=0.03353691101074219, train_time=0.02167534828186035
[Epoch 0][Step 57], time=0.061774253845214844, ext_time=0.033068180084228516, train_time=0.022990942001342773
[Epoch 0][Step 58], time=0.061435699462890625, ext_time=0.03400468826293945, train_time=0.02167201042175293
[Epoch 0][Step 59], time=0.06136059761047363, ext_time=0.03397846221923828, train_time=0.021655797958374023
[Epoch 0][Step 60], time=0.061506032943725586, ext_time=0.03344607353210449, train_time=0.022294282913208008
[Epoch 0][Step 61], time=0.0620880126953125, ext_time=0.03414154052734375, train_time=0.022149324417114258
[Epoch 0][Step 62], time=0.061138153076171875, ext_time=0.033490657806396484, train_time=0.021884918212890625
[Epoch 0][Step 63], time=0.06080317497253418, ext_time=0.0326535701751709, train_time=0.02244853973388672
[Epoch 0][Step 64], time=0.06143760681152344, ext_time=0.03407621383666992, train_time=0.021641969680786133
[Epoch 0][Step 65], time=0.0611729621887207, ext_time=0.033675193786621094, train_time=0.02178502082824707
[Epoch 0][Step 66], time=0.061118125915527344, ext_time=0.033061981201171875, train_time=0.022395610809326172
[Epoch 0][Step 67], time=0.061104536056518555, ext_time=0.03362679481506348, train_time=0.021778583526611328
[Epoch 0][Step 68], time=0.06191706657409668, ext_time=0.03384590148925781, train_time=0.02222728729248047
[Epoch 0][Step 69], time=0.06154608726501465, ext_time=0.03329277038574219, train_time=0.022534847259521484
[Epoch 0][Step 70], time=0.06062006950378418, ext_time=0.033852338790893555, train_time=0.021024703979492188
[Epoch 0][Step 71], time=0.06092357635498047, ext_time=0.03367924690246582, train_time=0.0215151309967041
[Epoch 0][Step 72], time=0.06227445602416992, ext_time=0.03437328338623047, train_time=0.0221102237701416
[Epoch 0][Step 73], time=0.06116294860839844, ext_time=0.03374028205871582, train_time=0.021654844284057617
[Epoch 0][Step 74], time=0.06152844429016113, ext_time=0.03359818458557129, train_time=0.022221088409423828
[Epoch 0][Step 75], time=0.06071639060974121, ext_time=0.03322744369506836, train_time=0.02177286148071289
[Epoch 0][Step 76], time=0.0609283447265625, ext_time=0.03334403038024902, train_time=0.021820545196533203
[Epoch 0][Step 77], time=0.06187033653259277, ext_time=0.03362441062927246, train_time=0.02250075340270996
[Epoch 0][Step 78], time=0.0608830451965332, ext_time=0.033365488052368164, train_time=0.02182459831237793
[Epoch 0][Step 79], time=0.06165337562561035, ext_time=0.03327012062072754, train_time=0.022698640823364258
[Epoch 0][Step 80], time=0.06259655952453613, ext_time=0.03379178047180176, train_time=0.023067712783813477
[Epoch 0][Step 81], time=0.06171584129333496, ext_time=0.033277034759521484, train_time=0.02274799346923828
[Epoch 0][Step 82], time=0.06232500076293945, ext_time=0.03347158432006836, train_time=0.02321004867553711
[Epoch 0][Step 83], time=0.06242036819458008, ext_time=0.03299450874328613, train_time=0.023684024810791016
[Epoch 0][Step 84], time=0.06272101402282715, ext_time=0.03318929672241211, train_time=0.02384471893310547
[Epoch 0][Step 85], time=0.06199145317077637, ext_time=0.03316807746887207, train_time=0.02309727668762207
[Epoch 0][Step 86], time=0.06200051307678223, ext_time=0.03362441062927246, train_time=0.022676944732666016
[Epoch 0][Step 87], time=0.061705589294433594, ext_time=0.03337740898132324, train_time=0.02261185646057129
[Epoch 0][Step 88], time=0.06333351135253906, ext_time=0.03395390510559082, train_time=0.02363109588623047
[Epoch 0][Step 89], time=0.06161904335021973, ext_time=0.03393077850341797, train_time=0.0219576358795166
[Epoch 0][Step 90], time=0.06285500526428223, ext_time=0.03302645683288574, train_time=0.02415752410888672
[Epoch 0][Step 91], time=0.06113243103027344, ext_time=0.03386497497558594, train_time=0.021301984786987305
[Epoch 0][Step 92], time=0.06066751480102539, ext_time=0.03381633758544922, train_time=0.02111983299255371
[Epoch 0][Step 93], time=0.06064176559448242, ext_time=0.033043861389160156, train_time=0.021851301193237305
[Epoch 0][Step 94], time=0.06099271774291992, ext_time=0.03291034698486328, train_time=0.02237558364868164
[Epoch 0][Step 95], time=0.060417890548706055, ext_time=0.03321552276611328, train_time=0.021476030349731445
[Epoch 0][Step 96], time=0.06235861778259277, ext_time=0.033048152923583984, train_time=0.023577451705932617
[Epoch 0][Step 97], time=0.06142759323120117, ext_time=0.03400683403015137, train_time=0.021635055541992188
[Epoch 0][Step 98], time=0.062357187271118164, ext_time=0.032242536544799805, train_time=0.024405717849731445
[Epoch 0][Step 99], time=0.06167268753051758, ext_time=0.033171892166137695, train_time=0.02278590202331543
[Epoch 0][Step 100], time=0.06125330924987793, ext_time=0.03340744972229004, train_time=0.021989822387695312
[Epoch 0][Step 101], time=0.0642099380493164, ext_time=0.032989501953125, train_time=0.025501489639282227
[Epoch 0][Step 102], time=0.061606407165527344, ext_time=0.033963680267333984, train_time=0.021513700485229492
[Epoch 0][Step 103], time=0.06113696098327637, ext_time=0.03306174278259277, train_time=0.0222928524017334
[Epoch 0][Step 104], time=0.061066389083862305, ext_time=0.0334622859954834, train_time=0.02156209945678711
[Epoch 0][Step 105], time=0.06146669387817383, ext_time=0.03285789489746094, train_time=0.02288055419921875
[Epoch 0][Step 106], time=0.06069660186767578, ext_time=0.033199310302734375, train_time=0.021793127059936523
[Epoch 0][Step 107], time=0.062196969985961914, ext_time=0.033126115798950195, train_time=0.02331995964050293
[Epoch 0][Step 108], time=0.06092381477355957, ext_time=0.033081769943237305, train_time=0.022040605545043945
[Epoch 0][Step 109], time=0.06083822250366211, ext_time=0.03332710266113281, train_time=0.021822452545166016
[Epoch 0][Step 110], time=0.061460256576538086, ext_time=0.032811641693115234, train_time=0.022960424423217773
[Epoch 0][Step 111], time=0.06112527847290039, ext_time=0.033901214599609375, train_time=0.021470069885253906
[Epoch 0][Step 112], time=0.06060004234313965, ext_time=0.03332805633544922, train_time=0.021547555923461914
[Epoch 0][Step 113], time=0.0615839958190918, ext_time=0.033429861068725586, train_time=0.022414684295654297
[Epoch 0][Step 114], time=0.06076312065124512, ext_time=0.03333544731140137, train_time=0.021725177764892578
[Epoch 0][Step 115], time=0.06150627136230469, ext_time=0.03340768814086914, train_time=0.022309303283691406
[Epoch 0][Step 116], time=0.06126236915588379, ext_time=0.03309917449951172, train_time=0.02241206169128418
[Epoch 0][Step 117], time=0.06303048133850098, ext_time=0.033737897872924805, train_time=0.023432254791259766
[Epoch 0][Step 118], time=0.06163144111633301, ext_time=0.034384965896606445, train_time=0.02148127555847168
[Epoch 0][Step 119], time=0.06084752082824707, ext_time=0.03316855430603027, train_time=0.022002696990966797
[Epoch 0][Step 120], time=0.06238412857055664, ext_time=0.03358745574951172, train_time=0.02308797836303711
[Epoch 0][Step 121], time=0.06119871139526367, ext_time=0.0330960750579834, train_time=0.022382259368896484
[Epoch 0][Step 122], time=0.06064772605895996, ext_time=0.03350090980529785, train_time=0.02142786979675293
[Epoch 0][Step 123], time=0.06096243858337402, ext_time=0.03353619575500488, train_time=0.021681785583496094
[Epoch 0][Step 124], time=0.06056571006774902, ext_time=0.03287100791931152, train_time=0.021964311599731445
[Epoch 0][Step 125], time=0.062212467193603516, ext_time=0.03361821174621582, train_time=0.022897720336914062
[Epoch 0][Step 126], time=0.06374192237854004, ext_time=0.03353309631347656, train_time=0.0244600772857666
[Epoch 0][Step 127], time=0.06377625465393066, ext_time=0.032867431640625, train_time=0.02515578269958496
[Epoch 0][Step 128], time=0.06102347373962402, ext_time=0.033747196197509766, train_time=0.02155160903930664
[Epoch 0][Step 129], time=0.06116795539855957, ext_time=0.03365159034729004, train_time=0.02173638343811035
[Epoch 0][Step 130], time=0.06107354164123535, ext_time=0.0334324836730957, train_time=0.021939516067504883
[Epoch 0][Step 131], time=0.06237292289733887, ext_time=0.03292655944824219, train_time=0.023665428161621094
[Epoch 0][Step 132], time=0.06160283088684082, ext_time=0.03325247764587402, train_time=0.022632837295532227
[Epoch 0][Step 133], time=0.06314444541931152, ext_time=0.034194231033325195, train_time=0.023125648498535156
[Epoch 0][Step 134], time=0.06025075912475586, ext_time=0.03335237503051758, train_time=0.021125078201293945
[Epoch 0][Step 135], time=0.0617375373840332, ext_time=0.034325361251831055, train_time=0.021622419357299805
[Epoch 0][Step 136], time=0.061109066009521484, ext_time=0.033570289611816406, train_time=0.02182769775390625
[Epoch 0][Step 137], time=0.061151742935180664, ext_time=0.03306317329406738, train_time=0.02239990234375
[Epoch 0][Step 138], time=0.060712337493896484, ext_time=0.032655954360961914, train_time=0.022387266159057617
[Epoch 0][Step 139], time=0.061116695404052734, ext_time=0.03387928009033203, train_time=0.021418094635009766
[Epoch 0][Step 140], time=0.061417341232299805, ext_time=0.03333163261413574, train_time=0.022370576858520508
[Epoch 0][Step 141], time=0.06131458282470703, ext_time=0.033807992935180664, train_time=0.02179574966430664
[Epoch 0][Step 142], time=0.061127424240112305, ext_time=0.032907962799072266, train_time=0.022541522979736328
[Epoch 0][Step 143], time=0.06080484390258789, ext_time=0.03302741050720215, train_time=0.02214646339416504
[Epoch 0][Step 144], time=0.06366395950317383, ext_time=0.03339505195617676, train_time=0.024425029754638672
[Epoch 0][Step 145], time=0.06243300437927246, ext_time=0.03324007987976074, train_time=0.023439884185791016
[Epoch 0][Step 146], time=0.06227684020996094, ext_time=0.03430891036987305, train_time=0.022063255310058594
[Epoch 0][Step 147], time=0.06247687339782715, ext_time=0.033670663833618164, train_time=0.02138376235961914
[Epoch 0][Step 148], time=0.061911821365356445, ext_time=0.033601999282836914, train_time=0.022552013397216797
[Epoch 0][Step 149], time=0.06183600425720215, ext_time=0.033289194107055664, train_time=0.022825241088867188
[Epoch 0][Step 150], time=0.06096696853637695, ext_time=0.03305554389953613, train_time=0.022194385528564453
[Epoch 0][Step 151], time=0.06155657768249512, ext_time=0.033481597900390625, train_time=0.022388696670532227
[Epoch 0][Step 152], time=0.061165809631347656, ext_time=0.033144235610961914, train_time=0.022304534912109375
[Epoch 0][Step 153], time=0.06145024299621582, ext_time=0.032889604568481445, train_time=0.022784948348999023
[Epoch 0][Step 154], time=0.06199789047241211, ext_time=0.03382682800292969, train_time=0.021840810775756836
[Epoch 0][Step 155], time=0.06177878379821777, ext_time=0.03398537635803223, train_time=0.022000551223754883
[Epoch 0][Step 156], time=0.060851335525512695, ext_time=0.033447265625, train_time=0.021752595901489258
[Epoch 0][Step 157], time=0.06146669387817383, ext_time=0.03369617462158203, train_time=0.022014617919921875
[Epoch 0][Step 158], time=0.061955928802490234, ext_time=0.03238034248352051, train_time=0.023898839950561523
[Epoch 0][Step 159], time=0.06092238426208496, ext_time=0.0336151123046875, train_time=0.02159404754638672
[Epoch 0][Step 160], time=0.06154274940490723, ext_time=0.03373527526855469, train_time=0.02210211753845215
[Epoch 0][Step 161], time=0.061707496643066406, ext_time=0.033797502517700195, train_time=0.022138595581054688
[Epoch 0][Step 162], time=0.06126093864440918, ext_time=0.033093929290771484, train_time=0.02246546745300293
[Epoch 0][Step 163], time=0.06131434440612793, ext_time=0.033835649490356445, train_time=0.021723508834838867
[Epoch 0][Step 164], time=0.06082773208618164, ext_time=0.03314018249511719, train_time=0.021971940994262695
[Epoch 0][Step 165], time=0.06090521812438965, ext_time=0.03351235389709473, train_time=0.021622657775878906
[Epoch 0][Step 166], time=0.061592817306518555, ext_time=0.0333254337310791, train_time=0.022597312927246094
[Epoch 0][Step 167], time=0.06099581718444824, ext_time=0.03312849998474121, train_time=0.022187471389770508
[Epoch 0][Step 168], time=0.06187772750854492, ext_time=0.033547163009643555, train_time=0.02266716957092285
[Epoch 0][Step 169], time=0.061553955078125, ext_time=0.0334010124206543, train_time=0.022426366806030273
[Epoch 0][Step 170], time=0.060883522033691406, ext_time=0.0332334041595459, train_time=0.021946191787719727
[Epoch 0][Step 171], time=0.060984134674072266, ext_time=0.032511234283447266, train_time=0.02279067039489746
[Epoch 0][Step 172], time=0.06071114540100098, ext_time=0.033234596252441406, train_time=0.021831035614013672
[Epoch 0][Step 173], time=0.06072878837585449, ext_time=0.0332341194152832, train_time=0.021817684173583984
[Epoch 0][Step 174], time=0.0616302490234375, ext_time=0.03391456604003906, train_time=0.021957874298095703
[Epoch 0][Step 175], time=0.06101107597351074, ext_time=0.03350520133972168, train_time=0.02179265022277832
[Epoch 0][Step 176], time=0.061109066009521484, ext_time=0.033186912536621094, train_time=0.022210121154785156
[Epoch 0][Step 177], time=0.06107282638549805, ext_time=0.03367447853088379, train_time=0.021657228469848633
[Epoch 0][Step 178], time=0.06120872497558594, ext_time=0.03279471397399902, train_time=0.022679567337036133
[Epoch 0][Step 179], time=0.06103181838989258, ext_time=0.0332798957824707, train_time=0.022073745727539062
[Epoch 0][Step 180], time=0.061368465423583984, ext_time=0.033064842224121094, train_time=0.022619247436523438
[Epoch 0][Step 181], time=0.06186389923095703, ext_time=0.03335905075073242, train_time=0.02276325225830078
[Epoch 0][Step 182], time=0.06128644943237305, ext_time=0.03391218185424805, train_time=0.021637439727783203
[Epoch 0][Step 183], time=0.06072521209716797, ext_time=0.033356666564941406, train_time=0.021593570709228516
[Epoch 0][Step 184], time=0.06264543533325195, ext_time=0.033152103424072266, train_time=0.02379894256591797
[Epoch 0][Step 185], time=0.06097698211669922, ext_time=0.033191680908203125, train_time=0.02204108238220215
[Epoch 0][Step 186], time=0.0608515739440918, ext_time=0.033666372299194336, train_time=0.021433115005493164
[Epoch 0][Step 187], time=0.06100296974182129, ext_time=0.033514976501464844, train_time=0.021726608276367188
[Epoch 0][Step 188], time=0.061158180236816406, ext_time=0.03280282020568848, train_time=0.02265453338623047
[Epoch 0][Step 189], time=0.06050300598144531, ext_time=0.03349900245666504, train_time=0.021312475204467773
[Epoch 0][Step 190], time=0.06078362464904785, ext_time=0.033696889877319336, train_time=0.02141547203063965
[Epoch 0][Step 191], time=0.0614018440246582, ext_time=0.03407716751098633, train_time=0.021544218063354492
[Epoch 0][Step 192], time=0.06160116195678711, ext_time=0.03369021415710449, train_time=0.022188901901245117
[Epoch 0][Step 193], time=0.06075119972229004, ext_time=0.03336477279663086, train_time=0.02162337303161621
[Epoch 0][Step 194], time=0.0609440803527832, ext_time=0.03346872329711914, train_time=0.0217587947845459
[Epoch 0][Step 195], time=0.06267333030700684, ext_time=0.03300309181213379, train_time=0.02404952049255371
[Epoch 0][Step 196], time=0.061095476150512695, ext_time=0.033312082290649414, train_time=0.02204728126525879
[Epoch 0][Step 197], time=0.060372114181518555, ext_time=0.03306078910827637, train_time=0.021596193313598633
[Epoch 0][Step 198], time=0.06179213523864746, ext_time=0.0342562198638916, train_time=0.021782636642456055
[Epoch 0][Step 199], time=0.0615544319152832, ext_time=0.03313636779785156, train_time=0.022670984268188477
[Epoch 0][Step 200], time=0.061696767807006836, ext_time=0.03400731086730957, train_time=0.021970748901367188
[Epoch 0][Step 201], time=0.061521053314208984, ext_time=0.0332646369934082, train_time=0.022504568099975586
[Epoch 0][Step 202], time=0.06104230880737305, ext_time=0.033074140548706055, train_time=0.02227950096130371
[Epoch 0][Step 203], time=0.06133532524108887, ext_time=0.03337240219116211, train_time=0.022238492965698242
[Epoch 0][Step 204], time=0.06069159507751465, ext_time=0.03350973129272461, train_time=0.021394968032836914
[Epoch 0][Step 205], time=0.061254262924194336, ext_time=0.03290867805480957, train_time=0.022658586502075195
[Epoch 0][Step 206], time=0.06172490119934082, ext_time=0.03274226188659668, train_time=0.023332834243774414
[Epoch 0][Step 207], time=0.06227445602416992, ext_time=0.03354525566101074, train_time=0.022991418838500977
[Epoch 0][Step 208], time=0.06116604804992676, ext_time=0.034009456634521484, train_time=0.021435260772705078
[Epoch 0][Step 209], time=0.06146645545959473, ext_time=0.033788442611694336, train_time=0.021874666213989258
[Epoch 0][Step 210], time=0.06107473373413086, ext_time=0.0337214469909668, train_time=0.021595001220703125
[Epoch 0][Step 211], time=0.06106686592102051, ext_time=0.03324079513549805, train_time=0.022125959396362305
[Epoch 0][Step 212], time=0.06098651885986328, ext_time=0.03303813934326172, train_time=0.02227783203125
[Epoch 0][Step 213], time=0.06179642677307129, ext_time=0.03384900093078613, train_time=0.022217273712158203
[Epoch 0][Step 214], time=0.06215333938598633, ext_time=0.033117055892944336, train_time=0.023336410522460938
[Epoch 0][Step 215], time=0.06168651580810547, ext_time=0.033721923828125, train_time=0.0221407413482666
[Epoch 0][Step 216], time=0.06168651580810547, ext_time=0.03312826156616211, train_time=0.0228426456451416
[Epoch 0][Step 217], time=0.061434030532836914, ext_time=0.03409838676452637, train_time=0.021532773971557617
[Epoch 0][Step 218], time=0.06085348129272461, ext_time=0.03350067138671875, train_time=0.021639347076416016
[Epoch 0][Step 219], time=0.06078767776489258, ext_time=0.03345918655395508, train_time=0.021614551544189453
[Epoch 0][Step 220], time=0.061118125915527344, ext_time=0.033596038818359375, train_time=0.021806716918945312
[Epoch 0][Step 221], time=0.061415910720825195, ext_time=0.03311276435852051, train_time=0.022647857666015625
[Epoch 0][Step 222], time=0.06233048439025879, ext_time=0.03341102600097656, train_time=0.02322101593017578
[Epoch 0][Step 223], time=0.060922861099243164, ext_time=0.03345847129821777, train_time=0.02171492576599121
[Epoch 0][Step 224], time=0.06306242942810059, ext_time=0.03397011756896973, train_time=0.022593975067138672
[Epoch 0][Step 225], time=0.06133580207824707, ext_time=0.03300809860229492, train_time=0.022418737411499023
[Epoch 0][Step 226], time=0.061003684997558594, ext_time=0.0331730842590332, train_time=0.022107362747192383
[Epoch 0][Step 227], time=0.061243534088134766, ext_time=0.033699750900268555, train_time=0.021734952926635742
[Epoch 0][Step 228], time=0.06120729446411133, ext_time=0.03290200233459473, train_time=0.022592782974243164
[Epoch 0][Step 229], time=0.06072497367858887, ext_time=0.0336451530456543, train_time=0.021373271942138672
[Epoch 0][Step 230], time=0.06260824203491211, ext_time=0.03252816200256348, train_time=0.024422407150268555
[Epoch 0][Step 231], time=0.06152653694152832, ext_time=0.03354787826538086, train_time=0.02221846580505371
[Epoch 0][Step 232], time=0.061240196228027344, ext_time=0.03347349166870117, train_time=0.02187943458557129
[Epoch 0][Step 233], time=0.060546875, ext_time=0.033670663833618164, train_time=0.021071672439575195
[Epoch 0][Step 234], time=0.061438560485839844, ext_time=0.0334782600402832, train_time=0.022181034088134766
[Epoch 0][Step 235], time=0.0608668327331543, ext_time=0.03314614295959473, train_time=0.022010326385498047
[Epoch 0][Step 236], time=0.06103515625, ext_time=0.033712148666381836, train_time=0.021598339080810547
[Epoch 0][Step 237], time=0.06124734878540039, ext_time=0.03408050537109375, train_time=0.021486520767211914
[Epoch 0][Step 238], time=0.0612330436706543, ext_time=0.03403902053833008, train_time=0.02146625518798828
[Epoch 0][Step 239], time=0.061284780502319336, ext_time=0.033308982849121094, train_time=0.02225661277770996
[Epoch 0][Step 240], time=0.06225705146789551, ext_time=0.033631086349487305, train_time=0.022890090942382812
[Epoch 0][Step 241], time=0.060933589935302734, ext_time=0.03348684310913086, train_time=0.021732091903686523
[Epoch 0][Step 242], time=0.06136322021484375, ext_time=0.03364276885986328, train_time=0.021924257278442383
[Epoch 0][Step 243], time=0.06075572967529297, ext_time=0.03327536582946777, train_time=0.02176809310913086
[Epoch 0][Step 244], time=0.06164383888244629, ext_time=0.03341937065124512, train_time=0.022474050521850586
[Epoch 0][Step 245], time=0.06101202964782715, ext_time=0.033149003982543945, train_time=0.022132396697998047
[Epoch 0][Step 246], time=0.061540842056274414, ext_time=0.03384804725646973, train_time=0.02185821533203125
[Epoch 0][Step 247], time=0.061005592346191406, ext_time=0.03368973731994629, train_time=0.0215909481048584
[Epoch 0][Step 248], time=0.061490774154663086, ext_time=0.033945560455322266, train_time=0.0217437744140625
[Epoch 0][Step 249], time=0.061936140060424805, ext_time=0.03307151794433594, train_time=0.02321004867553711
[Epoch 0], time=16.555619716644287, loss=0.6931472420692444
[Epoch 1][Step 0], time=0.0614163875579834, ext_time=0.03374838829040527, train_time=0.021926164627075195
[Epoch 1][Step 1], time=0.06122112274169922, ext_time=0.03324604034423828, train_time=0.02230548858642578
[Epoch 1][Step 2], time=0.060746192932128906, ext_time=0.03295445442199707, train_time=0.022087812423706055
[Epoch 1][Step 3], time=0.06119871139526367, ext_time=0.03367972373962402, train_time=0.021801233291625977
[Epoch 1][Step 4], time=0.06171989440917969, ext_time=0.03353285789489746, train_time=0.022486448287963867
[Epoch 1][Step 5], time=0.06197762489318848, ext_time=0.03310513496398926, train_time=0.023148775100708008
[Epoch 1][Step 6], time=0.06074023246765137, ext_time=0.03333544731140137, train_time=0.02167224884033203
[Epoch 1][Step 7], time=0.06174015998840332, ext_time=0.033098459243774414, train_time=0.0229494571685791
[Epoch 1][Step 8], time=0.06150937080383301, ext_time=0.033257484436035156, train_time=0.022530794143676758
[Epoch 1][Step 9], time=0.060810089111328125, ext_time=0.03290414810180664, train_time=0.02224278450012207
[Epoch 1][Step 10], time=0.0615847110748291, ext_time=0.03318047523498535, train_time=0.02269458770751953
[Epoch 1][Step 11], time=0.06179976463317871, ext_time=0.033365726470947266, train_time=0.02268671989440918
[Epoch 1][Step 12], time=0.06195998191833496, ext_time=0.03336596488952637, train_time=0.022877931594848633
[Epoch 1][Step 13], time=0.06039595603942871, ext_time=0.033103227615356445, train_time=0.021523237228393555
[Epoch 1][Step 14], time=0.06136488914489746, ext_time=0.03314781188964844, train_time=0.022499561309814453
[Epoch 1][Step 15], time=0.061075687408447266, ext_time=0.033934593200683594, train_time=0.02135181427001953
[Epoch 1][Step 16], time=0.06112861633300781, ext_time=0.033538818359375, train_time=0.021882295608520508
[Epoch 1][Step 17], time=0.06079387664794922, ext_time=0.03279471397399902, train_time=0.022307157516479492
[Epoch 1][Step 18], time=0.06062150001525879, ext_time=0.03351259231567383, train_time=0.02140212059020996
[Epoch 1][Step 19], time=0.06093573570251465, ext_time=0.03390192985534668, train_time=0.021262168884277344
[Epoch 1][Step 20], time=0.06090092658996582, ext_time=0.03361034393310547, train_time=0.02155613899230957
[Epoch 1][Step 21], time=0.06118416786193848, ext_time=0.03372907638549805, train_time=0.021637678146362305
[Epoch 1][Step 22], time=0.06111955642700195, ext_time=0.03356528282165527, train_time=0.02188873291015625
[Epoch 1][Step 23], time=0.06249427795410156, ext_time=0.03344535827636719, train_time=0.0233156681060791
[Epoch 1][Step 24], time=0.0612185001373291, ext_time=0.03376483917236328, train_time=0.021715641021728516
[Epoch 1][Step 25], time=0.06185555458068848, ext_time=0.03294634819030762, train_time=0.023199081420898438
[Epoch 1][Step 26], time=0.060984134674072266, ext_time=0.033704519271850586, train_time=0.02155280113220215
[Epoch 1][Step 27], time=0.06101727485656738, ext_time=0.033408403396606445, train_time=0.021912574768066406
[Epoch 1][Step 28], time=0.06118035316467285, ext_time=0.03390979766845703, train_time=0.021523237228393555
[Epoch 1][Step 29], time=0.061438560485839844, ext_time=0.0340726375579834, train_time=0.02154231071472168
[Epoch 1][Step 30], time=0.06033682823181152, ext_time=0.033638715744018555, train_time=0.020975828170776367
[Epoch 1][Step 31], time=0.061398983001708984, ext_time=0.033066749572753906, train_time=0.02267313003540039
[Epoch 1][Step 32], time=0.06118631362915039, ext_time=0.03289437294006348, train_time=0.022593259811401367
[Epoch 1][Step 33], time=0.061127662658691406, ext_time=0.033358097076416016, train_time=0.022101879119873047
[Epoch 1][Step 34], time=0.06067538261413574, ext_time=0.033457279205322266, train_time=0.02148723602294922
[Epoch 1][Step 35], time=0.061298370361328125, ext_time=0.03339409828186035, train_time=0.022197961807250977
[Epoch 1][Step 36], time=0.060698747634887695, ext_time=0.03316903114318848, train_time=0.021762371063232422
[Epoch 1][Step 37], time=0.0612947940826416, ext_time=0.03352928161621094, train_time=0.021942615509033203
[Epoch 1][Step 38], time=0.060240745544433594, ext_time=0.033479928970336914, train_time=0.02098560333251953
[Epoch 1][Step 39], time=0.061627864837646484, ext_time=0.03350067138671875, train_time=0.022393226623535156
[Epoch 1][Step 40], time=0.06082010269165039, ext_time=0.03328132629394531, train_time=0.021795272827148438
[Epoch 1][Step 41], time=0.061409950256347656, ext_time=0.03313112258911133, train_time=0.022638797760009766
[Epoch 1][Step 42], time=0.06045389175415039, ext_time=0.03293204307556152, train_time=0.021804332733154297
[Epoch 1][Step 43], time=0.11962318420410156, ext_time=0.033614158630371094, train_time=0.08030080795288086
[Epoch 1][Step 44], time=0.06183147430419922, ext_time=0.03341412544250488, train_time=0.022164106369018555
[Epoch 1][Step 45], time=0.0615236759185791, ext_time=0.03262138366699219, train_time=0.023231983184814453
[Epoch 1][Step 46], time=0.06328248977661133, ext_time=0.03378486633300781, train_time=0.023767948150634766
[Epoch 1][Step 47], time=0.06193423271179199, ext_time=0.03343319892883301, train_time=0.022736310958862305
[Epoch 1][Step 48], time=0.06061530113220215, ext_time=0.03328657150268555, train_time=0.021624326705932617
[Epoch 1][Step 49], time=0.06161761283874512, ext_time=0.03363370895385742, train_time=0.0222170352935791
[Epoch 1][Step 50], time=0.060983896255493164, ext_time=0.0335545539855957, train_time=0.021730661392211914
[Epoch 1][Step 51], time=0.06144356727600098, ext_time=0.03348350524902344, train_time=0.02225971221923828
[Epoch 1][Step 52], time=0.06424617767333984, ext_time=0.03273129463195801, train_time=0.025818824768066406
[Epoch 1][Step 53], time=0.061043500900268555, ext_time=0.03368830680847168, train_time=0.021556377410888672
[Epoch 1][Step 54], time=0.0609745979309082, ext_time=0.03357553482055664, train_time=0.02163076400756836
[Epoch 1][Step 55], time=0.06160569190979004, ext_time=0.03396463394165039, train_time=0.02188277244567871
[Epoch 1][Step 56], time=0.061495304107666016, ext_time=0.0339961051940918, train_time=0.02177572250366211
[Epoch 1][Step 57], time=0.06068992614746094, ext_time=0.03323221206665039, train_time=0.021736860275268555
[Epoch 1][Step 58], time=0.0622103214263916, ext_time=0.033782958984375, train_time=0.022709369659423828
[Epoch 1][Step 59], time=0.0618436336517334, ext_time=0.0341951847076416, train_time=0.021874666213989258
[Epoch 1][Step 60], time=0.06099343299865723, ext_time=0.03353714942932129, train_time=0.021693944931030273
[Epoch 1][Step 61], time=0.061004638671875, ext_time=0.0339052677154541, train_time=0.02140045166015625
[Epoch 1][Step 62], time=0.06134486198425293, ext_time=0.03327655792236328, train_time=0.02237248420715332
[Epoch 1][Step 63], time=0.060723066329956055, ext_time=0.03322482109069824, train_time=0.021703481674194336
[Epoch 1][Step 64], time=0.060752153396606445, ext_time=0.03348875045776367, train_time=0.021609783172607422
[Epoch 1][Step 65], time=0.061435699462890625, ext_time=0.03407573699951172, train_time=0.02160501480102539
[Epoch 1][Step 66], time=0.06134223937988281, ext_time=0.033503055572509766, train_time=0.022138357162475586
[Epoch 1][Step 67], time=0.06213092803955078, ext_time=0.0335080623626709, train_time=0.021486759185791016
[Epoch 1][Step 68], time=0.061270952224731445, ext_time=0.03386950492858887, train_time=0.02171921730041504
[Epoch 1][Step 69], time=0.0619809627532959, ext_time=0.03337836265563965, train_time=0.022863388061523438
[Epoch 1][Step 70], time=0.06149625778198242, ext_time=0.033951759338378906, train_time=0.021778106689453125
[Epoch 1][Step 71], time=0.06107902526855469, ext_time=0.033689260482788086, train_time=0.021687746047973633
[Epoch 1][Step 72], time=0.061757564544677734, ext_time=0.03413581848144531, train_time=0.021869421005249023
[Epoch 1][Step 73], time=0.061750173568725586, ext_time=0.0334930419921875, train_time=0.022547483444213867
[Epoch 1][Step 74], time=0.0607914924621582, ext_time=0.033580780029296875, train_time=0.0215146541595459
[Epoch 1][Step 75], time=0.06078290939331055, ext_time=0.033480167388916016, train_time=0.02152276039123535
[Epoch 1][Step 76], time=0.06004047393798828, ext_time=0.03262209892272949, train_time=0.02178478240966797
[Epoch 1][Step 77], time=0.06145811080932617, ext_time=0.03336524963378906, train_time=0.022411823272705078
[Epoch 1][Step 78], time=0.060691118240356445, ext_time=0.0333709716796875, train_time=0.02160787582397461
[Epoch 1][Step 79], time=0.06097579002380371, ext_time=0.03338170051574707, train_time=0.02187800407409668
[Epoch 1][Step 80], time=0.06043577194213867, ext_time=0.03356146812438965, train_time=0.021165847778320312
[Epoch 1][Step 81], time=0.06143307685852051, ext_time=0.033371925354003906, train_time=0.022364377975463867
[Epoch 1][Step 82], time=0.06178641319274902, ext_time=0.03412985801696777, train_time=0.02190232276916504
[Epoch 1][Step 83], time=0.06054234504699707, ext_time=0.03311300277709961, train_time=0.021631240844726562
[Epoch 1][Step 84], time=0.06132984161376953, ext_time=0.03307032585144043, train_time=0.0225217342376709
[Epoch 1][Step 85], time=0.06073713302612305, ext_time=0.033225297927856445, train_time=0.021735668182373047
[Epoch 1][Step 86], time=0.06198620796203613, ext_time=0.03292059898376465, train_time=0.023366928100585938
[Epoch 1][Step 87], time=0.060935258865356445, ext_time=0.032807111740112305, train_time=0.022410869598388672
[Epoch 1][Step 88], time=0.0616757869720459, ext_time=0.034052371978759766, train_time=0.021889686584472656
[Epoch 1][Step 89], time=0.06117677688598633, ext_time=0.032990217208862305, train_time=0.022506237030029297
[Epoch 1][Step 90], time=0.06121993064880371, ext_time=0.03332710266113281, train_time=0.022158384323120117
[Epoch 1][Step 91], time=0.060474395751953125, ext_time=0.03327536582946777, train_time=0.021312952041625977
[Epoch 1][Step 92], time=0.060622215270996094, ext_time=0.03396296501159668, train_time=0.02095937728881836
[Epoch 1][Step 93], time=0.06059622764587402, ext_time=0.03341507911682129, train_time=0.021427392959594727
[Epoch 1][Step 94], time=0.06086564064025879, ext_time=0.03338003158569336, train_time=0.02176642417907715
[Epoch 1][Step 95], time=0.06016945838928223, ext_time=0.03346705436706543, train_time=0.021041393280029297
[Epoch 1][Step 96], time=0.060828447341918945, ext_time=0.03335714340209961, train_time=0.021770477294921875
[Epoch 1][Step 97], time=0.06199455261230469, ext_time=0.033252716064453125, train_time=0.023036479949951172
[Epoch 1][Step 98], time=0.06128644943237305, ext_time=0.03291678428649902, train_time=0.022605419158935547
[Epoch 1][Step 99], time=0.06070208549499512, ext_time=0.033125877380371094, train_time=0.021887540817260742
[Epoch 1][Step 100], time=0.06048107147216797, ext_time=0.03334999084472656, train_time=0.021414995193481445
[Epoch 1][Step 101], time=0.06191229820251465, ext_time=0.03357863426208496, train_time=0.022631168365478516
[Epoch 1][Step 102], time=0.061125755310058594, ext_time=0.03346443176269531, train_time=0.021999359130859375
[Epoch 1][Step 103], time=0.0618128776550293, ext_time=0.0337071418762207, train_time=0.02223515510559082
[Epoch 1][Step 104], time=0.06078362464904785, ext_time=0.03370404243469238, train_time=0.0212554931640625
[Epoch 1][Step 105], time=0.0611872673034668, ext_time=0.03291440010070801, train_time=0.022563695907592773
[Epoch 1][Step 106], time=0.061425209045410156, ext_time=0.03321981430053711, train_time=0.02241373062133789
[Epoch 1][Step 107], time=0.06143784523010254, ext_time=0.03310275077819824, train_time=0.02256178855895996
[Epoch 1][Step 108], time=0.06099081039428711, ext_time=0.03284597396850586, train_time=0.02240729331970215
[Epoch 1][Step 109], time=0.060666799545288086, ext_time=0.03339219093322754, train_time=0.021526575088500977
[Epoch 1][Step 110], time=0.05993914604187012, ext_time=0.03321409225463867, train_time=0.021011829376220703
[Epoch 1][Step 111], time=0.06315374374389648, ext_time=0.03360271453857422, train_time=0.023833274841308594
[Epoch 1][Step 112], time=0.06122016906738281, ext_time=0.03318953514099121, train_time=0.022298336029052734
[Epoch 1][Step 113], time=0.061112403869628906, ext_time=0.033592939376831055, train_time=0.021823406219482422
[Epoch 1][Step 114], time=0.06178617477416992, ext_time=0.033854007720947266, train_time=0.021951675415039062
[Epoch 1][Step 115], time=0.06141996383666992, ext_time=0.034105539321899414, train_time=0.021448612213134766
[Epoch 1][Step 116], time=0.0610809326171875, ext_time=0.0329890251159668, train_time=0.022334814071655273
[Epoch 1][Step 117], time=0.060813188552856445, ext_time=0.033233642578125, train_time=0.021828174591064453
[Epoch 1][Step 118], time=0.06116771697998047, ext_time=0.034314632415771484, train_time=0.021110057830810547
[Epoch 1][Step 119], time=0.060888051986694336, ext_time=0.03338766098022461, train_time=0.0217897891998291
[Epoch 1][Step 120], time=0.06151604652404785, ext_time=0.03388643264770508, train_time=0.02188706398010254
[Epoch 1][Step 121], time=0.0607452392578125, ext_time=0.03368067741394043, train_time=0.021335601806640625
[Epoch 1][Step 122], time=0.060567617416381836, ext_time=0.03381848335266113, train_time=0.021001815795898438
[Epoch 1][Step 123], time=0.06045174598693848, ext_time=0.03361868858337402, train_time=0.021169185638427734
[Epoch 1][Step 124], time=0.06037735939025879, ext_time=0.03293299674987793, train_time=0.021756649017333984
[Epoch 1][Step 125], time=0.06110858917236328, ext_time=0.033867597579956055, train_time=0.021526813507080078
[Epoch 1][Step 126], time=0.06210637092590332, ext_time=0.033254384994506836, train_time=0.02315235137939453
[Epoch 1][Step 127], time=0.0618588924407959, ext_time=0.03300881385803223, train_time=0.023126840591430664
[Epoch 1][Step 128], time=0.06072378158569336, ext_time=0.03358054161071777, train_time=0.02148151397705078
[Epoch 1][Step 129], time=0.0611417293548584, ext_time=0.0334475040435791, train_time=0.02201104164123535
[Epoch 1][Step 130], time=0.060834646224975586, ext_time=0.03360557556152344, train_time=0.021478652954101562
[Epoch 1][Step 131], time=0.06070423126220703, ext_time=0.03281354904174805, train_time=0.022167682647705078
[Epoch 1][Step 132], time=0.06070590019226074, ext_time=0.03365468978881836, train_time=0.021329164505004883
[Epoch 1][Step 133], time=0.06084322929382324, ext_time=0.03370165824890137, train_time=0.021351337432861328
[Epoch 1][Step 134], time=0.06045818328857422, ext_time=0.033571720123291016, train_time=0.021134138107299805
[Epoch 1][Step 135], time=0.06089353561401367, ext_time=0.033682823181152344, train_time=0.021465063095092773
[Epoch 1][Step 136], time=0.061501264572143555, ext_time=0.033776044845581055, train_time=0.02193284034729004
[Epoch 1][Step 137], time=0.06072115898132324, ext_time=0.03349661827087402, train_time=0.021538496017456055
[Epoch 1][Step 138], time=0.06086993217468262, ext_time=0.032785654067993164, train_time=0.022352218627929688
[Epoch 1][Step 139], time=0.06105923652648926, ext_time=0.034128665924072266, train_time=0.021164894104003906
[Epoch 1][Step 140], time=0.06088376045227051, ext_time=0.03343677520751953, train_time=0.02173900604248047
[Epoch 1][Step 141], time=0.06051754951477051, ext_time=0.03332400321960449, train_time=0.021564006805419922
[Epoch 1][Step 142], time=0.06020712852478027, ext_time=0.03309345245361328, train_time=0.021381139755249023
[Epoch 1][Step 143], time=0.060769081115722656, ext_time=0.03368425369262695, train_time=0.02130270004272461
[Epoch 1][Step 144], time=0.06049847602844238, ext_time=0.033204078674316406, train_time=0.02158522605895996
[Epoch 1][Step 145], time=0.06144261360168457, ext_time=0.033417463302612305, train_time=0.022300004959106445
[Epoch 1][Step 146], time=0.06071281433105469, ext_time=0.03355765342712402, train_time=0.021421432495117188
[Epoch 1][Step 147], time=0.060629844665527344, ext_time=0.03380227088928223, train_time=0.021109580993652344
[Epoch 1][Step 148], time=0.06102466583251953, ext_time=0.03348207473754883, train_time=0.02182912826538086
[Epoch 1][Step 149], time=0.06115603446960449, ext_time=0.03337502479553223, train_time=0.022153854370117188
[Epoch 1][Step 150], time=0.06039094924926758, ext_time=0.033129215240478516, train_time=0.02154088020324707
[Epoch 1][Step 151], time=0.06077718734741211, ext_time=0.033838510513305664, train_time=0.021213531494140625
[Epoch 1][Step 152], time=0.062131404876708984, ext_time=0.03341960906982422, train_time=0.022916793823242188
[Epoch 1][Step 153], time=0.061255693435668945, ext_time=0.03313946723937988, train_time=0.02223801612854004
[Epoch 1][Step 154], time=0.060756683349609375, ext_time=0.03365206718444824, train_time=0.021418333053588867
[Epoch 1][Step 155], time=0.061678171157836914, ext_time=0.03355836868286133, train_time=0.022401809692382812
[Epoch 1][Step 156], time=0.061394453048706055, ext_time=0.033822059631347656, train_time=0.021897077560424805
[Epoch 1][Step 157], time=0.06163978576660156, ext_time=0.03343462944030762, train_time=0.022515058517456055
[Epoch 1][Step 158], time=0.06043362617492676, ext_time=0.03325653076171875, train_time=0.021410703659057617
[Epoch 1][Step 159], time=0.06097841262817383, ext_time=0.033725738525390625, train_time=0.02154254913330078
[Epoch 1][Step 160], time=0.06115245819091797, ext_time=0.03363609313964844, train_time=0.021797657012939453
[Epoch 1][Step 161], time=0.06105184555053711, ext_time=0.03405904769897461, train_time=0.021170377731323242
[Epoch 1][Step 162], time=0.06074166297912598, ext_time=0.033507585525512695, train_time=0.021529436111450195
[Epoch 1][Step 163], time=0.06148815155029297, ext_time=0.03388857841491699, train_time=0.021841049194335938
[Epoch 1][Step 164], time=0.060573577880859375, ext_time=0.033072710037231445, train_time=0.0217742919921875
[Epoch 1][Step 165], time=0.06123232841491699, ext_time=0.033678531646728516, train_time=0.021770715713500977
[Epoch 1][Step 166], time=0.06023097038269043, ext_time=0.03311514854431152, train_time=0.021425962448120117
[Epoch 1][Step 167], time=0.061187028884887695, ext_time=0.033627986907958984, train_time=0.02181410789489746
[Epoch 1][Step 168], time=0.06090545654296875, ext_time=0.03401350975036621, train_time=0.021224021911621094
[Epoch 1][Step 169], time=0.06124758720397949, ext_time=0.033782958984375, train_time=0.021624088287353516
[Epoch 1][Step 170], time=0.060384273529052734, ext_time=0.0327610969543457, train_time=0.021909236907958984
[Epoch 1][Step 171], time=0.061531782150268555, ext_time=0.032265424728393555, train_time=0.023585081100463867
[Epoch 1][Step 172], time=0.060761213302612305, ext_time=0.033484458923339844, train_time=0.021541833877563477
[Epoch 1][Step 173], time=0.06024670600891113, ext_time=0.03348493576049805, train_time=0.021037817001342773
[Epoch 1][Step 174], time=0.0605626106262207, ext_time=0.0335385799407959, train_time=0.021322011947631836
[Epoch 1][Step 175], time=0.061124324798583984, ext_time=0.03358054161071777, train_time=0.021831274032592773
[Epoch 1][Step 176], time=0.06231093406677246, ext_time=0.03436636924743652, train_time=0.022149085998535156
[Epoch 1][Step 177], time=0.06159567832946777, ext_time=0.03405904769897461, train_time=0.021578073501586914
[Epoch 1][Step 178], time=0.061742305755615234, ext_time=0.03233814239501953, train_time=0.023727893829345703
[Epoch 1][Step 179], time=0.0613713264465332, ext_time=0.03408932685852051, train_time=0.021485328674316406
[Epoch 1][Step 180], time=0.06250810623168945, ext_time=0.03345751762390137, train_time=0.023344993591308594
[Epoch 1][Step 181], time=0.0610346794128418, ext_time=0.033728837966918945, train_time=0.021497488021850586
[Epoch 1][Step 182], time=0.06127500534057617, ext_time=0.03393983840942383, train_time=0.021619081497192383
[Epoch 1][Step 183], time=0.06105637550354004, ext_time=0.03345465660095215, train_time=0.021885395050048828
[Epoch 1][Step 184], time=0.060431480407714844, ext_time=0.03328704833984375, train_time=0.02150416374206543
[Epoch 1][Step 185], time=0.06067991256713867, ext_time=0.033394575119018555, train_time=0.021527767181396484
[Epoch 1][Step 186], time=0.060930728912353516, ext_time=0.0336916446685791, train_time=0.021525859832763672
[Epoch 1][Step 187], time=0.06070113182067871, ext_time=0.03320002555847168, train_time=0.021788597106933594
[Epoch 1][Step 188], time=0.06081390380859375, ext_time=0.0331573486328125, train_time=0.021850109100341797
[Epoch 1][Step 189], time=0.06069636344909668, ext_time=0.033693552017211914, train_time=0.021300315856933594
[Epoch 1][Step 190], time=0.062302589416503906, ext_time=0.03436565399169922, train_time=0.022176027297973633
[Epoch 1][Step 191], time=0.061507225036621094, ext_time=0.03403902053833008, train_time=0.021601200103759766
[Epoch 1][Step 192], time=0.06117844581604004, ext_time=0.03329610824584961, train_time=0.022178173065185547
[Epoch 1][Step 193], time=0.06128835678100586, ext_time=0.03382253646850586, train_time=0.021734952926635742
[Epoch 1][Step 194], time=0.06067252159118652, ext_time=0.033107757568359375, train_time=0.02193164825439453
[Epoch 1][Step 195], time=0.061191558837890625, ext_time=0.033246755599975586, train_time=0.022233247756958008
[Epoch 1][Step 196], time=0.0609588623046875, ext_time=0.03347444534301758, train_time=0.021733760833740234
[Epoch 1][Step 197], time=0.06056070327758789, ext_time=0.03314566612243652, train_time=0.021636247634887695
[Epoch 1][Step 198], time=0.06117606163024902, ext_time=0.033701419830322266, train_time=0.02173614501953125
[Epoch 1][Step 199], time=0.06100606918334961, ext_time=0.03339266777038574, train_time=0.02186727523803711
[Epoch 1][Step 200], time=0.060759782791137695, ext_time=0.03349876403808594, train_time=0.021584749221801758
[Epoch 1][Step 201], time=0.060606956481933594, ext_time=0.0330655574798584, train_time=0.021829843521118164
[Epoch 1][Step 202], time=0.061750173568725586, ext_time=0.03396320343017578, train_time=0.021960735321044922
[Epoch 1][Step 203], time=0.061325788497924805, ext_time=0.03343629837036133, train_time=0.022185564041137695
[Epoch 1][Step 204], time=0.06121253967285156, ext_time=0.03375363349914551, train_time=0.02169179916381836
[Epoch 1][Step 205], time=0.06163167953491211, ext_time=0.03328227996826172, train_time=0.02264404296875
[Epoch 1][Step 206], time=0.060881853103637695, ext_time=0.03331160545349121, train_time=0.02183389663696289
[Epoch 1][Step 207], time=0.06103253364562988, ext_time=0.03383445739746094, train_time=0.021409988403320312
[Epoch 1][Step 208], time=0.061614274978637695, ext_time=0.03417229652404785, train_time=0.021663904190063477
[Epoch 1][Step 209], time=0.06137681007385254, ext_time=0.03355669975280762, train_time=0.022058725357055664
[Epoch 1][Step 210], time=0.06091499328613281, ext_time=0.03326916694641113, train_time=0.021939516067504883
[Epoch 1][Step 211], time=0.06093263626098633, ext_time=0.03298211097717285, train_time=0.022267818450927734
[Epoch 1][Step 212], time=0.061025381088256836, ext_time=0.03327512741088867, train_time=0.022025585174560547
[Epoch 1][Step 213], time=0.06055498123168945, ext_time=0.03349041938781738, train_time=0.021398544311523438
[Epoch 1][Step 214], time=0.060626983642578125, ext_time=0.033223628997802734, train_time=0.02167963981628418
[Epoch 1][Step 215], time=0.061756134033203125, ext_time=0.034152984619140625, train_time=0.021842241287231445
[Epoch 1][Step 216], time=0.06156349182128906, ext_time=0.03301405906677246, train_time=0.022815465927124023
[Epoch 1][Step 217], time=0.0608365535736084, ext_time=0.0336458683013916, train_time=0.021510601043701172
[Epoch 1][Step 218], time=0.06094837188720703, ext_time=0.033461570739746094, train_time=0.021767377853393555
[Epoch 1][Step 219], time=0.061460256576538086, ext_time=0.033033132553100586, train_time=0.02271127700805664
[Epoch 1][Step 220], time=0.061675310134887695, ext_time=0.033467769622802734, train_time=0.022501707077026367
[Epoch 1][Step 221], time=0.060392141342163086, ext_time=0.033359527587890625, train_time=0.021352291107177734
[Epoch 1][Step 222], time=0.06087231636047363, ext_time=0.03330183029174805, train_time=0.021885395050048828
[Epoch 1][Step 223], time=0.06196117401123047, ext_time=0.0342564582824707, train_time=0.021932125091552734
[Epoch 1][Step 224], time=0.06087374687194824, ext_time=0.03301358222961426, train_time=0.02210235595703125
[Epoch 1][Step 225], time=0.06080174446105957, ext_time=0.03309369087219238, train_time=0.021976947784423828
[Epoch 1][Step 226], time=0.06074190139770508, ext_time=0.03297066688537598, train_time=0.022095203399658203
[Epoch 1][Step 227], time=0.0613248348236084, ext_time=0.03350067138671875, train_time=0.0221405029296875
[Epoch 1][Step 228], time=0.062233924865722656, ext_time=0.03322625160217285, train_time=0.023303747177124023
[Epoch 1][Step 229], time=0.060797929763793945, ext_time=0.03348946571350098, train_time=0.021641969680786133
[Epoch 1][Step 230], time=0.061150550842285156, ext_time=0.0333101749420166, train_time=0.022062063217163086
[Epoch 1][Step 231], time=0.06142592430114746, ext_time=0.03376007080078125, train_time=0.02191615104675293
[Epoch 1][Step 232], time=0.06143593788146973, ext_time=0.03371691703796387, train_time=0.02191019058227539
[Epoch 1][Step 233], time=0.061248779296875, ext_time=0.03340482711791992, train_time=0.022075653076171875
[Epoch 1][Step 234], time=0.060773372650146484, ext_time=0.03325343132019043, train_time=0.02175450325012207
[Epoch 1][Step 235], time=0.06114530563354492, ext_time=0.033237457275390625, train_time=0.022129297256469727
[Epoch 1][Step 236], time=0.06093716621398926, ext_time=0.03347897529602051, train_time=0.021743059158325195
[Epoch 1][Step 237], time=0.06252169609069824, ext_time=0.03419828414916992, train_time=0.021137237548828125
[Epoch 1][Step 238], time=0.06147313117980957, ext_time=0.03406167030334473, train_time=0.021698474884033203
[Epoch 1][Step 239], time=0.061524152755737305, ext_time=0.03325033187866211, train_time=0.022475242614746094
[Epoch 1][Step 240], time=0.06136298179626465, ext_time=0.03396201133728027, train_time=0.02164936065673828
[Epoch 1][Step 241], time=0.06100177764892578, ext_time=0.03310370445251465, train_time=0.02220940589904785
[Epoch 1][Step 242], time=0.061353445053100586, ext_time=0.03358149528503418, train_time=0.022006988525390625
[Epoch 1][Step 243], time=0.06078958511352539, ext_time=0.03370523452758789, train_time=0.021292686462402344
[Epoch 1][Step 244], time=0.06196928024291992, ext_time=0.03339505195617676, train_time=0.022843122482299805
[Epoch 1][Step 245], time=0.061740875244140625, ext_time=0.03289341926574707, train_time=0.02314615249633789
[Epoch 1][Step 246], time=0.06139421463012695, ext_time=0.033438682556152344, train_time=0.022230863571166992
[Epoch 1][Step 247], time=0.060628652572631836, ext_time=0.03347039222717285, train_time=0.021281003952026367
[Epoch 1][Step 248], time=0.06041359901428223, ext_time=0.033620595932006836, train_time=0.021131038665771484
[Epoch 1][Step 249], time=0.061136722564697266, ext_time=0.03310871124267578, train_time=0.022325754165649414
[Epoch 1], time=15.366747617721558, loss=0.6931472420692444
[Epoch 2][Step 0], time=0.06112051010131836, ext_time=0.033478736877441406, train_time=0.021923065185546875
[Epoch 2][Step 1], time=0.060915231704711914, ext_time=0.033254384994506836, train_time=0.021924972534179688
[Epoch 2][Step 2], time=0.060605764389038086, ext_time=0.03305983543395996, train_time=0.021849870681762695
[Epoch 2][Step 3], time=0.060303449630737305, ext_time=0.03339099884033203, train_time=0.021195650100708008
[Epoch 2][Step 4], time=0.06122398376464844, ext_time=0.03356003761291504, train_time=0.021943092346191406
[Epoch 2][Step 5], time=0.061179399490356445, ext_time=0.03354978561401367, train_time=0.021859407424926758
[Epoch 2][Step 6], time=0.061511993408203125, ext_time=0.03344154357910156, train_time=0.02237868309020996
[Epoch 2][Step 7], time=0.06114649772644043, ext_time=0.0328974723815918, train_time=0.022573471069335938
[Epoch 2][Step 8], time=0.06064414978027344, ext_time=0.03311038017272949, train_time=0.0218505859375
[Epoch 2][Step 9], time=0.060625314712524414, ext_time=0.03322315216064453, train_time=0.021743297576904297
[Epoch 2][Step 10], time=0.06107783317565918, ext_time=0.03357410430908203, train_time=0.021790504455566406
[Epoch 2][Step 11], time=0.06108999252319336, ext_time=0.03290843963623047, train_time=0.022504568099975586
[Epoch 2][Step 12], time=0.06070351600646973, ext_time=0.03340435028076172, train_time=0.021584510803222656
[Epoch 2][Step 13], time=0.0610353946685791, ext_time=0.03348422050476074, train_time=0.021816492080688477
[Epoch 2][Step 14], time=0.060625314712524414, ext_time=0.03294658660888672, train_time=0.02196478843688965
[Epoch 2][Step 15], time=0.06089591979980469, ext_time=0.033518075942993164, train_time=0.02162456512451172
[Epoch 2][Step 16], time=0.06173539161682129, ext_time=0.034110307693481445, train_time=0.02184462547302246
[Epoch 2][Step 17], time=0.060894012451171875, ext_time=0.03308820724487305, train_time=0.02213120460510254
[Epoch 2][Step 18], time=0.06110858917236328, ext_time=0.03384971618652344, train_time=0.021564722061157227
[Epoch 2][Step 19], time=0.061872005462646484, ext_time=0.033390045166015625, train_time=0.022812604904174805
[Epoch 2][Step 20], time=0.06366229057312012, ext_time=0.03356742858886719, train_time=0.02414226531982422
[Epoch 2][Step 21], time=0.06085610389709473, ext_time=0.03334212303161621, train_time=0.0217282772064209
[Epoch 2][Step 22], time=0.06105804443359375, ext_time=0.03359675407409668, train_time=0.02169966697692871
[Epoch 2][Step 23], time=0.06063270568847656, ext_time=0.032855987548828125, train_time=0.022066831588745117
[Epoch 2][Step 24], time=0.06074118614196777, ext_time=0.03323483467102051, train_time=0.021804094314575195
[Epoch 2][Step 25], time=0.06102418899536133, ext_time=0.0331721305847168, train_time=0.022232770919799805
[Epoch 2][Step 26], time=0.060564279556274414, ext_time=0.033292531967163086, train_time=0.02161574363708496
[Epoch 2][Step 27], time=0.06122565269470215, ext_time=0.033571720123291016, train_time=0.021867990493774414
[Epoch 2][Step 28], time=0.06122612953186035, ext_time=0.03338217735290527, train_time=0.022034168243408203
[Epoch 2][Step 29], time=0.06159543991088867, ext_time=0.034180402755737305, train_time=0.021687746047973633
[Epoch 2][Step 30], time=0.06121253967285156, ext_time=0.03318023681640625, train_time=0.022340774536132812
[Epoch 2][Step 31], time=0.061011552810668945, ext_time=0.03359484672546387, train_time=0.021694183349609375
[Epoch 2][Step 32], time=0.06115269660949707, ext_time=0.03298807144165039, train_time=0.022423744201660156
[Epoch 2][Step 33], time=0.061008453369140625, ext_time=0.033551931381225586, train_time=0.021701335906982422
[Epoch 2][Step 34], time=0.06147503852844238, ext_time=0.03294801712036133, train_time=0.02280426025390625
[Epoch 2][Step 35], time=0.061769962310791016, ext_time=0.03347659111022949, train_time=0.022589445114135742
[Epoch 2][Step 36], time=0.06072831153869629, ext_time=0.032855987548828125, train_time=0.02212357521057129
[Epoch 2][Step 37], time=0.061386823654174805, ext_time=0.03342127799987793, train_time=0.022230863571166992
[Epoch 2][Step 38], time=0.06243252754211426, ext_time=0.0330204963684082, train_time=0.023705005645751953
[Epoch 2][Step 39], time=0.06148266792297363, ext_time=0.03318190574645996, train_time=0.022563695907592773
[Epoch 2][Step 40], time=0.06098675727844238, ext_time=0.03345441818237305, train_time=0.021799564361572266
[Epoch 2][Step 41], time=0.06134343147277832, ext_time=0.033325910568237305, train_time=0.02221536636352539
[Epoch 2][Step 42], time=0.06091618537902832, ext_time=0.03307509422302246, train_time=0.02217864990234375
[Epoch 2][Step 43], time=0.06179070472717285, ext_time=0.03427743911743164, train_time=0.021786212921142578
[Epoch 2][Step 44], time=0.06090545654296875, ext_time=0.03360891342163086, train_time=0.021505355834960938
[Epoch 2][Step 45], time=0.06105351448059082, ext_time=0.03310656547546387, train_time=0.022168636322021484
[Epoch 2][Step 46], time=0.06127595901489258, ext_time=0.03396010398864746, train_time=0.02157759666442871
[Epoch 2][Step 47], time=0.06083869934082031, ext_time=0.03350996971130371, train_time=0.021587133407592773
[Epoch 2][Step 48], time=0.06066274642944336, ext_time=0.03342151641845703, train_time=0.021559476852416992
[Epoch 2][Step 49], time=0.060669660568237305, ext_time=0.033212900161743164, train_time=0.021777868270874023
[Epoch 2][Step 50], time=0.06165122985839844, ext_time=0.033219337463378906, train_time=0.022748947143554688
[Epoch 2][Step 51], time=0.06140327453613281, ext_time=0.033559560775756836, train_time=0.02214980125427246
[Epoch 2][Step 52], time=0.061151742935180664, ext_time=0.03274345397949219, train_time=0.022609710693359375
[Epoch 2][Step 53], time=0.06188249588012695, ext_time=0.03397631645202637, train_time=0.022134780883789062
[Epoch 2][Step 54], time=0.06136751174926758, ext_time=0.03377389907836914, train_time=0.02181696891784668
[Epoch 2][Step 55], time=0.06122398376464844, ext_time=0.03371548652648926, train_time=0.021750926971435547
[Epoch 2][Step 56], time=0.0604863166809082, ext_time=0.03332781791687012, train_time=0.021519184112548828
[Epoch 2][Step 57], time=0.060570478439331055, ext_time=0.03315234184265137, train_time=0.021634578704833984
[Epoch 2][Step 58], time=0.06132364273071289, ext_time=0.03370976448059082, train_time=0.021837234497070312
[Epoch 2][Step 59], time=0.061872005462646484, ext_time=0.03364443778991699, train_time=0.022490501403808594
[Epoch 2][Step 60], time=0.06091594696044922, ext_time=0.03307986259460449, train_time=0.020681381225585938
[Epoch 2][Step 61], time=0.061699628829956055, ext_time=0.0339200496673584, train_time=0.022051572799682617
[Epoch 2][Step 62], time=0.06083416938781738, ext_time=0.03321194648742676, train_time=0.02196025848388672
[Epoch 2][Step 63], time=0.06008577346801758, ext_time=0.032639503479003906, train_time=0.021758079528808594
[Epoch 2][Step 64], time=0.060830116271972656, ext_time=0.03348994255065918, train_time=0.02164459228515625
[Epoch 2][Step 65], time=0.06145191192626953, ext_time=0.03390979766845703, train_time=0.021805763244628906
[Epoch 2][Step 66], time=0.06134629249572754, ext_time=0.033107757568359375, train_time=0.022533893585205078
[Epoch 2][Step 67], time=0.06175494194030762, ext_time=0.033567190170288086, train_time=0.02256178855895996
[Epoch 2][Step 68], time=0.06229567527770996, ext_time=0.0349421501159668, train_time=0.02132248878479004
[Epoch 2][Step 69], time=0.06128430366516113, ext_time=0.03317832946777344, train_time=0.022374391555786133
[Epoch 2][Step 70], time=0.06128692626953125, ext_time=0.03366565704345703, train_time=0.02190113067626953
[Epoch 2][Step 71], time=0.06127524375915527, ext_time=0.0337681770324707, train_time=0.0217440128326416
[Epoch 2][Step 72], time=0.06134200096130371, ext_time=0.0335690975189209, train_time=0.02203083038330078
[Epoch 2][Step 73], time=0.060929298400878906, ext_time=0.03391289710998535, train_time=0.021295785903930664
[Epoch 2][Step 74], time=0.06104850769042969, ext_time=0.03327345848083496, train_time=0.022116422653198242
[Epoch 2][Step 75], time=0.06152796745300293, ext_time=0.03344583511352539, train_time=0.022219419479370117
[Epoch 2][Step 76], time=0.05997347831726074, ext_time=0.03310132026672363, train_time=0.021048784255981445
[Epoch 2][Step 77], time=0.0617520809173584, ext_time=0.03335833549499512, train_time=0.0227203369140625
[Epoch 2][Step 78], time=0.0608975887298584, ext_time=0.03315401077270508, train_time=0.022022008895874023
[Epoch 2][Step 79], time=0.06120133399963379, ext_time=0.03308224678039551, train_time=0.022448062896728516
[Epoch 2][Step 80], time=0.061130523681640625, ext_time=0.033806562423706055, train_time=0.021503686904907227
[Epoch 2][Step 81], time=0.061319589614868164, ext_time=0.03351712226867676, train_time=0.022031068801879883
[Epoch 2][Step 82], time=0.06080508232116699, ext_time=0.033627986907958984, train_time=0.02146315574645996
[Epoch 2][Step 83], time=0.061461448669433594, ext_time=0.03284001350402832, train_time=0.02291393280029297
[Epoch 2][Step 84], time=0.06131935119628906, ext_time=0.03330111503601074, train_time=0.022186994552612305
[Epoch 2][Step 85], time=0.06063985824584961, ext_time=0.03327679634094238, train_time=0.021522998809814453
[Epoch 2][Step 86], time=0.06144118309020996, ext_time=0.033170223236083984, train_time=0.022644758224487305
[Epoch 2][Step 87], time=0.06056070327758789, ext_time=0.032343149185180664, train_time=0.02261829376220703
[Epoch 2][Step 88], time=0.06131172180175781, ext_time=0.033966779708862305, train_time=0.0215914249420166
[Epoch 2][Step 89], time=0.061420440673828125, ext_time=0.0340113639831543, train_time=0.021648883819580078
[Epoch 2][Step 90], time=0.06181955337524414, ext_time=0.03349471092224121, train_time=0.022598981857299805
[Epoch 2][Step 91], time=0.06098508834838867, ext_time=0.03328895568847656, train_time=0.02190685272216797
[Epoch 2][Step 92], time=0.06097698211669922, ext_time=0.03398561477661133, train_time=0.021323680877685547
[Epoch 2][Step 93], time=0.061438560485839844, ext_time=0.03326249122619629, train_time=0.02249002456665039
[Epoch 2][Step 94], time=0.060849666595458984, ext_time=0.033143043518066406, train_time=0.02201676368713379
[Epoch 2][Step 95], time=0.060503482818603516, ext_time=0.03369855880737305, train_time=0.02108287811279297
[Epoch 2][Step 96], time=0.060584306716918945, ext_time=0.033399105072021484, train_time=0.021436214447021484
[Epoch 2][Step 97], time=0.061226844787597656, ext_time=0.03372526168823242, train_time=0.02177715301513672
[Epoch 2][Step 98], time=0.06085968017578125, ext_time=0.03245234489440918, train_time=0.02277970314025879
[Epoch 2][Step 99], time=0.06109499931335449, ext_time=0.03269195556640625, train_time=0.02271890640258789
[Epoch 2][Step 100], time=0.060454368591308594, ext_time=0.033576250076293945, train_time=0.02114725112915039
[Epoch 2][Step 101], time=0.060837745666503906, ext_time=0.03337526321411133, train_time=0.021778583526611328
[Epoch 2][Step 102], time=0.06110239028930664, ext_time=0.03384733200073242, train_time=0.021525144577026367
[Epoch 2][Step 103], time=0.06047511100769043, ext_time=0.03358602523803711, train_time=0.021162748336791992
[Epoch 2][Step 104], time=0.06019139289855957, ext_time=0.03342103958129883, train_time=0.02106928825378418
[Epoch 2][Step 105], time=0.06356668472290039, ext_time=0.0326387882232666, train_time=0.0253145694732666
[Epoch 2][Step 106], time=0.06232094764709473, ext_time=0.03341817855834961, train_time=0.02321028709411621
[Epoch 2][Step 107], time=0.06366276741027832, ext_time=0.0329890251159668, train_time=0.024760723114013672
[Epoch 2][Step 108], time=0.060387372970581055, ext_time=0.03262734413146973, train_time=0.02200460433959961
[Epoch 2][Step 109], time=0.061330556869506836, ext_time=0.03363966941833496, train_time=0.021910667419433594
[Epoch 2][Step 110], time=0.06035947799682617, ext_time=0.033316612243652344, train_time=0.021239757537841797
[Epoch 2][Step 111], time=0.06107807159423828, ext_time=0.033357858657836914, train_time=0.021961688995361328
[Epoch 2][Step 112], time=0.06071066856384277, ext_time=0.03304314613342285, train_time=0.02188873291015625
[Epoch 2][Step 113], time=0.061431169509887695, ext_time=0.033408164978027344, train_time=0.022249937057495117
[Epoch 2][Step 114], time=0.06052255630493164, ext_time=0.0333704948425293, train_time=0.021241426467895508
[Epoch 2][Step 115], time=0.06163930892944336, ext_time=0.03407931327819824, train_time=0.021721839904785156
[Epoch 2][Step 116], time=0.06087350845336914, ext_time=0.03310060501098633, train_time=0.022033214569091797
[Epoch 2][Step 117], time=0.06137871742248535, ext_time=0.03338146209716797, train_time=0.02226734161376953
[Epoch 2][Step 118], time=0.061844825744628906, ext_time=0.03423619270324707, train_time=0.021889209747314453
[Epoch 2][Step 119], time=0.06068778038024902, ext_time=0.03296971321105957, train_time=0.02205657958984375
[Epoch 2][Step 120], time=0.06104922294616699, ext_time=0.03366208076477051, train_time=0.021671056747436523
[Epoch 2][Step 121], time=0.06139373779296875, ext_time=0.033036231994628906, train_time=0.022681713104248047
[Epoch 2][Step 122], time=0.061009883880615234, ext_time=0.03339743614196777, train_time=0.02184605598449707
[Epoch 2][Step 123], time=0.06177520751953125, ext_time=0.03405928611755371, train_time=0.021919727325439453
[Epoch 2][Step 124], time=0.06216859817504883, ext_time=0.03309512138366699, train_time=0.02326178550720215
[Epoch 2][Step 125], time=0.061345815658569336, ext_time=0.03377985954284668, train_time=0.0218658447265625
[Epoch 2][Step 126], time=0.06130552291870117, ext_time=0.03412652015686035, train_time=0.02137279510498047
[Epoch 2][Step 127], time=0.061330556869506836, ext_time=0.033503055572509766, train_time=0.022065162658691406
[Epoch 2][Step 128], time=0.061033010482788086, ext_time=0.033675432205200195, train_time=0.021661043167114258
[Epoch 2][Step 129], time=0.06114935874938965, ext_time=0.03349781036376953, train_time=0.02194952964782715
[Epoch 2][Step 130], time=0.06182432174682617, ext_time=0.03357100486755371, train_time=0.022449016571044922
[Epoch 2][Step 131], time=0.060568809509277344, ext_time=0.03309130668640137, train_time=0.021780729293823242
[Epoch 2][Step 132], time=0.06147408485412598, ext_time=0.033800601959228516, train_time=0.021888017654418945
[Epoch 2][Step 133], time=0.061852455139160156, ext_time=0.03396797180175781, train_time=0.02204108238220215
[Epoch 2][Step 134], time=0.06097888946533203, ext_time=0.03343629837036133, train_time=0.02174210548400879
[Epoch 2][Step 135], time=0.061336517333984375, ext_time=0.03336358070373535, train_time=0.02225971221923828
[Epoch 2][Step 136], time=0.062213897705078125, ext_time=0.03357195854187012, train_time=0.022867441177368164
[Epoch 2][Step 137], time=0.061223506927490234, ext_time=0.0336003303527832, train_time=0.021916866302490234
[Epoch 2][Step 138], time=0.06255912780761719, ext_time=0.03316330909729004, train_time=0.02344369888305664
[Epoch 2][Step 139], time=0.06064867973327637, ext_time=0.033519744873046875, train_time=0.021418333053588867
[Epoch 2][Step 140], time=0.06062602996826172, ext_time=0.03350973129272461, train_time=0.021373987197875977
[Epoch 2][Step 141], time=0.062021732330322266, ext_time=0.033594369888305664, train_time=0.022723674774169922
[Epoch 2][Step 142], time=0.06138491630554199, ext_time=0.03366279602050781, train_time=0.021940231323242188
[Epoch 2][Step 143], time=0.060091495513916016, ext_time=0.03293585777282715, train_time=0.02144908905029297
[Epoch 2][Step 144], time=0.06084918975830078, ext_time=0.03315472602844238, train_time=0.021976709365844727
[Epoch 2][Step 145], time=0.06154131889343262, ext_time=0.033644914627075195, train_time=0.02217388153076172
[Epoch 2][Step 146], time=0.060892343521118164, ext_time=0.033834218978881836, train_time=0.02124810218811035
[Epoch 2][Step 147], time=0.06032705307006836, ext_time=0.03325247764587402, train_time=0.02137279510498047
[Epoch 2][Step 148], time=0.06146597862243652, ext_time=0.03389406204223633, train_time=0.021817922592163086
[Epoch 2][Step 149], time=0.06139492988586426, ext_time=0.033373355865478516, train_time=0.022351503372192383
[Epoch 2][Step 150], time=0.06138467788696289, ext_time=0.03395962715148926, train_time=0.02163219451904297
[Epoch 2][Step 151], time=0.06201505661010742, ext_time=0.03385567665100098, train_time=0.0223996639251709
[Epoch 2][Step 152], time=0.06118297576904297, ext_time=0.03363156318664551, train_time=0.021819591522216797
[Epoch 2][Step 153], time=0.06155252456665039, ext_time=0.03248739242553711, train_time=0.023345232009887695
[Epoch 2][Step 154], time=0.06081557273864746, ext_time=0.03381466865539551, train_time=0.021334171295166016
[Epoch 2][Step 155], time=0.06112241744995117, ext_time=0.034108877182006836, train_time=0.021245718002319336
[Epoch 2][Step 156], time=0.06138944625854492, ext_time=0.03387045860290527, train_time=0.021812915802001953
[Epoch 2][Step 157], time=0.06256365776062012, ext_time=0.03362727165222168, train_time=0.02176189422607422
[Epoch 2][Step 158], time=0.061287879943847656, ext_time=0.03293180465698242, train_time=0.022642135620117188
[Epoch 2][Step 159], time=0.061438560485839844, ext_time=0.03371572494506836, train_time=0.022029638290405273
[Epoch 2][Step 160], time=0.061469078063964844, ext_time=0.03335285186767578, train_time=0.022455453872680664
[Epoch 2][Step 161], time=0.061241865158081055, ext_time=0.033388376235961914, train_time=0.02192091941833496
[Epoch 2][Step 162], time=0.06052231788635254, ext_time=0.03313016891479492, train_time=0.021683454513549805
[Epoch 2][Step 163], time=0.062195777893066406, ext_time=0.03429555892944336, train_time=0.02205348014831543
[Epoch 2][Step 164], time=0.060733795166015625, ext_time=0.03284096717834473, train_time=0.02215266227722168
[Epoch 2][Step 165], time=0.06115365028381348, ext_time=0.03332662582397461, train_time=0.02212381362915039
[Epoch 2][Step 166], time=0.06107378005981445, ext_time=0.03348541259765625, train_time=0.021880626678466797
[Epoch 2][Step 167], time=0.061338186264038086, ext_time=0.03283333778381348, train_time=0.022884607315063477
[Epoch 2][Step 168], time=0.06143617630004883, ext_time=0.03398609161376953, train_time=0.021763086318969727
[Epoch 2][Step 169], time=0.06091761589050293, ext_time=0.033399343490600586, train_time=0.021716594696044922
[Epoch 2][Step 170], time=0.06232309341430664, ext_time=0.03316354751586914, train_time=0.02338409423828125
[Epoch 2][Step 171], time=0.06130409240722656, ext_time=0.03208470344543457, train_time=0.02359938621520996
[Epoch 2][Step 172], time=0.06226086616516113, ext_time=0.03448963165283203, train_time=0.021975278854370117
[Epoch 2][Step 173], time=0.06083106994628906, ext_time=0.033631324768066406, train_time=0.021518468856811523
[Epoch 2][Step 174], time=0.06088829040527344, ext_time=0.03286910057067871, train_time=0.022350311279296875
[Epoch 2][Step 175], time=0.060446977615356445, ext_time=0.03261065483093262, train_time=0.022191286087036133
[Epoch 2][Step 176], time=0.06090974807739258, ext_time=0.0332942008972168, train_time=0.021895885467529297
[Epoch 2][Step 177], time=0.061170339584350586, ext_time=0.033882856369018555, train_time=0.02155447006225586
[Epoch 2][Step 178], time=0.0610356330871582, ext_time=0.03279566764831543, train_time=0.022530555725097656
[Epoch 2][Step 179], time=0.060692787170410156, ext_time=0.03322339057922363, train_time=0.02188849449157715
[Epoch 2][Step 180], time=0.06094789505004883, ext_time=0.033457279205322266, train_time=0.021781444549560547
[Epoch 2][Step 181], time=0.06071066856384277, ext_time=0.033151865005493164, train_time=0.021813154220581055
[Epoch 2][Step 182], time=0.06113576889038086, ext_time=0.03379034996032715, train_time=0.021651506423950195
[Epoch 2][Step 183], time=0.0620119571685791, ext_time=0.033479928970336914, train_time=0.022812843322753906
[Epoch 2][Step 184], time=0.06069588661193848, ext_time=0.03330588340759277, train_time=0.02169656753540039
[Epoch 2][Step 185], time=0.06118917465209961, ext_time=0.03286862373352051, train_time=0.022563695907592773
[Epoch 2][Step 186], time=0.060334205627441406, ext_time=0.033148765563964844, train_time=0.02154254913330078
[Epoch 2][Step 187], time=0.06214761734008789, ext_time=0.0335383415222168, train_time=0.02282404899597168
[Epoch 2][Step 188], time=0.06030440330505371, ext_time=0.03283858299255371, train_time=0.021726608276367188
[Epoch 2][Step 189], time=0.06118059158325195, ext_time=0.03380107879638672, train_time=0.0216522216796875
[Epoch 2][Step 190], time=0.06087517738342285, ext_time=0.03357243537902832, train_time=0.021538972854614258
[Epoch 2][Step 191], time=0.06145048141479492, ext_time=0.03357744216918945, train_time=0.022136211395263672
[Epoch 2][Step 192], time=0.06062030792236328, ext_time=0.032994747161865234, train_time=0.02190685272216797
[Epoch 2][Step 193], time=0.061185359954833984, ext_time=0.03385663032531738, train_time=0.021596431732177734
[Epoch 2][Step 194], time=0.060781002044677734, ext_time=0.033538103103637695, train_time=0.021557331085205078
[Epoch 2][Step 195], time=0.06086993217468262, ext_time=0.03302621841430664, train_time=0.022197961807250977
[Epoch 2][Step 196], time=0.060483455657958984, ext_time=0.03301239013671875, train_time=0.021832942962646484
[Epoch 2][Step 197], time=0.06022214889526367, ext_time=0.032764434814453125, train_time=0.02171015739440918
[Epoch 2][Step 198], time=0.06181001663208008, ext_time=0.03322863578796387, train_time=0.02285146713256836
[Epoch 2][Step 199], time=0.06111598014831543, ext_time=0.03290915489196777, train_time=0.022474288940429688
[Epoch 2][Step 200], time=0.06142139434814453, ext_time=0.03374218940734863, train_time=0.021943330764770508
[Epoch 2][Step 201], time=0.06116795539855957, ext_time=0.03299117088317871, train_time=0.022454261779785156
[Epoch 2][Step 202], time=0.06080961227416992, ext_time=0.033209800720214844, train_time=0.02189016342163086
[Epoch 2][Step 203], time=0.06134223937988281, ext_time=0.03376889228820801, train_time=0.021779775619506836
[Epoch 2][Step 204], time=0.0614171028137207, ext_time=0.03385615348815918, train_time=0.021788835525512695
[Epoch 2][Step 205], time=0.060906171798706055, ext_time=0.03301095962524414, train_time=0.022193193435668945
[Epoch 2][Step 206], time=0.06148028373718262, ext_time=0.03346848487854004, train_time=0.022220134735107422
[Epoch 2][Step 207], time=0.06226491928100586, ext_time=0.033461570739746094, train_time=0.02304983139038086
[Epoch 2][Step 208], time=0.06286025047302246, ext_time=0.03456282615661621, train_time=0.022148609161376953
[Epoch 2][Step 209], time=0.06120443344116211, ext_time=0.03317379951477051, train_time=0.022278308868408203
[Epoch 2][Step 210], time=0.06079459190368652, ext_time=0.033557891845703125, train_time=0.021488428115844727
[Epoch 2][Step 211], time=0.0609896183013916, ext_time=0.03258919715881348, train_time=0.02274608612060547
[Epoch 2][Step 212], time=0.060837745666503906, ext_time=0.03317117691040039, train_time=0.02195882797241211
[Epoch 2][Step 213], time=0.0614013671875, ext_time=0.033818721771240234, train_time=0.021837711334228516
[Epoch 2][Step 214], time=0.061597585678100586, ext_time=0.03270435333251953, train_time=0.023204565048217773
[Epoch 2][Step 215], time=0.06238293647766113, ext_time=0.03410530090332031, train_time=0.02245807647705078
[Epoch 2][Step 216], time=0.060778141021728516, ext_time=0.033287763595581055, train_time=0.021741151809692383
[Epoch 2][Step 217], time=0.06130337715148926, ext_time=0.033965110778808594, train_time=0.021638870239257812
[Epoch 2][Step 218], time=0.06071877479553223, ext_time=0.03291893005371094, train_time=0.022144556045532227
[Epoch 2][Step 219], time=0.06036376953125, ext_time=0.032784461975097656, train_time=0.021891355514526367
[Epoch 2][Step 220], time=0.060691118240356445, ext_time=0.03359222412109375, train_time=0.021373271942138672
[Epoch 2][Step 221], time=0.06089520454406738, ext_time=0.03288722038269043, train_time=0.02237105369567871
[Epoch 2][Step 222], time=0.06066393852233887, ext_time=0.03322100639343262, train_time=0.02174973487854004
[Epoch 2][Step 223], time=0.061623573303222656, ext_time=0.03370785713195801, train_time=0.02214336395263672
[Epoch 2][Step 224], time=0.061747074127197266, ext_time=0.034000396728515625, train_time=0.021959781646728516
[Epoch 2][Step 225], time=0.06231188774108887, ext_time=0.03391408920288086, train_time=0.02258133888244629
[Epoch 2][Step 226], time=0.06093001365661621, ext_time=0.03276848793029785, train_time=0.022429943084716797
[Epoch 2][Step 227], time=0.06079292297363281, ext_time=0.033185482025146484, train_time=0.021923542022705078
[Epoch 2][Step 228], time=0.06070995330810547, ext_time=0.03384208679199219, train_time=0.02106499671936035
[Epoch 2][Step 229], time=0.06034541130065918, ext_time=0.033240318298339844, train_time=0.021465063095092773
[Epoch 2][Step 230], time=0.06091809272766113, ext_time=0.03317117691040039, train_time=0.02205944061279297
[Epoch 2][Step 231], time=0.06216597557067871, ext_time=0.03372383117675781, train_time=0.02268052101135254
[Epoch 2][Step 232], time=0.06017947196960449, ext_time=0.03347039222717285, train_time=0.02098846435546875
[Epoch 2][Step 233], time=0.061215877532958984, ext_time=0.03325843811035156, train_time=0.0222318172454834
[Epoch 2][Step 234], time=0.06143522262573242, ext_time=0.03310704231262207, train_time=0.022598743438720703
[Epoch 2][Step 235], time=0.06343793869018555, ext_time=0.03317117691040039, train_time=0.024428844451904297
[Epoch 2][Step 236], time=0.06061220169067383, ext_time=0.03335070610046387, train_time=0.0215606689453125
[Epoch 2][Step 237], time=0.06113266944885254, ext_time=0.03421163558959961, train_time=0.021172523498535156
[Epoch 2][Step 238], time=0.06158781051635742, ext_time=0.03447771072387695, train_time=0.021358013153076172
[Epoch 2][Step 239], time=0.06112408638000488, ext_time=0.03309178352355957, train_time=0.022253751754760742
[Epoch 2][Step 240], time=0.06119370460510254, ext_time=0.03329205513000488, train_time=0.02213430404663086
[Epoch 2][Step 241], time=0.060632944107055664, ext_time=0.0334930419921875, train_time=0.02132892608642578
[Epoch 2][Step 242], time=0.06045246124267578, ext_time=0.03310585021972656, train_time=0.021582603454589844
[Epoch 2][Step 243], time=0.0605623722076416, ext_time=0.03304934501647949, train_time=0.02181839942932129
[Epoch 2][Step 244], time=0.06097412109375, ext_time=0.033440589904785156, train_time=0.021792173385620117
[Epoch 2][Step 245], time=0.06143784523010254, ext_time=0.03330063819885254, train_time=0.02241826057434082
[Epoch 2][Step 246], time=0.061165809631347656, ext_time=0.033067941665649414, train_time=0.022386550903320312
[Epoch 2][Step 247], time=0.06130337715148926, ext_time=0.03332972526550293, train_time=0.022258281707763672
[Epoch 2][Step 248], time=0.060480594635009766, ext_time=0.03370094299316406, train_time=0.021075963973999023
[Epoch 2][Step 249], time=0.060894012451171875, ext_time=0.03263401985168457, train_time=0.022580623626708984
[Epoch 2], time=15.31577181816101, loss=0.6931472420692444
[Epoch 3][Step 0], time=0.06111884117126465, ext_time=0.033644676208496094, train_time=0.021739959716796875
[Epoch 3][Step 1], time=0.061202287673950195, ext_time=0.03372454643249512, train_time=0.02176070213317871
[Epoch 3][Step 2], time=0.06217789649963379, ext_time=0.03304910659790039, train_time=0.02343297004699707
[Epoch 3][Step 3], time=0.06120920181274414, ext_time=0.033345699310302734, train_time=0.022216081619262695
[Epoch 3][Step 4], time=0.06176900863647461, ext_time=0.03394746780395508, train_time=0.02211308479309082
[Epoch 3][Step 5], time=0.06154155731201172, ext_time=0.03338360786437988, train_time=0.022364139556884766
[Epoch 3][Step 6], time=0.06168341636657715, ext_time=0.03361010551452637, train_time=0.02234339714050293
[Epoch 3][Step 7], time=0.06172037124633789, ext_time=0.03266453742980957, train_time=0.023427486419677734
[Epoch 3][Step 8], time=0.06203317642211914, ext_time=0.03300142288208008, train_time=0.023350954055786133
[Epoch 3][Step 9], time=0.06283450126647949, ext_time=0.03321218490600586, train_time=0.023915529251098633
[Epoch 3][Step 10], time=0.060961246490478516, ext_time=0.033524274826049805, train_time=0.02176213264465332
[Epoch 3][Step 11], time=0.062157630920410156, ext_time=0.03311300277709961, train_time=0.023360490798950195
[Epoch 3][Step 12], time=0.06178617477416992, ext_time=0.03278088569641113, train_time=0.02326035499572754
[Epoch 3][Step 13], time=0.06193232536315918, ext_time=0.03316497802734375, train_time=0.0229341983795166
[Epoch 3][Step 14], time=0.06061077117919922, ext_time=0.03262662887573242, train_time=0.022315025329589844
[Epoch 3][Step 15], time=0.061197757720947266, ext_time=0.03340554237365723, train_time=0.022052764892578125
[Epoch 3][Step 16], time=0.06106829643249512, ext_time=0.03378176689147949, train_time=0.02154254913330078
[Epoch 3][Step 17], time=0.06258487701416016, ext_time=0.03346514701843262, train_time=0.023337841033935547
[Epoch 3][Step 18], time=0.061191558837890625, ext_time=0.03365683555603027, train_time=0.02175760269165039
[Epoch 3][Step 19], time=0.06238985061645508, ext_time=0.033628225326538086, train_time=0.022924423217773438
[Epoch 3][Step 20], time=0.06184720993041992, ext_time=0.03401303291320801, train_time=0.022061824798583984
[Epoch 3][Step 21], time=0.0624232292175293, ext_time=0.033248186111450195, train_time=0.023430585861206055
[Epoch 3][Step 22], time=0.06167411804199219, ext_time=0.033304691314697266, train_time=0.022698163986206055
[Epoch 3][Step 23], time=0.060799360275268555, ext_time=0.03300881385803223, train_time=0.02207636833190918
[Epoch 3][Step 24], time=0.06137204170227051, ext_time=0.03355884552001953, train_time=0.02209305763244629
[Epoch 3][Step 25], time=0.06072282791137695, ext_time=0.03329825401306152, train_time=0.021717309951782227
[Epoch 3][Step 26], time=0.061540842056274414, ext_time=0.033823251724243164, train_time=0.021923303604125977
[Epoch 3][Step 27], time=0.06246304512023926, ext_time=0.033515214920043945, train_time=0.023214101791381836
[Epoch 3][Step 28], time=0.06163835525512695, ext_time=0.03342723846435547, train_time=0.02194952964782715
[Epoch 3][Step 29], time=0.06115269660949707, ext_time=0.03394341468811035, train_time=0.021515846252441406
[Epoch 3][Step 30], time=0.0613555908203125, ext_time=0.03294706344604492, train_time=0.022763490676879883
[Epoch 3][Step 31], time=0.06114840507507324, ext_time=0.0333707332611084, train_time=0.022070884704589844
[Epoch 3][Step 32], time=0.061499595642089844, ext_time=0.0330960750579834, train_time=0.022685527801513672
[Epoch 3][Step 33], time=0.06171417236328125, ext_time=0.03321075439453125, train_time=0.022815942764282227
[Epoch 3][Step 34], time=0.06102633476257324, ext_time=0.033306121826171875, train_time=0.021979093551635742
[Epoch 3][Step 35], time=0.06125187873840332, ext_time=0.03324604034423828, train_time=0.022317886352539062
[Epoch 3][Step 36], time=0.06108379364013672, ext_time=0.033446550369262695, train_time=0.021863222122192383
[Epoch 3][Step 37], time=0.06200218200683594, ext_time=0.033643245697021484, train_time=0.022641897201538086
[Epoch 3][Step 38], time=0.06117606163024902, ext_time=0.033092498779296875, train_time=0.022404909133911133
[Epoch 3][Step 39], time=0.06160545349121094, ext_time=0.033362388610839844, train_time=0.022547245025634766
[Epoch 3][Step 40], time=0.060999155044555664, ext_time=0.03331780433654785, train_time=0.02198934555053711
[Epoch 3][Step 41], time=0.06286311149597168, ext_time=0.03352832794189453, train_time=0.02356243133544922
[Epoch 3][Step 42], time=0.06109476089477539, ext_time=0.03357386589050293, train_time=0.02175140380859375
[Epoch 3][Step 43], time=0.0610508918762207, ext_time=0.03351712226867676, train_time=0.021854639053344727
[Epoch 3][Step 44], time=0.06141495704650879, ext_time=0.03371405601501465, train_time=0.021929264068603516
[Epoch 3][Step 45], time=0.06134939193725586, ext_time=0.03286004066467285, train_time=0.02277851104736328
[Epoch 3][Step 46], time=0.06161665916442871, ext_time=0.033859968185424805, train_time=0.021993637084960938
[Epoch 3][Step 47], time=0.061449527740478516, ext_time=0.03371906280517578, train_time=0.02199077606201172
[Epoch 3][Step 48], time=0.061621904373168945, ext_time=0.0338892936706543, train_time=0.02199840545654297
[Epoch 3][Step 49], time=0.06233620643615723, ext_time=0.03337883949279785, train_time=0.023314237594604492
[Epoch 3][Step 50], time=0.061739206314086914, ext_time=0.03365898132324219, train_time=0.022414207458496094
[Epoch 3][Step 51], time=0.061881065368652344, ext_time=0.034183502197265625, train_time=0.021927833557128906
[Epoch 3][Step 52], time=0.06221342086791992, ext_time=0.032917022705078125, train_time=0.023539066314697266
[Epoch 3][Step 53], time=0.061905860900878906, ext_time=0.03357648849487305, train_time=0.022544145584106445
[Epoch 3][Step 54], time=0.061873435974121094, ext_time=0.033655405044555664, train_time=0.02245640754699707
[Epoch 3][Step 55], time=0.06134295463562012, ext_time=0.03311753273010254, train_time=0.02258610725402832
[Epoch 3][Step 56], time=0.0617527961730957, ext_time=0.033648014068603516, train_time=0.022402524948120117
[Epoch 3][Step 57], time=0.06297636032104492, ext_time=0.033846378326416016, train_time=0.02335977554321289
[Epoch 3][Step 58], time=0.06101393699645996, ext_time=0.03401613235473633, train_time=0.021252155303955078
[Epoch 3][Step 59], time=0.061797380447387695, ext_time=0.033770084381103516, train_time=0.02222895622253418
[Epoch 3][Step 60], time=0.06064939498901367, ext_time=0.03323006629943848, train_time=0.021648168563842773
[Epoch 3][Step 61], time=0.06079912185668945, ext_time=0.03398609161376953, train_time=0.02108454704284668
[Epoch 3][Step 62], time=0.061283111572265625, ext_time=0.033380746841430664, train_time=0.022240400314331055
[Epoch 3][Step 63], time=0.06018257141113281, ext_time=0.03277015686035156, train_time=0.02171778678894043
[Epoch 3][Step 64], time=0.06133008003234863, ext_time=0.033837318420410156, train_time=0.021786928176879883
[Epoch 3][Step 65], time=0.061968326568603516, ext_time=0.03379082679748535, train_time=0.022470474243164062
[Epoch 3][Step 66], time=0.06119179725646973, ext_time=0.03335881233215332, train_time=0.02213144302368164
[Epoch 3][Step 67], time=0.061823129653930664, ext_time=0.03424263000488281, train_time=0.021820783615112305
[Epoch 3][Step 68], time=0.06148052215576172, ext_time=0.03392386436462402, train_time=0.02182745933532715
[Epoch 3][Step 69], time=0.06155538558959961, ext_time=0.033299922943115234, train_time=0.022583484649658203
[Epoch 3][Step 70], time=0.0617680549621582, ext_time=0.03347349166870117, train_time=0.022622346878051758
[Epoch 3][Step 71], time=0.06168246269226074, ext_time=0.033612966537475586, train_time=0.02234625816345215
[Epoch 3][Step 72], time=0.061205148696899414, ext_time=0.033449649810791016, train_time=0.022043704986572266
[Epoch 3][Step 73], time=0.06235456466674805, ext_time=0.03331327438354492, train_time=0.023297786712646484
[Epoch 3][Step 74], time=0.06185317039489746, ext_time=0.0336148738861084, train_time=0.022566556930541992
[Epoch 3][Step 75], time=0.06137824058532715, ext_time=0.03362321853637695, train_time=0.02194690704345703
[Epoch 3][Step 76], time=0.06112861633300781, ext_time=0.03277993202209473, train_time=0.022646665573120117
[Epoch 3][Step 77], time=0.06243562698364258, ext_time=0.03305935859680176, train_time=0.022183895111083984
[Epoch 3][Step 78], time=0.06078004837036133, ext_time=0.033702850341796875, train_time=0.021365880966186523
[Epoch 3][Step 79], time=0.06408858299255371, ext_time=0.03326296806335449, train_time=0.02511882781982422
[Epoch 3][Step 80], time=0.06190824508666992, ext_time=0.0338590145111084, train_time=0.02225518226623535
[Epoch 3][Step 81], time=0.06156325340270996, ext_time=0.03417038917541504, train_time=0.02157425880432129
[Epoch 3][Step 82], time=0.06220674514770508, ext_time=0.033579349517822266, train_time=0.02292943000793457
[Epoch 3][Step 83], time=0.06133222579956055, ext_time=0.032750844955444336, train_time=0.022861242294311523
[Epoch 3][Step 84], time=0.061894893646240234, ext_time=0.033222198486328125, train_time=0.022960424423217773
[Epoch 3][Step 85], time=0.06156420707702637, ext_time=0.03328514099121094, train_time=0.02254176139831543
[Epoch 3][Step 86], time=0.061827659606933594, ext_time=0.03354334831237793, train_time=0.022594690322875977
[Epoch 3][Step 87], time=0.062432289123535156, ext_time=0.03266406059265137, train_time=0.02410268783569336
[Epoch 3][Step 88], time=0.061731576919555664, ext_time=0.03339838981628418, train_time=0.022663354873657227
[Epoch 3][Step 89], time=0.061586856842041016, ext_time=0.033605337142944336, train_time=0.022240400314331055
[Epoch 3][Step 90], time=0.0615544319152832, ext_time=0.03395223617553711, train_time=0.021775484085083008
[Epoch 3][Step 91], time=0.06128811836242676, ext_time=0.033035993576049805, train_time=0.02256488800048828
[Epoch 3][Step 92], time=0.06146693229675293, ext_time=0.033216238021850586, train_time=0.02260279655456543
[Epoch 3][Step 93], time=0.06085038185119629, ext_time=0.03255939483642578, train_time=0.022700786590576172
[Epoch 3][Step 94], time=0.06054353713989258, ext_time=0.032745361328125, train_time=0.022169113159179688
[Epoch 3][Step 95], time=0.060822486877441406, ext_time=0.033731698989868164, train_time=0.021401405334472656
[Epoch 3][Step 96], time=0.061754703521728516, ext_time=0.03299975395202637, train_time=0.023077011108398438
[Epoch 3][Step 97], time=0.06177973747253418, ext_time=0.033560991287231445, train_time=0.022473573684692383
[Epoch 3][Step 98], time=0.06093859672546387, ext_time=0.03249216079711914, train_time=0.022246122360229492
[Epoch 3][Step 99], time=0.06198263168334961, ext_time=0.03317093849182129, train_time=0.023098230361938477
[Epoch 3][Step 100], time=0.06151986122131348, ext_time=0.03366255760192871, train_time=0.02209615707397461
[Epoch 3][Step 101], time=0.061335086822509766, ext_time=0.0334169864654541, train_time=0.022206783294677734
[Epoch 3][Step 102], time=0.06076693534851074, ext_time=0.033512115478515625, train_time=0.0215761661529541
[Epoch 3][Step 103], time=0.061731576919555664, ext_time=0.033453941345214844, train_time=0.022582530975341797
[Epoch 3][Step 104], time=0.06094813346862793, ext_time=0.033684730529785156, train_time=0.021518707275390625
[Epoch 3][Step 105], time=0.06374335289001465, ext_time=0.03339433670043945, train_time=0.02461385726928711
[Epoch 3][Step 106], time=0.06185770034790039, ext_time=0.03379654884338379, train_time=0.022295236587524414
[Epoch 3][Step 107], time=0.061945438385009766, ext_time=0.03291726112365723, train_time=0.023336172103881836
[Epoch 3][Step 108], time=0.06191086769104004, ext_time=0.03248286247253418, train_time=0.023787736892700195
[Epoch 3][Step 109], time=0.06153440475463867, ext_time=0.03304934501647949, train_time=0.022790193557739258
[Epoch 3][Step 110], time=0.06169724464416504, ext_time=0.0330808162689209, train_time=0.02289748191833496
[Epoch 3][Step 111], time=0.06187891960144043, ext_time=0.033423423767089844, train_time=0.022716760635375977
[Epoch 3][Step 112], time=0.063629150390625, ext_time=0.033098459243774414, train_time=0.024731159210205078
[Epoch 3][Step 113], time=0.0619661808013916, ext_time=0.03388214111328125, train_time=0.022279977798461914
[Epoch 3][Step 114], time=0.061251163482666016, ext_time=0.03285622596740723, train_time=0.022723913192749023
[Epoch 3][Step 115], time=0.061075448989868164, ext_time=0.03324079513549805, train_time=0.022096633911132812
[Epoch 3][Step 116], time=0.06101369857788086, ext_time=0.03287529945373535, train_time=0.022393226623535156
[Epoch 3][Step 117], time=0.061481475830078125, ext_time=0.0334627628326416, train_time=0.02223682403564453
[Epoch 3][Step 118], time=0.061109304428100586, ext_time=0.03397846221923828, train_time=0.02138519287109375
[Epoch 3][Step 119], time=0.06122469902038574, ext_time=0.033715009689331055, train_time=0.02178049087524414
[Epoch 3][Step 120], time=0.06085610389709473, ext_time=0.03307461738586426, train_time=0.02213144302368164
[Epoch 3][Step 121], time=0.06201529502868652, ext_time=0.033521175384521484, train_time=0.022800207138061523
[Epoch 3][Step 122], time=0.06058788299560547, ext_time=0.03343391418457031, train_time=0.021394729614257812
[Epoch 3][Step 123], time=0.06198740005493164, ext_time=0.03417658805847168, train_time=0.02203965187072754
[Epoch 3][Step 124], time=0.061144113540649414, ext_time=0.0328061580657959, train_time=0.02257990837097168
[Epoch 3][Step 125], time=0.06123828887939453, ext_time=0.0331425666809082, train_time=0.0224459171295166
[Epoch 3][Step 126], time=0.0624847412109375, ext_time=0.033319950103759766, train_time=0.023427724838256836
[Epoch 3][Step 127], time=0.06237673759460449, ext_time=0.03320717811584473, train_time=0.02341914176940918
[Epoch 3][Step 128], time=0.06167721748352051, ext_time=0.033713579177856445, train_time=0.022229433059692383
[Epoch 3][Step 129], time=0.06074047088623047, ext_time=0.033086538314819336, train_time=0.02195143699645996
[Epoch 3][Step 130], time=0.06194782257080078, ext_time=0.03417801856994629, train_time=0.02199387550354004
[Epoch 3][Step 131], time=0.06113553047180176, ext_time=0.03368568420410156, train_time=0.021612167358398438
[Epoch 3][Step 132], time=0.062042236328125, ext_time=0.033030033111572266, train_time=0.023310422897338867
[Epoch 3][Step 133], time=0.06122946739196777, ext_time=0.03373312950134277, train_time=0.021743297576904297
[Epoch 3][Step 134], time=0.1281280517578125, ext_time=0.0330960750579834, train_time=0.08932876586914062
[Epoch 3][Step 135], time=0.07033109664916992, ext_time=0.033992767333984375, train_time=0.030591487884521484
[Epoch 3][Step 136], time=0.06430268287658691, ext_time=0.03392934799194336, train_time=0.02457284927368164
[Epoch 3][Step 137], time=0.06335759162902832, ext_time=0.0335080623626709, train_time=0.024148225784301758
[Epoch 3][Step 138], time=0.06248593330383301, ext_time=0.03348135948181152, train_time=0.023236513137817383
[Epoch 3][Step 139], time=0.06064152717590332, ext_time=0.0337061882019043, train_time=0.02122783660888672
[Epoch 3][Step 140], time=0.061914920806884766, ext_time=0.03340935707092285, train_time=0.022817611694335938
[Epoch 3][Step 141], time=0.06130170822143555, ext_time=0.03366684913635254, train_time=0.02195453643798828
[Epoch 3][Step 142], time=0.06064963340759277, ext_time=0.03356528282165527, train_time=0.021363496780395508
[Epoch 3][Step 143], time=0.060968875885009766, ext_time=0.03296303749084473, train_time=0.022397756576538086
[Epoch 3][Step 144], time=0.06036663055419922, ext_time=0.03301358222961426, train_time=0.021605491638183594
[Epoch 3][Step 145], time=0.06109333038330078, ext_time=0.033660888671875, train_time=0.021697998046875
[Epoch 3][Step 146], time=0.06112051010131836, ext_time=0.03355264663696289, train_time=0.021864891052246094
[Epoch 3][Step 147], time=0.06260967254638672, ext_time=0.03324580192565918, train_time=0.023675918579101562
[Epoch 3][Step 148], time=0.06122255325317383, ext_time=0.03333735466003418, train_time=0.02212691307067871
[Epoch 3][Step 149], time=0.06080484390258789, ext_time=0.03339743614196777, train_time=0.02173900604248047
[Epoch 3][Step 150], time=0.061063289642333984, ext_time=0.03326010704040527, train_time=0.022075176239013672
[Epoch 3][Step 151], time=0.06106233596801758, ext_time=0.03357696533203125, train_time=0.021746397018432617
[Epoch 3][Step 152], time=0.0606694221496582, ext_time=0.03312945365905762, train_time=0.02182793617248535
[Epoch 3][Step 153], time=0.06106734275817871, ext_time=0.03300142288208008, train_time=0.02237558364868164
[Epoch 3][Step 154], time=0.06059122085571289, ext_time=0.03349184989929199, train_time=0.021468400955200195
[Epoch 3][Step 155], time=0.060416460037231445, ext_time=0.03355860710144043, train_time=0.021139860153198242
[Epoch 3][Step 156], time=0.06026148796081543, ext_time=0.03377532958984375, train_time=0.020820140838623047
[Epoch 3][Step 157], time=0.06215620040893555, ext_time=0.03383660316467285, train_time=0.02257823944091797
[Epoch 3][Step 158], time=0.0614469051361084, ext_time=0.03322720527648926, train_time=0.02250075340270996
[Epoch 3][Step 159], time=0.06110072135925293, ext_time=0.034081459045410156, train_time=0.021246910095214844
[Epoch 3][Step 160], time=0.06132698059082031, ext_time=0.033410072326660156, train_time=0.02227640151977539
[Epoch 3][Step 161], time=0.060628652572631836, ext_time=0.03342485427856445, train_time=0.021520137786865234
[Epoch 3][Step 162], time=0.061562299728393555, ext_time=0.033803701400756836, train_time=0.02200937271118164
[Epoch 3][Step 163], time=0.060880184173583984, ext_time=0.03348207473754883, train_time=0.02169179916381836
[Epoch 3][Step 164], time=0.06137442588806152, ext_time=0.03315162658691406, train_time=0.022486448287963867
[Epoch 3][Step 165], time=0.06063127517700195, ext_time=0.03349494934082031, train_time=0.021326780319213867
[Epoch 3][Step 166], time=0.06119871139526367, ext_time=0.03311753273010254, train_time=0.022344112396240234
[Epoch 3][Step 167], time=0.060994863510131836, ext_time=0.0329592227935791, train_time=0.022142410278320312
[Epoch 3][Step 168], time=0.061516523361206055, ext_time=0.033739566802978516, train_time=0.022101402282714844
[Epoch 3][Step 169], time=0.06173396110534668, ext_time=0.033051490783691406, train_time=0.02299356460571289
[Epoch 3][Step 170], time=0.0614168643951416, ext_time=0.033109426498413086, train_time=0.022277116775512695
[Epoch 3][Step 171], time=0.06072711944580078, ext_time=0.0324404239654541, train_time=0.022361040115356445
[Epoch 3][Step 172], time=0.06193137168884277, ext_time=0.03415417671203613, train_time=0.021818161010742188
[Epoch 3][Step 173], time=0.06153678894042969, ext_time=0.033771514892578125, train_time=0.02182626724243164
[Epoch 3][Step 174], time=0.06159043312072754, ext_time=0.03354001045227051, train_time=0.022107362747192383
[Epoch 3][Step 175], time=0.06162905693054199, ext_time=0.03337216377258301, train_time=0.022298097610473633
[Epoch 3][Step 176], time=0.06084918975830078, ext_time=0.03331112861633301, train_time=0.021637439727783203
[Epoch 3][Step 177], time=0.06205296516418457, ext_time=0.034079551696777344, train_time=0.02197098731994629
[Epoch 3][Step 178], time=0.060753822326660156, ext_time=0.03237485885620117, train_time=0.02245306968688965
[Epoch 3][Step 179], time=0.06186628341674805, ext_time=0.03409719467163086, train_time=0.021837472915649414
[Epoch 3][Step 180], time=0.06128501892089844, ext_time=0.033208370208740234, train_time=0.022171497344970703
[Epoch 3][Step 181], time=0.06194639205932617, ext_time=0.03349709510803223, train_time=0.02252960205078125
[Epoch 3][Step 182], time=0.061730384826660156, ext_time=0.03369307518005371, train_time=0.022142410278320312
[Epoch 3][Step 183], time=0.06195783615112305, ext_time=0.033345937728881836, train_time=0.022666454315185547
[Epoch 3][Step 184], time=0.06069207191467285, ext_time=0.03318071365356445, train_time=0.02164626121520996
[Epoch 3][Step 185], time=0.06094670295715332, ext_time=0.0333404541015625, train_time=0.02168416976928711
[Epoch 3][Step 186], time=0.06193065643310547, ext_time=0.03350090980529785, train_time=0.02254772186279297
[Epoch 3][Step 187], time=0.06140708923339844, ext_time=0.03352928161621094, train_time=0.021890640258789062
[Epoch 3][Step 188], time=0.06095433235168457, ext_time=0.033083438873291016, train_time=0.021903276443481445
[Epoch 3][Step 189], time=0.06141233444213867, ext_time=0.03376197814941406, train_time=0.0217587947845459
[Epoch 3][Step 190], time=0.061800241470336914, ext_time=0.03360772132873535, train_time=0.02231144905090332
[Epoch 3][Step 191], time=0.06258273124694824, ext_time=0.03374981880187988, train_time=0.022745609283447266
[Epoch 3][Step 192], time=0.06075310707092285, ext_time=0.033199310302734375, train_time=0.02163839340209961
[Epoch 3][Step 193], time=0.06129860877990723, ext_time=0.033792734146118164, train_time=0.02156805992126465
[Epoch 3][Step 194], time=0.061660051345825195, ext_time=0.03390336036682129, train_time=0.02182292938232422
[Epoch 3][Step 195], time=0.06044888496398926, ext_time=0.03280448913574219, train_time=0.021875619888305664
[Epoch 3][Step 196], time=0.06134176254272461, ext_time=0.03288865089416504, train_time=0.022589683532714844
[Epoch 3][Step 197], time=0.06112074851989746, ext_time=0.03292202949523926, train_time=0.02232050895690918
[Epoch 3][Step 198], time=0.061914920806884766, ext_time=0.033922433853149414, train_time=0.022025108337402344
[Epoch 3][Step 199], time=0.06198906898498535, ext_time=0.03350043296813965, train_time=0.022538423538208008
[Epoch 3][Step 200], time=0.061739444732666016, ext_time=0.034131526947021484, train_time=0.02168107032775879
[Epoch 3][Step 201], time=0.060889244079589844, ext_time=0.033356666564941406, train_time=0.02165842056274414
[Epoch 3][Step 202], time=0.061415672302246094, ext_time=0.03360295295715332, train_time=0.021897554397583008
[Epoch 3][Step 203], time=0.06172513961791992, ext_time=0.03374981880187988, train_time=0.021977663040161133
[Epoch 3][Step 204], time=0.062067270278930664, ext_time=0.03363323211669922, train_time=0.022461652755737305
[Epoch 3][Step 205], time=0.06176567077636719, ext_time=0.03360748291015625, train_time=0.022194862365722656
[Epoch 3][Step 206], time=0.06195378303527832, ext_time=0.03354978561401367, train_time=0.022417783737182617
[Epoch 3][Step 207], time=0.062070608139038086, ext_time=0.033431291580200195, train_time=0.022733449935913086
[Epoch 3][Step 208], time=0.06247234344482422, ext_time=0.03413581848144531, train_time=0.022408246994018555
[Epoch 3][Step 209], time=0.06164717674255371, ext_time=0.03288674354553223, train_time=0.02290058135986328
[Epoch 3][Step 210], time=0.06271076202392578, ext_time=0.03417778015136719, train_time=0.022541284561157227
[Epoch 3][Step 211], time=0.06269383430480957, ext_time=0.032706260681152344, train_time=0.02413630485534668
[Epoch 3][Step 212], time=0.06122446060180664, ext_time=0.033324241638183594, train_time=0.021965742111206055
[Epoch 3][Step 213], time=0.062448978424072266, ext_time=0.033951520919799805, train_time=0.02254962921142578
[Epoch 3][Step 214], time=0.06092119216918945, ext_time=0.03310394287109375, train_time=0.02182602882385254
[Epoch 3][Step 215], time=0.06217527389526367, ext_time=0.03420758247375488, train_time=0.021996259689331055
[Epoch 3][Step 216], time=0.06166958808898926, ext_time=0.03321242332458496, train_time=0.02255845069885254
[Epoch 3][Step 217], time=0.06105613708496094, ext_time=0.033594608306884766, train_time=0.021613597869873047
[Epoch 3][Step 218], time=0.06183028221130371, ext_time=0.03346538543701172, train_time=0.022457122802734375
[Epoch 3][Step 219], time=0.06081819534301758, ext_time=0.03327631950378418, train_time=0.021602153778076172
[Epoch 3][Step 220], time=0.061116695404052734, ext_time=0.033281803131103516, train_time=0.021908998489379883
[Epoch 3][Step 221], time=0.061605215072631836, ext_time=0.03371381759643555, train_time=0.021994590759277344
[Epoch 3][Step 222], time=0.061257362365722656, ext_time=0.03362107276916504, train_time=0.021698474884033203
[Epoch 3][Step 223], time=0.061545372009277344, ext_time=0.03360748291015625, train_time=0.022053956985473633
[Epoch 3][Step 224], time=0.061379432678222656, ext_time=0.03342723846435547, train_time=0.02201700210571289
[Epoch 3][Step 225], time=0.06096625328063965, ext_time=0.032962799072265625, train_time=0.02210521697998047
[Epoch 3][Step 226], time=0.061046600341796875, ext_time=0.0334773063659668, train_time=0.021651029586791992
[Epoch 3][Step 227], time=0.06108903884887695, ext_time=0.03358769416809082, train_time=0.021618366241455078
[Epoch 3][Step 228], time=0.06148982048034668, ext_time=0.03371858596801758, train_time=0.02184319496154785
[Epoch 3][Step 229], time=0.062744140625, ext_time=0.034012794494628906, train_time=0.02278447151184082
[Epoch 3][Step 230], time=0.060967206954956055, ext_time=0.033132076263427734, train_time=0.021712064743041992
[Epoch 3][Step 231], time=0.061890363693237305, ext_time=0.034001827239990234, train_time=0.021914005279541016
[Epoch 3][Step 232], time=0.06135249137878418, ext_time=0.03351187705993652, train_time=0.021919727325439453
[Epoch 3][Step 233], time=0.060979604721069336, ext_time=0.033359527587890625, train_time=0.021716833114624023
[Epoch 3][Step 234], time=0.06169295310974121, ext_time=0.033266305923461914, train_time=0.022486209869384766
[Epoch 3][Step 235], time=0.06103849411010742, ext_time=0.03287982940673828, train_time=0.022229671478271484
[Epoch 3][Step 236], time=0.06214165687561035, ext_time=0.033867597579956055, train_time=0.02233576774597168
[Epoch 3][Step 237], time=0.062059640884399414, ext_time=0.03396940231323242, train_time=0.022087574005126953
[Epoch 3][Step 238], time=0.06257081031799316, ext_time=0.034603118896484375, train_time=0.021985530853271484
[Epoch 3][Step 239], time=0.06152534484863281, ext_time=0.033452510833740234, train_time=0.022062301635742188
[Epoch 3][Step 240], time=0.06194877624511719, ext_time=0.03373384475708008, train_time=0.02224445343017578
[Epoch 3][Step 241], time=0.06089162826538086, ext_time=0.03314471244812012, train_time=0.021792173385620117
[Epoch 3][Step 242], time=0.061203718185424805, ext_time=0.03330850601196289, train_time=0.021908283233642578
[Epoch 3][Step 243], time=0.06136322021484375, ext_time=0.03358912467956543, train_time=0.021811485290527344
[Epoch 3][Step 244], time=0.0617222785949707, ext_time=0.03321337699890137, train_time=0.02258467674255371
[Epoch 3][Step 245], time=0.060956478118896484, ext_time=0.032689571380615234, train_time=0.022388219833374023
[Epoch 3][Step 246], time=0.06152987480163574, ext_time=0.033532142639160156, train_time=0.022006511688232422
[Epoch 3][Step 247], time=0.06260824203491211, ext_time=0.03353166580200195, train_time=0.02192234992980957
[Epoch 3][Step 248], time=0.061266422271728516, ext_time=0.0333251953125, train_time=0.02203536033630371
[Epoch 3][Step 249], time=0.06099295616149902, ext_time=0.032991886138916016, train_time=0.022151947021484375
[Epoch 3], time=15.478603839874268, loss=0.6931472420692444
    [Step(average) Profiler Level 1 E3 S999]
        L1  sample           0.005786 | send           0.000000
        L1  recv             0.000000 | copy           0.033127 | convert time 0.000000 | train  0.022576
        L1  feature nbytes    1.06 GB | label nbytes 0.00 Bytes
        L1  id nbytes      0.00 Bytes | graph nbytes 0.00 Bytes
        L1  miss nbytes     379.93 MB | remote nbytes  528.97 MB
        L1  num nodes               0 | num samples           0
        L1  seq duration     0.000000 | refresh duration   0.000000
    [Step(average) Profiler Level 2 E3 S999]
        L2  shuffle     0.000000 | core sample  0.000000 | id remap        0.000000
        L2  graph copy  0.000000 | id copy      0.000000 | cache feat copy 0.033127
        L2  last layer sample time 0.000000 | size 0.000000
    [Step(average) Profiler Level 3 E3 S999]
        L3  khop sample coo  0.000000 | khop sort coo      0.000000 | khop count edge     0.000000 | khop compact edge 0.000000
        L3  walk sample coo  0.000000 | walk topk total    0.000000 | walk topk step1     0.000000 | walk topk step2   0.000000
        L3  walk topk step3  0.000000 | walk topk step4    0.000000 | walk topk step5     0.000000
        L3  walk topk step6  0.000000 | walk topk step7    0.000000
        L3  remap unique     0.000000 | remap populate     0.000000 | remap mapnode       0.000000 | remap mapedge     0.000000
        L3  cache get_index  0.000967 | cache copy_index   0.000000 | cache extract_miss  0.000000
        L3  cache copy_miss  0.000000 | cache combine_miss 0.032111 | cache combine cache 0.000535 | cache combine remote 0.004598
        L3  label extract  0.000000
    [Profiler Level Percentiles E3 S999]
        p50.00_tail_logl2featcopy=0.033116
        p90.00_tail_logl2featcopy=0.033684
        p95.00_tail_logl2featcopy=0.033856
        p99.00_tail_logl2featcopy=0.034198
        p99.90_tail_logl2featcopy=0.039030
[CUDA] cuda: usage: 15.09 GB
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   76011 KB |    1897 MB |    4777 GB |    4777 GB |
|       from large pool |   63396 KB |    1886 MB |    4734 GB |    4734 GB |
|       from small pool |   12614 KB |      22 MB |      43 GB |      43 GB |
|---------------------------------------------------------------------------|
| Active memory         |   76011 KB |    1897 MB |    4777 GB |    4777 GB |
|       from large pool |   63396 KB |    1886 MB |    4734 GB |    4734 GB |
|       from small pool |   12614 KB |      22 MB |      43 GB |      43 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    6332 MB |    6332 MB |    6332 MB |       0 B  |
|       from large pool |    6302 MB |    6302 MB |    6302 MB |       0 B  |
|       from small pool |      30 MB |      30 MB |      30 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  145173 KB |    3676 MB |    5118 GB |    5118 GB |
|       from large pool |  137307 KB |    3668 MB |    5073 GB |    5072 GB |
|       from small pool |    7865 KB |      14 MB |      45 GB |      45 GB |
|---------------------------------------------------------------------------|
| Allocations           |      69    |      99    |  320297    |  320228    |
|       from large pool |      13    |      24    |   95512    |   95499    |
|       from small pool |      56    |      79    |  224785    |  224729    |
|---------------------------------------------------------------------------|
| Active allocs         |      69    |      99    |  320297    |  320228    |
|       from large pool |      13    |      24    |   95512    |   95499    |
|       from small pool |      56    |      79    |  224785    |  224729    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      28    |      28    |      28    |       0    |
|       from large pool |      13    |      13    |      13    |       0    |
|       from small pool |      15    |      15    |      15    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      34    |      52    |  118563    |  118529    |
|       from large pool |       8    |      19    |   45909    |   45901    |
|       from small pool |      26    |      39    |   72654    |   72628    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[TRAIN_TIME] train time is 62.718175 seconds
[EPOCH_TIME] 15.679544 seconds, maybe large due to not enough epoch skipped.
[EPOCH_TIME] 15.397330 seconds
worker 1 running with pid=32100
loading train edge idx from disk
loading train edge idx from disk done
tensor([ 312558501,  165303846,  382592436, 3465360478, 1289294319, 1055724137,
        3392581687,  213217736, 3047409731, 2134151289, 2553067370, 2969120916,
        2293768477, 1618302669,  184738216, 1829492105, 1438364301,  143975391,
        3488855025, 1525393396,  484788782, 1824160758, 3278914432, 1791042494,
        2531399103, 1976393697,  267524578, 1415973226, 3055112374, 2304304850,
        2970740983,  463733153,  470323953,  172504368,  314487920,  565768019,
        1325206124,    3902063, 2558324563, 2631782915, 3561616031, 2061569113,
        1776804911, 3574237973,  226132407,  361666075, 1514025674, 2274739441,
         125808586,  613763319, 1680587044,   50300193, 1625798297, 1321548596,
        3372445782, 1162803676, 1779255988, 2824765390, 1859433431, 2244623276,
        2673542557, 2014397343,  787107922, 1470797842,  653592026, 3063416664,
        2396187549,   39784734,  782941200, 2597902117, 1950931722,  539301441,
         881167165, 2566715114, 1143946729, 1063252333,  374533248, 2050371892,
        3306915207,  552684244, 1631811769,  588251379,  562506265,   42541411,
        1864901246, 2976754698, 1822251476,  641961590,  819864454, 3489874270,
        3553458922, 3534464258, 1694742715, 1593217661,  209704235, 1093043746,
        2390506997,   76009729,   77103172, 2606303238])
Rank=1, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.007437, per step: 0.000030
presamping
presamping takes 14.061785221099854
worker 3 running with pid=32102
loading train edge idx from disk
loading train edge idx from disk done
tensor([ 312558501,  165303846,  382592436, 3465360478, 1289294319, 1055724137,
        3392581687,  213217736, 3047409731, 2134151289, 2553067370, 2969120916,
        2293768477, 1618302669,  184738216, 1829492105, 1438364301,  143975391,
        3488855025, 1525393396,  484788782, 1824160758, 3278914432, 1791042494,
        2531399103, 1976393697,  267524578, 1415973226, 3055112374, 2304304850,
        2970740983,  463733153,  470323953,  172504368,  314487920,  565768019,
        1325206124,    3902063, 2558324563, 2631782915, 3561616031, 2061569113,
        1776804911, 3574237973,  226132407,  361666075, 1514025674, 2274739441,
         125808586,  613763319, 1680587044,   50300193, 1625798297, 1321548596,
        3372445782, 1162803676, 1779255988, 2824765390, 1859433431, 2244623276,
        2673542557, 2014397343,  787107922, 1470797842,  653592026, 3063416664,
        2396187549,   39784734,  782941200, 2597902117, 1950931722,  539301441,
         881167165, 2566715114, 1143946729, 1063252333,  374533248, 2050371892,
        3306915207,  552684244, 1631811769,  588251379,  562506265,   42541411,
        1864901246, 2976754698, 1822251476,  641961590,  819864454, 3489874270,
        3553458922, 3534464258, 1694742715, 1593217661,  209704235, 1093043746,
        2390506997,   76009729,   77103172, 2606303238])
Rank=3, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.007412, per step: 0.000030
presamping
presamping takes 14.467580795288086
worker 2 running with pid=32101
loading train edge idx from disk
loading train edge idx from disk done
tensor([ 312558501,  165303846,  382592436, 3465360478, 1289294319, 1055724137,
        3392581687,  213217736, 3047409731, 2134151289, 2553067370, 2969120916,
        2293768477, 1618302669,  184738216, 1829492105, 1438364301,  143975391,
        3488855025, 1525393396,  484788782, 1824160758, 3278914432, 1791042494,
        2531399103, 1976393697,  267524578, 1415973226, 3055112374, 2304304850,
        2970740983,  463733153,  470323953,  172504368,  314487920,  565768019,
        1325206124,    3902063, 2558324563, 2631782915, 3561616031, 2061569113,
        1776804911, 3574237973,  226132407,  361666075, 1514025674, 2274739441,
         125808586,  613763319, 1680587044,   50300193, 1625798297, 1321548596,
        3372445782, 1162803676, 1779255988, 2824765390, 1859433431, 2244623276,
        2673542557, 2014397343,  787107922, 1470797842,  653592026, 3063416664,
        2396187549,   39784734,  782941200, 2597902117, 1950931722,  539301441,
         881167165, 2566715114, 1143946729, 1063252333,  374533248, 2050371892,
        3306915207,  552684244, 1631811769,  588251379,  562506265,   42541411,
        1864901246, 2976754698, 1822251476,  641961590,  819864454, 3489874270,
        3553458922, 3534464258, 1694742715, 1593217661,  209704235, 1093043746,
        2390506997,   76009729,   77103172, 2606303238])
Rank=2, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.015266, per step: 0.000061
presamping
presamping takes 14.270487546920776

