succeed=True
[CUDA] cuda: usage: 5.32 GB
0 :  {link #0 : 1}, {link #1 : 2}, {link #2 : 3},
1 :  {link #0 : 2}, {link #1 : 3}, {link #2 : 0},
2 :  {link #0 : 3}, {link #1 : 0}, {link #2 : 1},
3 :  {link #0 : 0}, {link #1 : 1}, {link #2 : 2},
0 :  {link #0 : 1}, {link #1 : 2}, {link #2 : 3},
1 :  {link #0 : 2}, {link #1 : 3}, {link #2 : 0},
2 :  {link #0 : 3}, {link #1 : 0}, {link #2 : 1},
3 :  {link #0 : 0}, {link #1 : 1}, {link #2 : 2},
0 :  {link #0 : 1}, {link #1 : 2}, {link #2 : 3},
1 :  {link #0 : 2}, {link #1 : 3}, {link #2 : 0},
2 :  {link #0 : 3}, {link #1 : 0}, {link #2 : 1},
3 :  {link #0 : 0}, {link #1 : 1}, {link #2 : 2},
0 : local 80, cpu 0 {link #0 : g1 0}, {link #1 : g2 0}, {link #2 : g3 0},
1 : local 80, cpu 0 {link #0 : g2 0}, {link #1 : g3 0}, {link #2 : g0 0},
2 : local 80, cpu 0 {link #0 : g3 0}, {link #1 : g0 0}, {link #2 : g1 0},
3 : local 80, cpu 0 {link #0 : g0 0}, {link #1 : g1 0}, {link #2 : g2 0},
0 : local 80, cpu 0 {link #0 : g1 0}, {link #1 : g2 0}, {link #2 : g3 0},
1 : local 80, cpu 0 {link #0 : g2 0}, {link #1 : g3 0}, {link #2 : g0 0},
2 : local 80, cpu 0 {link #0 : g3 0}, {link #1 : g0 0}, {link #2 : g1 0},
3 : local 80, cpu 0 {link #0 : g0 0}, {link #1 : g1 0}, {link #2 : g2 0},
0 : local 80, cpu 0 {link #0 : g1 0}, {link #1 : g2 0}, {link #2 : g3 0},
1 : local 80, cpu 0 {link #0 : g2 0}, {link #1 : g3 0}, {link #2 : g0 0},
2 : local 80, cpu 0 {link #0 : g3 0}, {link #1 : g0 0}, {link #2 : g1 0},
3 : local 80, cpu 0 {link #0 : g0 0}, {link #1 : g1 0}, {link #2 : g2 0},
0 :  {link #0 : 1}, {link #1 : 2}, {link #2 : 3},
1 :  {link #0 : 2}, {link #1 : 3}, {link #2 : 0},
2 :  {link #0 : 3}, {link #1 : 0}, {link #2 : 1},
3 :  {link #0 : 0}, {link #1 : 1}, {link #2 : 2},
0 : local 80, cpu 0 {link #0 : g1 0}, {link #1 : g2 0}, {link #2 : g3 0},
1 : local 80, cpu 0 {link #0 : g2 0}, {link #1 : g3 0}, {link #2 : g0 0},
2 : local 80, cpu 0 {link #0 : g3 0}, {link #1 : g0 0}, {link #2 : g1 0},
3 : local 80, cpu 0 {link #0 : g0 0}, {link #1 : g1 0}, {link #2 : g2 0},
coll_cache:optimal_rep_storage=0
coll_cache:optimal_part_storage=0.28
coll_cache:optimal_cpu_storage=0.72
coll_cache:optimal_local_storage=0.07
coll_cache:optimal_remote_storage=0.21
coll_cache:optimal_local_rate=0.217947
coll_cache:optimal_remote_rate=0.653842
coll_cache:optimal_cpu_rate=0.128211
z=15468.2,15468.2,15468.2,15468.2,
test_result:init:feat_nbytes=67182966784
test_result:init:cache_nbytes=4769989632
test_result:init:feat_nbytes=67182966784
test_result:init:cache_nbytes=4769989632
test_result:init:feat_nbytes=67182966784
test_result:init:cache_nbytes=4769989632
test_result:init:feat_nbytes=67182966784
test_result:init:cache_nbytes=4769989632
config:eval_tsp="2023-08-04 19:21:11"
config:num_worker=4
config:num_intra_size=4
config:root_dir=/datasets_gnn/wholegraph
config:graph_name=com-friendster
config:epochs=4
config:batchsize=2000
config:skip_epoch=2
config:local_step=250
config:presc_epoch=2
config:neighbors=15,10,5
config:hiddensize=256
config:num_layer=3
config:model=gcn
config:framework=dgl
config:dataloaderworkers=0
config:dropout=0.5
config:weight_decay=0.0005
config:lr=0.003
config:use_nccl=False
config:use_amp=True
config:use_collcache=True
config:cache_percentage=0.07
config:cache_policy=clique_part
config:omp_thread_num=40
config:unsupervised=False
config:classnum=100
config:global_barrier=<multiprocessing.synchronize.Barrier object at 0x7f9ac3e0f7f0>
config:worker_id=0
creating_intra_node_communicator root=0, local_size=4, world_size=4
Rank=0, Graph loaded.
!!!!Train_dataloader(with 125 items) enumerate latency: 0.39749836921691895
torch.Size([2000]) torch.Size([2000])
torch.Size([2104]) torch.Size([2104])
!!!!Train_data_list(with 125 items) enumerate latency: 1.1205673217773438e-05, transfer latency: 0.38605761528015137
epoch=4 total_steps=500
presamping
presamping takes 5.836712837219238
start training...
[Epoch 0][Step 0], time=1.1854441165924072, ext_time=0.0206756591796875, train_time=1.1579070091247559
[Epoch 0][Step 1], time=0.04346871376037598, ext_time=0.015091896057128906, train_time=0.021683454513549805
[Epoch 0][Step 2], time=0.039487361907958984, ext_time=0.014854669570922852, train_time=0.01964116096496582
[Epoch 0][Step 3], time=0.03893923759460449, ext_time=0.01482391357421875, train_time=0.019187211990356445
[Epoch 0][Step 4], time=0.039307355880737305, ext_time=0.01488804817199707, train_time=0.019455432891845703
[Epoch 0][Step 5], time=0.03848624229431152, ext_time=0.014516353607177734, train_time=0.019048213958740234
[Epoch 0][Step 6], time=0.03879857063293457, ext_time=0.01463007926940918, train_time=0.01929783821105957
[Epoch 0][Step 7], time=0.03917527198791504, ext_time=0.014668941497802734, train_time=0.019607067108154297
[Epoch 0][Step 8], time=0.038526296615600586, ext_time=0.014380693435668945, train_time=0.01935124397277832
[Epoch 0][Step 9], time=0.0394444465637207, ext_time=0.014938592910766602, train_time=0.019573211669921875
[Epoch 0][Step 10], time=0.03928351402282715, ext_time=0.015016317367553711, train_time=0.019292116165161133
[Epoch 0][Step 11], time=0.03895688056945801, ext_time=0.014903068542480469, train_time=0.019133329391479492
[Epoch 0][Step 12], time=0.039381980895996094, ext_time=0.015040159225463867, train_time=0.019382953643798828
[Epoch 0][Step 13], time=0.03891181945800781, ext_time=0.014684200286865234, train_time=0.01931309700012207
[Epoch 0][Step 14], time=0.0392765998840332, ext_time=0.014998435974121094, train_time=0.019276142120361328
[Epoch 0][Step 15], time=0.0393671989440918, ext_time=0.014901161193847656, train_time=0.019512414932250977
[Epoch 0][Step 16], time=0.03937864303588867, ext_time=0.015043020248413086, train_time=0.01935267448425293
[Epoch 0][Step 17], time=0.03931117057800293, ext_time=0.014627933502197266, train_time=0.01981520652770996
[Epoch 0][Step 18], time=0.03925490379333496, ext_time=0.014882564544677734, train_time=0.0194551944732666
[Epoch 0][Step 19], time=0.039217472076416016, ext_time=0.014768838882446289, train_time=0.019547700881958008
[Epoch 0][Step 20], time=0.03960108757019043, ext_time=0.015105247497558594, train_time=0.019435882568359375
[Epoch 0][Step 21], time=0.03945469856262207, ext_time=0.015021085739135742, train_time=0.019472599029541016
[Epoch 0][Step 22], time=0.03958940505981445, ext_time=0.014494657516479492, train_time=0.020267724990844727
[Epoch 0][Step 23], time=0.040749311447143555, ext_time=0.015046358108520508, train_time=0.020714282989501953
[Epoch 0][Step 24], time=0.03943634033203125, ext_time=0.015017032623291016, train_time=0.019411325454711914
[Epoch 0][Step 25], time=0.03937816619873047, ext_time=0.014664173126220703, train_time=0.019838333129882812
[Epoch 0][Step 26], time=0.04072093963623047, ext_time=0.015002012252807617, train_time=0.02075362205505371
[Epoch 0][Step 27], time=0.041414499282836914, ext_time=0.014608621597290039, train_time=0.021954774856567383
[Epoch 0][Step 28], time=0.039285898208618164, ext_time=0.01510310173034668, train_time=0.019167184829711914
[Epoch 0][Step 29], time=0.040398359298706055, ext_time=0.014982223510742188, train_time=0.020479202270507812
[Epoch 0][Step 30], time=0.03904390335083008, ext_time=0.014801740646362305, train_time=0.019304990768432617
[Epoch 0][Step 31], time=0.03984856605529785, ext_time=0.015289783477783203, train_time=0.019505023956298828
[Epoch 0][Step 32], time=0.03949594497680664, ext_time=0.014805078506469727, train_time=0.01974201202392578
[Epoch 0][Step 33], time=0.038887977600097656, ext_time=0.014780759811401367, train_time=0.01920151710510254
[Epoch 0][Step 34], time=0.03912758827209473, ext_time=0.014737129211425781, train_time=0.019547700881958008
[Epoch 0][Step 35], time=0.03990817070007324, ext_time=0.014321327209472656, train_time=0.02078700065612793
[Epoch 0][Step 36], time=0.0398256778717041, ext_time=0.01491689682006836, train_time=0.019970417022705078
[Epoch 0][Step 37], time=0.039581298828125, ext_time=0.015161991119384766, train_time=0.019362449645996094
[Epoch 0][Step 38], time=0.0399017333984375, ext_time=0.014941930770874023, train_time=0.020020484924316406
[Epoch 0][Step 39], time=0.03991246223449707, ext_time=0.014238119125366211, train_time=0.020920276641845703
[Epoch 0][Step 40], time=0.0395512580871582, ext_time=0.014946222305297852, train_time=0.0196533203125
[Epoch 0][Step 41], time=0.03963804244995117, ext_time=0.014805793762207031, train_time=0.01989126205444336
[Epoch 0][Step 42], time=0.03887796401977539, ext_time=0.014673471450805664, train_time=0.01931476593017578
[Epoch 0][Step 43], time=0.039246559143066406, ext_time=0.014812469482421875, train_time=0.01953291893005371
[Epoch 0][Step 44], time=0.039508819580078125, ext_time=0.014952421188354492, train_time=0.01960444450378418
[Epoch 0][Step 45], time=0.03887605667114258, ext_time=0.014853954315185547, train_time=0.01907658576965332
[Epoch 0][Step 46], time=0.04179692268371582, ext_time=0.015175819396972656, train_time=0.021682024002075195
[Epoch 0][Step 47], time=0.04006171226501465, ext_time=0.015095949172973633, train_time=0.02017688751220703
[Epoch 0][Step 48], time=0.03999614715576172, ext_time=0.014899492263793945, train_time=0.02002739906311035
[Epoch 0][Step 49], time=0.039377450942993164, ext_time=0.014982461929321289, train_time=0.019433975219726562
[Epoch 0][Step 50], time=0.03949332237243652, ext_time=0.014569520950317383, train_time=0.020087718963623047
[Epoch 0][Step 51], time=0.03966188430786133, ext_time=0.014763832092285156, train_time=0.019952774047851562
[Epoch 0][Step 52], time=0.03974103927612305, ext_time=0.014906644821166992, train_time=0.019893884658813477
[Epoch 0][Step 53], time=0.03916144371032715, ext_time=0.014594554901123047, train_time=0.01972222328186035
[Epoch 0][Step 54], time=0.04031777381896973, ext_time=0.014783143997192383, train_time=0.020660877227783203
[Epoch 0][Step 55], time=0.03907132148742676, ext_time=0.014379262924194336, train_time=0.019867420196533203
[Epoch 0][Step 56], time=0.040040016174316406, ext_time=0.014427900314331055, train_time=0.020815372467041016
[Epoch 0][Step 57], time=0.0392913818359375, ext_time=0.014789342880249023, train_time=0.019611120223999023
[Epoch 0][Step 58], time=0.03956961631774902, ext_time=0.014407634735107422, train_time=0.0203704833984375
[Epoch 0][Step 59], time=0.039476633071899414, ext_time=0.014927148818969727, train_time=0.019561290740966797
[Epoch 0][Step 60], time=0.03905296325683594, ext_time=0.014594793319702148, train_time=0.019585609436035156
[Epoch 0][Step 61], time=0.04051661491394043, ext_time=0.014958620071411133, train_time=0.020616769790649414
[Epoch 0][Step 62], time=0.03969907760620117, ext_time=0.014577865600585938, train_time=0.020291566848754883
[Epoch 0][Step 63], time=0.039614200592041016, ext_time=0.014495372772216797, train_time=0.020208358764648438
[Epoch 0][Step 64], time=0.03962540626525879, ext_time=0.014728784561157227, train_time=0.020002365112304688
[Epoch 0][Step 65], time=0.039130210876464844, ext_time=0.014689207077026367, train_time=0.019543170928955078
[Epoch 0][Step 66], time=0.03969097137451172, ext_time=0.014743328094482422, train_time=0.02005910873413086
[Epoch 0][Step 67], time=0.04051804542541504, ext_time=0.014932870864868164, train_time=0.02052903175354004
[Epoch 0][Step 68], time=0.039034128189086914, ext_time=0.014630794525146484, train_time=0.019525766372680664
[Epoch 0][Step 69], time=0.038457393646240234, ext_time=0.014528989791870117, train_time=0.019095182418823242
[Epoch 0][Step 70], time=0.03937649726867676, ext_time=0.014809370040893555, train_time=0.019667387008666992
[Epoch 0][Step 71], time=0.03909564018249512, ext_time=0.014926671981811523, train_time=0.019187211990356445
[Epoch 0][Step 72], time=0.03950929641723633, ext_time=0.015132427215576172, train_time=0.019429922103881836
[Epoch 0][Step 73], time=0.03945612907409668, ext_time=0.014709234237670898, train_time=0.019854068756103516
[Epoch 0][Step 74], time=0.03927302360534668, ext_time=0.014415979385375977, train_time=0.02004408836364746
[Epoch 0][Step 75], time=0.039601802825927734, ext_time=0.014674663543701172, train_time=0.0200502872467041
[Epoch 0][Step 76], time=0.03989815711975098, ext_time=0.014787435531616211, train_time=0.020200729370117188
[Epoch 0][Step 77], time=0.03974437713623047, ext_time=0.015211105346679688, train_time=0.019512176513671875
[Epoch 0][Step 78], time=0.0395967960357666, ext_time=0.014594554901123047, train_time=0.020104169845581055
[Epoch 0][Step 79], time=0.040076255798339844, ext_time=0.014851570129394531, train_time=0.02038264274597168
[Epoch 0][Step 80], time=0.03872513771057129, ext_time=0.014770269393920898, train_time=0.018908023834228516
[Epoch 0][Step 81], time=0.039450883865356445, ext_time=0.014688968658447266, train_time=0.019893646240234375
[Epoch 0][Step 82], time=0.03937792778015137, ext_time=0.014630794525146484, train_time=0.01987290382385254
[Epoch 0][Step 83], time=0.03944087028503418, ext_time=0.014950275421142578, train_time=0.019569873809814453
[Epoch 0][Step 84], time=0.0397944450378418, ext_time=0.014652013778686523, train_time=0.020243406295776367
[Epoch 0][Step 85], time=0.041327714920043945, ext_time=0.015114068984985352, train_time=0.021233320236206055
[Epoch 0][Step 86], time=0.039618492126464844, ext_time=0.014999628067016602, train_time=0.019609928131103516
[Epoch 0][Step 87], time=0.039578914642333984, ext_time=0.015122175216674805, train_time=0.01947617530822754
[Epoch 0][Step 88], time=0.03923606872558594, ext_time=0.014622688293457031, train_time=0.01978898048400879
[Epoch 0][Step 89], time=0.038609981536865234, ext_time=0.014747142791748047, train_time=0.018949270248413086
[Epoch 0][Step 90], time=0.03957366943359375, ext_time=0.014798879623413086, train_time=0.019896507263183594
[Epoch 0][Step 91], time=0.03901219367980957, ext_time=0.014614582061767578, train_time=0.019551515579223633
[Epoch 0][Step 92], time=0.039876699447631836, ext_time=0.015247583389282227, train_time=0.019587039947509766
[Epoch 0][Step 93], time=0.03997206687927246, ext_time=0.015221834182739258, train_time=0.019774675369262695
[Epoch 0][Step 94], time=0.03914308547973633, ext_time=0.015037298202514648, train_time=0.019140005111694336
[Epoch 0][Step 95], time=0.039399147033691406, ext_time=0.014704704284667969, train_time=0.019846439361572266
[Epoch 0][Step 96], time=0.04009890556335449, ext_time=0.014672279357910156, train_time=0.020580291748046875
[Epoch 0][Step 97], time=0.0388340950012207, ext_time=0.01462101936340332, train_time=0.019393444061279297
[Epoch 0][Step 98], time=0.041056156158447266, ext_time=0.014762163162231445, train_time=0.021230697631835938
[Epoch 0][Step 99], time=0.03949904441833496, ext_time=0.014657735824584961, train_time=0.01996636390686035
[Epoch 0][Step 100], time=0.04022622108459473, ext_time=0.014746427536010742, train_time=0.02060222625732422
[Epoch 0][Step 101], time=0.039467573165893555, ext_time=0.014884233474731445, train_time=0.019652605056762695
[Epoch 0][Step 102], time=0.041948795318603516, ext_time=0.014711380004882812, train_time=0.02235889434814453
[Epoch 0][Step 103], time=0.03928995132446289, ext_time=0.014880180358886719, train_time=0.019353151321411133
[Epoch 0][Step 104], time=0.03904891014099121, ext_time=0.01500248908996582, train_time=0.019064664840698242
[Epoch 0][Step 105], time=0.04012489318847656, ext_time=0.014335393905639648, train_time=0.021010637283325195
[Epoch 0][Step 106], time=0.039855003356933594, ext_time=0.01464223861694336, train_time=0.02032613754272461
[Epoch 0][Step 107], time=0.0394597053527832, ext_time=0.014984130859375, train_time=0.019553422927856445
[Epoch 0][Step 108], time=0.03934288024902344, ext_time=0.014795541763305664, train_time=0.01962566375732422
[Epoch 0][Step 109], time=0.03960227966308594, ext_time=0.014812469482421875, train_time=0.019836902618408203
[Epoch 0][Step 110], time=0.03931689262390137, ext_time=0.01497340202331543, train_time=0.019381046295166016
[Epoch 0][Step 111], time=0.03992938995361328, ext_time=0.014710187911987305, train_time=0.02036118507385254
[Epoch 0][Step 112], time=0.03967761993408203, ext_time=0.015129566192626953, train_time=0.019542217254638672
[Epoch 0][Step 113], time=0.0396728515625, ext_time=0.014744043350219727, train_time=0.020046472549438477
[Epoch 0][Step 114], time=0.03978705406188965, ext_time=0.014708995819091797, train_time=0.02020573616027832
[Epoch 0][Step 115], time=0.039807796478271484, ext_time=0.014741897583007812, train_time=0.020171403884887695
[Epoch 0][Step 116], time=0.03911590576171875, ext_time=0.01464390754699707, train_time=0.0195920467376709
[Epoch 0][Step 117], time=0.04056096076965332, ext_time=0.015145301818847656, train_time=0.020431041717529297
[Epoch 0][Step 118], time=0.03947019577026367, ext_time=0.015071868896484375, train_time=0.019331693649291992
[Epoch 0][Step 119], time=0.03890371322631836, ext_time=0.014842033386230469, train_time=0.019162416458129883
[Epoch 0][Step 120], time=0.039603471755981445, ext_time=0.014857292175292969, train_time=0.01983952522277832
[Epoch 0][Step 121], time=0.039392948150634766, ext_time=0.014905214309692383, train_time=0.01957869529724121
[Epoch 0][Step 122], time=0.04022073745727539, ext_time=0.014782428741455078, train_time=0.020516633987426758
[Epoch 0][Step 123], time=0.039098262786865234, ext_time=0.014855384826660156, train_time=0.019272327423095703
[Epoch 0][Step 124], time=0.03954911231994629, ext_time=0.014769315719604492, train_time=0.019875526428222656
[Epoch 0], time=6.106085300445557, loss=3.874769449234009
[Epoch 1][Step 0], time=0.04313516616821289, ext_time=0.015459537506103516, train_time=0.022522926330566406
[Epoch 1][Step 1], time=0.03977799415588379, ext_time=0.01507115364074707, train_time=0.019234418869018555
[Epoch 1][Step 2], time=0.03960871696472168, ext_time=0.014790534973144531, train_time=0.01992654800415039
[Epoch 1][Step 3], time=0.03931307792663574, ext_time=0.01495051383972168, train_time=0.01948857307434082
[Epoch 1][Step 4], time=0.03974008560180664, ext_time=0.014870405197143555, train_time=0.019916296005249023
[Epoch 1][Step 5], time=0.03889966011047363, ext_time=0.014448165893554688, train_time=0.019639015197753906
[Epoch 1][Step 6], time=0.03893589973449707, ext_time=0.014670133590698242, train_time=0.019406795501708984
[Epoch 1][Step 7], time=0.038863182067871094, ext_time=0.014693021774291992, train_time=0.019308090209960938
[Epoch 1][Step 8], time=0.038709163665771484, ext_time=0.014402627944946289, train_time=0.01952505111694336
[Epoch 1][Step 9], time=0.03908991813659668, ext_time=0.014927864074707031, train_time=0.01927971839904785
[Epoch 1][Step 10], time=0.039296865463256836, ext_time=0.014989376068115234, train_time=0.01930832862854004
[Epoch 1][Step 11], time=0.039014577865600586, ext_time=0.01488637924194336, train_time=0.019221782684326172
[Epoch 1][Step 12], time=0.0413966178894043, ext_time=0.014998674392700195, train_time=0.021450519561767578
[Epoch 1][Step 13], time=0.039483070373535156, ext_time=0.014692306518554688, train_time=0.019889354705810547
[Epoch 1][Step 14], time=0.03909111022949219, ext_time=0.01494908332824707, train_time=0.019144535064697266
[Epoch 1][Step 15], time=0.039185523986816406, ext_time=0.014942169189453125, train_time=0.0192718505859375
[Epoch 1][Step 16], time=0.03947305679321289, ext_time=0.014969587326049805, train_time=0.019545793533325195
[Epoch 1][Step 17], time=0.03926682472229004, ext_time=0.01465749740600586, train_time=0.01976633071899414
[Epoch 1][Step 18], time=0.039339303970336914, ext_time=0.014809370040893555, train_time=0.019617319107055664
[Epoch 1][Step 19], time=0.03928518295288086, ext_time=0.014738321304321289, train_time=0.01966094970703125
[Epoch 1][Step 20], time=0.03943490982055664, ext_time=0.015105009078979492, train_time=0.019327878952026367
[Epoch 1][Step 21], time=0.03953099250793457, ext_time=0.015061140060424805, train_time=0.019418716430664062
[Epoch 1][Step 22], time=0.039374589920043945, ext_time=0.014428138732910156, train_time=0.02011394500732422
[Epoch 1][Step 23], time=0.03948545455932617, ext_time=0.014966249465942383, train_time=0.019541501998901367
[Epoch 1][Step 24], time=0.03921222686767578, ext_time=0.01501154899597168, train_time=0.019234418869018555
[Epoch 1][Step 25], time=0.03995037078857422, ext_time=0.014688491821289062, train_time=0.020394086837768555
[Epoch 1][Step 26], time=0.03919649124145508, ext_time=0.01497650146484375, train_time=0.019280433654785156
[Epoch 1][Step 27], time=0.03911399841308594, ext_time=0.014538764953613281, train_time=0.019731760025024414
[Epoch 1][Step 28], time=0.039396047592163086, ext_time=0.015053272247314453, train_time=0.019379138946533203
[Epoch 1][Step 29], time=0.0393218994140625, ext_time=0.014958620071411133, train_time=0.019455432891845703
[Epoch 1][Step 30], time=0.03920102119445801, ext_time=0.014823675155639648, train_time=0.01948261260986328
[Epoch 1][Step 31], time=0.03958320617675781, ext_time=0.015237569808959961, train_time=0.019348621368408203
[Epoch 1][Step 32], time=0.039263248443603516, ext_time=0.014770269393920898, train_time=0.019623994827270508
[Epoch 1][Step 33], time=0.03879857063293457, ext_time=0.014878034591674805, train_time=0.019014596939086914
[Epoch 1][Step 34], time=0.03917121887207031, ext_time=0.014831304550170898, train_time=0.019510507583618164
[Epoch 1][Step 35], time=0.03993582725524902, ext_time=0.014372110366821289, train_time=0.02078700065612793
[Epoch 1][Step 36], time=0.03959345817565918, ext_time=0.014944314956665039, train_time=0.019714832305908203
[Epoch 1][Step 37], time=0.04053497314453125, ext_time=0.015311717987060547, train_time=0.020226478576660156
[Epoch 1][Step 38], time=0.04055595397949219, ext_time=0.014892339706420898, train_time=0.020741939544677734
[Epoch 1][Step 39], time=0.039273977279663086, ext_time=0.014258384704589844, train_time=0.020174026489257812
[Epoch 1][Step 40], time=0.03936171531677246, ext_time=0.014969825744628906, train_time=0.019451379776000977
[Epoch 1][Step 41], time=0.03996706008911133, ext_time=0.014829874038696289, train_time=0.020212888717651367
[Epoch 1][Step 42], time=0.03894400596618652, ext_time=0.014657258987426758, train_time=0.019400596618652344
[Epoch 1][Step 43], time=0.039153337478637695, ext_time=0.014796733856201172, train_time=0.019452333450317383
[Epoch 1][Step 44], time=0.03927183151245117, ext_time=0.014923572540283203, train_time=0.019410133361816406
[Epoch 1][Step 45], time=0.03953218460083008, ext_time=0.01493072509765625, train_time=0.019638776779174805
[Epoch 1][Step 46], time=0.03925776481628418, ext_time=0.015014886856079102, train_time=0.019277095794677734
[Epoch 1][Step 47], time=0.03990435600280762, ext_time=0.014371633529663086, train_time=0.020776033401489258
[Epoch 1][Step 48], time=0.04046273231506348, ext_time=0.014978170394897461, train_time=0.020565271377563477
[Epoch 1][Step 49], time=0.03949308395385742, ext_time=0.015008687973022461, train_time=0.01955413818359375
[Epoch 1][Step 50], time=0.03943204879760742, ext_time=0.014551162719726562, train_time=0.020054101943969727
[Epoch 1][Step 51], time=0.03918719291687012, ext_time=0.014591455459594727, train_time=0.019774436950683594
[Epoch 1][Step 52], time=0.04035830497741699, ext_time=0.014951944351196289, train_time=0.020485639572143555
[Epoch 1][Step 53], time=0.03909754753112793, ext_time=0.014586925506591797, train_time=0.019683361053466797
[Epoch 1][Step 54], time=0.03922319412231445, ext_time=0.014719247817993164, train_time=0.0196378231048584
[Epoch 1][Step 55], time=0.039108991622924805, ext_time=0.014373779296875, train_time=0.019944190979003906
[Epoch 1][Step 56], time=0.03978848457336426, ext_time=0.014438152313232422, train_time=0.02053666114807129
[Epoch 1][Step 57], time=0.039034366607666016, ext_time=0.014787673950195312, train_time=0.019355297088623047
[Epoch 1][Step 58], time=0.03948521614074707, ext_time=0.01439046859741211, train_time=0.020344257354736328
[Epoch 1][Step 59], time=0.039345741271972656, ext_time=0.01483297348022461, train_time=0.01961040496826172
[Epoch 1][Step 60], time=0.03886246681213379, ext_time=0.014625310897827148, train_time=0.019382953643798828
[Epoch 1][Step 61], time=0.0396265983581543, ext_time=0.014893293380737305, train_time=0.019810914993286133
[Epoch 1][Step 62], time=0.039812326431274414, ext_time=0.01453709602355957, train_time=0.020419597625732422
[Epoch 1][Step 63], time=0.039795637130737305, ext_time=0.014459609985351562, train_time=0.020498275756835938
[Epoch 1][Step 64], time=0.039624929428100586, ext_time=0.014744043350219727, train_time=0.019964218139648438
[Epoch 1][Step 65], time=0.03947806358337402, ext_time=0.014639616012573242, train_time=0.019986867904663086
[Epoch 1][Step 66], time=0.040265560150146484, ext_time=0.014870166778564453, train_time=0.020503520965576172
[Epoch 1][Step 67], time=0.03915548324584961, ext_time=0.014917135238647461, train_time=0.019266128540039062
[Epoch 1][Step 68], time=0.0388031005859375, ext_time=0.014677286148071289, train_time=0.019246816635131836
[Epoch 1][Step 69], time=0.038605690002441406, ext_time=0.014504194259643555, train_time=0.019278764724731445
[Epoch 1][Step 70], time=0.04191088676452637, ext_time=0.014840841293334961, train_time=0.02213740348815918
[Epoch 1][Step 71], time=0.0389552116394043, ext_time=0.014935731887817383, train_time=0.019097566604614258
[Epoch 1][Step 72], time=0.039234161376953125, ext_time=0.01499032974243164, train_time=0.01932239532470703
[Epoch 1][Step 73], time=0.03959536552429199, ext_time=0.014669656753540039, train_time=0.020047903060913086
[Epoch 1][Step 74], time=0.03906893730163574, ext_time=0.014457464218139648, train_time=0.019793033599853516
[Epoch 1][Step 75], time=0.03979635238647461, ext_time=0.014704465866088867, train_time=0.020229816436767578
[Epoch 1][Step 76], time=0.04005002975463867, ext_time=0.014792203903198242, train_time=0.0203704833984375
[Epoch 1][Step 77], time=0.03973817825317383, ext_time=0.015240669250488281, train_time=0.019467592239379883
[Epoch 1][Step 78], time=0.03970217704772949, ext_time=0.014532327651977539, train_time=0.02031540870666504
[Epoch 1][Step 79], time=0.03917717933654785, ext_time=0.014682292938232422, train_time=0.019654035568237305
[Epoch 1][Step 80], time=0.03885197639465332, ext_time=0.014772891998291016, train_time=0.019204139709472656
[Epoch 1][Step 81], time=0.03965115547180176, ext_time=0.01458597183227539, train_time=0.020186901092529297
[Epoch 1][Step 82], time=0.03931903839111328, ext_time=0.014716625213623047, train_time=0.01973414421081543
[Epoch 1][Step 83], time=0.03945159912109375, ext_time=0.014845609664916992, train_time=0.019663572311401367
[Epoch 1][Step 84], time=0.03986668586730957, ext_time=0.014693260192871094, train_time=0.020290374755859375
[Epoch 1][Step 85], time=0.03994488716125488, ext_time=0.01503443717956543, train_time=0.019914627075195312
[Epoch 1][Step 86], time=0.039459228515625, ext_time=0.015020132064819336, train_time=0.019448280334472656
[Epoch 1][Step 87], time=0.0419313907623291, ext_time=0.015073537826538086, train_time=0.021897077560424805
[Epoch 1][Step 88], time=0.03888559341430664, ext_time=0.014578580856323242, train_time=0.019352436065673828
[Epoch 1][Step 89], time=0.038574934005737305, ext_time=0.014777660369873047, train_time=0.018848180770874023
[Epoch 1][Step 90], time=0.0394892692565918, ext_time=0.01482391357421875, train_time=0.01980113983154297
[Epoch 1][Step 91], time=0.0391998291015625, ext_time=0.014662981033325195, train_time=0.019691944122314453
[Epoch 1][Step 92], time=0.03950834274291992, ext_time=0.01519012451171875, train_time=0.01930546760559082
[Epoch 1][Step 93], time=0.03983879089355469, ext_time=0.01519012451171875, train_time=0.019693613052368164
[Epoch 1][Step 94], time=0.03909635543823242, ext_time=0.014949560165405273, train_time=0.019215106964111328
[Epoch 1][Step 95], time=0.03934144973754883, ext_time=0.014745950698852539, train_time=0.019742250442504883
[Epoch 1][Step 96], time=0.04021954536437988, ext_time=0.014696836471557617, train_time=0.019435644149780273
[Epoch 1][Step 97], time=0.03905487060546875, ext_time=0.014649629592895508, train_time=0.019552946090698242
[Epoch 1][Step 98], time=0.039038658142089844, ext_time=0.014600992202758789, train_time=0.019606828689575195
[Epoch 1][Step 99], time=0.039441585540771484, ext_time=0.014633893966674805, train_time=0.01994919776916504
[Epoch 1][Step 100], time=0.03957176208496094, ext_time=0.01470327377319336, train_time=0.019999027252197266
[Epoch 1][Step 101], time=0.039671897888183594, ext_time=0.014924764633178711, train_time=0.019800186157226562
[Epoch 1][Step 102], time=0.04007577896118164, ext_time=0.014688253402709961, train_time=0.02051997184753418
[Epoch 1][Step 103], time=0.0393221378326416, ext_time=0.01482844352722168, train_time=0.019568204879760742
[Epoch 1][Step 104], time=0.039309024810791016, ext_time=0.01508331298828125, train_time=0.019284725189208984
[Epoch 1][Step 105], time=0.03996467590332031, ext_time=0.014262914657592773, train_time=0.02090907096862793
[Epoch 1][Step 106], time=0.040140628814697266, ext_time=0.014579057693481445, train_time=0.020702362060546875
[Epoch 1][Step 107], time=0.03892350196838379, ext_time=0.014940738677978516, train_time=0.01906609535217285
[Epoch 1][Step 108], time=0.03917980194091797, ext_time=0.014792680740356445, train_time=0.019482851028442383
[Epoch 1][Step 109], time=0.039465904235839844, ext_time=0.014864921569824219, train_time=0.019681215286254883
[Epoch 1][Step 110], time=0.03931903839111328, ext_time=0.014891386032104492, train_time=0.019488811492919922
[Epoch 1][Step 111], time=0.03986215591430664, ext_time=0.014666080474853516, train_time=0.020335674285888672
[Epoch 1][Step 112], time=0.039612531661987305, ext_time=0.015166044235229492, train_time=0.019459962844848633
[Epoch 1][Step 113], time=0.03960251808166504, ext_time=0.014791727066040039, train_time=0.019901275634765625
[Epoch 1][Step 114], time=0.03959059715270996, ext_time=0.01474905014038086, train_time=0.019974708557128906
[Epoch 1][Step 115], time=0.039585113525390625, ext_time=0.014719486236572266, train_time=0.019979476928710938
[Epoch 1][Step 116], time=0.03917121887207031, ext_time=0.01465606689453125, train_time=0.01963973045349121
[Epoch 1][Step 117], time=0.03963875770568848, ext_time=0.015121936798095703, train_time=0.019545793533325195
[Epoch 1][Step 118], time=0.039644718170166016, ext_time=0.015076637268066406, train_time=0.0196230411529541
[Epoch 1][Step 119], time=0.039188385009765625, ext_time=0.014743804931640625, train_time=0.019575834274291992
[Epoch 1][Step 120], time=0.04018092155456543, ext_time=0.014823198318481445, train_time=0.02044844627380371
[Epoch 1][Step 121], time=0.03944993019104004, ext_time=0.014910221099853516, train_time=0.019664525985717773
[Epoch 1][Step 122], time=0.04009819030761719, ext_time=0.014787435531616211, train_time=0.02040886878967285
[Epoch 1][Step 123], time=0.039038896560668945, ext_time=0.014833450317382812, train_time=0.01929497718811035
[Epoch 1][Step 124], time=0.03954458236694336, ext_time=0.014730215072631836, train_time=0.019932985305786133
[Epoch 1], time=4.949856281280518, loss=3.159688949584961
[Epoch 2][Step 0], time=0.04086947441101074, ext_time=0.015473604202270508, train_time=0.02029132843017578
[Epoch 2][Step 1], time=0.03974270820617676, ext_time=0.015093803405761719, train_time=0.019674062728881836
[Epoch 2][Step 2], time=0.0397191047668457, ext_time=0.014984846115112305, train_time=0.01983189582824707
[Epoch 2][Step 3], time=0.039339303970336914, ext_time=0.014789819717407227, train_time=0.01965475082397461
[Epoch 2][Step 4], time=0.039473533630371094, ext_time=0.014907360076904297, train_time=0.0196380615234375
[Epoch 2][Step 5], time=0.03878140449523926, ext_time=0.014530420303344727, train_time=0.019430160522460938
[Epoch 2][Step 6], time=0.03902459144592285, ext_time=0.014619112014770508, train_time=0.01954507827758789
[Epoch 2][Step 7], time=0.03889656066894531, ext_time=0.014614343643188477, train_time=0.019425153732299805
[Epoch 2][Step 8], time=0.03864407539367676, ext_time=0.01446986198425293, train_time=0.019394636154174805
[Epoch 2][Step 9], time=0.03870248794555664, ext_time=0.014881610870361328, train_time=0.018932342529296875
[Epoch 2][Step 10], time=0.03918170928955078, ext_time=0.015065908432006836, train_time=0.019164562225341797
[Epoch 2][Step 11], time=0.038846731185913086, ext_time=0.014912128448486328, train_time=0.01903986930847168
[Epoch 2][Step 12], time=0.03921246528625488, ext_time=0.014992237091064453, train_time=0.01929616928100586
[Epoch 2][Step 13], time=0.03948235511779785, ext_time=0.014638423919677734, train_time=0.01993703842163086
[Epoch 2][Step 14], time=0.0389857292175293, ext_time=0.014993906021118164, train_time=0.019052505493164062
[Epoch 2][Step 15], time=0.038858890533447266, ext_time=0.014890193939208984, train_time=0.019060850143432617
[Epoch 2][Step 16], time=0.039664506912231445, ext_time=0.015054941177368164, train_time=0.019663572311401367
[Epoch 2][Step 17], time=0.03907370567321777, ext_time=0.014652729034423828, train_time=0.019560575485229492
[Epoch 2][Step 18], time=0.03894639015197754, ext_time=0.014878988265991211, train_time=0.01914691925048828
[Epoch 2][Step 19], time=0.03927111625671387, ext_time=0.014721393585205078, train_time=0.019640684127807617
[Epoch 2][Step 20], time=0.03939032554626465, ext_time=0.015121936798095703, train_time=0.019274234771728516
[Epoch 2][Step 21], time=0.04009079933166504, ext_time=0.015021800994873047, train_time=0.020140647888183594
[Epoch 2][Step 22], time=0.03919792175292969, ext_time=0.01454782485961914, train_time=0.019724369049072266
[Epoch 2][Step 23], time=0.03957486152648926, ext_time=0.015022754669189453, train_time=0.019579410552978516
[Epoch 2][Step 24], time=0.04004549980163574, ext_time=0.01508474349975586, train_time=0.02000141143798828
[Epoch 2][Step 25], time=0.03981614112854004, ext_time=0.014677762985229492, train_time=0.020290136337280273
[Epoch 2][Step 26], time=0.03935647010803223, ext_time=0.015012264251708984, train_time=0.019403696060180664
[Epoch 2][Step 27], time=0.03879547119140625, ext_time=0.014590978622436523, train_time=0.01938176155090332
[Epoch 2][Step 28], time=0.03930234909057617, ext_time=0.015068769454956055, train_time=0.019215822219848633
[Epoch 2][Step 29], time=0.03959369659423828, ext_time=0.01497340202331543, train_time=0.019669055938720703
[Epoch 2][Step 30], time=0.039255380630493164, ext_time=0.014803886413574219, train_time=0.019443273544311523
[Epoch 2][Step 31], time=0.039531707763671875, ext_time=0.015211820602416992, train_time=0.019339561462402344
[Epoch 2][Step 32], time=0.0392000675201416, ext_time=0.014725208282470703, train_time=0.019602060317993164
[Epoch 2][Step 33], time=0.03857994079589844, ext_time=0.014806032180786133, train_time=0.018880128860473633
[Epoch 2][Step 34], time=0.03907418251037598, ext_time=0.014769315719604492, train_time=0.019460678100585938
[Epoch 2][Step 35], time=0.03992271423339844, ext_time=0.0143585205078125, train_time=0.020798206329345703
[Epoch 2][Step 36], time=0.03964948654174805, ext_time=0.014931917190551758, train_time=0.019796371459960938
[Epoch 2][Step 37], time=0.03945565223693848, ext_time=0.015156745910644531, train_time=0.019314050674438477
[Epoch 2][Step 38], time=0.039391517639160156, ext_time=0.014909744262695312, train_time=0.019520282745361328
[Epoch 2][Step 39], time=0.039327144622802734, ext_time=0.014183282852172852, train_time=0.020413875579833984
[Epoch 2][Step 40], time=0.03955245018005371, ext_time=0.014986276626586914, train_time=0.019292116165161133
[Epoch 2][Step 41], time=0.03947162628173828, ext_time=0.014865636825561523, train_time=0.019681453704833984
[Epoch 2][Step 42], time=0.03898906707763672, ext_time=0.014693737030029297, train_time=0.019426584243774414
[Epoch 2][Step 43], time=0.03945183753967285, ext_time=0.014792442321777344, train_time=0.019762277603149414
[Epoch 2][Step 44], time=0.0390627384185791, ext_time=0.014939546585083008, train_time=0.01919102668762207
[Epoch 2][Step 45], time=0.03887748718261719, ext_time=0.014868736267089844, train_time=0.019070863723754883
[Epoch 2][Step 46], time=0.03930950164794922, ext_time=0.014954328536987305, train_time=0.019428730010986328
[Epoch 2][Step 47], time=0.039725303649902344, ext_time=0.014405488967895508, train_time=0.020543813705444336
[Epoch 2][Step 48], time=0.04117298126220703, ext_time=0.014883756637573242, train_time=0.021380901336669922
[Epoch 2][Step 49], time=0.039856672286987305, ext_time=0.014995813369750977, train_time=0.019910573959350586
[Epoch 2][Step 50], time=0.03927898406982422, ext_time=0.014574527740478516, train_time=0.01983165740966797
[Epoch 2][Step 51], time=0.039295196533203125, ext_time=0.014566421508789062, train_time=0.01990818977355957
[Epoch 2][Step 52], time=0.040561676025390625, ext_time=0.014905452728271484, train_time=0.02072739601135254
[Epoch 2][Step 53], time=0.039316415786743164, ext_time=0.014631271362304688, train_time=0.019880294799804688
[Epoch 2][Step 54], time=0.03940129280090332, ext_time=0.014757871627807617, train_time=0.01975870132446289
[Epoch 2][Step 55], time=0.03937077522277832, ext_time=0.014376640319824219, train_time=0.020218610763549805
[Epoch 2][Step 56], time=0.04097127914428711, ext_time=0.014402389526367188, train_time=0.021776437759399414
[Epoch 2][Step 57], time=0.03905463218688965, ext_time=0.014746665954589844, train_time=0.019406557083129883
[Epoch 2][Step 58], time=0.03946280479431152, ext_time=0.014397859573364258, train_time=0.020313262939453125
[Epoch 2][Step 59], time=0.03921341896057129, ext_time=0.01484370231628418, train_time=0.01947188377380371
[Epoch 2][Step 60], time=0.03958320617675781, ext_time=0.014585733413696289, train_time=0.020170211791992188
[Epoch 2][Step 61], time=0.039595842361450195, ext_time=0.014946699142456055, train_time=0.01971435546875
[Epoch 2][Step 62], time=0.03949737548828125, ext_time=0.014578104019165039, train_time=0.02007913589477539
[Epoch 2][Step 63], time=0.03991556167602539, ext_time=0.014509916305541992, train_time=0.020575284957885742
[Epoch 2][Step 64], time=0.039606571197509766, ext_time=0.014708518981933594, train_time=0.020033836364746094
[Epoch 2][Step 65], time=0.03928971290588379, ext_time=0.01468658447265625, train_time=0.01973748207092285
[Epoch 2][Step 66], time=0.03943657875061035, ext_time=0.014806747436523438, train_time=0.019704580307006836
[Epoch 2][Step 67], time=0.039071083068847656, ext_time=0.014923810958862305, train_time=0.01922893524169922
[Epoch 2][Step 68], time=0.03908705711364746, ext_time=0.014641284942626953, train_time=0.01959371566772461
[Epoch 2][Step 69], time=0.03859972953796387, ext_time=0.014476537704467773, train_time=0.0193021297454834
[Epoch 2][Step 70], time=0.039381980895996094, ext_time=0.014848470687866211, train_time=0.0196382999420166
[Epoch 2][Step 71], time=0.03919625282287598, ext_time=0.014978170394897461, train_time=0.01923823356628418
[Epoch 2][Step 72], time=0.038958072662353516, ext_time=0.01496744155883789, train_time=0.01907038688659668
[Epoch 2][Step 73], time=0.039427757263183594, ext_time=0.01470184326171875, train_time=0.019853830337524414
[Epoch 2][Step 74], time=0.038902997970581055, ext_time=0.014449119567871094, train_time=0.01966118812561035
[Epoch 2][Step 75], time=0.03956913948059082, ext_time=0.014677286148071289, train_time=0.02004528045654297
[Epoch 2][Step 76], time=0.03976249694824219, ext_time=0.014791727066040039, train_time=0.020078182220458984
[Epoch 2][Step 77], time=0.03955388069152832, ext_time=0.015220165252685547, train_time=0.019313812255859375
[Epoch 2][Step 78], time=0.040087223052978516, ext_time=0.014619112014770508, train_time=0.020598173141479492
[Epoch 2][Step 79], time=0.03916811943054199, ext_time=0.014710187911987305, train_time=0.019594907760620117
[Epoch 2][Step 80], time=0.03866863250732422, ext_time=0.01477670669555664, train_time=0.01901721954345703
[Epoch 2][Step 81], time=0.03941035270690918, ext_time=0.014634370803833008, train_time=0.019914865493774414
[Epoch 2][Step 82], time=0.03931069374084473, ext_time=0.014636754989624023, train_time=0.019802093505859375
[Epoch 2][Step 83], time=0.03924393653869629, ext_time=0.014833450317382812, train_time=0.0195004940032959
[Epoch 2][Step 84], time=0.04049324989318848, ext_time=0.014642477035522461, train_time=0.02094101905822754
[Epoch 2][Step 85], time=0.04006171226501465, ext_time=0.015112638473510742, train_time=0.01994466781616211
[Epoch 2][Step 86], time=0.03960871696472168, ext_time=0.014983177185058594, train_time=0.01964592933654785
[Epoch 2][Step 87], time=0.03977465629577637, ext_time=0.015123844146728516, train_time=0.01966238021850586
[Epoch 2][Step 88], time=0.03944897651672363, ext_time=0.014521360397338867, train_time=0.02008509635925293
[Epoch 2][Step 89], time=0.03862810134887695, ext_time=0.014725446701049805, train_time=0.01903676986694336
[Epoch 2][Step 90], time=0.03951454162597656, ext_time=0.014846563339233398, train_time=0.01979684829711914
[Epoch 2][Step 91], time=0.03879213333129883, ext_time=0.01463174819946289, train_time=0.0193178653717041
[Epoch 2][Step 92], time=0.03960275650024414, ext_time=0.015229463577270508, train_time=0.019350290298461914
[Epoch 2][Step 93], time=0.03993058204650879, ext_time=0.01516270637512207, train_time=0.019798755645751953
[Epoch 2][Step 94], time=0.040644168853759766, ext_time=0.01508021354675293, train_time=0.02063155174255371
[Epoch 2][Step 95], time=0.03952193260192871, ext_time=0.014830589294433594, train_time=0.019648075103759766
[Epoch 2][Step 96], time=0.03954648971557617, ext_time=0.014745712280273438, train_time=0.019798755645751953
[Epoch 2][Step 97], time=0.03908991813659668, ext_time=0.014640569686889648, train_time=0.019481182098388672
[Epoch 2][Step 98], time=0.039075374603271484, ext_time=0.014614343643188477, train_time=0.019440650939941406
[Epoch 2][Step 99], time=0.039587974548339844, ext_time=0.014715194702148438, train_time=0.019843101501464844
[Epoch 2][Step 100], time=0.04084300994873047, ext_time=0.015011310577392578, train_time=0.020782947540283203
[Epoch 2][Step 101], time=0.04003000259399414, ext_time=0.014974117279052734, train_time=0.01980137825012207
[Epoch 2][Step 102], time=0.04153561592102051, ext_time=0.01470947265625, train_time=0.02175450325012207
[Epoch 2][Step 103], time=0.0396115779876709, ext_time=0.01486968994140625, train_time=0.019638776779174805
[Epoch 2][Step 104], time=0.0399777889251709, ext_time=0.01505279541015625, train_time=0.019811391830444336
[Epoch 2][Step 105], time=0.03989911079406738, ext_time=0.014368534088134766, train_time=0.020596027374267578
[Epoch 2][Step 106], time=0.039742231369018555, ext_time=0.014577627182006836, train_time=0.020163536071777344
[Epoch 2][Step 107], time=0.03981137275695801, ext_time=0.014961004257202148, train_time=0.01974773406982422
[Epoch 2][Step 108], time=0.03965425491333008, ext_time=0.014820098876953125, train_time=0.019770145416259766
[Epoch 2][Step 109], time=0.03983044624328613, ext_time=0.014892339706420898, train_time=0.019838333129882812
[Epoch 2][Step 110], time=0.039994001388549805, ext_time=0.014982223510742188, train_time=0.019899606704711914
[Epoch 2][Step 111], time=0.03982377052307129, ext_time=0.014755010604858398, train_time=0.020041942596435547
[Epoch 2][Step 112], time=0.04086947441101074, ext_time=0.015285730361938477, train_time=0.02039337158203125
[Epoch 2][Step 113], time=0.039537668228149414, ext_time=0.014763593673706055, train_time=0.019690752029418945
[Epoch 2][Step 114], time=0.03992199897766113, ext_time=0.014723539352416992, train_time=0.020173311233520508
[Epoch 2][Step 115], time=0.039537906646728516, ext_time=0.014742851257324219, train_time=0.01973891258239746
[Epoch 2][Step 116], time=0.039511680603027344, ext_time=0.014701128005981445, train_time=0.019786834716796875
[Epoch 2][Step 117], time=0.04023623466491699, ext_time=0.015158414840698242, train_time=0.019898176193237305
[Epoch 2][Step 118], time=0.04004478454589844, ext_time=0.01510167121887207, train_time=0.019814014434814453
[Epoch 2][Step 119], time=0.039582014083862305, ext_time=0.01482701301574707, train_time=0.01969742774963379
[Epoch 2][Step 120], time=0.0397031307220459, ext_time=0.014836311340332031, train_time=0.019782543182373047
[Epoch 2][Step 121], time=0.039574623107910156, ext_time=0.014937162399291992, train_time=0.019571542739868164
[Epoch 2][Step 122], time=0.04020953178405762, ext_time=0.014831781387329102, train_time=0.020285367965698242
[Epoch 2][Step 123], time=0.03998589515686035, ext_time=0.01491856575012207, train_time=0.019973039627075195
[Epoch 2][Step 124], time=0.03962516784667969, ext_time=0.014798641204833984, train_time=0.019747257232666016
[Epoch 2], time=4.950722932815552, loss=2.483710527420044
[Epoch 3][Step 0], time=0.04096174240112305, ext_time=0.015531778335571289, train_time=0.02014303207397461
[Epoch 3][Step 1], time=0.040262699127197266, ext_time=0.015125036239624023, train_time=0.019984960556030273
[Epoch 3][Step 2], time=0.039784908294677734, ext_time=0.014889001846313477, train_time=0.019814491271972656
[Epoch 3][Step 3], time=0.03945350646972656, ext_time=0.014812946319580078, train_time=0.019594907760620117
[Epoch 3][Step 4], time=0.03979325294494629, ext_time=0.014951229095458984, train_time=0.019739866256713867
[Epoch 3][Step 5], time=0.038985252380371094, ext_time=0.014529228210449219, train_time=0.019489526748657227
[Epoch 3][Step 6], time=0.039427757263183594, ext_time=0.014688968658447266, train_time=0.01967644691467285
[Epoch 3][Step 7], time=0.03934907913208008, ext_time=0.014692306518554688, train_time=0.019636154174804688
[Epoch 3][Step 8], time=0.03864884376525879, ext_time=0.014501333236694336, train_time=0.019205331802368164
[Epoch 3][Step 9], time=0.03956151008605957, ext_time=0.014924764633178711, train_time=0.01959228515625
[Epoch 3][Step 10], time=0.03997683525085449, ext_time=0.015028238296508789, train_time=0.01981830596923828
[Epoch 3][Step 11], time=0.04003596305847168, ext_time=0.014924764633178711, train_time=0.02004265785217285
[Epoch 3][Step 12], time=0.040022850036621094, ext_time=0.015066862106323242, train_time=0.01984095573425293
[Epoch 3][Step 13], time=0.039672136306762695, ext_time=0.01469111442565918, train_time=0.01994466781616211
[Epoch 3][Step 14], time=0.03986978530883789, ext_time=0.014992475509643555, train_time=0.019763708114624023
[Epoch 3][Step 15], time=0.039649009704589844, ext_time=0.014899969100952148, train_time=0.019665956497192383
[Epoch 3][Step 16], time=0.04011344909667969, ext_time=0.015056371688842773, train_time=0.019936800003051758
[Epoch 3][Step 17], time=0.03936600685119629, ext_time=0.014637231826782227, train_time=0.01972818374633789
[Epoch 3][Step 18], time=0.039653778076171875, ext_time=0.014828205108642578, train_time=0.019737958908081055
[Epoch 3][Step 19], time=0.039632320404052734, ext_time=0.014782428741455078, train_time=0.019778966903686523
[Epoch 3][Step 20], time=0.040375709533691406, ext_time=0.015087604522705078, train_time=0.0200958251953125
[Epoch 3][Step 21], time=0.04007315635681152, ext_time=0.014995098114013672, train_time=0.01995849609375
[Epoch 3][Step 22], time=0.039551734924316406, ext_time=0.014481544494628906, train_time=0.020081043243408203
[Epoch 3][Step 23], time=0.04040241241455078, ext_time=0.015090703964233398, train_time=0.020153045654296875
[Epoch 3][Step 24], time=0.04034137725830078, ext_time=0.01507878303527832, train_time=0.02008795738220215
[Epoch 3][Step 25], time=0.03980302810668945, ext_time=0.014777421951293945, train_time=0.019972801208496094
[Epoch 3][Step 26], time=0.03981971740722656, ext_time=0.014966726303100586, train_time=0.019755125045776367
[Epoch 3][Step 27], time=0.038877248764038086, ext_time=0.014540910720825195, train_time=0.01936507225036621
[Epoch 3][Step 28], time=0.040346622467041016, ext_time=0.015120744705200195, train_time=0.020053386688232422
[Epoch 3][Step 29], time=0.03995013236999512, ext_time=0.014997720718383789, train_time=0.0198516845703125
[Epoch 3][Step 30], time=0.03961181640625, ext_time=0.014785528182983398, train_time=0.019751310348510742
[Epoch 3][Step 31], time=0.04040098190307617, ext_time=0.015197038650512695, train_time=0.020000696182250977
[Epoch 3][Step 32], time=0.03949403762817383, ext_time=0.014840841293334961, train_time=0.01960158348083496
[Epoch 3][Step 33], time=0.03970694541931152, ext_time=0.014810323715209961, train_time=0.019783973693847656
[Epoch 3][Step 34], time=0.03936934471130371, ext_time=0.014798402786254883, train_time=0.019529342651367188
[Epoch 3][Step 35], time=0.040018558502197266, ext_time=0.014458179473876953, train_time=0.020627737045288086
[Epoch 3][Step 36], time=0.039832353591918945, ext_time=0.014903783798217773, train_time=0.019822359085083008
[Epoch 3][Step 37], time=0.04050040245056152, ext_time=0.015223503112792969, train_time=0.020109176635742188
[Epoch 3][Step 38], time=0.03997087478637695, ext_time=0.014934778213500977, train_time=0.019923925399780273
[Epoch 3][Step 39], time=0.039447784423828125, ext_time=0.01424551010131836, train_time=0.02031707763671875
[Epoch 3][Step 40], time=0.039989471435546875, ext_time=0.014932394027709961, train_time=0.019972562789916992
[Epoch 3][Step 41], time=0.039824485778808594, ext_time=0.014792203903198242, train_time=0.01991128921508789
[Epoch 3][Step 42], time=0.03968644142150879, ext_time=0.014765262603759766, train_time=0.01986384391784668
[Epoch 3][Step 43], time=0.03969931602478027, ext_time=0.014853715896606445, train_time=0.019755125045776367
[Epoch 3][Step 44], time=0.03986859321594238, ext_time=0.015012264251708984, train_time=0.019766569137573242
[Epoch 3][Step 45], time=0.039755821228027344, ext_time=0.014912128448486328, train_time=0.01974654197692871
[Epoch 3][Step 46], time=0.03976702690124512, ext_time=0.014921426773071289, train_time=0.01975393295288086
[Epoch 3][Step 47], time=0.039908647537231445, ext_time=0.014499425888061523, train_time=0.020478010177612305
[Epoch 3][Step 48], time=0.040183067321777344, ext_time=0.014958381652832031, train_time=0.020137786865234375
[Epoch 3][Step 49], time=0.0399022102355957, ext_time=0.014998674392700195, train_time=0.01979970932006836
[Epoch 3][Step 50], time=0.03930401802062988, ext_time=0.014594316482543945, train_time=0.01973557472229004
[Epoch 3][Step 51], time=0.03925967216491699, ext_time=0.014574050903320312, train_time=0.01968216896057129
[Epoch 3][Step 52], time=0.04032588005065918, ext_time=0.0149688720703125, train_time=0.020258665084838867
[Epoch 3][Step 53], time=0.039083242416381836, ext_time=0.014600038528442383, train_time=0.019511938095092773
[Epoch 3][Step 54], time=0.0393834114074707, ext_time=0.014783382415771484, train_time=0.019573211669921875
[Epoch 3][Step 55], time=0.03910017013549805, ext_time=0.014391422271728516, train_time=0.019754648208618164
[Epoch 3][Step 56], time=0.039598941802978516, ext_time=0.014456510543823242, train_time=0.02014470100402832
[Epoch 3][Step 57], time=0.039452552795410156, ext_time=0.014768123626708984, train_time=0.01962900161743164
[Epoch 3][Step 58], time=0.03925323486328125, ext_time=0.014483928680419922, train_time=0.019840002059936523
[Epoch 3][Step 59], time=0.04086875915527344, ext_time=0.015101194381713867, train_time=0.020688533782958984
[Epoch 3][Step 60], time=0.03965592384338379, ext_time=0.014634132385253906, train_time=0.01987743377685547
[Epoch 3][Step 61], time=0.03977560997009277, ext_time=0.014968156814575195, train_time=0.019707441329956055
[Epoch 3][Step 62], time=0.03960013389587402, ext_time=0.014626741409301758, train_time=0.01998138427734375
[Epoch 3][Step 63], time=0.03970479965209961, ext_time=0.014558076858520508, train_time=0.02016472816467285
[Epoch 3][Step 64], time=0.03952908515930176, ext_time=0.014802217483520508, train_time=0.019674062728881836
[Epoch 3][Step 65], time=0.03933525085449219, ext_time=0.014681339263916016, train_time=0.01962733268737793
[Epoch 3][Step 66], time=0.04075884819030762, ext_time=0.014824867248535156, train_time=0.020890474319458008
[Epoch 3][Step 67], time=0.03969216346740723, ext_time=0.014898300170898438, train_time=0.019696712493896484
[Epoch 3][Step 68], time=0.03930997848510742, ext_time=0.014702081680297852, train_time=0.01959824562072754
[Epoch 3][Step 69], time=0.03905344009399414, ext_time=0.014575004577636719, train_time=0.019492387771606445
[Epoch 3][Step 70], time=0.039526939392089844, ext_time=0.014819860458374023, train_time=0.01963496208190918
[Epoch 3][Step 71], time=0.03962516784667969, ext_time=0.014984846115112305, train_time=0.01952528953552246
[Epoch 3][Step 72], time=0.03985333442687988, ext_time=0.014898300170898438, train_time=0.019834518432617188
[Epoch 3][Step 73], time=0.039955854415893555, ext_time=0.014677286148071289, train_time=0.020206928253173828
[Epoch 3][Step 74], time=0.03940105438232422, ext_time=0.014571189880371094, train_time=0.019803762435913086
[Epoch 3][Step 75], time=0.03943514823913574, ext_time=0.01470327377319336, train_time=0.01970505714416504
[Epoch 3][Step 76], time=0.0396723747253418, ext_time=0.014798164367675781, train_time=0.019840002059936523
[Epoch 3][Step 77], time=0.0403141975402832, ext_time=0.015245914459228516, train_time=0.019902467727661133
[Epoch 3][Step 78], time=0.03979659080505371, ext_time=0.014653921127319336, train_time=0.020121335983276367
[Epoch 3][Step 79], time=0.039261817932128906, ext_time=0.014733076095581055, train_time=0.019514083862304688
[Epoch 3][Step 80], time=0.03943324089050293, ext_time=0.014801979064941406, train_time=0.019577980041503906
[Epoch 3][Step 81], time=0.03937172889709473, ext_time=0.014694452285766602, train_time=0.019650697708129883
[Epoch 3][Step 82], time=0.03956413269042969, ext_time=0.014712810516357422, train_time=0.019814014434814453
[Epoch 3][Step 83], time=0.039411306381225586, ext_time=0.01483464241027832, train_time=0.01949286460876465
[Epoch 3][Step 84], time=0.04103350639343262, ext_time=0.014692306518554688, train_time=0.021318674087524414
[Epoch 3][Step 85], time=0.040312767028808594, ext_time=0.015063762664794922, train_time=0.0201108455657959
[Epoch 3][Step 86], time=0.039917707443237305, ext_time=0.014986515045166016, train_time=0.01978302001953125
[Epoch 3][Step 87], time=0.04018759727478027, ext_time=0.015098333358764648, train_time=0.019950151443481445
[Epoch 3][Step 88], time=0.039312124252319336, ext_time=0.01455998420715332, train_time=0.019721508026123047
[Epoch 3][Step 89], time=0.0394899845123291, ext_time=0.014749526977539062, train_time=0.019696950912475586
[Epoch 3][Step 90], time=0.03958702087402344, ext_time=0.014808177947998047, train_time=0.019741296768188477
[Epoch 3][Step 91], time=0.03906750679016113, ext_time=0.014596939086914062, train_time=0.01944732666015625
[Epoch 3][Step 92], time=0.040575504302978516, ext_time=0.015290021896362305, train_time=0.0200655460357666
[Epoch 3][Step 93], time=0.04025530815124512, ext_time=0.015273332595825195, train_time=0.019845962524414062
[Epoch 3][Step 94], time=0.03980875015258789, ext_time=0.014969587326049805, train_time=0.019737720489501953
[Epoch 3][Step 95], time=0.03956890106201172, ext_time=0.014803409576416016, train_time=0.019716978073120117
[Epoch 3][Step 96], time=0.03996443748474121, ext_time=0.014651775360107422, train_time=0.020290851593017578
[Epoch 3][Step 97], time=0.03919267654418945, ext_time=0.014690876007080078, train_time=0.019495010375976562
[Epoch 3][Step 98], time=0.03894376754760742, ext_time=0.014594316482543945, train_time=0.01937699317932129
[Epoch 3][Step 99], time=0.03941512107849121, ext_time=0.014678478240966797, train_time=0.01970648765563965
[Epoch 3][Step 100], time=0.03959488868713379, ext_time=0.01472330093383789, train_time=0.019830703735351562
[Epoch 3][Step 101], time=0.039849042892456055, ext_time=0.015004873275756836, train_time=0.01974964141845703
[Epoch 3][Step 102], time=0.040123701095581055, ext_time=0.014673471450805664, train_time=0.020409107208251953
[Epoch 3][Step 103], time=0.039749860763549805, ext_time=0.014824628829956055, train_time=0.019835233688354492
[Epoch 3][Step 104], time=0.03986406326293945, ext_time=0.015065193176269531, train_time=0.019692420959472656
[Epoch 3][Step 105], time=0.03961944580078125, ext_time=0.014302492141723633, train_time=0.02041029930114746
[Epoch 3][Step 106], time=0.039901018142700195, ext_time=0.014595985412597656, train_time=0.02031564712524414
[Epoch 3][Step 107], time=0.03992271423339844, ext_time=0.01500082015991211, train_time=0.019833087921142578
[Epoch 3][Step 108], time=0.03981971740722656, ext_time=0.014816522598266602, train_time=0.01993703842163086
[Epoch 3][Step 109], time=0.04032182693481445, ext_time=0.01491093635559082, train_time=0.02032017707824707
[Epoch 3][Step 110], time=0.03981733322143555, ext_time=0.014920234680175781, train_time=0.019797563552856445
[Epoch 3][Step 111], time=0.039859771728515625, ext_time=0.014751195907592773, train_time=0.020101547241210938
[Epoch 3][Step 112], time=0.039923906326293945, ext_time=0.015153884887695312, train_time=0.019605159759521484
[Epoch 3][Step 113], time=0.04015469551086426, ext_time=0.01479029655456543, train_time=0.020319700241088867
[Epoch 3][Step 114], time=0.039571285247802734, ext_time=0.014756917953491211, train_time=0.019776344299316406
[Epoch 3][Step 115], time=0.03961539268493652, ext_time=0.014795303344726562, train_time=0.019765138626098633
[Epoch 3][Step 116], time=0.03956031799316406, ext_time=0.014662981033325195, train_time=0.019861698150634766
[Epoch 3][Step 117], time=0.0404205322265625, ext_time=0.015204906463623047, train_time=0.020030975341796875
[Epoch 3][Step 118], time=0.040117502212524414, ext_time=0.015023231506347656, train_time=0.019979238510131836
[Epoch 3][Step 119], time=0.03947782516479492, ext_time=0.014805316925048828, train_time=0.01961207389831543
[Epoch 3][Step 120], time=0.039691925048828125, ext_time=0.014852285385131836, train_time=0.019762516021728516
[Epoch 3][Step 121], time=0.03969454765319824, ext_time=0.014931201934814453, train_time=0.01972222328186035
[Epoch 3][Step 122], time=0.03996706008911133, ext_time=0.014819145202636719, train_time=0.02006697654724121
[Epoch 3][Step 123], time=0.039698123931884766, ext_time=0.014904260635375977, train_time=0.01970052719116211
[Epoch 3][Step 124], time=0.0397951602935791, ext_time=0.014785051345825195, train_time=0.019931316375732422
[Epoch 3], time=4.980205535888672, loss=1.8749489784240723
    [Step(average) Profiler Level 1 E3 S499]
        L1  sample           0.004961 | send           0.000000
        L1  recv             0.000000 | copy           0.014873 | convert time 0.000000 | train  0.019786
        L1  feature nbytes  960.37 MB | label nbytes 0.00 Bytes
        L1  id nbytes      0.00 Bytes | graph nbytes 0.00 Bytes
        L1  miss nbytes    0.00 Bytes | remote nbytes 0.00 Bytes
        L1  num nodes               0 | num samples           0
        L1  seq duration     0.000000 | refresh duration   0.000000
    [Step(average) Profiler Level 2 E3 S499]
        L2  shuffle     0.000000 | core sample  0.000000 | id remap        0.000000
        L2  graph copy  0.000000 | id copy      0.000000 | cache feat copy 0.014873
        L2  last layer sample time 0.000000 | size 0.000000
    [Step(average) Profiler Level 3 E3 S499]
        L3  khop sample coo  0.000000 | khop sort coo      0.000000 | khop count edge     0.000000 | khop compact edge 0.000000
        L3  walk sample coo  0.000000 | walk topk total    0.000000 | walk topk step1     0.000000 | walk topk step2   0.000000
        L3  walk topk step3  0.000000 | walk topk step4    0.000000 | walk topk step5     0.000000
        L3  walk topk step6  0.000000 | walk topk step7    0.000000
        L3  remap unique     0.000000 | remap populate     0.000000 | remap mapnode       0.000000 | remap mapedge     0.000000
        L3  cache get_index  0.000698 | cache copy_index   0.000000 | cache extract_miss  0.000000
        L3  cache copy_miss  0.000000 | cache combine_miss 0.000000 | cache combine cache 0.014142 | cache combine remote 0.000000
        L3  label extract  0.000000
    [Profiler Level Percentiles E3 S499]
        p50.00_tail_logl2featcopy=0.014855
        p90.00_tail_logl2featcopy=0.015156
        p95.00_tail_logl2featcopy=0.015248
        p99.00_tail_logl2featcopy=0.015483
        p99.90_tail_logl2featcopy=0.020670
[CUDA] cuda: usage: 13.28 GB
Rank=1, Graph loaded.
!!!!Train_dataloader(with 125 items) enumerate latency: 0.40918755531311035
torch.Size([2000]) torch.Size([2000])
torch.Size([2104]) torch.Size([2104])
!!!!Train_data_list(with 125 items) enumerate latency: 1.33514404296875e-05, transfer latency: 0.3905949592590332
presamping
presamping takes 8.37099814414978
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   74219 KB |    1706 MB |    2116 GB |    2116 GB |
|       from large pool |   62410 KB |    1695 MB |    2097 GB |    2097 GB |
|       from small pool |   11808 KB |      19 MB |      18 GB |      18 GB |
|---------------------------------------------------------------------------|
| Active memory         |   74219 KB |    1706 MB |    2116 GB |    2116 GB |
|       from large pool |   62410 KB |    1695 MB |    2097 GB |    2097 GB |
|       from small pool |   11808 KB |      19 MB |      18 GB |      18 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    1832 MB |    1832 MB |    1832 MB |       0 B  |
|       from large pool |    1802 MB |    1802 MB |    1802 MB |       0 B  |
|       from small pool |      30 MB |      30 MB |      30 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   60949 KB |    1530 MB |    2439 GB |    2439 GB |
|       from large pool |   52277 KB |    1516 MB |    2420 GB |    2420 GB |
|       from small pool |    8671 KB |      17 MB |      19 GB |      19 GB |
|---------------------------------------------------------------------------|
| Allocations           |      66    |      95    |  136046    |  135980    |
|       from large pool |      12    |      23    |   44754    |   44742    |
|       from small pool |      54    |      73    |   91292    |   91238    |
|---------------------------------------------------------------------------|
| Active allocs         |      66    |      95    |  136046    |  135980    |
|       from large pool |      12    |      23    |   44754    |   44742    |
|       from small pool |      54    |      73    |   91292    |   91238    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      25    |      25    |      25    |       0    |
|       from large pool |      10    |      10    |      10    |       0    |
|       from small pool |      15    |      15    |      15    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      35    |      51    |   51209    |   51174    |
|       from large pool |       7    |      16    |   23712    |   23705    |
|       from small pool |      28    |      41    |   27497    |   27469    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[TRAIN_TIME] train time is 20.998597 seconds
[EPOCH_TIME] 5.249649 seconds, maybe large due to not enough epoch skipped.
[EPOCH_TIME] 4.965617 seconds
Rank=2, Graph loaded.
!!!!Train_dataloader(with 125 items) enumerate latency: 0.39144396781921387
torch.Size([2000]) torch.Size([2000])
torch.Size([2104]) torch.Size([2104])
!!!!Train_data_list(with 125 items) enumerate latency: 1.0728836059570312e-05, transfer latency: 0.367537260055542
presamping
presamping takes 7.578174591064453
Rank=3, Graph loaded.
!!!!Train_dataloader(with 125 items) enumerate latency: 0.4087510108947754
torch.Size([2000]) torch.Size([2000])
torch.Size([2104]) torch.Size([2104])
!!!!Train_data_list(with 125 items) enumerate latency: 1.0013580322265625e-05, transfer latency: 0.3891434669494629
presamping
presamping takes 7.333219051361084

