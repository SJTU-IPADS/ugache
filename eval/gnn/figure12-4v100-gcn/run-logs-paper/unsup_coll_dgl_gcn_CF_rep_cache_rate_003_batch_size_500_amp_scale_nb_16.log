succeed=True
[CUDA] cuda: usage: 5.44 GB
0 :  {link #0 : 1}, {link #1 : 2}, {link #2 : 3},
1 :  {link #0 : 2}, {link #1 : 3}, {link #2 : 0},
2 :  {link #0 : 3}, {link #1 : 0}, {link #2 : 1},
3 :  {link #0 : 0}, {link #1 : 1}, {link #2 : 2},
0 :  {link #0 : 1}, {link #1 : 2}, {link #2 : 3},
1 :  {link #0 : 2}, {link #1 : 3}, {link #2 : 0},
2 :  {link #0 : 3}, {link #1 : 0}, {link #2 : 1},
3 :  {link #0 : 0}, {link #1 : 1}, {link #2 : 2},
0 :  {link #0 : 1}, {link #1 : 2}, {link #2 : 3},
1 :  {link #0 : 2}, {link #1 : 3}, {link #2 : 0},
2 :  {link #0 : 3}, {link #1 : 0}, {link #2 : 1},
3 :  {link #0 : 0}, {link #1 : 1}, {link #2 : 2},
0 : local 80, cpu 0 {link #0 : g1 0}, {link #1 : g2 0}, {link #2 : g3 0},
1 : local 80, cpu 0 {link #0 : g2 0}, {link #1 : g3 0}, {link #2 : g0 0},
2 : local 80, cpu 0 {link #0 : g3 0}, {link #1 : g0 0}, {link #2 : g1 0},
3 : local 80, cpu 0 {link #0 : g0 0}, {link #1 : g1 0}, {link #2 : g2 0},
0 : local 80, cpu 0 {link #0 : g1 0}, {link #1 : g2 0}, {link #2 : g3 0},
1 : local 80, cpu 0 {link #0 : g2 0}, {link #1 : g3 0}, {link #2 : g0 0},
2 : local 80, cpu 0 {link #0 : g3 0}, {link #1 : g0 0}, {link #2 : g1 0},
3 : local 80, cpu 0 {link #0 : g0 0}, {link #1 : g1 0}, {link #2 : g2 0},
0 : local 80, cpu 0 {link #0 : g1 0}, {link #1 : g2 0}, {link #2 : g3 0},
1 : local 80, cpu 0 {link #0 : g2 0}, {link #1 : g3 0}, {link #2 : g0 0},
2 : local 80, cpu 0 {link #0 : g3 0}, {link #1 : g0 0}, {link #2 : g1 0},
3 : local 80, cpu 0 {link #0 : g0 0}, {link #1 : g1 0}, {link #2 : g2 0},
0 :  {link #0 : 1}, {link #1 : 2}, {link #2 : 3},
1 :  {link #0 : 2}, {link #1 : 3}, {link #2 : 0},
2 :  {link #0 : 3}, {link #1 : 0}, {link #2 : 1},
3 :  {link #0 : 0}, {link #1 : 1}, {link #2 : 2},
0 : local 80, cpu 0 {link #0 : g1 0}, {link #1 : g2 0}, {link #2 : g3 0},
1 : local 80, cpu 0 {link #0 : g2 0}, {link #1 : g3 0}, {link #2 : g0 0},
2 : local 80, cpu 0 {link #0 : g3 0}, {link #1 : g0 0}, {link #2 : g1 0},
3 : local 80, cpu 0 {link #0 : g0 0}, {link #1 : g1 0}, {link #2 : g2 0},
coll_cache:optimal_rep_storage=0.03
coll_cache:optimal_part_storage=0
coll_cache:optimal_cpu_storage=0.97
coll_cache:optimal_local_storage=0.03
coll_cache:optimal_remote_storage=0
coll_cache:optimal_local_rate=0.321787
coll_cache:optimal_remote_rate=0
coll_cache:optimal_cpu_rate=0.678213
z=74402.2
test_result:init:feat_nbytes=67182966784
test_result:init:cache_nbytes=2082671616
test_result:init:feat_nbytes=67182966784
test_result:init:cache_nbytes=2082671616
test_result:init:feat_nbytes=67182966784
test_result:init:cache_nbytes=2082671616
test_result:init:feat_nbytes=67182966784
test_result:init:cache_nbytes=2082671616
worker 0 running with pid=48381
config:eval_tsp="2023-08-06 19:02:17"
config:num_worker=4
config:num_intra_size=4
config:root_dir=/datasets_gnn/wholegraph
config:graph_name=com-friendster
config:epochs=4
config:batchsize=500
config:skip_epoch=2
config:local_step=250
config:presc_epoch=2
config:neighbors=15,10,5
config:hiddensize=256
config:num_layer=3
config:model=gcn
config:framework=dgl
config:dataloaderworkers=0
config:dropout=0.5
config:weight_decay=0.0005
config:lr=0.003
config:use_nccl=False
config:use_amp=True
config:use_collcache=True
config:cache_percentage=0.03
config:cache_policy=rep
config:omp_thread_num=40
config:unsupervised=True
config:classnum=100
config:global_barrier=<multiprocessing.synchronize.Barrier object at 0x7f82d4b2f820>
config:worker_id=0
creating_intra_node_communicator root=0, local_size=4, world_size=4
loading train edge idx from disk
loading train edge idx from disk done
tensor([ 312558501,  165303846,  382592436, 3465360478, 1289294319, 1055724137,
        3392581687,  213217736, 3047409731, 2134151289, 2553067370, 2969120916,
        2293768477, 1618302669,  184738216, 1829492105, 1438364301,  143975391,
        3488855025, 1525393396,  484788782, 1824160758, 3278914432, 1791042494,
        2531399103, 1976393697,  267524578, 1415973226, 3055112374, 2304304850,
        2970740983,  463733153,  470323953,  172504368,  314487920,  565768019,
        1325206124,    3902063, 2558324563, 2631782915, 3561616031, 2061569113,
        1776804911, 3574237973,  226132407,  361666075, 1514025674, 2274739441,
         125808586,  613763319, 1680587044,   50300193, 1625798297, 1321548596,
        3372445782, 1162803676, 1779255988, 2824765390, 1859433431, 2244623276,
        2673542557, 2014397343,  787107922, 1470797842,  653592026, 3063416664,
        2396187549,   39784734,  782941200, 2597902117, 1950931722,  539301441,
         881167165, 2566715114, 1143946729, 1063252333,  374533248, 2050371892,
        3306915207,  552684244, 1631811769,  588251379,  562506265,   42541411,
        1864901246, 2976754698, 1822251476,  641961590,  819864454, 3489874270,
        3553458922, 3534464258, 1694742715, 1593217661,  209704235, 1093043746,
        2390506997,   76009729,   77103172, 2606303238])
Rank=0, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.009999, per step: 0.000040
epoch=4 total_steps=1000
presamping
presamping takes 14.303301334381104
start training...
[Epoch 0][Step 0], time=1.1879119873046875, ext_time=0.07167458534240723, train_time=1.1071548461914062
[Epoch 0][Step 1], time=0.09933090209960938, ext_time=0.06473445892333984, train_time=0.027442216873168945
[Epoch 0][Step 2], time=0.09163475036621094, ext_time=0.06314921379089355, train_time=0.022618770599365234
[Epoch 0][Step 3], time=0.09171557426452637, ext_time=0.0645151138305664, train_time=0.021503925323486328
[Epoch 0][Step 4], time=0.09407496452331543, ext_time=0.06479692459106445, train_time=0.02347707748413086
[Epoch 0][Step 5], time=0.09301066398620605, ext_time=0.06468939781188965, train_time=0.022537708282470703
[Epoch 0][Step 6], time=0.09134840965270996, ext_time=0.06463503837585449, train_time=0.020984172821044922
[Epoch 0][Step 7], time=0.09421801567077637, ext_time=0.06406998634338379, train_time=0.024424314498901367
[Epoch 0][Step 8], time=0.09182524681091309, ext_time=0.06418800354003906, train_time=0.021849632263183594
[Epoch 0][Step 9], time=0.09293055534362793, ext_time=0.06492161750793457, train_time=0.022219181060791016
[Epoch 0][Step 10], time=0.09763026237487793, ext_time=0.06398391723632812, train_time=0.02790999412536621
[Epoch 0][Step 11], time=0.0927591323852539, ext_time=0.06407737731933594, train_time=0.02089691162109375
[Epoch 0][Step 12], time=0.09232616424560547, ext_time=0.06282162666320801, train_time=0.023856401443481445
[Epoch 0][Step 13], time=0.09179854393005371, ext_time=0.06433963775634766, train_time=0.021754026412963867
[Epoch 0][Step 14], time=0.09285616874694824, ext_time=0.06365132331848145, train_time=0.023458003997802734
[Epoch 0][Step 15], time=0.09163904190063477, ext_time=0.06458663940429688, train_time=0.02130913734436035
[Epoch 0][Step 16], time=0.09315180778503418, ext_time=0.06495904922485352, train_time=0.022437095642089844
[Epoch 0][Step 17], time=0.15052580833435059, ext_time=0.06445002555847168, train_time=0.08033943176269531
[Epoch 0][Step 18], time=0.09492325782775879, ext_time=0.06519007682800293, train_time=0.02379131317138672
[Epoch 0][Step 19], time=0.09271788597106934, ext_time=0.06499433517456055, train_time=0.021913766860961914
[Epoch 0][Step 20], time=0.09234285354614258, ext_time=0.06484031677246094, train_time=0.021770477294921875
[Epoch 0][Step 21], time=0.09191298484802246, ext_time=0.06395959854125977, train_time=0.02221822738647461
[Epoch 0][Step 22], time=0.09209561347961426, ext_time=0.06375002861022949, train_time=0.022665739059448242
[Epoch 0][Step 23], time=0.09543895721435547, ext_time=0.06376171112060547, train_time=0.02599310874938965
[Epoch 0][Step 24], time=0.09427022933959961, ext_time=0.06416940689086914, train_time=0.024293899536132812
[Epoch 0][Step 25], time=0.09361505508422852, ext_time=0.06479406356811523, train_time=0.023015975952148438
[Epoch 0][Step 26], time=0.09343910217285156, ext_time=0.06441354751586914, train_time=0.02325892448425293
[Epoch 0][Step 27], time=0.09439420700073242, ext_time=0.06381916999816895, train_time=0.024851560592651367
[Epoch 0][Step 28], time=0.09277796745300293, ext_time=0.06397628784179688, train_time=0.023034095764160156
[Epoch 0][Step 29], time=0.0921022891998291, ext_time=0.06460952758789062, train_time=0.021657466888427734
[Epoch 0][Step 30], time=0.0926210880279541, ext_time=0.06431198120117188, train_time=0.02249884605407715
[Epoch 0][Step 31], time=0.09139490127563477, ext_time=0.06376814842224121, train_time=0.02194833755493164
[Epoch 0][Step 32], time=0.09193062782287598, ext_time=0.06345725059509277, train_time=0.022788047790527344
[Epoch 0][Step 33], time=0.09279322624206543, ext_time=0.06492733955383301, train_time=0.022103309631347656
[Epoch 0][Step 34], time=0.09425830841064453, ext_time=0.06530499458312988, train_time=0.02314472198486328
[Epoch 0][Step 35], time=0.09252166748046875, ext_time=0.06462860107421875, train_time=0.022128582000732422
[Epoch 0][Step 36], time=0.09225130081176758, ext_time=0.06454825401306152, train_time=0.02190852165222168
[Epoch 0][Step 37], time=0.0925593376159668, ext_time=0.06491637229919434, train_time=0.0218660831451416
[Epoch 0][Step 38], time=0.09316468238830566, ext_time=0.06481742858886719, train_time=0.022575855255126953
[Epoch 0][Step 39], time=0.0921471118927002, ext_time=0.06454014778137207, train_time=0.02182936668395996
[Epoch 0][Step 40], time=0.09259653091430664, ext_time=0.06405901908874512, train_time=0.022827625274658203
[Epoch 0][Step 41], time=0.09163928031921387, ext_time=0.0637967586517334, train_time=0.022115230560302734
[Epoch 0][Step 42], time=0.09212422370910645, ext_time=0.06454992294311523, train_time=0.021816492080688477
[Epoch 0][Step 43], time=0.09610843658447266, ext_time=0.06524324417114258, train_time=0.02510523796081543
[Epoch 0][Step 44], time=0.09179520606994629, ext_time=0.0638587474822998, train_time=0.022202730178833008
[Epoch 0][Step 45], time=0.09298348426818848, ext_time=0.06470012664794922, train_time=0.02251410484313965
[Epoch 0][Step 46], time=0.09264636039733887, ext_time=0.06451082229614258, train_time=0.022467613220214844
[Epoch 0][Step 47], time=0.09195280075073242, ext_time=0.06457114219665527, train_time=0.02166914939880371
[Epoch 0][Step 48], time=0.09171581268310547, ext_time=0.06456232070922852, train_time=0.021450281143188477
[Epoch 0][Step 49], time=0.09190940856933594, ext_time=0.06452465057373047, train_time=0.021556854248046875
[Epoch 0][Step 50], time=0.09324169158935547, ext_time=0.0653524398803711, train_time=0.022112131118774414
[Epoch 0][Step 51], time=0.09211397171020508, ext_time=0.0647425651550293, train_time=0.021639585494995117
[Epoch 0][Step 52], time=0.09187984466552734, ext_time=0.06435108184814453, train_time=0.02178335189819336
[Epoch 0][Step 53], time=0.09253454208374023, ext_time=0.06478619575500488, train_time=0.022019624710083008
[Epoch 0][Step 54], time=0.09229230880737305, ext_time=0.06370186805725098, train_time=0.022769927978515625
[Epoch 0][Step 55], time=0.09279680252075195, ext_time=0.06498026847839355, train_time=0.02202606201171875
[Epoch 0][Step 56], time=0.09179854393005371, ext_time=0.06380748748779297, train_time=0.02217841148376465
[Epoch 0][Step 57], time=0.09208488464355469, ext_time=0.06433272361755371, train_time=0.021911144256591797
[Epoch 0][Step 58], time=0.09261131286621094, ext_time=0.06404590606689453, train_time=0.022893905639648438
[Epoch 0][Step 59], time=0.09244275093078613, ext_time=0.0649564266204834, train_time=0.0217742919921875
[Epoch 0][Step 60], time=0.09386801719665527, ext_time=0.06380009651184082, train_time=0.024323463439941406
[Epoch 0][Step 61], time=0.09224343299865723, ext_time=0.06471014022827148, train_time=0.0217282772064209
[Epoch 0][Step 62], time=0.0922701358795166, ext_time=0.0635831356048584, train_time=0.023000240325927734
[Epoch 0][Step 63], time=0.09197807312011719, ext_time=0.06374859809875488, train_time=0.022437572479248047
[Epoch 0][Step 64], time=0.0924386978149414, ext_time=0.06355452537536621, train_time=0.02317357063293457
[Epoch 0][Step 65], time=0.09218215942382812, ext_time=0.06480884552001953, train_time=0.02165532112121582
[Epoch 0][Step 66], time=0.09231162071228027, ext_time=0.06463956832885742, train_time=0.021862030029296875
[Epoch 0][Step 67], time=0.09187173843383789, ext_time=0.06449723243713379, train_time=0.02164745330810547
[Epoch 0][Step 68], time=0.09252190589904785, ext_time=0.0647735595703125, train_time=0.022063493728637695
[Epoch 0][Step 69], time=0.09233331680297852, ext_time=0.06373119354248047, train_time=0.02289748191833496
[Epoch 0][Step 70], time=0.0925285816192627, ext_time=0.06475186347961426, train_time=0.022053241729736328
[Epoch 0][Step 71], time=0.0919044017791748, ext_time=0.06436467170715332, train_time=0.021851062774658203
[Epoch 0][Step 72], time=0.09264683723449707, ext_time=0.06503891944885254, train_time=0.021759748458862305
[Epoch 0][Step 73], time=0.09214377403259277, ext_time=0.06459283828735352, train_time=0.021770715713500977
[Epoch 0][Step 74], time=0.09208893775939941, ext_time=0.06449532508850098, train_time=0.021866559982299805
[Epoch 0][Step 75], time=0.09330296516418457, ext_time=0.06556892395019531, train_time=0.021913766860961914
[Epoch 0][Step 76], time=0.09217095375061035, ext_time=0.0642693042755127, train_time=0.022116899490356445
[Epoch 0][Step 77], time=0.09218311309814453, ext_time=0.06459569931030273, train_time=0.021746158599853516
[Epoch 0][Step 78], time=0.09180879592895508, ext_time=0.06384968757629395, train_time=0.022279977798461914
[Epoch 0][Step 79], time=0.09581160545349121, ext_time=0.06333088874816895, train_time=0.02688312530517578
[Epoch 0][Step 80], time=0.09291911125183105, ext_time=0.06524062156677246, train_time=0.021889209747314453
[Epoch 0][Step 81], time=0.0920400619506836, ext_time=0.06457281112670898, train_time=0.021717548370361328
[Epoch 0][Step 82], time=0.0930178165435791, ext_time=0.06467747688293457, train_time=0.022617340087890625
[Epoch 0][Step 83], time=0.09208869934082031, ext_time=0.06331825256347656, train_time=0.0229184627532959
[Epoch 0][Step 84], time=0.09119725227355957, ext_time=0.06381583213806152, train_time=0.021636962890625
[Epoch 0][Step 85], time=0.09329795837402344, ext_time=0.06552767753601074, train_time=0.021961688995361328
[Epoch 0][Step 86], time=0.09218263626098633, ext_time=0.06402111053466797, train_time=0.022480487823486328
[Epoch 0][Step 87], time=0.09163427352905273, ext_time=0.06385493278503418, train_time=0.022065162658691406
[Epoch 0][Step 88], time=0.09167075157165527, ext_time=0.06441760063171387, train_time=0.021573543548583984
[Epoch 0][Step 89], time=0.09350013732910156, ext_time=0.06406354904174805, train_time=0.02374863624572754
[Epoch 0][Step 90], time=0.09298872947692871, ext_time=0.06486344337463379, train_time=0.022319793701171875
[Epoch 0][Step 91], time=0.09161615371704102, ext_time=0.06408190727233887, train_time=0.021825313568115234
[Epoch 0][Step 92], time=0.09333229064941406, ext_time=0.06566309928894043, train_time=0.021903276443481445
[Epoch 0][Step 93], time=0.09306049346923828, ext_time=0.06330418586730957, train_time=0.024077653884887695
[Epoch 0][Step 94], time=0.09220337867736816, ext_time=0.06412124633789062, train_time=0.022379398345947266
[Epoch 0][Step 95], time=0.09173941612243652, ext_time=0.06440401077270508, train_time=0.021594762802124023
[Epoch 0][Step 96], time=0.0921010971069336, ext_time=0.06306934356689453, train_time=0.023391246795654297
[Epoch 0][Step 97], time=0.14960765838623047, ext_time=0.06469583511352539, train_time=0.07918071746826172
[Epoch 0][Step 98], time=0.09206366539001465, ext_time=0.06373333930969238, train_time=0.022568225860595703
[Epoch 0][Step 99], time=0.10024404525756836, ext_time=0.06409406661987305, train_time=0.030434131622314453
[Epoch 0][Step 100], time=0.09177231788635254, ext_time=0.06483221054077148, train_time=0.021176576614379883
[Epoch 0][Step 101], time=0.0928657054901123, ext_time=0.06380295753479004, train_time=0.02335071563720703
[Epoch 0][Step 102], time=0.09303879737854004, ext_time=0.06438589096069336, train_time=0.022914409637451172
[Epoch 0][Step 103], time=0.09259033203125, ext_time=0.06473636627197266, train_time=0.022011518478393555
[Epoch 0][Step 104], time=0.09229302406311035, ext_time=0.06464576721191406, train_time=0.02188897132873535
[Epoch 0][Step 105], time=0.0928030014038086, ext_time=0.06376051902770996, train_time=0.02329707145690918
[Epoch 0][Step 106], time=0.09269833564758301, ext_time=0.06475996971130371, train_time=0.022204160690307617
[Epoch 0][Step 107], time=0.09525871276855469, ext_time=0.0644080638885498, train_time=0.025087833404541016
[Epoch 0][Step 108], time=0.09178805351257324, ext_time=0.06245827674865723, train_time=0.023674726486206055
[Epoch 0][Step 109], time=0.09221386909484863, ext_time=0.06371092796325684, train_time=0.02277517318725586
[Epoch 0][Step 110], time=0.09199047088623047, ext_time=0.06424212455749512, train_time=0.02202439308166504
[Epoch 0][Step 111], time=0.09208321571350098, ext_time=0.06362390518188477, train_time=0.0226743221282959
[Epoch 0][Step 112], time=0.0925900936126709, ext_time=0.06419062614440918, train_time=0.022626876831054688
[Epoch 0][Step 113], time=0.09201550483703613, ext_time=0.06402730941772461, train_time=0.022265911102294922
[Epoch 0][Step 114], time=0.09170079231262207, ext_time=0.06428766250610352, train_time=0.021638870239257812
[Epoch 0][Step 115], time=0.0930178165435791, ext_time=0.06538939476013184, train_time=0.0218350887298584
[Epoch 0][Step 116], time=0.09250593185424805, ext_time=0.06431198120117188, train_time=0.02246570587158203
[Epoch 0][Step 117], time=0.09208965301513672, ext_time=0.06432008743286133, train_time=0.0219876766204834
[Epoch 0][Step 118], time=0.0923604965209961, ext_time=0.06373953819274902, train_time=0.02300119400024414
[Epoch 0][Step 119], time=0.09202718734741211, ext_time=0.06356430053710938, train_time=0.02273845672607422
[Epoch 0][Step 120], time=0.09246253967285156, ext_time=0.06504154205322266, train_time=0.02170395851135254
[Epoch 0][Step 121], time=0.0920102596282959, ext_time=0.06401324272155762, train_time=0.022301197052001953
[Epoch 0][Step 122], time=0.09213662147521973, ext_time=0.06464767456054688, train_time=0.021725177764892578
[Epoch 0][Step 123], time=0.09256100654602051, ext_time=0.0649867057800293, train_time=0.021823883056640625
[Epoch 0][Step 124], time=0.0928795337677002, ext_time=0.06378388404846191, train_time=0.023406267166137695
[Epoch 0][Step 125], time=0.09246826171875, ext_time=0.06413674354553223, train_time=0.02248382568359375
[Epoch 0][Step 126], time=0.09277820587158203, ext_time=0.06489253044128418, train_time=0.02208089828491211
[Epoch 0][Step 127], time=0.15796804428100586, ext_time=0.06400942802429199, train_time=0.0881655216217041
[Epoch 0][Step 128], time=0.09404635429382324, ext_time=0.0651693344116211, train_time=0.02303624153137207
[Epoch 0][Step 129], time=0.09285593032836914, ext_time=0.06381344795227051, train_time=0.023189067840576172
[Epoch 0][Step 130], time=0.0928041934967041, ext_time=0.06496524810791016, train_time=0.02198195457458496
[Epoch 0][Step 131], time=0.09169125556945801, ext_time=0.0636756420135498, train_time=0.022316694259643555
[Epoch 0][Step 132], time=0.09331130981445312, ext_time=0.06381106376647949, train_time=0.023796796798706055
[Epoch 0][Step 133], time=0.09310007095336914, ext_time=0.06544780731201172, train_time=0.021862268447875977
[Epoch 0][Step 134], time=0.09264063835144043, ext_time=0.06457901000976562, train_time=0.02229475975036621
[Epoch 0][Step 135], time=0.09232759475708008, ext_time=0.06481289863586426, train_time=0.021730661392211914
[Epoch 0][Step 136], time=0.0922236442565918, ext_time=0.06462955474853516, train_time=0.021844148635864258
[Epoch 0][Step 137], time=0.09240126609802246, ext_time=0.06455254554748535, train_time=0.02213287353515625
[Epoch 0][Step 138], time=0.09331989288330078, ext_time=0.06390857696533203, train_time=0.023730039596557617
[Epoch 0][Step 139], time=0.09343242645263672, ext_time=0.06455230712890625, train_time=0.02305436134338379
[Epoch 0][Step 140], time=0.09191703796386719, ext_time=0.06335806846618652, train_time=0.02280712127685547
[Epoch 0][Step 141], time=0.09199762344360352, ext_time=0.06437873840332031, train_time=0.021819353103637695
[Epoch 0][Step 142], time=0.09200930595397949, ext_time=0.06431293487548828, train_time=0.02188706398010254
[Epoch 0][Step 143], time=0.0916748046875, ext_time=0.06325435638427734, train_time=0.02276325225830078
[Epoch 0][Step 144], time=0.09215164184570312, ext_time=0.0652761459350586, train_time=0.02112269401550293
[Epoch 0][Step 145], time=0.09296131134033203, ext_time=0.06470823287963867, train_time=0.022229671478271484
[Epoch 0][Step 146], time=0.09286093711853027, ext_time=0.06499505043029785, train_time=0.02198338508605957
[Epoch 0][Step 147], time=0.09574770927429199, ext_time=0.06413817405700684, train_time=0.021536588668823242
[Epoch 0][Step 148], time=0.09274649620056152, ext_time=0.06503438949584961, train_time=0.021966934204101562
[Epoch 0][Step 149], time=0.09261631965637207, ext_time=0.06382632255554199, train_time=0.023197650909423828
[Epoch 0][Step 150], time=0.09276556968688965, ext_time=0.06450748443603516, train_time=0.022540569305419922
[Epoch 0][Step 151], time=0.09251999855041504, ext_time=0.0646369457244873, train_time=0.022077083587646484
[Epoch 0][Step 152], time=0.09222006797790527, ext_time=0.06389427185058594, train_time=0.022661447525024414
[Epoch 0][Step 153], time=0.09239411354064941, ext_time=0.06409740447998047, train_time=0.022511959075927734
[Epoch 0][Step 154], time=0.09249663352966309, ext_time=0.06488275527954102, train_time=0.021876811981201172
[Epoch 0][Step 155], time=0.09236764907836914, ext_time=0.0653994083404541, train_time=0.02122783660888672
[Epoch 0][Step 156], time=0.09293055534362793, ext_time=0.06449317932128906, train_time=0.022694110870361328
[Epoch 0][Step 157], time=0.09328699111938477, ext_time=0.06470990180969238, train_time=0.02280735969543457
[Epoch 0][Step 158], time=0.092132568359375, ext_time=0.06446075439453125, train_time=0.021954059600830078
[Epoch 0][Step 159], time=0.09110665321350098, ext_time=0.06451153755187988, train_time=0.020832300186157227
[Epoch 0][Step 160], time=0.09116935729980469, ext_time=0.06398558616638184, train_time=0.021558046340942383
[Epoch 0][Step 161], time=0.09455752372741699, ext_time=0.06556940078735352, train_time=0.023234128952026367
[Epoch 0][Step 162], time=0.09238696098327637, ext_time=0.06412792205810547, train_time=0.022362232208251953
[Epoch 0][Step 163], time=0.09425568580627441, ext_time=0.0650339126586914, train_time=0.023453474044799805
[Epoch 0][Step 164], time=0.09155774116516113, ext_time=0.06396269798278809, train_time=0.021834373474121094
[Epoch 0][Step 165], time=0.0931401252746582, ext_time=0.0652165412902832, train_time=0.022134065628051758
[Epoch 0][Step 166], time=0.09156513214111328, ext_time=0.06412124633789062, train_time=0.02166914939880371
[Epoch 0][Step 167], time=0.09148502349853516, ext_time=0.06415104866027832, train_time=0.021610498428344727
[Epoch 0][Step 168], time=0.09265518188476562, ext_time=0.06491613388061523, train_time=0.022049665451049805
[Epoch 0][Step 169], time=0.09337520599365234, ext_time=0.06525158882141113, train_time=0.022353410720825195
[Epoch 0][Step 170], time=0.09212851524353027, ext_time=0.06326127052307129, train_time=0.023191452026367188
[Epoch 0][Step 171], time=0.09139895439147949, ext_time=0.06260347366333008, train_time=0.023181676864624023
[Epoch 0][Step 172], time=0.09281158447265625, ext_time=0.06435537338256836, train_time=0.02273273468017578
[Epoch 0][Step 173], time=0.09300875663757324, ext_time=0.06397390365600586, train_time=0.023374080657958984
[Epoch 0][Step 174], time=0.0929110050201416, ext_time=0.0634298324584961, train_time=0.02385401725769043
[Epoch 0][Step 175], time=0.09241509437561035, ext_time=0.06504058837890625, train_time=0.021593093872070312
[Epoch 0][Step 176], time=0.09153342247009277, ext_time=0.06442451477050781, train_time=0.021439075469970703
[Epoch 0][Step 177], time=0.09372234344482422, ext_time=0.06518030166625977, train_time=0.022843599319458008
[Epoch 0][Step 178], time=0.09276175498962402, ext_time=0.06446957588195801, train_time=0.02244257926940918
[Epoch 0][Step 179], time=0.09214568138122559, ext_time=0.06369733810424805, train_time=0.02276301383972168
[Epoch 0][Step 180], time=0.09174013137817383, ext_time=0.06381011009216309, train_time=0.022182226181030273
[Epoch 0][Step 181], time=0.09136319160461426, ext_time=0.06399893760681152, train_time=0.021590471267700195
[Epoch 0][Step 182], time=0.09251713752746582, ext_time=0.06515264511108398, train_time=0.02167534828186035
[Epoch 0][Step 183], time=0.0925900936126709, ext_time=0.06416964530944824, train_time=0.022650480270385742
[Epoch 0][Step 184], time=0.09235477447509766, ext_time=0.06461024284362793, train_time=0.021994352340698242
[Epoch 0][Step 185], time=0.09181690216064453, ext_time=0.06394362449645996, train_time=0.02217411994934082
[Epoch 0][Step 186], time=0.09199047088623047, ext_time=0.06416082382202148, train_time=0.022095441818237305
[Epoch 0][Step 187], time=0.09289717674255371, ext_time=0.06467199325561523, train_time=0.022435665130615234
[Epoch 0][Step 188], time=0.09157061576843262, ext_time=0.06317591667175293, train_time=0.022544145584106445
[Epoch 0][Step 189], time=0.09131979942321777, ext_time=0.06421041488647461, train_time=0.021482229232788086
[Epoch 0][Step 190], time=0.09200620651245117, ext_time=0.06463241577148438, train_time=0.021668672561645508
[Epoch 0][Step 191], time=0.09261751174926758, ext_time=0.06437873840332031, train_time=0.022519350051879883
[Epoch 0][Step 192], time=0.09194660186767578, ext_time=0.06434035301208496, train_time=0.021851778030395508
[Epoch 0][Step 193], time=0.09207844734191895, ext_time=0.06477689743041992, train_time=0.021610736846923828
[Epoch 0][Step 194], time=0.09307169914245605, ext_time=0.06365585327148438, train_time=0.023745298385620117
[Epoch 0][Step 195], time=0.09263038635253906, ext_time=0.06336855888366699, train_time=0.02364325523376465
[Epoch 0][Step 196], time=0.0922236442565918, ext_time=0.064056396484375, train_time=0.022458314895629883
[Epoch 0][Step 197], time=0.09203743934631348, ext_time=0.0643606185913086, train_time=0.021899938583374023
[Epoch 0][Step 198], time=0.09382915496826172, ext_time=0.06591153144836426, train_time=0.022095203399658203
[Epoch 0][Step 199], time=0.09178829193115234, ext_time=0.0641789436340332, train_time=0.02182745933532715
[Epoch 0][Step 200], time=0.09162664413452148, ext_time=0.06442093849182129, train_time=0.021552324295043945
[Epoch 0][Step 201], time=0.09248161315917969, ext_time=0.06362009048461914, train_time=0.023215532302856445
[Epoch 0][Step 202], time=0.09292316436767578, ext_time=0.0651698112487793, train_time=0.02201247215270996
[Epoch 0][Step 203], time=0.09264898300170898, ext_time=0.06448078155517578, train_time=0.02242898941040039
[Epoch 0][Step 204], time=0.09350085258483887, ext_time=0.0648043155670166, train_time=0.022341489791870117
[Epoch 0][Step 205], time=0.09190487861633301, ext_time=0.06445455551147461, train_time=0.02169942855834961
[Epoch 0][Step 206], time=0.09223151206970215, ext_time=0.06476235389709473, train_time=0.02173924446105957
[Epoch 0][Step 207], time=0.09345173835754395, ext_time=0.06420183181762695, train_time=0.023556232452392578
[Epoch 0][Step 208], time=0.09265875816345215, ext_time=0.06386184692382812, train_time=0.023128032684326172
[Epoch 0][Step 209], time=0.09348273277282715, ext_time=0.06535983085632324, train_time=0.02232670783996582
[Epoch 0][Step 210], time=0.09345865249633789, ext_time=0.06564211845397949, train_time=0.021979808807373047
[Epoch 0][Step 211], time=0.09222793579101562, ext_time=0.06380844116210938, train_time=0.022669315338134766
[Epoch 0][Step 212], time=0.09127044677734375, ext_time=0.06395220756530762, train_time=0.02161884307861328
[Epoch 0][Step 213], time=0.09282684326171875, ext_time=0.06523704528808594, train_time=0.02184009552001953
[Epoch 0][Step 214], time=0.09244513511657715, ext_time=0.06354069709777832, train_time=0.02317976951599121
[Epoch 0][Step 215], time=0.09161090850830078, ext_time=0.06420350074768066, train_time=0.021648406982421875
[Epoch 0][Step 216], time=0.09163117408752441, ext_time=0.0639948844909668, train_time=0.021908044815063477
[Epoch 0][Step 217], time=0.09260678291320801, ext_time=0.06432509422302246, train_time=0.022633790969848633
[Epoch 0][Step 218], time=0.09268784523010254, ext_time=0.0644838809967041, train_time=0.022459983825683594
[Epoch 0][Step 219], time=0.09206748008728027, ext_time=0.06414365768432617, train_time=0.022234201431274414
[Epoch 0][Step 220], time=0.09323453903198242, ext_time=0.06486272811889648, train_time=0.022625207901000977
[Epoch 0][Step 221], time=0.09191155433654785, ext_time=0.06441950798034668, train_time=0.021801233291625977
[Epoch 0][Step 222], time=0.09125018119812012, ext_time=0.06409382820129395, train_time=0.021484851837158203
[Epoch 0][Step 223], time=0.09136343002319336, ext_time=0.06376147270202637, train_time=0.021930932998657227
[Epoch 0][Step 224], time=0.09247493743896484, ext_time=0.0636599063873291, train_time=0.02313065528869629
[Epoch 0][Step 225], time=0.09297728538513184, ext_time=0.0646827220916748, train_time=0.022483110427856445
[Epoch 0][Step 226], time=0.09183859825134277, ext_time=0.0636589527130127, train_time=0.022307872772216797
[Epoch 0][Step 227], time=0.0918276309967041, ext_time=0.06418275833129883, train_time=0.021924972534179688
[Epoch 0][Step 228], time=0.09271550178527832, ext_time=0.06495285034179688, train_time=0.021945714950561523
[Epoch 0][Step 229], time=0.09090018272399902, ext_time=0.06333684921264648, train_time=0.02193617820739746
[Epoch 0][Step 230], time=0.09146356582641602, ext_time=0.06324124336242676, train_time=0.022563457489013672
[Epoch 0][Step 231], time=0.09265923500061035, ext_time=0.06504321098327637, train_time=0.02182793617248535
[Epoch 0][Step 232], time=0.09181070327758789, ext_time=0.06426787376403809, train_time=0.021747350692749023
[Epoch 0][Step 233], time=0.09253525733947754, ext_time=0.0646369457244873, train_time=0.022153377532958984
[Epoch 0][Step 234], time=0.09184145927429199, ext_time=0.06324577331542969, train_time=0.022920608520507812
[Epoch 0][Step 235], time=0.09214138984680176, ext_time=0.06450462341308594, train_time=0.021889209747314453
[Epoch 0][Step 236], time=0.09226560592651367, ext_time=0.0646975040435791, train_time=0.021885156631469727
[Epoch 0][Step 237], time=0.09318161010742188, ext_time=0.06561470031738281, train_time=0.021714210510253906
[Epoch 0][Step 238], time=0.09314656257629395, ext_time=0.06564712524414062, train_time=0.02177286148071289
[Epoch 0][Step 239], time=0.09210681915283203, ext_time=0.06372475624084473, train_time=0.022680044174194336
[Epoch 0][Step 240], time=0.0932009220123291, ext_time=0.0653524398803711, train_time=0.022049903869628906
[Epoch 0][Step 241], time=0.09310770034790039, ext_time=0.06462383270263672, train_time=0.02275562286376953
[Epoch 0][Step 242], time=0.09162116050720215, ext_time=0.06382918357849121, train_time=0.021883726119995117
[Epoch 0][Step 243], time=0.09250903129577637, ext_time=0.06427955627441406, train_time=0.022518634796142578
[Epoch 0][Step 244], time=0.09235119819641113, ext_time=0.06444549560546875, train_time=0.022116422653198242
[Epoch 0][Step 245], time=0.09177494049072266, ext_time=0.06341958045959473, train_time=0.02267932891845703
[Epoch 0][Step 246], time=0.09424519538879395, ext_time=0.06525087356567383, train_time=0.0231781005859375
[Epoch 0][Step 247], time=0.0918886661529541, ext_time=0.06421709060668945, train_time=0.021833181381225586
[Epoch 0][Step 248], time=0.09292197227478027, ext_time=0.06534886360168457, train_time=0.02180314064025879
[Epoch 0][Step 249], time=0.0942234992980957, ext_time=0.06379890441894531, train_time=0.024712562561035156
[Epoch 0], time=24.44329857826233, loss=0.6931472420692444
[Epoch 1][Step 0], time=0.09200453758239746, ext_time=0.06454229354858398, train_time=0.021729707717895508
[Epoch 1][Step 1], time=0.09250044822692871, ext_time=0.06507396697998047, train_time=0.02170562744140625
[Epoch 1][Step 2], time=0.09206843376159668, ext_time=0.06342482566833496, train_time=0.022897958755493164
[Epoch 1][Step 3], time=0.09252309799194336, ext_time=0.0649876594543457, train_time=0.02176690101623535
[Epoch 1][Step 4], time=0.09244728088378906, ext_time=0.06510066986083984, train_time=0.021582365036010742
[Epoch 1][Step 5], time=0.09148097038269043, ext_time=0.06476497650146484, train_time=0.020930051803588867
[Epoch 1][Step 6], time=0.09226441383361816, ext_time=0.06546568870544434, train_time=0.02101731300354004
[Epoch 1][Step 7], time=0.09106016159057617, ext_time=0.06360292434692383, train_time=0.02180171012878418
[Epoch 1][Step 8], time=0.09139084815979004, ext_time=0.0647125244140625, train_time=0.0208740234375
[Epoch 1][Step 9], time=0.09084725379943848, ext_time=0.06438422203063965, train_time=0.02073073387145996
[Epoch 1][Step 10], time=0.09114789962768555, ext_time=0.06394314765930176, train_time=0.021532058715820312
[Epoch 1][Step 11], time=0.09105038642883301, ext_time=0.06417274475097656, train_time=0.021207094192504883
[Epoch 1][Step 12], time=0.09074258804321289, ext_time=0.06367993354797363, train_time=0.021381139755249023
[Epoch 1][Step 13], time=0.09111881256103516, ext_time=0.06407999992370605, train_time=0.021146059036254883
[Epoch 1][Step 14], time=0.09159564971923828, ext_time=0.06306052207946777, train_time=0.022820234298706055
[Epoch 1][Step 15], time=0.0913090705871582, ext_time=0.06375002861022949, train_time=0.021896839141845703
[Epoch 1][Step 16], time=0.09158205986022949, ext_time=0.06492733955383301, train_time=0.020905017852783203
[Epoch 1][Step 17], time=0.09186077117919922, ext_time=0.06436753273010254, train_time=0.02173614501953125
[Epoch 1][Step 18], time=0.09178566932678223, ext_time=0.06505060195922852, train_time=0.020975589752197266
[Epoch 1][Step 19], time=0.09082841873168945, ext_time=0.06415700912475586, train_time=0.020949363708496094
[Epoch 1][Step 20], time=0.09147763252258301, ext_time=0.06369161605834961, train_time=0.022152423858642578
[Epoch 1][Step 21], time=0.09132266044616699, ext_time=0.0645895004272461, train_time=0.0209958553314209
[Epoch 1][Step 22], time=0.09330344200134277, ext_time=0.06462979316711426, train_time=0.02298283576965332
[Epoch 1][Step 23], time=0.09313273429870605, ext_time=0.06459522247314453, train_time=0.022847414016723633
[Epoch 1][Step 24], time=0.09225010871887207, ext_time=0.0642092227935791, train_time=0.022306442260742188
[Epoch 1][Step 25], time=0.09170126914978027, ext_time=0.0644524097442627, train_time=0.021549463272094727
[Epoch 1][Step 26], time=0.09151244163513184, ext_time=0.06341767311096191, train_time=0.022469282150268555
[Epoch 1][Step 27], time=0.0930013656616211, ext_time=0.06384944915771484, train_time=0.02346062660217285
[Epoch 1][Step 28], time=0.09264326095581055, ext_time=0.0642695426940918, train_time=0.02266550064086914
[Epoch 1][Step 29], time=0.09217619895935059, ext_time=0.06442904472351074, train_time=0.02120065689086914
[Epoch 1][Step 30], time=0.09238743782043457, ext_time=0.063232421875, train_time=0.02344036102294922
[Epoch 1][Step 31], time=0.09207010269165039, ext_time=0.06433296203613281, train_time=0.022027969360351562
[Epoch 1][Step 32], time=0.0908365249633789, ext_time=0.06339383125305176, train_time=0.0217745304107666
[Epoch 1][Step 33], time=0.09250020980834961, ext_time=0.06480526924133301, train_time=0.021993637084960938
[Epoch 1][Step 34], time=0.09313488006591797, ext_time=0.06532788276672363, train_time=0.021965742111206055
[Epoch 1][Step 35], time=0.09183239936828613, ext_time=0.06378340721130371, train_time=0.022380590438842773
[Epoch 1][Step 36], time=0.0919499397277832, ext_time=0.06438922882080078, train_time=0.0218045711517334
[Epoch 1][Step 37], time=0.09225153923034668, ext_time=0.06381988525390625, train_time=0.02272939682006836
[Epoch 1][Step 38], time=0.09257221221923828, ext_time=0.06471490859985352, train_time=0.02208876609802246
[Epoch 1][Step 39], time=0.09261465072631836, ext_time=0.06374168395996094, train_time=0.023211956024169922
[Epoch 1][Step 40], time=0.09206795692443848, ext_time=0.0645897388458252, train_time=0.021697044372558594
[Epoch 1][Step 41], time=0.09211349487304688, ext_time=0.06440162658691406, train_time=0.022040605545043945
[Epoch 1][Step 42], time=0.09234023094177246, ext_time=0.06474089622497559, train_time=0.021859407424926758
[Epoch 1][Step 43], time=0.09227657318115234, ext_time=0.0647439956665039, train_time=0.021836280822753906
[Epoch 1][Step 44], time=0.09228825569152832, ext_time=0.06483197212219238, train_time=0.021712541580200195
[Epoch 1][Step 45], time=0.09233522415161133, ext_time=0.06327056884765625, train_time=0.023204565048217773
[Epoch 1][Step 46], time=0.09196782112121582, ext_time=0.06449484825134277, train_time=0.021789073944091797
[Epoch 1][Step 47], time=0.09133696556091309, ext_time=0.06395196914672852, train_time=0.021716833114624023
[Epoch 1][Step 48], time=0.09167361259460449, ext_time=0.0643608570098877, train_time=0.021605730056762695
[Epoch 1][Step 49], time=0.09143400192260742, ext_time=0.06410360336303711, train_time=0.021618366241455078
[Epoch 1][Step 50], time=0.09256243705749512, ext_time=0.06373953819274902, train_time=0.02314615249633789
[Epoch 1][Step 51], time=0.09345006942749023, ext_time=0.06555008888244629, train_time=0.022089719772338867
[Epoch 1][Step 52], time=0.09252023696899414, ext_time=0.06401610374450684, train_time=0.022742509841918945
[Epoch 1][Step 53], time=0.09289932250976562, ext_time=0.0652163028717041, train_time=0.021877288818359375
[Epoch 1][Step 54], time=0.09173250198364258, ext_time=0.06403875350952148, train_time=0.02197265625
[Epoch 1][Step 55], time=0.09284448623657227, ext_time=0.06517171859741211, train_time=0.021877765655517578
[Epoch 1][Step 56], time=0.0910491943359375, ext_time=0.06385564804077148, train_time=0.021515369415283203
[Epoch 1][Step 57], time=0.09201312065124512, ext_time=0.06367301940917969, train_time=0.022652626037597656
[Epoch 1][Step 58], time=0.09215641021728516, ext_time=0.06441855430603027, train_time=0.02203822135925293
[Epoch 1][Step 59], time=0.09333443641662598, ext_time=0.06561446189880371, train_time=0.021950721740722656
[Epoch 1][Step 60], time=0.09264326095581055, ext_time=0.06501221656799316, train_time=0.021849632263183594
[Epoch 1][Step 61], time=0.09336614608764648, ext_time=0.06524920463562012, train_time=0.022372961044311523
[Epoch 1][Step 62], time=0.0926213264465332, ext_time=0.06488204002380371, train_time=0.021849632263183594
[Epoch 1][Step 63], time=0.09160089492797852, ext_time=0.06362700462341309, train_time=0.022234678268432617
[Epoch 1][Step 64], time=0.09245920181274414, ext_time=0.06483197212219238, train_time=0.02182602882385254
[Epoch 1][Step 65], time=0.09252214431762695, ext_time=0.06497406959533691, train_time=0.02175450325012207
[Epoch 1][Step 66], time=0.09246611595153809, ext_time=0.06366419792175293, train_time=0.02308797836303711
[Epoch 1][Step 67], time=0.09294581413269043, ext_time=0.06420302391052246, train_time=0.02173638343811035
[Epoch 1][Step 68], time=0.0929710865020752, ext_time=0.06392121315002441, train_time=0.0233919620513916
[Epoch 1][Step 69], time=0.0928184986114502, ext_time=0.06347799301147461, train_time=0.02365422248840332
[Epoch 1][Step 70], time=0.09290456771850586, ext_time=0.0644674301147461, train_time=0.022682666778564453
[Epoch 1][Step 71], time=0.0935525894165039, ext_time=0.06534075736999512, train_time=0.022449493408203125
[Epoch 1][Step 72], time=0.0941460132598877, ext_time=0.06548190116882324, train_time=0.022304773330688477
[Epoch 1][Step 73], time=0.09195518493652344, ext_time=0.06424379348754883, train_time=0.02194809913635254
[Epoch 1][Step 74], time=0.09202170372009277, ext_time=0.06483888626098633, train_time=0.021449565887451172
[Epoch 1][Step 75], time=0.09203958511352539, ext_time=0.06425261497497559, train_time=0.022095918655395508
[Epoch 1][Step 76], time=0.09138798713684082, ext_time=0.06317734718322754, train_time=0.02252030372619629
[Epoch 1][Step 77], time=0.09323883056640625, ext_time=0.06455039978027344, train_time=0.022908449172973633
[Epoch 1][Step 78], time=0.09271383285522461, ext_time=0.06492376327514648, train_time=0.02200174331665039
[Epoch 1][Step 79], time=0.09329414367675781, ext_time=0.06470060348510742, train_time=0.02287745475769043
[Epoch 1][Step 80], time=0.09224557876586914, ext_time=0.06466484069824219, train_time=0.021807193756103516
[Epoch 1][Step 81], time=0.09354567527770996, ext_time=0.06558108329772949, train_time=0.02216315269470215
[Epoch 1][Step 82], time=0.09255361557006836, ext_time=0.06471896171569824, train_time=0.022072315216064453
[Epoch 1][Step 83], time=0.09198522567749023, ext_time=0.0627889633178711, train_time=0.023545265197753906
[Epoch 1][Step 84], time=0.09188270568847656, ext_time=0.06354689598083496, train_time=0.022667407989501953
[Epoch 1][Step 85], time=0.09211611747741699, ext_time=0.06451821327209473, train_time=0.0218656063079834
[Epoch 1][Step 86], time=0.09322476387023926, ext_time=0.06520795822143555, train_time=0.02223968505859375
[Epoch 1][Step 87], time=0.09125423431396484, ext_time=0.06341171264648438, train_time=0.022121191024780273
[Epoch 1][Step 88], time=0.09261655807495117, ext_time=0.06536722183227539, train_time=0.021469593048095703
[Epoch 1][Step 89], time=0.09206604957580566, ext_time=0.06450414657592773, train_time=0.02183699607849121
[Epoch 1][Step 90], time=0.0922846794128418, ext_time=0.06454944610595703, train_time=0.0219728946685791
[Epoch 1][Step 91], time=0.09197092056274414, ext_time=0.06350946426391602, train_time=0.022802114486694336
[Epoch 1][Step 92], time=0.09273815155029297, ext_time=0.06435203552246094, train_time=0.022680282592773438
[Epoch 1][Step 93], time=0.09195780754089355, ext_time=0.06421947479248047, train_time=0.02198314666748047
[Epoch 1][Step 94], time=0.09211182594299316, ext_time=0.06339836120605469, train_time=0.022950172424316406
[Epoch 1][Step 95], time=0.09203982353210449, ext_time=0.06453227996826172, train_time=0.021802425384521484
[Epoch 1][Step 96], time=0.09179854393005371, ext_time=0.0641777515411377, train_time=0.021860599517822266
[Epoch 1][Step 97], time=0.09305953979492188, ext_time=0.06542420387268066, train_time=0.02182793617248535
[Epoch 1][Step 98], time=0.09199738502502441, ext_time=0.06374478340148926, train_time=0.0225677490234375
[Epoch 1][Step 99], time=0.09337258338928223, ext_time=0.06509590148925781, train_time=0.022463560104370117
[Epoch 1][Step 100], time=0.09278535842895508, ext_time=0.06499862670898438, train_time=0.022011518478393555
[Epoch 1][Step 101], time=0.0920100212097168, ext_time=0.06400799751281738, train_time=0.02229905128479004
[Epoch 1][Step 102], time=0.09242892265319824, ext_time=0.06492233276367188, train_time=0.02173900604248047
[Epoch 1][Step 103], time=0.09224176406860352, ext_time=0.06363224983215332, train_time=0.02292013168334961
[Epoch 1][Step 104], time=0.09181642532348633, ext_time=0.06429815292358398, train_time=0.02179098129272461
[Epoch 1][Step 105], time=0.09275627136230469, ext_time=0.06393146514892578, train_time=0.022962331771850586
[Epoch 1][Step 106], time=0.09268498420715332, ext_time=0.06430721282958984, train_time=0.022670269012451172
[Epoch 1][Step 107], time=0.09159588813781738, ext_time=0.06421542167663574, train_time=0.02167034149169922
[Epoch 1][Step 108], time=0.09213113784790039, ext_time=0.06307697296142578, train_time=0.023370742797851562
[Epoch 1][Step 109], time=0.09250712394714355, ext_time=0.06391000747680664, train_time=0.02291584014892578
[Epoch 1][Step 110], time=0.09176516532897949, ext_time=0.06403422355651855, train_time=0.021842002868652344
[Epoch 1][Step 111], time=0.09326410293579102, ext_time=0.06400489807128906, train_time=0.023564577102661133
[Epoch 1][Step 112], time=0.09223246574401855, ext_time=0.06453108787536621, train_time=0.0219266414642334
[Epoch 1][Step 113], time=0.09285116195678711, ext_time=0.06465268135070801, train_time=0.02245020866394043
[Epoch 1][Step 114], time=0.09316039085388184, ext_time=0.0642244815826416, train_time=0.02321457862854004
[Epoch 1][Step 115], time=0.09253859519958496, ext_time=0.0649569034576416, train_time=0.021630287170410156
[Epoch 1][Step 116], time=0.09323287010192871, ext_time=0.06428837776184082, train_time=0.02322697639465332
[Epoch 1][Step 117], time=0.09273028373718262, ext_time=0.06322598457336426, train_time=0.02385234832763672
[Epoch 1][Step 118], time=0.09075117111206055, ext_time=0.06374835968017578, train_time=0.021399736404418945
[Epoch 1][Step 119], time=0.09178280830383301, ext_time=0.06415700912475586, train_time=0.021932601928710938
[Epoch 1][Step 120], time=0.09306073188781738, ext_time=0.06520342826843262, train_time=0.02209329605102539
[Epoch 1][Step 121], time=0.09206962585449219, ext_time=0.0645589828491211, train_time=0.02169489860534668
[Epoch 1][Step 122], time=0.0917818546295166, ext_time=0.06446599960327148, train_time=0.02162909507751465
[Epoch 1][Step 123], time=0.09274625778198242, ext_time=0.06520771980285645, train_time=0.02177715301513672
[Epoch 1][Step 124], time=0.09193706512451172, ext_time=0.06440043449401855, train_time=0.021762371063232422
[Epoch 1][Step 125], time=0.09475350379943848, ext_time=0.0637671947479248, train_time=0.02532362937927246
[Epoch 1][Step 126], time=0.09311294555664062, ext_time=0.0639810562133789, train_time=0.02337336540222168
[Epoch 1][Step 127], time=0.09314894676208496, ext_time=0.06424570083618164, train_time=0.023153305053710938
[Epoch 1][Step 128], time=0.09210348129272461, ext_time=0.06462979316711426, train_time=0.021763086318969727
[Epoch 1][Step 129], time=0.09267330169677734, ext_time=0.06508255004882812, train_time=0.021826744079589844
[Epoch 1][Step 130], time=0.0923924446105957, ext_time=0.06465721130371094, train_time=0.022003173828125
[Epoch 1][Step 131], time=0.09327530860900879, ext_time=0.0649721622467041, train_time=0.022317171096801758
[Epoch 1][Step 132], time=0.0921473503112793, ext_time=0.06387948989868164, train_time=0.022489070892333984
[Epoch 1][Step 133], time=0.09334921836853027, ext_time=0.06543469429016113, train_time=0.022110462188720703
[Epoch 1][Step 134], time=0.09235191345214844, ext_time=0.06475639343261719, train_time=0.021808385848999023
[Epoch 1][Step 135], time=0.09229207038879395, ext_time=0.06484293937683105, train_time=0.021716594696044922
[Epoch 1][Step 136], time=0.09266352653503418, ext_time=0.06441283226013184, train_time=0.022527694702148438
[Epoch 1][Step 137], time=0.09337687492370605, ext_time=0.06391501426696777, train_time=0.023743867874145508
[Epoch 1][Step 138], time=0.09299707412719727, ext_time=0.06508469581604004, train_time=0.022084951400756836
[Epoch 1][Step 139], time=0.0927419662475586, ext_time=0.06487083435058594, train_time=0.022049903869628906
[Epoch 1][Step 140], time=0.09231424331665039, ext_time=0.06458020210266113, train_time=0.021993637084960938
[Epoch 1][Step 141], time=0.09138965606689453, ext_time=0.06449341773986816, train_time=0.021206140518188477
[Epoch 1][Step 142], time=0.09243631362915039, ext_time=0.06381630897521973, train_time=0.022869110107421875
[Epoch 1][Step 143], time=0.0911870002746582, ext_time=0.06389975547790527, train_time=0.021597623825073242
[Epoch 1][Step 144], time=0.09242653846740723, ext_time=0.06369972229003906, train_time=0.02310490608215332
[Epoch 1][Step 145], time=0.09154057502746582, ext_time=0.06399393081665039, train_time=0.021863460540771484
[Epoch 1][Step 146], time=0.09279704093933105, ext_time=0.06519699096679688, train_time=0.021837472915649414
[Epoch 1][Step 147], time=0.09373807907104492, ext_time=0.06487178802490234, train_time=0.023095369338989258
[Epoch 1][Step 148], time=0.09561705589294434, ext_time=0.06480145454406738, train_time=0.024760961532592773
[Epoch 1][Step 149], time=0.0931246280670166, ext_time=0.06436705589294434, train_time=0.02303624153137207
[Epoch 1][Step 150], time=0.09397149085998535, ext_time=0.062474966049194336, train_time=0.025807619094848633
[Epoch 1][Step 151], time=0.09235239028930664, ext_time=0.06490063667297363, train_time=0.02171158790588379
[Epoch 1][Step 152], time=0.09265851974487305, ext_time=0.06404566764831543, train_time=0.022939205169677734
[Epoch 1][Step 153], time=0.09300899505615234, ext_time=0.06287574768066406, train_time=0.024429798126220703
[Epoch 1][Step 154], time=0.09099292755126953, ext_time=0.06413125991821289, train_time=0.021209001541137695
[Epoch 1][Step 155], time=0.09330010414123535, ext_time=0.06541061401367188, train_time=0.022134780883789062
[Epoch 1][Step 156], time=0.09401392936706543, ext_time=0.06386375427246094, train_time=0.024485111236572266
[Epoch 1][Step 157], time=0.09167671203613281, ext_time=0.06414628028869629, train_time=0.021854639053344727
[Epoch 1][Step 158], time=0.09182190895080566, ext_time=0.06434369087219238, train_time=0.021692514419555664
[Epoch 1][Step 159], time=0.09237027168273926, ext_time=0.06466794013977051, train_time=0.021975278854370117
[Epoch 1][Step 160], time=0.09223556518554688, ext_time=0.06466269493103027, train_time=0.021826744079589844
[Epoch 1][Step 161], time=0.09232616424560547, ext_time=0.06484436988830566, train_time=0.02174973487854004
[Epoch 1][Step 162], time=0.09286069869995117, ext_time=0.06353545188903809, train_time=0.02368950843811035
[Epoch 1][Step 163], time=0.09227514266967773, ext_time=0.06403660774230957, train_time=0.02254009246826172
[Epoch 1][Step 164], time=0.09241771697998047, ext_time=0.06329727172851562, train_time=0.023347854614257812
[Epoch 1][Step 165], time=0.09223103523254395, ext_time=0.06452655792236328, train_time=0.021892070770263672
[Epoch 1][Step 166], time=0.09226679801940918, ext_time=0.06423616409301758, train_time=0.02235579490661621
[Epoch 1][Step 167], time=0.09337210655212402, ext_time=0.06469583511352539, train_time=0.02295684814453125
[Epoch 1][Step 168], time=0.09324836730957031, ext_time=0.0644993782043457, train_time=0.02306365966796875
[Epoch 1][Step 169], time=0.09250450134277344, ext_time=0.0649271011352539, train_time=0.02177572250366211
[Epoch 1][Step 170], time=0.09276771545410156, ext_time=0.06501293182373047, train_time=0.02190995216369629
[Epoch 1][Step 171], time=0.09258794784545898, ext_time=0.06268525123596191, train_time=0.024205446243286133
[Epoch 1][Step 172], time=0.09242558479309082, ext_time=0.06415104866027832, train_time=0.022557735443115234
[Epoch 1][Step 173], time=0.09288406372070312, ext_time=0.06288480758666992, train_time=0.024351835250854492
[Epoch 1][Step 174], time=0.09274435043334961, ext_time=0.06439948081970215, train_time=0.02259373664855957
[Epoch 1][Step 175], time=0.09205460548400879, ext_time=0.06378626823425293, train_time=0.022600650787353516
[Epoch 1][Step 176], time=0.09232330322265625, ext_time=0.06482386589050293, train_time=0.021730899810791016
[Epoch 1][Step 177], time=0.09336423873901367, ext_time=0.06518983840942383, train_time=0.02244877815246582
[Epoch 1][Step 178], time=0.09223222732543945, ext_time=0.06333065032958984, train_time=0.023173809051513672
[Epoch 1][Step 179], time=0.09256958961486816, ext_time=0.06497597694396973, train_time=0.021877765655517578
[Epoch 1][Step 180], time=0.09213590621948242, ext_time=0.06460714340209961, train_time=0.02170252799987793
[Epoch 1][Step 181], time=0.0928490161895752, ext_time=0.06401515007019043, train_time=0.023114919662475586
[Epoch 1][Step 182], time=0.09231805801391602, ext_time=0.06440281867980957, train_time=0.022226810455322266
[Epoch 1][Step 183], time=0.09238362312316895, ext_time=0.06386637687683105, train_time=0.02283334732055664
[Epoch 1][Step 184], time=0.09224605560302734, ext_time=0.0641031265258789, train_time=0.022449493408203125
[Epoch 1][Step 185], time=0.09363913536071777, ext_time=0.06452536582946777, train_time=0.023193359375
[Epoch 1][Step 186], time=0.09318256378173828, ext_time=0.06393933296203613, train_time=0.023574352264404297
[Epoch 1][Step 187], time=0.0954582691192627, ext_time=0.06375479698181152, train_time=0.02596259117126465
[Epoch 1][Step 188], time=0.09304380416870117, ext_time=0.06416440010070801, train_time=0.023141145706176758
[Epoch 1][Step 189], time=0.09374880790710449, ext_time=0.06504583358764648, train_time=0.022969722747802734
[Epoch 1][Step 190], time=0.09291958808898926, ext_time=0.06473255157470703, train_time=0.022335290908813477
[Epoch 1][Step 191], time=0.09267354011535645, ext_time=0.06467247009277344, train_time=0.022248029708862305
[Epoch 1][Step 192], time=0.09212255477905273, ext_time=0.06374073028564453, train_time=0.02269124984741211
[Epoch 1][Step 193], time=0.09242939949035645, ext_time=0.06477832794189453, train_time=0.021915912628173828
[Epoch 1][Step 194], time=0.09233331680297852, ext_time=0.06368684768676758, train_time=0.022953271865844727
[Epoch 1][Step 195], time=0.09326910972595215, ext_time=0.06401729583740234, train_time=0.02353382110595703
[Epoch 1][Step 196], time=0.09214258193969727, ext_time=0.06412339210510254, train_time=0.02225494384765625
[Epoch 1][Step 197], time=0.09244942665100098, ext_time=0.06483864784240723, train_time=0.021828651428222656
[Epoch 1][Step 198], time=0.09205317497253418, ext_time=0.06472635269165039, train_time=0.02164459228515625
[Epoch 1][Step 199], time=0.09279441833496094, ext_time=0.06462454795837402, train_time=0.022409677505493164
[Epoch 1][Step 200], time=0.09270596504211426, ext_time=0.06447649002075195, train_time=0.02245640754699707
[Epoch 1][Step 201], time=0.09136605262756348, ext_time=0.0639185905456543, train_time=0.021741151809692383
[Epoch 1][Step 202], time=0.09258127212524414, ext_time=0.0639338493347168, train_time=0.022989511489868164
[Epoch 1][Step 203], time=0.09286069869995117, ext_time=0.06454205513000488, train_time=0.022614717483520508
[Epoch 1][Step 204], time=0.0929417610168457, ext_time=0.06450772285461426, train_time=0.0227205753326416
[Epoch 1][Step 205], time=0.09296846389770508, ext_time=0.0650491714477539, train_time=0.022166728973388672
[Epoch 1][Step 206], time=0.09198522567749023, ext_time=0.06358027458190918, train_time=0.02253103256225586
[Epoch 1][Step 207], time=0.09162330627441406, ext_time=0.06304430961608887, train_time=0.022957324981689453
[Epoch 1][Step 208], time=0.09254956245422363, ext_time=0.06344223022460938, train_time=0.023450851440429688
[Epoch 1][Step 209], time=0.09310507774353027, ext_time=0.06418347358703613, train_time=0.023180723190307617
[Epoch 1][Step 210], time=0.09116411209106445, ext_time=0.06379580497741699, train_time=0.0217130184173584
[Epoch 1][Step 211], time=0.09223270416259766, ext_time=0.0630183219909668, train_time=0.023531675338745117
[Epoch 1][Step 212], time=0.09188532829284668, ext_time=0.06382322311401367, train_time=0.022321462631225586
[Epoch 1][Step 213], time=0.09249114990234375, ext_time=0.06429886817932129, train_time=0.022515058517456055
[Epoch 1][Step 214], time=0.09183979034423828, ext_time=0.06319117546081543, train_time=0.02297806739807129
[Epoch 1][Step 215], time=0.09280729293823242, ext_time=0.06495380401611328, train_time=0.02211785316467285
[Epoch 1][Step 216], time=0.09271836280822754, ext_time=0.0641169548034668, train_time=0.022842884063720703
[Epoch 1][Step 217], time=0.0916745662689209, ext_time=0.06432414054870605, train_time=0.02160334587097168
[Epoch 1][Step 218], time=0.09199333190917969, ext_time=0.06464099884033203, train_time=0.021650314331054688
[Epoch 1][Step 219], time=0.09224843978881836, ext_time=0.06323051452636719, train_time=0.023355960845947266
[Epoch 1][Step 220], time=0.09246826171875, ext_time=0.06432867050170898, train_time=0.022449254989624023
[Epoch 1][Step 221], time=0.09205222129821777, ext_time=0.06467032432556152, train_time=0.021643877029418945
[Epoch 1][Step 222], time=0.09277057647705078, ext_time=0.06453371047973633, train_time=0.022605180740356445
[Epoch 1][Step 223], time=0.09303593635559082, ext_time=0.06515216827392578, train_time=0.021912336349487305
[Epoch 1][Step 224], time=0.09227204322814941, ext_time=0.06336092948913574, train_time=0.023226499557495117
[Epoch 1][Step 225], time=0.09309959411621094, ext_time=0.06457638740539551, train_time=0.02270817756652832
[Epoch 1][Step 226], time=0.09229874610900879, ext_time=0.06376910209655762, train_time=0.022581100463867188
[Epoch 1][Step 227], time=0.09264993667602539, ext_time=0.06443309783935547, train_time=0.02220749855041504
[Epoch 1][Step 228], time=0.09236407279968262, ext_time=0.06418752670288086, train_time=0.022301673889160156
[Epoch 1][Step 229], time=0.09501194953918457, ext_time=0.06497550010681152, train_time=0.024139881134033203
[Epoch 1][Step 230], time=0.09185385704040527, ext_time=0.06306576728820801, train_time=0.022611618041992188
[Epoch 1][Step 231], time=0.09312772750854492, ext_time=0.06480693817138672, train_time=0.022400379180908203
[Epoch 1][Step 232], time=0.09386062622070312, ext_time=0.06516623497009277, train_time=0.022684812545776367
[Epoch 1][Step 233], time=0.0926065444946289, ext_time=0.06385636329650879, train_time=0.02283501625061035
[Epoch 1][Step 234], time=0.09341883659362793, ext_time=0.06438159942626953, train_time=0.023016691207885742
[Epoch 1][Step 235], time=0.09339213371276855, ext_time=0.06473612785339355, train_time=0.022622108459472656
[Epoch 1][Step 236], time=0.09324860572814941, ext_time=0.06493568420410156, train_time=0.022356510162353516
[Epoch 1][Step 237], time=0.09536385536193848, ext_time=0.06588149070739746, train_time=0.02257847785949707
[Epoch 1][Step 238], time=0.09211349487304688, ext_time=0.0642399787902832, train_time=0.021928787231445312
[Epoch 1][Step 239], time=0.0930938720703125, ext_time=0.06499385833740234, train_time=0.022111892700195312
[Epoch 1][Step 240], time=0.09487414360046387, ext_time=0.06520771980285645, train_time=0.023751258850097656
[Epoch 1][Step 241], time=0.09311556816101074, ext_time=0.0644526481628418, train_time=0.022783756256103516
[Epoch 1][Step 242], time=0.09211397171020508, ext_time=0.06375932693481445, train_time=0.02241373062133789
[Epoch 1][Step 243], time=0.09263062477111816, ext_time=0.06397438049316406, train_time=0.022690534591674805
[Epoch 1][Step 244], time=0.09276461601257324, ext_time=0.06435608863830566, train_time=0.022400617599487305
[Epoch 1][Step 245], time=0.09187602996826172, ext_time=0.06363081932067871, train_time=0.022287368774414062
[Epoch 1][Step 246], time=0.09308052062988281, ext_time=0.06467652320861816, train_time=0.022472143173217773
[Epoch 1][Step 247], time=0.09296560287475586, ext_time=0.06466388702392578, train_time=0.02239227294921875
[Epoch 1][Step 248], time=0.09301304817199707, ext_time=0.06451582908630371, train_time=0.022630929946899414
[Epoch 1][Step 249], time=0.09366059303283691, ext_time=0.0649862289428711, train_time=0.0226132869720459
[Epoch 1], time=23.138326168060303, loss=0.6931472420692444
[Epoch 2][Step 0], time=0.09537768363952637, ext_time=0.06536650657653809, train_time=0.024062633514404297
[Epoch 2][Step 1], time=0.09371805191040039, ext_time=0.06523394584655762, train_time=0.022536277770996094
[Epoch 2][Step 2], time=0.09200358390808105, ext_time=0.06377744674682617, train_time=0.022301197052001953
[Epoch 2][Step 3], time=0.0946035385131836, ext_time=0.06580615043640137, train_time=0.0227968692779541
[Epoch 2][Step 4], time=0.09278631210327148, ext_time=0.06452393531799316, train_time=0.022330760955810547
[Epoch 2][Step 5], time=0.09502673149108887, ext_time=0.0644080638885498, train_time=0.02476358413696289
[Epoch 2][Step 6], time=0.09251070022583008, ext_time=0.0642547607421875, train_time=0.022322416305541992
[Epoch 2][Step 7], time=0.09192919731140137, ext_time=0.06380629539489746, train_time=0.02222466468811035
[Epoch 2][Step 8], time=0.09203958511352539, ext_time=0.06383657455444336, train_time=0.02234363555908203
[Epoch 2][Step 9], time=0.09288239479064941, ext_time=0.06414628028869629, train_time=0.022789955139160156
[Epoch 2][Step 10], time=0.09258675575256348, ext_time=0.0640568733215332, train_time=0.022521495819091797
[Epoch 2][Step 11], time=0.09346652030944824, ext_time=0.0644690990447998, train_time=0.02309584617614746
[Epoch 2][Step 12], time=0.09200263023376465, ext_time=0.06380391120910645, train_time=0.022322416305541992
[Epoch 2][Step 13], time=0.09454107284545898, ext_time=0.06576681137084961, train_time=0.022766590118408203
[Epoch 2][Step 14], time=0.09345889091491699, ext_time=0.06417489051818848, train_time=0.02339959144592285
[Epoch 2][Step 15], time=0.09405016899108887, ext_time=0.06533503532409668, train_time=0.02257704734802246
[Epoch 2][Step 16], time=0.09303998947143555, ext_time=0.06474852561950684, train_time=0.022379636764526367
[Epoch 2][Step 17], time=0.09251785278320312, ext_time=0.06426215171813965, train_time=0.02235579490661621
[Epoch 2][Step 18], time=0.09332752227783203, ext_time=0.06508398056030273, train_time=0.022290706634521484
[Epoch 2][Step 19], time=0.09230852127075195, ext_time=0.06399226188659668, train_time=0.022482633590698242
[Epoch 2][Step 20], time=0.09405398368835449, ext_time=0.06524205207824707, train_time=0.022647857666015625
[Epoch 2][Step 21], time=0.09230351448059082, ext_time=0.06401634216308594, train_time=0.022372722625732422
[Epoch 2][Step 22], time=0.09298992156982422, ext_time=0.0641016960144043, train_time=0.02304697036743164
[Epoch 2][Step 23], time=0.09278225898742676, ext_time=0.06440591812133789, train_time=0.02248072624206543
[Epoch 2][Step 24], time=0.09195160865783691, ext_time=0.0637507438659668, train_time=0.022283077239990234
[Epoch 2][Step 25], time=0.09284734725952148, ext_time=0.06431770324707031, train_time=0.022652626037597656
[Epoch 2][Step 26], time=0.09290933609008789, ext_time=0.06452798843383789, train_time=0.022397279739379883
[Epoch 2][Step 27], time=0.09358596801757812, ext_time=0.06458020210266113, train_time=0.023044586181640625
[Epoch 2][Step 28], time=0.0928046703338623, ext_time=0.0643613338470459, train_time=0.02246403694152832
[Epoch 2][Step 29], time=0.09214425086975098, ext_time=0.06371140480041504, train_time=0.02258610725402832
[Epoch 2][Step 30], time=0.09306454658508301, ext_time=0.06462812423706055, train_time=0.022522926330566406
[Epoch 2][Step 31], time=0.09299063682556152, ext_time=0.06453251838684082, train_time=0.022567033767700195
[Epoch 2][Step 32], time=0.09183740615844727, ext_time=0.06329751014709473, train_time=0.022597074508666992
[Epoch 2][Step 33], time=0.09204840660095215, ext_time=0.06382179260253906, train_time=0.02230691909790039
[Epoch 2][Step 34], time=0.09318399429321289, ext_time=0.06469368934631348, train_time=0.022537946701049805
[Epoch 2][Step 35], time=0.092559814453125, ext_time=0.06372833251953125, train_time=0.022931337356567383
[Epoch 2][Step 36], time=0.09462952613830566, ext_time=0.06537413597106934, train_time=0.022893428802490234
[Epoch 2][Step 37], time=0.09298253059387207, ext_time=0.0644989013671875, train_time=0.022438526153564453
[Epoch 2][Step 38], time=0.09238314628601074, ext_time=0.06419920921325684, train_time=0.02226543426513672
[Epoch 2][Step 39], time=0.09223818778991699, ext_time=0.06415033340454102, train_time=0.022215604782104492
[Epoch 2][Step 40], time=0.09191775321960449, ext_time=0.06425881385803223, train_time=0.021767854690551758
[Epoch 2][Step 41], time=0.09246182441711426, ext_time=0.06346535682678223, train_time=0.023196935653686523
[Epoch 2][Step 42], time=0.09192299842834473, ext_time=0.06438374519348145, train_time=0.021569252014160156
[Epoch 2][Step 43], time=0.09337806701660156, ext_time=0.06495308876037598, train_time=0.02255082130432129
[Epoch 2][Step 44], time=0.0928337574005127, ext_time=0.06491398811340332, train_time=0.021937131881713867
[Epoch 2][Step 45], time=0.09237909317016602, ext_time=0.0640714168548584, train_time=0.022434234619140625
[Epoch 2][Step 46], time=0.09459090232849121, ext_time=0.06586384773254395, train_time=0.02272629737854004
[Epoch 2][Step 47], time=0.09421777725219727, ext_time=0.06561136245727539, train_time=0.022579431533813477
[Epoch 2][Step 48], time=0.0921640396118164, ext_time=0.06410431861877441, train_time=0.022205352783203125
[Epoch 2][Step 49], time=0.09306788444519043, ext_time=0.06468009948730469, train_time=0.02248525619506836
[Epoch 2][Step 50], time=0.09260416030883789, ext_time=0.06430816650390625, train_time=0.02239060401916504
[Epoch 2][Step 51], time=0.09302330017089844, ext_time=0.06478381156921387, train_time=0.0223085880279541
[Epoch 2][Step 52], time=0.0948190689086914, ext_time=0.06377077102661133, train_time=0.023138999938964844
[Epoch 2][Step 53], time=0.09403157234191895, ext_time=0.06548166275024414, train_time=0.022439241409301758
[Epoch 2][Step 54], time=0.09215164184570312, ext_time=0.06374073028564453, train_time=0.022513866424560547
[Epoch 2][Step 55], time=0.09330296516418457, ext_time=0.06519150733947754, train_time=0.02218937873840332
[Epoch 2][Step 56], time=0.0931694507598877, ext_time=0.06494998931884766, train_time=0.022330522537231445
[Epoch 2][Step 57], time=0.09340047836303711, ext_time=0.064727783203125, train_time=0.02271413803100586
[Epoch 2][Step 58], time=0.09343075752258301, ext_time=0.06488656997680664, train_time=0.022630691528320312
[Epoch 2][Step 59], time=0.09263134002685547, ext_time=0.06441617012023926, train_time=0.022309303283691406
[Epoch 2][Step 60], time=0.09336733818054199, ext_time=0.06470608711242676, train_time=0.02262282371520996
[Epoch 2][Step 61], time=0.09260725975036621, ext_time=0.06428194046020508, train_time=0.022413253784179688
[Epoch 2][Step 62], time=0.09426450729370117, ext_time=0.06510114669799805, train_time=0.023168563842773438
[Epoch 2][Step 63], time=0.09235692024230957, ext_time=0.06365084648132324, train_time=0.022653579711914062
[Epoch 2][Step 64], time=0.0929257869720459, ext_time=0.0643765926361084, train_time=0.02256464958190918
[Epoch 2][Step 65], time=0.09323668479919434, ext_time=0.06499576568603516, train_time=0.02223658561706543
[Epoch 2][Step 66], time=0.09304141998291016, ext_time=0.06469917297363281, train_time=0.02239847183227539
[Epoch 2][Step 67], time=0.09460115432739258, ext_time=0.06562519073486328, train_time=0.02301788330078125
[Epoch 2][Step 68], time=0.09405636787414551, ext_time=0.0652320384979248, train_time=0.022808074951171875
[Epoch 2][Step 69], time=0.09249472618103027, ext_time=0.06301164627075195, train_time=0.023604154586791992
[Epoch 2][Step 70], time=0.09331369400024414, ext_time=0.06511902809143066, train_time=0.02223992347717285
[Epoch 2][Step 71], time=0.09375596046447754, ext_time=0.06539773941040039, train_time=0.022374868392944336
[Epoch 2][Step 72], time=0.09285736083984375, ext_time=0.0647587776184082, train_time=0.02213454246520996
[Epoch 2][Step 73], time=0.09275197982788086, ext_time=0.06453609466552734, train_time=0.02228260040283203
[Epoch 2][Step 74], time=0.09271025657653809, ext_time=0.0644991397857666, train_time=0.022307634353637695
[Epoch 2][Step 75], time=0.09232258796691895, ext_time=0.06437277793884277, train_time=0.02204442024230957
[Epoch 2][Step 76], time=0.09220027923583984, ext_time=0.06422901153564453, train_time=0.02207183837890625
[Epoch 2][Step 77], time=0.09242081642150879, ext_time=0.06435251235961914, train_time=0.022140979766845703
[Epoch 2][Step 78], time=0.09322071075439453, ext_time=0.06457686424255371, train_time=0.022727251052856445
[Epoch 2][Step 79], time=0.0934901237487793, ext_time=0.0650019645690918, train_time=0.02244877815246582
[Epoch 2][Step 80], time=0.09344220161437988, ext_time=0.06498837471008301, train_time=0.022496461868286133
[Epoch 2][Step 81], time=0.09347915649414062, ext_time=0.06497025489807129, train_time=0.022521257400512695
[Epoch 2][Step 82], time=0.09344244003295898, ext_time=0.06527018547058105, train_time=0.022182703018188477
[Epoch 2][Step 83], time=0.09198784828186035, ext_time=0.06373190879821777, train_time=0.022371292114257812
[Epoch 2][Step 84], time=0.092071533203125, ext_time=0.06376838684082031, train_time=0.022380352020263672
[Epoch 2][Step 85], time=0.09359407424926758, ext_time=0.06505060195922852, train_time=0.022555828094482422
[Epoch 2][Step 86], time=0.09317207336425781, ext_time=0.0645749568939209, train_time=0.022657155990600586
[Epoch 2][Step 87], time=0.09305024147033691, ext_time=0.06469035148620605, train_time=0.022413969039916992
[Epoch 2][Step 88], time=0.09360456466674805, ext_time=0.06520438194274902, train_time=0.02245330810546875
[Epoch 2][Step 89], time=0.09256386756896973, ext_time=0.06419897079467773, train_time=0.02246379852294922
[Epoch 2][Step 90], time=0.09290289878845215, ext_time=0.0644233226776123, train_time=0.022461414337158203
[Epoch 2][Step 91], time=0.09294962882995605, ext_time=0.06465482711791992, train_time=0.02234482765197754
[Epoch 2][Step 92], time=0.09328413009643555, ext_time=0.0645289421081543, train_time=0.022908449172973633
[Epoch 2][Step 93], time=0.09149813652038574, ext_time=0.06345129013061523, train_time=0.02221369743347168
[Epoch 2][Step 94], time=0.09339642524719238, ext_time=0.06395697593688965, train_time=0.023550748825073242
[Epoch 2][Step 95], time=0.0924384593963623, ext_time=0.06389307975769043, train_time=0.022380352020263672
[Epoch 2][Step 96], time=0.09290122985839844, ext_time=0.06442070007324219, train_time=0.02247142791748047
[Epoch 2][Step 97], time=0.09222865104675293, ext_time=0.06407952308654785, train_time=0.022254228591918945
[Epoch 2][Step 98], time=0.09212541580200195, ext_time=0.06390953063964844, train_time=0.022328615188598633
[Epoch 2][Step 99], time=0.09338903427124023, ext_time=0.0645134449005127, train_time=0.022972822189331055
[Epoch 2][Step 100], time=0.09270238876342773, ext_time=0.0642690658569336, train_time=0.022485733032226562
[Epoch 2][Step 101], time=0.09337496757507324, ext_time=0.06358647346496582, train_time=0.023885250091552734
[Epoch 2][Step 102], time=0.09294247627258301, ext_time=0.06434941291809082, train_time=0.02265167236328125
[Epoch 2][Step 103], time=0.09374570846557617, ext_time=0.06507229804992676, train_time=0.02268385887145996
[Epoch 2][Step 104], time=0.09252047538757324, ext_time=0.06416797637939453, train_time=0.02242898941040039
[Epoch 2][Step 105], time=0.09333419799804688, ext_time=0.06446957588195801, train_time=0.022922515869140625
[Epoch 2][Step 106], time=0.09267973899841309, ext_time=0.06450343132019043, train_time=0.02218031883239746
[Epoch 2][Step 107], time=0.09305977821350098, ext_time=0.06351041793823242, train_time=0.023708581924438477
[Epoch 2][Step 108], time=0.09170746803283691, ext_time=0.06346940994262695, train_time=0.022323131561279297
[Epoch 2][Step 109], time=0.09310150146484375, ext_time=0.06468534469604492, train_time=0.02243828773498535
[Epoch 2][Step 110], time=0.09279918670654297, ext_time=0.06441020965576172, train_time=0.02245640754699707
[Epoch 2][Step 111], time=0.09276485443115234, ext_time=0.06440901756286621, train_time=0.0224609375
[Epoch 2][Step 112], time=0.09247016906738281, ext_time=0.06412196159362793, train_time=0.022439956665039062
[Epoch 2][Step 113], time=0.09248971939086914, ext_time=0.06320667266845703, train_time=0.023456335067749023
[Epoch 2][Step 114], time=0.09322714805603027, ext_time=0.06463193893432617, train_time=0.022631168365478516
[Epoch 2][Step 115], time=0.09333252906799316, ext_time=0.06428408622741699, train_time=0.023137331008911133
[Epoch 2][Step 116], time=0.0925147533416748, ext_time=0.06410622596740723, train_time=0.022266626358032227
[Epoch 2][Step 117], time=0.09319138526916504, ext_time=0.0649423599243164, train_time=0.022298574447631836
[Epoch 2][Step 118], time=0.09247970581054688, ext_time=0.06448507308959961, train_time=0.022155046463012695
[Epoch 2][Step 119], time=0.09211373329162598, ext_time=0.06396675109863281, train_time=0.02228069305419922
[Epoch 2][Step 120], time=0.09289050102233887, ext_time=0.06474423408508301, train_time=0.02227640151977539
[Epoch 2][Step 121], time=0.0933690071105957, ext_time=0.06475472450256348, train_time=0.022674083709716797
[Epoch 2][Step 122], time=0.09370994567871094, ext_time=0.06506609916687012, train_time=0.02262425422668457
[Epoch 2][Step 123], time=0.09257960319519043, ext_time=0.06486630439758301, train_time=0.021744251251220703
[Epoch 2][Step 124], time=0.09099102020263672, ext_time=0.06360960006713867, train_time=0.02153158187866211
[Epoch 2][Step 125], time=0.0924828052520752, ext_time=0.06348538398742676, train_time=0.023195981979370117
[Epoch 2][Step 126], time=0.09290599822998047, ext_time=0.0643002986907959, train_time=0.022722721099853516
[Epoch 2][Step 127], time=0.09299373626708984, ext_time=0.06460976600646973, train_time=0.022391796112060547
[Epoch 2][Step 128], time=0.09270572662353516, ext_time=0.06484460830688477, train_time=0.02196526527404785
[Epoch 2][Step 129], time=0.09283971786499023, ext_time=0.06482243537902832, train_time=0.022080659866333008
[Epoch 2][Step 130], time=0.09229326248168945, ext_time=0.06408834457397461, train_time=0.022298097610473633
[Epoch 2][Step 131], time=0.09542393684387207, ext_time=0.064453125, train_time=0.025043964385986328
[Epoch 2][Step 132], time=0.09298038482666016, ext_time=0.06465911865234375, train_time=0.022171735763549805
[Epoch 2][Step 133], time=0.09351468086242676, ext_time=0.065032958984375, train_time=0.022562503814697266
[Epoch 2][Step 134], time=0.09279775619506836, ext_time=0.06446003913879395, train_time=0.02239847183227539
[Epoch 2][Step 135], time=0.09357523918151855, ext_time=0.06526541709899902, train_time=0.022380352020263672
[Epoch 2][Step 136], time=0.09334373474121094, ext_time=0.06483912467956543, train_time=0.022549152374267578
[Epoch 2][Step 137], time=0.0930643081665039, ext_time=0.06406450271606445, train_time=0.023108959197998047
[Epoch 2][Step 138], time=0.0922708511352539, ext_time=0.06389141082763672, train_time=0.0223391056060791
[Epoch 2][Step 139], time=0.09241867065429688, ext_time=0.06429100036621094, train_time=0.022258520126342773
[Epoch 2][Step 140], time=0.09311628341674805, ext_time=0.06467914581298828, train_time=0.022493839263916016
[Epoch 2][Step 141], time=0.09367251396179199, ext_time=0.06527376174926758, train_time=0.022421598434448242
[Epoch 2][Step 142], time=0.0925290584564209, ext_time=0.06403207778930664, train_time=0.02261972427368164
[Epoch 2][Step 143], time=0.09352874755859375, ext_time=0.06491732597351074, train_time=0.022625446319580078
[Epoch 2][Step 144], time=0.09292459487915039, ext_time=0.06456375122070312, train_time=0.022394895553588867
[Epoch 2][Step 145], time=0.09282875061035156, ext_time=0.06456995010375977, train_time=0.02237391471862793
[Epoch 2][Step 146], time=0.0938265323638916, ext_time=0.06519222259521484, train_time=0.022693395614624023
[Epoch 2][Step 147], time=0.0930318832397461, ext_time=0.06448197364807129, train_time=0.02255988121032715
[Epoch 2][Step 148], time=0.09310173988342285, ext_time=0.06471824645996094, train_time=0.022404909133911133
[Epoch 2][Step 149], time=0.0928354263305664, ext_time=0.06463503837585449, train_time=0.022332429885864258
[Epoch 2][Step 150], time=0.09177851676940918, ext_time=0.06281638145446777, train_time=0.023096323013305664
[Epoch 2][Step 151], time=0.09176945686340332, ext_time=0.0636909008026123, train_time=0.022261619567871094
[Epoch 2][Step 152], time=0.0923006534576416, ext_time=0.06406140327453613, train_time=0.022359132766723633
[Epoch 2][Step 153], time=0.09186220169067383, ext_time=0.06287622451782227, train_time=0.023111343383789062
[Epoch 2][Step 154], time=0.09277081489562988, ext_time=0.06425333023071289, train_time=0.022541284561157227
[Epoch 2][Step 155], time=0.09189987182617188, ext_time=0.06360125541687012, train_time=0.022367000579833984
[Epoch 2][Step 156], time=0.09416532516479492, ext_time=0.06549739837646484, train_time=0.022629737854003906
[Epoch 2][Step 157], time=0.09433650970458984, ext_time=0.0647423267364502, train_time=0.02268528938293457
[Epoch 2][Step 158], time=0.09361958503723145, ext_time=0.06469321250915527, train_time=0.02288818359375
[Epoch 2][Step 159], time=0.0926980972290039, ext_time=0.06421613693237305, train_time=0.022444486618041992
[Epoch 2][Step 160], time=0.09205412864685059, ext_time=0.06420683860778809, train_time=0.022026777267456055
[Epoch 2][Step 161], time=0.09273076057434082, ext_time=0.06440854072570801, train_time=0.02246236801147461
[Epoch 2][Step 162], time=0.09132885932922363, ext_time=0.06334137916564941, train_time=0.02215099334716797
[Epoch 2][Step 163], time=0.09253382682800293, ext_time=0.06429028511047363, train_time=0.022333145141601562
[Epoch 2][Step 164], time=0.09369826316833496, ext_time=0.06478714942932129, train_time=0.02283024787902832
[Epoch 2][Step 165], time=0.09246587753295898, ext_time=0.06415057182312012, train_time=0.022309064865112305
[Epoch 2][Step 166], time=0.0917212963104248, ext_time=0.06385421752929688, train_time=0.02200460433959961
[Epoch 2][Step 167], time=0.09221410751342773, ext_time=0.06426286697387695, train_time=0.022092819213867188
[Epoch 2][Step 168], time=0.09274983406066895, ext_time=0.06465864181518555, train_time=0.022249221801757812
[Epoch 2][Step 169], time=0.0942380428314209, ext_time=0.06464099884033203, train_time=0.023655176162719727
[Epoch 2][Step 170], time=0.09268474578857422, ext_time=0.06406116485595703, train_time=0.022562026977539062
[Epoch 2][Step 171], time=0.09232091903686523, ext_time=0.06293892860412598, train_time=0.023537397384643555
[Epoch 2][Step 172], time=0.09296846389770508, ext_time=0.06532597541809082, train_time=0.021702289581298828
[Epoch 2][Step 173], time=0.09301114082336426, ext_time=0.06468796730041504, train_time=0.022403478622436523
[Epoch 2][Step 174], time=0.09402585029602051, ext_time=0.0642690658569336, train_time=0.023859500885009766
[Epoch 2][Step 175], time=0.09211468696594238, ext_time=0.06394267082214355, train_time=0.0222628116607666
[Epoch 2][Step 176], time=0.09433484077453613, ext_time=0.06550168991088867, train_time=0.02283763885498047
[Epoch 2][Step 177], time=0.09254574775695801, ext_time=0.06423497200012207, train_time=0.022381305694580078
[Epoch 2][Step 178], time=0.09290099143981934, ext_time=0.06296825408935547, train_time=0.024107933044433594
[Epoch 2][Step 179], time=0.09311890602111816, ext_time=0.06460952758789062, train_time=0.022547006607055664
[Epoch 2][Step 180], time=0.09296607971191406, ext_time=0.06436657905578613, train_time=0.02258753776550293
[Epoch 2][Step 181], time=0.09176445007324219, ext_time=0.0633852481842041, train_time=0.022448062896728516
[Epoch 2][Step 182], time=0.09205174446105957, ext_time=0.06399226188659668, train_time=0.02220606803894043
[Epoch 2][Step 183], time=0.0916135311126709, ext_time=0.06354188919067383, train_time=0.022212505340576172
[Epoch 2][Step 184], time=0.09195709228515625, ext_time=0.06385946273803711, train_time=0.02222728729248047
[Epoch 2][Step 185], time=0.09262299537658691, ext_time=0.0643758773803711, train_time=0.022362709045410156
[Epoch 2][Step 186], time=0.09231090545654297, ext_time=0.06416893005371094, train_time=0.02225780487060547
[Epoch 2][Step 187], time=0.09256792068481445, ext_time=0.06433558464050293, train_time=0.022347450256347656
[Epoch 2][Step 188], time=0.09356117248535156, ext_time=0.06494355201721191, train_time=0.02265477180480957
[Epoch 2][Step 189], time=0.09458041191101074, ext_time=0.06594347953796387, train_time=0.02262401580810547
[Epoch 2][Step 190], time=0.09313797950744629, ext_time=0.06453919410705566, train_time=0.022676706314086914
[Epoch 2][Step 191], time=0.09308934211730957, ext_time=0.06461977958679199, train_time=0.022430419921875
[Epoch 2][Step 192], time=0.0929098129272461, ext_time=0.06451821327209473, train_time=0.022426843643188477
[Epoch 2][Step 193], time=0.09367609024047852, ext_time=0.06520724296569824, train_time=0.02253127098083496
[Epoch 2][Step 194], time=0.09234261512756348, ext_time=0.06423187255859375, train_time=0.022229433059692383
[Epoch 2][Step 195], time=0.09169983863830566, ext_time=0.06366848945617676, train_time=0.022169828414916992
[Epoch 2][Step 196], time=0.09357547760009766, ext_time=0.0649871826171875, train_time=0.022643089294433594
[Epoch 2][Step 197], time=0.09293150901794434, ext_time=0.0645437240600586, train_time=0.02242755889892578
[Epoch 2][Step 198], time=0.09380340576171875, ext_time=0.06516075134277344, train_time=0.022702932357788086
[Epoch 2][Step 199], time=0.0937652587890625, ext_time=0.06485271453857422, train_time=0.02288365364074707
[Epoch 2][Step 200], time=0.09490489959716797, ext_time=0.0659635066986084, train_time=0.02289581298828125
[Epoch 2][Step 201], time=0.09281730651855469, ext_time=0.06394624710083008, train_time=0.02293229103088379
[Epoch 2][Step 202], time=0.0919809341430664, ext_time=0.06377744674682617, train_time=0.022199153900146484
[Epoch 2][Step 203], time=0.09307694435119629, ext_time=0.06455111503601074, train_time=0.02262425422668457
[Epoch 2][Step 204], time=0.09273958206176758, ext_time=0.06442809104919434, train_time=0.022366762161254883
[Epoch 2][Step 205], time=0.09370827674865723, ext_time=0.06523990631103516, train_time=0.022532939910888672
[Epoch 2][Step 206], time=0.09386277198791504, ext_time=0.06449770927429199, train_time=0.023486614227294922
[Epoch 2][Step 207], time=0.0936121940612793, ext_time=0.06418800354003906, train_time=0.023401498794555664
[Epoch 2][Step 208], time=0.0931849479675293, ext_time=0.06488823890686035, train_time=0.022381305694580078
[Epoch 2][Step 209], time=0.09354114532470703, ext_time=0.06501889228820801, train_time=0.022602319717407227
[Epoch 2][Step 210], time=0.09423136711120605, ext_time=0.06555318832397461, train_time=0.022698402404785156
[Epoch 2][Step 211], time=0.09177517890930176, ext_time=0.06303977966308594, train_time=0.022884607315063477
[Epoch 2][Step 212], time=0.09412097930908203, ext_time=0.06514358520507812, train_time=0.02308511734008789
[Epoch 2][Step 213], time=0.09259748458862305, ext_time=0.0642843246459961, train_time=0.02228713035583496
[Epoch 2][Step 214], time=0.0923161506652832, ext_time=0.06447386741638184, train_time=0.021881580352783203
[Epoch 2][Step 215], time=0.09169244766235352, ext_time=0.06421804428100586, train_time=0.02162909507751465
[Epoch 2][Step 216], time=0.09332108497619629, ext_time=0.06449246406555176, train_time=0.02285933494567871
[Epoch 2][Step 217], time=0.09220409393310547, ext_time=0.06403970718383789, train_time=0.022268295288085938
[Epoch 2][Step 218], time=0.09197282791137695, ext_time=0.06398439407348633, train_time=0.022105932235717773
[Epoch 2][Step 219], time=0.09193825721740723, ext_time=0.0637044906616211, train_time=0.022368431091308594
[Epoch 2][Step 220], time=0.09178471565246582, ext_time=0.06366443634033203, train_time=0.022235631942749023
[Epoch 2][Step 221], time=0.09290027618408203, ext_time=0.06458544731140137, train_time=0.02237868309020996
[Epoch 2][Step 222], time=0.09189558029174805, ext_time=0.06379318237304688, train_time=0.022252559661865234
[Epoch 2][Step 223], time=0.09273838996887207, ext_time=0.0644381046295166, train_time=0.022373199462890625
[Epoch 2][Step 224], time=0.09369182586669922, ext_time=0.06495785713195801, train_time=0.022776126861572266
[Epoch 2][Step 225], time=0.0921640396118164, ext_time=0.06401991844177246, train_time=0.022245407104492188
[Epoch 2][Step 226], time=0.0920569896697998, ext_time=0.06313157081604004, train_time=0.023089170455932617
[Epoch 2][Step 227], time=0.09112071990966797, ext_time=0.0632016658782959, train_time=0.02210831642150879
[Epoch 2][Step 228], time=0.09336400032043457, ext_time=0.06475043296813965, train_time=0.0227203369140625
[Epoch 2][Step 229], time=0.09232735633850098, ext_time=0.06416964530944824, train_time=0.02225017547607422
[Epoch 2][Step 230], time=0.09305739402770996, ext_time=0.06351256370544434, train_time=0.023669004440307617
[Epoch 2][Step 231], time=0.09212279319763184, ext_time=0.0641026496887207, train_time=0.022173404693603516
[Epoch 2][Step 232], time=0.09115076065063477, ext_time=0.06316518783569336, train_time=0.022144794464111328
[Epoch 2][Step 233], time=0.09316110610961914, ext_time=0.06460094451904297, train_time=0.022627830505371094
[Epoch 2][Step 234], time=0.09204339981079102, ext_time=0.06378316879272461, train_time=0.022325754165649414
[Epoch 2][Step 235], time=0.09308695793151855, ext_time=0.06450319290161133, train_time=0.022602081298828125
[Epoch 2][Step 236], time=0.0932471752166748, ext_time=0.06490969657897949, train_time=0.022397518157958984
[Epoch 2][Step 237], time=0.09311795234680176, ext_time=0.06504559516906738, train_time=0.02222299575805664
[Epoch 2][Step 238], time=0.09345483779907227, ext_time=0.06500458717346191, train_time=0.022540569305419922
[Epoch 2][Step 239], time=0.09328389167785645, ext_time=0.06466245651245117, train_time=0.02253890037536621
[Epoch 2][Step 240], time=0.0928182601928711, ext_time=0.06452035903930664, train_time=0.022430896759033203
[Epoch 2][Step 241], time=0.09252476692199707, ext_time=0.06423449516296387, train_time=0.022222042083740234
[Epoch 2][Step 242], time=0.0920567512512207, ext_time=0.06380271911621094, train_time=0.0222930908203125
[Epoch 2][Step 243], time=0.09361696243286133, ext_time=0.0649569034576416, train_time=0.022675752639770508
[Epoch 2][Step 244], time=0.09475445747375488, ext_time=0.06503081321716309, train_time=0.023710250854492188
[Epoch 2][Step 245], time=0.09326958656311035, ext_time=0.06290459632873535, train_time=0.02434825897216797
[Epoch 2][Step 246], time=0.09298038482666016, ext_time=0.06453800201416016, train_time=0.022449493408203125
[Epoch 2][Step 247], time=0.09256982803344727, ext_time=0.06429696083068848, train_time=0.022365093231201172
[Epoch 2][Step 248], time=0.09338164329528809, ext_time=0.0649724006652832, train_time=0.022458791732788086
[Epoch 2][Step 249], time=0.09260940551757812, ext_time=0.06420373916625977, train_time=0.022521495819091797
[Epoch 2], time=23.25119400024414, loss=0.6931472420692444
[Epoch 3][Step 0], time=0.09375810623168945, ext_time=0.06506156921386719, train_time=0.02266216278076172
[Epoch 3][Step 1], time=0.0927743911743164, ext_time=0.06397771835327148, train_time=0.022878646850585938
[Epoch 3][Step 2], time=0.09305810928344727, ext_time=0.06446361541748047, train_time=0.022593975067138672
[Epoch 3][Step 3], time=0.09350848197937012, ext_time=0.06496572494506836, train_time=0.022615432739257812
[Epoch 3][Step 4], time=0.0946345329284668, ext_time=0.0645456314086914, train_time=0.024121522903442383
[Epoch 3][Step 5], time=0.09379863739013672, ext_time=0.06494450569152832, train_time=0.02273869514465332
[Epoch 3][Step 6], time=0.09405183792114258, ext_time=0.06536698341369629, train_time=0.022640705108642578
[Epoch 3][Step 7], time=0.09215950965881348, ext_time=0.06396055221557617, train_time=0.022299528121948242
[Epoch 3][Step 8], time=0.0918891429901123, ext_time=0.06365108489990234, train_time=0.022404193878173828
[Epoch 3][Step 9], time=0.09169435501098633, ext_time=0.06368446350097656, train_time=0.02216625213623047
[Epoch 3][Step 10], time=0.09343099594116211, ext_time=0.06470489501953125, train_time=0.02276897430419922
[Epoch 3][Step 11], time=0.09313178062438965, ext_time=0.06392216682434082, train_time=0.02326822280883789
[Epoch 3][Step 12], time=0.09279370307922363, ext_time=0.06440973281860352, train_time=0.022429943084716797
[Epoch 3][Step 13], time=0.09250879287719727, ext_time=0.06423711776733398, train_time=0.022339582443237305
[Epoch 3][Step 14], time=0.09262204170227051, ext_time=0.06383490562438965, train_time=0.02292943000793457
[Epoch 3][Step 15], time=0.09413385391235352, ext_time=0.06532526016235352, train_time=0.022830724716186523
[Epoch 3][Step 16], time=0.09300541877746582, ext_time=0.06444191932678223, train_time=0.022543668746948242
[Epoch 3][Step 17], time=0.09348201751708984, ext_time=0.06478643417358398, train_time=0.022758960723876953
[Epoch 3][Step 18], time=0.09237241744995117, ext_time=0.0639946460723877, train_time=0.022501468658447266
[Epoch 3][Step 19], time=0.09435844421386719, ext_time=0.0656592845916748, train_time=0.02261829376220703
[Epoch 3][Step 20], time=0.09347009658813477, ext_time=0.06486678123474121, train_time=0.022683382034301758
[Epoch 3][Step 21], time=0.09293866157531738, ext_time=0.06455063819885254, train_time=0.022402048110961914
[Epoch 3][Step 22], time=0.09182000160217285, ext_time=0.06367135047912598, train_time=0.02226734161376953
[Epoch 3][Step 23], time=0.09284710884094238, ext_time=0.06453537940979004, train_time=0.022377729415893555
[Epoch 3][Step 24], time=0.09303593635559082, ext_time=0.06387925148010254, train_time=0.023244619369506836
[Epoch 3][Step 25], time=0.09189486503601074, ext_time=0.06387066841125488, train_time=0.022186994552612305
[Epoch 3][Step 26], time=0.09288740158081055, ext_time=0.06462764739990234, train_time=0.022363662719726562
[Epoch 3][Step 27], time=0.09300732612609863, ext_time=0.06416201591491699, train_time=0.022938013076782227
[Epoch 3][Step 28], time=0.09237313270568848, ext_time=0.06409883499145508, train_time=0.02234673500061035
[Epoch 3][Step 29], time=0.09204459190368652, ext_time=0.06371808052062988, train_time=0.02248549461364746
[Epoch 3][Step 30], time=0.09193634986877441, ext_time=0.06379032135009766, train_time=0.022252798080444336
[Epoch 3][Step 31], time=0.09183692932128906, ext_time=0.06357836723327637, train_time=0.022400617599487305
[Epoch 3][Step 32], time=0.09261202812194824, ext_time=0.06415724754333496, train_time=0.022408723831176758
[Epoch 3][Step 33], time=0.09307694435119629, ext_time=0.06473946571350098, train_time=0.02241802215576172
[Epoch 3][Step 34], time=0.09343528747558594, ext_time=0.06421685218811035, train_time=0.023286104202270508
[Epoch 3][Step 35], time=0.09258317947387695, ext_time=0.06401538848876953, train_time=0.022640228271484375
[Epoch 3][Step 36], time=0.09589529037475586, ext_time=0.06547045707702637, train_time=0.024285078048706055
[Epoch 3][Step 37], time=0.09253716468811035, ext_time=0.06398797035217285, train_time=0.02246260643005371
[Epoch 3][Step 38], time=0.09422707557678223, ext_time=0.06553888320922852, train_time=0.0226898193359375
[Epoch 3][Step 39], time=0.09360289573669434, ext_time=0.06489419937133789, train_time=0.022714614868164062
[Epoch 3][Step 40], time=0.09240126609802246, ext_time=0.0639798641204834, train_time=0.02247166633605957
[Epoch 3][Step 41], time=0.09199810028076172, ext_time=0.06409001350402832, train_time=0.022059917449951172
[Epoch 3][Step 42], time=0.09174323081970215, ext_time=0.06322836875915527, train_time=0.022700786590576172
[Epoch 3][Step 43], time=0.09393453598022461, ext_time=0.06543612480163574, train_time=0.022519588470458984
[Epoch 3][Step 44], time=0.09327530860900879, ext_time=0.06437563896179199, train_time=0.022990942001342773
[Epoch 3][Step 45], time=0.09313774108886719, ext_time=0.0647125244140625, train_time=0.02242302894592285
[Epoch 3][Step 46], time=0.0932168960571289, ext_time=0.0649118423461914, train_time=0.022401809692382812
[Epoch 3][Step 47], time=0.09227824211120605, ext_time=0.0637977123260498, train_time=0.02258467674255371
[Epoch 3][Step 48], time=0.09251952171325684, ext_time=0.06430411338806152, train_time=0.022304058074951172
[Epoch 3][Step 49], time=0.09169483184814453, ext_time=0.06281423568725586, train_time=0.02307438850402832
[Epoch 3][Step 50], time=0.09248590469360352, ext_time=0.0641946792602539, train_time=0.022371530532836914
[Epoch 3][Step 51], time=0.09313702583312988, ext_time=0.06488394737243652, train_time=0.02235102653503418
[Epoch 3][Step 52], time=0.09237122535705566, ext_time=0.06396818161010742, train_time=0.022474050521850586
[Epoch 3][Step 53], time=0.09187769889831543, ext_time=0.06387495994567871, train_time=0.022086143493652344
[Epoch 3][Step 54], time=0.09269952774047852, ext_time=0.06425189971923828, train_time=0.022531509399414062
[Epoch 3][Step 55], time=0.09357643127441406, ext_time=0.06503677368164062, train_time=0.022569894790649414
[Epoch 3][Step 56], time=0.09417414665222168, ext_time=0.0654447078704834, train_time=0.022778034210205078
[Epoch 3][Step 57], time=0.09273123741149902, ext_time=0.06409859657287598, train_time=0.02257847785949707
[Epoch 3][Step 58], time=0.09282565116882324, ext_time=0.06434941291809082, train_time=0.02256035804748535
[Epoch 3][Step 59], time=0.09297394752502441, ext_time=0.0646357536315918, train_time=0.02232837677001953
[Epoch 3][Step 60], time=0.09272933006286621, ext_time=0.06448531150817871, train_time=0.022307634353637695
[Epoch 3][Step 61], time=0.09339404106140137, ext_time=0.06524801254272461, train_time=0.0222475528717041
[Epoch 3][Step 62], time=0.09303808212280273, ext_time=0.06485819816589355, train_time=0.02223658561706543
[Epoch 3][Step 63], time=0.09207725524902344, ext_time=0.06353759765625, train_time=0.022669553756713867
[Epoch 3][Step 64], time=0.09192204475402832, ext_time=0.06385064125061035, train_time=0.022174358367919922
[Epoch 3][Step 65], time=0.09322428703308105, ext_time=0.06493425369262695, train_time=0.022403955459594727
[Epoch 3][Step 66], time=0.09215259552001953, ext_time=0.06381511688232422, train_time=0.022439002990722656
[Epoch 3][Step 67], time=0.09422516822814941, ext_time=0.06567907333374023, train_time=0.02256035804748535
[Epoch 3][Step 68], time=0.0933983325958252, ext_time=0.0648488998413086, train_time=0.022668123245239258
[Epoch 3][Step 69], time=0.09321880340576172, ext_time=0.06348085403442383, train_time=0.02383279800415039
[Epoch 3][Step 70], time=0.09348464012145996, ext_time=0.06493473052978516, train_time=0.0225369930267334
[Epoch 3][Step 71], time=0.09350061416625977, ext_time=0.06486916542053223, train_time=0.02268052101135254
[Epoch 3][Step 72], time=0.09281492233276367, ext_time=0.06453657150268555, train_time=0.022350549697875977
[Epoch 3][Step 73], time=0.09290266036987305, ext_time=0.06458640098571777, train_time=0.022386789321899414
[Epoch 3][Step 74], time=0.09470057487487793, ext_time=0.06514930725097656, train_time=0.02359175682067871
[Epoch 3][Step 75], time=0.09336304664611816, ext_time=0.06479978561401367, train_time=0.0224759578704834
[Epoch 3][Step 76], time=0.09298253059387207, ext_time=0.06435704231262207, train_time=0.022710323333740234
[Epoch 3][Step 77], time=0.09393882751464844, ext_time=0.0643148422241211, train_time=0.022596359252929688
[Epoch 3][Step 78], time=0.09372377395629883, ext_time=0.06500363349914551, train_time=0.02276444435119629
[Epoch 3][Step 79], time=0.09255480766296387, ext_time=0.06396865844726562, train_time=0.02259969711303711
[Epoch 3][Step 80], time=0.09458398818969727, ext_time=0.06576848030090332, train_time=0.022702455520629883
[Epoch 3][Step 81], time=0.09240365028381348, ext_time=0.06427621841430664, train_time=0.022234439849853516
[Epoch 3][Step 82], time=0.09335207939147949, ext_time=0.06478071212768555, train_time=0.022670745849609375
[Epoch 3][Step 83], time=0.09526896476745605, ext_time=0.06361031532287598, train_time=0.025754451751708984
[Epoch 3][Step 84], time=0.09175586700439453, ext_time=0.06339812278747559, train_time=0.02249312400817871
[Epoch 3][Step 85], time=0.09381294250488281, ext_time=0.06518363952636719, train_time=0.02260756492614746
[Epoch 3][Step 86], time=0.09304213523864746, ext_time=0.06464385986328125, train_time=0.02242898941040039
[Epoch 3][Step 87], time=0.09202337265014648, ext_time=0.06385445594787598, train_time=0.022286176681518555
[Epoch 3][Step 88], time=0.09300994873046875, ext_time=0.06467556953430176, train_time=0.022401809692382812
[Epoch 3][Step 89], time=0.0926055908203125, ext_time=0.06438207626342773, train_time=0.022314071655273438
[Epoch 3][Step 90], time=0.09258770942687988, ext_time=0.06418323516845703, train_time=0.022461891174316406
[Epoch 3][Step 91], time=0.09244394302368164, ext_time=0.06425786018371582, train_time=0.022286653518676758
[Epoch 3][Step 92], time=0.09415864944458008, ext_time=0.06559491157531738, train_time=0.0226137638092041
[Epoch 3][Step 93], time=0.09131622314453125, ext_time=0.06386065483093262, train_time=0.021542072296142578
[Epoch 3][Step 94], time=0.09178709983825684, ext_time=0.06379842758178711, train_time=0.022133827209472656
[Epoch 3][Step 95], time=0.09307289123535156, ext_time=0.06470394134521484, train_time=0.02248215675354004
[Epoch 3][Step 96], time=0.09203958511352539, ext_time=0.06375861167907715, train_time=0.022324800491333008
[Epoch 3][Step 97], time=0.09386181831359863, ext_time=0.06535768508911133, train_time=0.022558212280273438
[Epoch 3][Step 98], time=0.09205198287963867, ext_time=0.06370329856872559, train_time=0.02250218391418457
[Epoch 3][Step 99], time=0.09299087524414062, ext_time=0.06464719772338867, train_time=0.022359609603881836
[Epoch 3][Step 100], time=0.09349942207336426, ext_time=0.06461954116821289, train_time=0.0229189395904541
[Epoch 3][Step 101], time=0.09377145767211914, ext_time=0.06473493576049805, train_time=0.02298903465270996
[Epoch 3][Step 102], time=0.0923609733581543, ext_time=0.06412434577941895, train_time=0.02229928970336914
[Epoch 3][Step 103], time=0.09244155883789062, ext_time=0.06409835815429688, train_time=0.022426366806030273
[Epoch 3][Step 104], time=0.0931556224822998, ext_time=0.06493473052978516, train_time=0.022266149520874023
[Epoch 3][Step 105], time=0.09235382080078125, ext_time=0.06393861770629883, train_time=0.022458791732788086
[Epoch 3][Step 106], time=0.09324002265930176, ext_time=0.06476640701293945, train_time=0.022554874420166016
[Epoch 3][Step 107], time=0.09245491027832031, ext_time=0.0639646053314209, train_time=0.022495269775390625
[Epoch 3][Step 108], time=0.09197282791137695, ext_time=0.06283831596374512, train_time=0.023318052291870117
[Epoch 3][Step 109], time=0.09254932403564453, ext_time=0.0642387866973877, train_time=0.022405385971069336
[Epoch 3][Step 110], time=0.09272074699401855, ext_time=0.06432104110717773, train_time=0.02246832847595215
[Epoch 3][Step 111], time=0.09352779388427734, ext_time=0.06475305557250977, train_time=0.02282571792602539
[Epoch 3][Step 112], time=0.09174680709838867, ext_time=0.06353211402893066, train_time=0.02226567268371582
[Epoch 3][Step 113], time=0.09206533432006836, ext_time=0.06375503540039062, train_time=0.022416353225708008
[Epoch 3][Step 114], time=0.0930945873260498, ext_time=0.06461572647094727, train_time=0.02259516716003418
[Epoch 3][Step 115], time=0.09423375129699707, ext_time=0.06566715240478516, train_time=0.022584199905395508
[Epoch 3][Step 116], time=0.09350228309631348, ext_time=0.06382894515991211, train_time=0.02382183074951172
[Epoch 3][Step 117], time=0.09325933456420898, ext_time=0.06453442573547363, train_time=0.02259230613708496
[Epoch 3][Step 118], time=0.09223604202270508, ext_time=0.06418681144714355, train_time=0.02216196060180664
[Epoch 3][Step 119], time=0.09213781356811523, ext_time=0.06402754783630371, train_time=0.02224564552307129
[Epoch 3][Step 120], time=0.09255528450012207, ext_time=0.06437087059020996, train_time=0.02227306365966797
[Epoch 3][Step 121], time=0.0946664810180664, ext_time=0.06478190422058105, train_time=0.02392888069152832
[Epoch 3][Step 122], time=0.09327888488769531, ext_time=0.0644218921661377, train_time=0.022885560989379883
[Epoch 3][Step 123], time=0.09352755546569824, ext_time=0.06511235237121582, train_time=0.022448062896728516
[Epoch 3][Step 124], time=0.09277081489562988, ext_time=0.06431078910827637, train_time=0.022485971450805664
[Epoch 3][Step 125], time=0.0927731990814209, ext_time=0.06442856788635254, train_time=0.022470474243164062
[Epoch 3][Step 126], time=0.09379458427429199, ext_time=0.06507515907287598, train_time=0.022711992263793945
[Epoch 3][Step 127], time=0.09432506561279297, ext_time=0.06540894508361816, train_time=0.022925376892089844
[Epoch 3][Step 128], time=0.09234499931335449, ext_time=0.06414985656738281, train_time=0.022249460220336914
[Epoch 3][Step 129], time=0.09322142601013184, ext_time=0.06496214866638184, train_time=0.022321701049804688
[Epoch 3][Step 130], time=0.09227824211120605, ext_time=0.06426000595092773, train_time=0.022163867950439453
[Epoch 3][Step 131], time=0.0930030345916748, ext_time=0.06448698043823242, train_time=0.022579669952392578
[Epoch 3][Step 132], time=0.09162259101867676, ext_time=0.06348705291748047, train_time=0.022272109985351562
[Epoch 3][Step 133], time=0.09446430206298828, ext_time=0.06562280654907227, train_time=0.022722959518432617
[Epoch 3][Step 134], time=0.09261250495910645, ext_time=0.06423640251159668, train_time=0.0223996639251709
[Epoch 3][Step 135], time=0.09358930587768555, ext_time=0.06506848335266113, train_time=0.022609472274780273
[Epoch 3][Step 136], time=0.09363937377929688, ext_time=0.0649423599243164, train_time=0.022687435150146484
[Epoch 3][Step 137], time=0.09164643287658691, ext_time=0.06348991394042969, train_time=0.022348642349243164
[Epoch 3][Step 138], time=0.09311294555664062, ext_time=0.0643153190612793, train_time=0.022815942764282227
[Epoch 3][Step 139], time=0.093048095703125, ext_time=0.06466388702392578, train_time=0.022394895553588867
[Epoch 3][Step 140], time=0.09294700622558594, ext_time=0.06407642364501953, train_time=0.022965192794799805
[Epoch 3][Step 141], time=0.09358716011047363, ext_time=0.06512784957885742, train_time=0.022524595260620117
[Epoch 3][Step 142], time=0.09097051620483398, ext_time=0.06302404403686523, train_time=0.022096872329711914
[Epoch 3][Step 143], time=0.0921943187713623, ext_time=0.06394815444946289, train_time=0.02234625816345215
[Epoch 3][Step 144], time=0.09315705299377441, ext_time=0.06471467018127441, train_time=0.022454023361206055
[Epoch 3][Step 145], time=0.0926978588104248, ext_time=0.06444311141967773, train_time=0.022330045700073242
[Epoch 3][Step 146], time=0.09422779083251953, ext_time=0.06561088562011719, train_time=0.022653579711914062
[Epoch 3][Step 147], time=0.09251713752746582, ext_time=0.06441187858581543, train_time=0.02218461036682129
[Epoch 3][Step 148], time=0.0928659439086914, ext_time=0.06455492973327637, train_time=0.022429227828979492
[Epoch 3][Step 149], time=0.0944814682006836, ext_time=0.0641334056854248, train_time=0.0244290828704834
[Epoch 3][Step 150], time=0.0930173397064209, ext_time=0.06291890144348145, train_time=0.024289369583129883
[Epoch 3][Step 151], time=0.0931851863861084, ext_time=0.06507420539855957, train_time=0.022205114364624023
[Epoch 3][Step 152], time=0.09227919578552246, ext_time=0.06376457214355469, train_time=0.022664308547973633
[Epoch 3][Step 153], time=0.09151768684387207, ext_time=0.0633707046508789, train_time=0.022274255752563477
[Epoch 3][Step 154], time=0.09256362915039062, ext_time=0.06364607810974121, train_time=0.023155927658081055
[Epoch 3][Step 155], time=0.09398818016052246, ext_time=0.0652003288269043, train_time=0.022699594497680664
[Epoch 3][Step 156], time=0.09351587295532227, ext_time=0.06505513191223145, train_time=0.022443056106567383
[Epoch 3][Step 157], time=0.09327340126037598, ext_time=0.06482434272766113, train_time=0.022505521774291992
[Epoch 3][Step 158], time=0.09242582321166992, ext_time=0.06398320198059082, train_time=0.022516250610351562
[Epoch 3][Step 159], time=0.0931859016418457, ext_time=0.06420254707336426, train_time=0.023062467575073242
[Epoch 3][Step 160], time=0.09169721603393555, ext_time=0.06374955177307129, train_time=0.022043704986572266
[Epoch 3][Step 161], time=0.09317803382873535, ext_time=0.06450486183166504, train_time=0.02277517318725586
[Epoch 3][Step 162], time=0.09322047233581543, ext_time=0.06462979316711426, train_time=0.022664308547973633
[Epoch 3][Step 163], time=0.09306883811950684, ext_time=0.06467819213867188, train_time=0.02245354652404785
[Epoch 3][Step 164], time=0.09213066101074219, ext_time=0.06394004821777344, train_time=0.022247314453125
[Epoch 3][Step 165], time=0.09351491928100586, ext_time=0.0638267993927002, train_time=0.023646831512451172
[Epoch 3][Step 166], time=0.09221196174621582, ext_time=0.06429481506347656, train_time=0.02189350128173828
[Epoch 3][Step 167], time=0.09212875366210938, ext_time=0.0646977424621582, train_time=0.02148270606994629
[Epoch 3][Step 168], time=0.09214401245117188, ext_time=0.0647127628326416, train_time=0.0215303897857666
[Epoch 3][Step 169], time=0.09232831001281738, ext_time=0.06489062309265137, train_time=0.021535873413085938
[Epoch 3][Step 170], time=0.09181022644042969, ext_time=0.06400752067565918, train_time=0.02193737030029297
[Epoch 3][Step 171], time=0.09074950218200684, ext_time=0.06255125999450684, train_time=0.02236342430114746
[Epoch 3][Step 172], time=0.09217429161071777, ext_time=0.06400942802429199, train_time=0.022313594818115234
[Epoch 3][Step 173], time=0.09353327751159668, ext_time=0.06471991539001465, train_time=0.022841930389404297
[Epoch 3][Step 174], time=0.09218144416809082, ext_time=0.06381964683532715, train_time=0.02239060401916504
[Epoch 3][Step 175], time=0.09333992004394531, ext_time=0.06474113464355469, train_time=0.022678375244140625
[Epoch 3][Step 176], time=0.0931851863861084, ext_time=0.06486988067626953, train_time=0.022354602813720703
[Epoch 3][Step 177], time=0.0923011302947998, ext_time=0.06382298469543457, train_time=0.022627592086791992
[Epoch 3][Step 178], time=0.09211325645446777, ext_time=0.06375503540039062, train_time=0.02245020866394043
[Epoch 3][Step 179], time=0.09357810020446777, ext_time=0.06510615348815918, train_time=0.022487163543701172
[Epoch 3][Step 180], time=0.0919184684753418, ext_time=0.06387853622436523, train_time=0.022177696228027344
[Epoch 3][Step 181], time=0.09324312210083008, ext_time=0.06520247459411621, train_time=0.022002458572387695
[Epoch 3][Step 182], time=0.09347271919250488, ext_time=0.06519198417663574, train_time=0.022386550903320312
[Epoch 3][Step 183], time=0.09241437911987305, ext_time=0.06411933898925781, train_time=0.022404193878173828
[Epoch 3][Step 184], time=0.09237313270568848, ext_time=0.06384897232055664, train_time=0.02263951301574707
[Epoch 3][Step 185], time=0.09312248229980469, ext_time=0.06473302841186523, train_time=0.022412776947021484
[Epoch 3][Step 186], time=0.09380722045898438, ext_time=0.06512236595153809, train_time=0.022752046585083008
[Epoch 3][Step 187], time=0.09265494346618652, ext_time=0.06423091888427734, train_time=0.022385835647583008
[Epoch 3][Step 188], time=0.09249544143676758, ext_time=0.06414008140563965, train_time=0.02241349220275879
[Epoch 3][Step 189], time=0.09373331069946289, ext_time=0.06507396697998047, train_time=0.022715330123901367
[Epoch 3][Step 190], time=0.09252786636352539, ext_time=0.06445074081420898, train_time=0.02212810516357422
[Epoch 3][Step 191], time=0.09513568878173828, ext_time=0.06568336486816406, train_time=0.0234372615814209
[Epoch 3][Step 192], time=0.09205079078674316, ext_time=0.06365060806274414, train_time=0.022355079650878906
[Epoch 3][Step 193], time=0.0940849781036377, ext_time=0.0654754638671875, train_time=0.02262091636657715
[Epoch 3][Step 194], time=0.09217286109924316, ext_time=0.06402230262756348, train_time=0.022281885147094727
[Epoch 3][Step 195], time=0.09283828735351562, ext_time=0.06357002258300781, train_time=0.023467063903808594
[Epoch 3][Step 196], time=0.093658447265625, ext_time=0.06450223922729492, train_time=0.023213624954223633
[Epoch 3][Step 197], time=0.0928189754486084, ext_time=0.06438183784484863, train_time=0.022431135177612305
[Epoch 3][Step 198], time=0.09419703483581543, ext_time=0.06552767753601074, train_time=0.022658824920654297
[Epoch 3][Step 199], time=0.093170166015625, ext_time=0.06388568878173828, train_time=0.02331399917602539
[Epoch 3][Step 200], time=0.09325599670410156, ext_time=0.06500625610351562, train_time=0.02234029769897461
[Epoch 3][Step 201], time=0.09272980690002441, ext_time=0.06355071067810059, train_time=0.023331880569458008
[Epoch 3][Step 202], time=0.09301638603210449, ext_time=0.06464147567749023, train_time=0.0225067138671875
[Epoch 3][Step 203], time=0.09330511093139648, ext_time=0.06486749649047852, train_time=0.022444963455200195
[Epoch 3][Step 204], time=0.09256172180175781, ext_time=0.06433415412902832, train_time=0.022347211837768555
[Epoch 3][Step 205], time=0.0927724838256836, ext_time=0.0644843578338623, train_time=0.02238607406616211
[Epoch 3][Step 206], time=0.09214472770690918, ext_time=0.06379151344299316, train_time=0.02243208885192871
[Epoch 3][Step 207], time=0.09193754196166992, ext_time=0.06373310089111328, train_time=0.02232980728149414
[Epoch 3][Step 208], time=0.0923311710357666, ext_time=0.06405901908874512, train_time=0.02233743667602539
[Epoch 3][Step 209], time=0.09434342384338379, ext_time=0.06562995910644531, train_time=0.022646427154541016
[Epoch 3][Step 210], time=0.0932614803314209, ext_time=0.06486248970031738, train_time=0.022489070892333984
[Epoch 3][Step 211], time=0.0920405387878418, ext_time=0.062296390533447266, train_time=0.023929119110107422
[Epoch 3][Step 212], time=0.09255290031433105, ext_time=0.06370377540588379, train_time=0.02296280860900879
[Epoch 3][Step 213], time=0.09337687492370605, ext_time=0.06490397453308105, train_time=0.022437572479248047
[Epoch 3][Step 214], time=0.09121179580688477, ext_time=0.06307864189147949, train_time=0.02225470542907715
[Epoch 3][Step 215], time=0.09286737442016602, ext_time=0.06451869010925293, train_time=0.022417306900024414
[Epoch 3][Step 216], time=0.09235072135925293, ext_time=0.06423735618591309, train_time=0.022225141525268555
[Epoch 3][Step 217], time=0.09290385246276855, ext_time=0.06484746932983398, train_time=0.022176742553710938
[Epoch 3][Step 218], time=0.0946497917175293, ext_time=0.06592917442321777, train_time=0.022735595703125
[Epoch 3][Step 219], time=0.09209203720092773, ext_time=0.06374287605285645, train_time=0.022452116012573242
[Epoch 3][Step 220], time=0.0928041934967041, ext_time=0.06452441215515137, train_time=0.02239394187927246
[Epoch 3][Step 221], time=0.09459185600280762, ext_time=0.06595492362976074, train_time=0.022614240646362305
[Epoch 3][Step 222], time=0.09323334693908691, ext_time=0.06492209434509277, train_time=0.02241683006286621
[Epoch 3][Step 223], time=0.09227156639099121, ext_time=0.0639345645904541, train_time=0.022460222244262695
[Epoch 3][Step 224], time=0.09352350234985352, ext_time=0.06481361389160156, train_time=0.02264237403869629
[Epoch 3][Step 225], time=0.09189748764038086, ext_time=0.06367683410644531, train_time=0.02229905128479004
[Epoch 3][Step 226], time=0.09140968322753906, ext_time=0.0626516342163086, train_time=0.0229644775390625
[Epoch 3][Step 227], time=0.09296870231628418, ext_time=0.06401801109313965, train_time=0.023046016693115234
[Epoch 3][Step 228], time=0.09446930885314941, ext_time=0.06460309028625488, train_time=0.02398228645324707
[Epoch 3][Step 229], time=0.0934286117553711, ext_time=0.06424474716186523, train_time=0.022775888442993164
[Epoch 3][Step 230], time=0.09272313117980957, ext_time=0.06385087966918945, train_time=0.022983789443969727
[Epoch 3][Step 231], time=0.09300589561462402, ext_time=0.0646510124206543, train_time=0.02245473861694336
[Epoch 3][Step 232], time=0.09252786636352539, ext_time=0.06404805183410645, train_time=0.02254629135131836
[Epoch 3][Step 233], time=0.09233379364013672, ext_time=0.0642232894897461, train_time=0.02219843864440918
[Epoch 3][Step 234], time=0.09277677536010742, ext_time=0.06417298316955566, train_time=0.022710800170898438
[Epoch 3][Step 235], time=0.09270858764648438, ext_time=0.0642540454864502, train_time=0.022463321685791016
[Epoch 3][Step 236], time=0.0924384593963623, ext_time=0.06427836418151855, train_time=0.022294282913208008
[Epoch 3][Step 237], time=0.09474992752075195, ext_time=0.06625175476074219, train_time=0.022491455078125
[Epoch 3][Step 238], time=0.09380149841308594, ext_time=0.06539463996887207, train_time=0.02249431610107422
[Epoch 3][Step 239], time=0.0935981273651123, ext_time=0.06481075286865234, train_time=0.022788047790527344
[Epoch 3][Step 240], time=0.09459733963012695, ext_time=0.06585073471069336, train_time=0.022732973098754883
[Epoch 3][Step 241], time=0.09313178062438965, ext_time=0.06472659111022949, train_time=0.022475719451904297
[Epoch 3][Step 242], time=0.09337186813354492, ext_time=0.0648036003112793, train_time=0.0225832462310791
[Epoch 3][Step 243], time=0.09265995025634766, ext_time=0.06435847282409668, train_time=0.022382020950317383
[Epoch 3][Step 244], time=0.0934748649597168, ext_time=0.0648198127746582, train_time=0.02266097068786621
[Epoch 3][Step 245], time=0.09205985069274902, ext_time=0.0638434886932373, train_time=0.022289276123046875
[Epoch 3][Step 246], time=0.09242129325866699, ext_time=0.06413960456848145, train_time=0.022351741790771484
[Epoch 3][Step 247], time=0.09410429000854492, ext_time=0.0644838809967041, train_time=0.02265310287475586
[Epoch 3][Step 248], time=0.0936727523803711, ext_time=0.06511545181274414, train_time=0.022598743438720703
[Epoch 3][Step 249], time=0.09325909614562988, ext_time=0.06444954872131348, train_time=0.02281785011291504
[Epoch 3], time=23.257643938064575, loss=0.6931472420692444
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   85421 KB |    1901 MB |    4780 GB |    4780 GB |
|       from large pool |   72705 KB |    1890 MB |    4737 GB |    4736 GB |
|       from small pool |   12716 KB |      22 MB |      43 GB |      43 GB |
|---------------------------------------------------------------------------|
| Active memory         |   85421 KB |    1901 MB |    4780 GB |    4780 GB |
|       from large pool |   72705 KB |    1890 MB |    4737 GB |    4736 GB |
|       from small pool |   12716 KB |      22 MB |      43 GB |      43 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    4246 MB |    4246 MB |    4246 MB |       0 B  |
|       from large pool |    4216 MB |    4216 MB |    4216 MB |       0 B  |
|       from small pool |      30 MB |      30 MB |      30 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  614994 KB |    3015 MB |    3933 GB |    3932 GB |
|       from large pool |  605182 KB |    3006 MB |    3887 GB |    3887 GB |
|       from small pool |    9812 KB |      14 MB |      45 GB |      45 GB |
|---------------------------------------------------------------------------|
| Allocations           |      69    |      99    |  320287    |  320218    |
|       from large pool |      13    |      24    |   95502    |   95489    |
|       from small pool |      56    |      79    |  224785    |  224729    |
|---------------------------------------------------------------------------|
| Active allocs         |      69    |      99    |  320287    |  320218    |
|       from large pool |      13    |      24    |   95502    |   95489    |
|       from small pool |      56    |      79    |  224785    |  224729    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      29    |      29    |      29    |       0    |
|       from large pool |      14    |      14    |      14    |       0    |
|       from small pool |      15    |      15    |      15    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      39    |      51    |  123130    |  123091    |
|       from large pool |      11    |      19    |   52871    |   52860    |
|       from small pool |      28    |      39    |   70259    |   70231    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[TRAIN_TIME] train time is 94.100801 seconds
[EPOCH_TIME] 23.525200 seconds, maybe large due to not enough epoch skipped.
    [Step(average) Profiler Level 1 E3 S999]
        L1  sample           0.005834 | send           0.000000
        L1  recv             0.000000 | copy           0.063736 | convert time 0.000000 | train  0.023228
        L1  feature nbytes    1.06 GB | label nbytes 0.00 Bytes
        L1  id nbytes      0.00 Bytes | graph nbytes 0.00 Bytes
        L1  miss nbytes    0.00 Bytes | remote nbytes 0.00 Bytes
        L1  num nodes               0 | num samples           0
        L1  seq duration     0.000000 | refresh duration   0.000000
    [Step(average) Profiler Level 2 E3 S999]
        L2  shuffle     0.000000 | core sample  0.000000 | id remap        0.000000
        L2  graph copy  0.000000 | id copy      0.000000 | cache feat copy 0.063736
        L2  last layer sample time 0.000000 | size 0.000000
    [Step(average) Profiler Level 3 E3 S999]
        L3  khop sample coo  0.000000 | khop sort coo      0.000000 | khop count edge     0.000000 | khop compact edge 0.000000
        L3  walk sample coo  0.000000 | walk topk total    0.000000 | walk topk step1     0.000000 | walk topk step2   0.000000
        L3  walk topk step3  0.000000 | walk topk step4    0.000000 | walk topk step5     0.000000
        L3  walk topk step6  0.000000 | walk topk step7    0.000000
        L3  remap unique     0.000000 | remap populate     0.000000 | remap mapnode       0.000000 | remap mapedge     0.000000
        L3  cache get_index  0.000689 | cache copy_index   0.000000 | cache extract_miss  0.000000
        L3  cache copy_miss  0.000000 | cache combine_miss 0.000000 | cache combine cache 0.063001 | cache combine remote 0.000000
        L3  label extract  0.000000
    [Profiler Level Percentiles E3 S999]
        p50.00_tail_logl2featcopy=0.063738
        p90.00_tail_logl2featcopy=0.064698
        p95.00_tail_logl2featcopy=0.064987
        p99.00_tail_logl2featcopy=0.065482
        p99.90_tail_logl2featcopy=0.067590
[CUDA] cuda: usage: 12.93 GB
[EPOCH_TIME] 23.254570 seconds
worker 1 running with pid=48383
loading train edge idx from disk
loading train edge idx from disk done
tensor([ 312558501,  165303846,  382592436, 3465360478, 1289294319, 1055724137,
        3392581687,  213217736, 3047409731, 2134151289, 2553067370, 2969120916,
        2293768477, 1618302669,  184738216, 1829492105, 1438364301,  143975391,
        3488855025, 1525393396,  484788782, 1824160758, 3278914432, 1791042494,
        2531399103, 1976393697,  267524578, 1415973226, 3055112374, 2304304850,
        2970740983,  463733153,  470323953,  172504368,  314487920,  565768019,
        1325206124,    3902063, 2558324563, 2631782915, 3561616031, 2061569113,
        1776804911, 3574237973,  226132407,  361666075, 1514025674, 2274739441,
         125808586,  613763319, 1680587044,   50300193, 1625798297, 1321548596,
        3372445782, 1162803676, 1779255988, 2824765390, 1859433431, 2244623276,
        2673542557, 2014397343,  787107922, 1470797842,  653592026, 3063416664,
        2396187549,   39784734,  782941200, 2597902117, 1950931722,  539301441,
         881167165, 2566715114, 1143946729, 1063252333,  374533248, 2050371892,
        3306915207,  552684244, 1631811769,  588251379,  562506265,   42541411,
        1864901246, 2976754698, 1822251476,  641961590,  819864454, 3489874270,
        3553458922, 3534464258, 1694742715, 1593217661,  209704235, 1093043746,
        2390506997,   76009729,   77103172, 2606303238])
Rank=1, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.007536, per step: 0.000030
presamping
presamping takes 15.364731788635254
worker 2 running with pid=48384
loading train edge idx from disk
loading train edge idx from disk done
tensor([ 312558501,  165303846,  382592436, 3465360478, 1289294319, 1055724137,
        3392581687,  213217736, 3047409731, 2134151289, 2553067370, 2969120916,
        2293768477, 1618302669,  184738216, 1829492105, 1438364301,  143975391,
        3488855025, 1525393396,  484788782, 1824160758, 3278914432, 1791042494,
        2531399103, 1976393697,  267524578, 1415973226, 3055112374, 2304304850,
        2970740983,  463733153,  470323953,  172504368,  314487920,  565768019,
        1325206124,    3902063, 2558324563, 2631782915, 3561616031, 2061569113,
        1776804911, 3574237973,  226132407,  361666075, 1514025674, 2274739441,
         125808586,  613763319, 1680587044,   50300193, 1625798297, 1321548596,
        3372445782, 1162803676, 1779255988, 2824765390, 1859433431, 2244623276,
        2673542557, 2014397343,  787107922, 1470797842,  653592026, 3063416664,
        2396187549,   39784734,  782941200, 2597902117, 1950931722,  539301441,
         881167165, 2566715114, 1143946729, 1063252333,  374533248, 2050371892,
        3306915207,  552684244, 1631811769,  588251379,  562506265,   42541411,
        1864901246, 2976754698, 1822251476,  641961590,  819864454, 3489874270,
        3553458922, 3534464258, 1694742715, 1593217661,  209704235, 1093043746,
        2390506997,   76009729,   77103172, 2606303238])
Rank=2, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.007454, per step: 0.000030
presamping
presamping takes 12.602991342544556
worker 3 running with pid=48386
loading train edge idx from disk
loading train edge idx from disk done
tensor([ 312558501,  165303846,  382592436, 3465360478, 1289294319, 1055724137,
        3392581687,  213217736, 3047409731, 2134151289, 2553067370, 2969120916,
        2293768477, 1618302669,  184738216, 1829492105, 1438364301,  143975391,
        3488855025, 1525393396,  484788782, 1824160758, 3278914432, 1791042494,
        2531399103, 1976393697,  267524578, 1415973226, 3055112374, 2304304850,
        2970740983,  463733153,  470323953,  172504368,  314487920,  565768019,
        1325206124,    3902063, 2558324563, 2631782915, 3561616031, 2061569113,
        1776804911, 3574237973,  226132407,  361666075, 1514025674, 2274739441,
         125808586,  613763319, 1680587044,   50300193, 1625798297, 1321548596,
        3372445782, 1162803676, 1779255988, 2824765390, 1859433431, 2244623276,
        2673542557, 2014397343,  787107922, 1470797842,  653592026, 3063416664,
        2396187549,   39784734,  782941200, 2597902117, 1950931722,  539301441,
         881167165, 2566715114, 1143946729, 1063252333,  374533248, 2050371892,
        3306915207,  552684244, 1631811769,  588251379,  562506265,   42541411,
        1864901246, 2976754698, 1822251476,  641961590,  819864454, 3489874270,
        3553458922, 3534464258, 1694742715, 1593217661,  209704235, 1093043746,
        2390506997,   76009729,   77103172, 2606303238])
Rank=3, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.011988, per step: 0.000048
presamping
presamping takes 15.935882091522217

