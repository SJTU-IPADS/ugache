succeed=True
[CUDA] cuda: usage: 5.52 GB
0 :  {link #0 : 1}, {link #1 : 2}, {link #2 : 3},
1 :  {link #0 : 2}, {link #1 : 3}, {link #2 : 0},
2 :  {link #0 : 3}, {link #1 : 0}, {link #2 : 1},
3 :  {link #0 : 0}, {link #1 : 1}, {link #2 : 2},
0 :  {link #0 : 1}, {link #1 : 2}, {link #2 : 3},
1 :  {link #0 : 2}, {link #1 : 3}, {link #2 : 0},
2 :  {link #0 : 3}, {link #1 : 0}, {link #2 : 1},
3 :  {link #0 : 0}, {link #1 : 1}, {link #2 : 2},
0 :  {link #0 : 1}, {link #1 : 2}, {link #2 : 3},
1 :  {link #0 : 2}, {link #1 : 3}, {link #2 : 0},
2 :  {link #0 : 3}, {link #1 : 0}, {link #2 : 1},
3 :  {link #0 : 0}, {link #1 : 1}, {link #2 : 2},
0 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g2 24}, {link #2 : g3 24},
1 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g3 24}, {link #2 : g0 24},
2 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g0 24}, {link #2 : g1 24},
3 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g1 24}, {link #2 : g2 24},
0 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g2 24}, {link #2 : g3 24},
1 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g3 24}, {link #2 : g0 24},
2 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g0 24}, {link #2 : g1 24},
3 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g1 24}, {link #2 : g2 24},
0 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g2 24}, {link #2 : g3 24},
1 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g3 24}, {link #2 : g0 24},
2 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g0 24}, {link #2 : g1 24},
3 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g1 24}, {link #2 : g2 24},
0 :  {link #0 : 1}, {link #1 : 2}, {link #2 : 3},
1 :  {link #0 : 2}, {link #1 : 3}, {link #2 : 0},
2 :  {link #0 : 3}, {link #1 : 0}, {link #2 : 1},
3 :  {link #0 : 0}, {link #1 : 1}, {link #2 : 2},
0 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g2 24}, {link #2 : g3 24},
1 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g3 24}, {link #2 : g0 24},
2 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g0 24}, {link #2 : g1 24},
3 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g1 24}, {link #2 : g2 24},
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID
Set parameter TimeLimit to value 200
Set parameter MIPGap to value 0.05
Set parameter LogFile to value "cppsolver.log"
Set parameter Threads to value 40
Academic license - for non-commercial use only - registered to xiaoniu.sxn@sjtu.edu.cn
Gurobi Optimizer version 9.5.1 build v9.5.1rc2 (linux64)
Thread count: 40 physical cores, 80 logical processors, using up to 40 threads
Academic license - for non-commercial use only - registered to xiaoniu.sxn@sjtu.edu.cn
Optimize a model with 23168 rows, 7570 columns and 71224 nonzeros
Model fingerprint: 0xb31206da
Variable types: 5 continuous, 7565 integer (7565 binary)
Coefficient statistics:
  Matrix range     [9e-10, 1e+04]
  Objective range  [1e+00, 1e+00]
  Bounds range     [1e+00, 1e+00]
  RHS range        [1e+00, 9e+03]
Warning: Model contains large matrix coefficient range
         Consider reformulating model or setting NumericFocus parameter
         to avoid numerical issues.
Found heuristic solution: objective 2.000000e+09
Presolve removed 16042 rows and 20 columns
Presolve time: 0.10s
Presolved: 7126 rows, 7550 columns, 34114 nonzeros
Found heuristic solution: objective 40568.292282
Variable types: 1 continuous, 7549 integer (7548 binary)

Root relaxation: objective 1.022634e+04, 7034 iterations, 0.07 seconds (0.05 work units)

    Nodes    |    Current Node    |     Objective Bounds      |     Work
 Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time

     0     0 10226.3417    0   21 40568.2923 10226.3417  74.8%     -    0s
H    0     0                    11152.055619 10226.3417  8.30%     -    0s
H    0     0                    10432.372926 10226.3417  1.97%     -    0s

Cutting planes:
  Gomory: 2
  Cover: 1
  MIR: 1
  RLT: 2

Explored 1 nodes (10571 simplex iterations) in 0.40 seconds (0.26 work units)
Thread count was 40 (of 80 available processors)

Solution count 4: 10432.4 11152.1 40568.3 2e+09 

Optimal solution found (tolerance 5.00e-02)
Best objective 1.043237292589e+04, best bound 1.022634173961e+04, gap 1.9749%
coll_cache:optimal_local_rate=0.177225,0.20839,0.235559,0.217156,
coll_cache:optimal_remote_rate=0.657254,0.62609,0.598921,0.617324,
coll_cache:optimal_cpu_rate=0.16552,0.16552,0.16552,0.16552,
z=10432.4
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=4605878272
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=4605878272
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=4605878272
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=4605878272
worker 0 running with pid=31101
config:eval_tsp="2023-08-06 08:28:45"
config:num_worker=4
config:num_intra_size=4
config:root_dir=/datasets_gnn/wholegraph
config:graph_name=ogbn-papers100M
config:epochs=4
config:batchsize=500
config:skip_epoch=2
config:local_step=250
config:presc_epoch=2
config:neighbors=15,10,5
config:hiddensize=256
config:num_layer=3
config:model=gcn
config:framework=dgl
config:dataloaderworkers=0
config:dropout=0.5
config:weight_decay=0.0005
config:lr=0.003
config:use_nccl=False
config:use_amp=True
config:use_collcache=True
config:cache_percentage=0.08
config:cache_policy=coll_cache_asymm_link
config:omp_thread_num=40
config:unsupervised=True
config:classnum=172
config:global_barrier=<multiprocessing.synchronize.Barrier object at 0x7fde129a6880>
config:worker_id=0
creating_intra_node_communicator root=0, local_size=4, world_size=4
loading train edge idx from disk
loading train edge idx from disk done
tensor([ 367470406, 3158702471, 3196913887,  537616058, 2622541626, 2707306334,
        2288750783,  341639546, 2394912536,   38094375,  701084300, 1665128055,
        3225579545,  811343571,  534157746,  726851972, 1000854521, 1061370191,
         597404666,  526478766,  499672205, 1382980281, 1363464091,  971316959,
        1643305663, 1559556869,  792051811, 2593715952, 2627476216,  869058904,
        1279512108,  281028249, 2848334841, 1142277951, 1624797255, 1682408139,
         514723102,  756902533, 1190696744, 1515340461,  396873136, 3079813016,
         574876927,   31156367,  833957351, 1664434120,  774080817, 2850247945,
         655998496,  888602410,  350570870,  850355735,   69778231,  638128676,
        1443388341, 1479712286, 2858804367,  550628163,  198023098, 2583590303,
        2518492873,    2593795, 2722269746,  659106604, 1369497066,  461650496,
         645516367, 3053389785,  148119355,  792250187, 1401047469, 1545651011,
        1827797263, 1275030316, 2075895474, 2919804301, 2493902937,  112768749,
          11701078,  726712463,  404737965,  786261376,  934911988,  757583227,
        1135493038, 3162165660, 1144120843, 2861906075,  226440368, 1866677628,
         329488287,   67449549, 1840253021,  973854642,  422444545, 3025516425,
         133597469,  981523193, 2348166713,  306896793])
Rank=0, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.007441, per step: 0.000030
epoch=4 total_steps=1000
presamping
presamping takes 13.124624013900757
start training...
[Epoch 0][Step 0], time=1.1586964130401611, ext_time=0.010864973068237305, train_time=1.139324426651001
[Epoch 0][Step 1], time=0.036301612854003906, ext_time=0.008982181549072266, train_time=0.021539688110351562
[Epoch 0][Step 2], time=0.03098893165588379, ext_time=0.008003950119018555, train_time=0.017478227615356445
[Epoch 0][Step 3], time=0.0317230224609375, ext_time=0.007944345474243164, train_time=0.018336057662963867
[Epoch 0][Step 4], time=0.030744075775146484, ext_time=0.00782322883605957, train_time=0.017498254776000977
[Epoch 0][Step 5], time=0.03189849853515625, ext_time=0.007912635803222656, train_time=0.018555641174316406
[Epoch 0][Step 6], time=0.030902862548828125, ext_time=0.007901430130004883, train_time=0.017668485641479492
[Epoch 0][Step 7], time=0.031168460845947266, ext_time=0.00794219970703125, train_time=0.017929553985595703
[Epoch 0][Step 8], time=0.03073859214782715, ext_time=0.008255481719970703, train_time=0.01712203025817871
[Epoch 0][Step 9], time=0.03090667724609375, ext_time=0.007957696914672852, train_time=0.017572402954101562
[Epoch 0][Step 10], time=0.03332877159118652, ext_time=0.007988691329956055, train_time=0.019966840744018555
[Epoch 0][Step 11], time=0.03312849998474121, ext_time=0.008053302764892578, train_time=0.016594409942626953
[Epoch 0][Step 12], time=0.030989408493041992, ext_time=0.00810098648071289, train_time=0.017505168914794922
[Epoch 0][Step 13], time=0.030271530151367188, ext_time=0.008028268814086914, train_time=0.016889095306396484
[Epoch 0][Step 14], time=0.030629396438598633, ext_time=0.007737398147583008, train_time=0.017517566680908203
[Epoch 0][Step 15], time=0.03129458427429199, ext_time=0.007776975631713867, train_time=0.018119335174560547
[Epoch 0][Step 16], time=0.031479835510253906, ext_time=0.007898807525634766, train_time=0.018139362335205078
[Epoch 0][Step 17], time=0.030579328536987305, ext_time=0.007894039154052734, train_time=0.017339229583740234
[Epoch 0][Step 18], time=0.030724287033081055, ext_time=0.008173704147338867, train_time=0.017055034637451172
[Epoch 0][Step 19], time=0.03138089179992676, ext_time=0.008064985275268555, train_time=0.017940998077392578
[Epoch 0][Step 20], time=0.03084397315979004, ext_time=0.008384466171264648, train_time=0.01694512367248535
[Epoch 0][Step 21], time=0.030776500701904297, ext_time=0.008148908615112305, train_time=0.017275571823120117
[Epoch 0][Step 22], time=0.03072214126586914, ext_time=0.008043766021728516, train_time=0.017246246337890625
[Epoch 0][Step 23], time=0.03063058853149414, ext_time=0.008282899856567383, train_time=0.016974687576293945
[Epoch 0][Step 24], time=0.030785799026489258, ext_time=0.007997274398803711, train_time=0.017395734786987305
[Epoch 0][Step 25], time=0.031430959701538086, ext_time=0.007910728454589844, train_time=0.018134593963623047
[Epoch 0][Step 26], time=0.03117680549621582, ext_time=0.007835149765014648, train_time=0.0180051326751709
[Epoch 0][Step 27], time=0.03168320655822754, ext_time=0.0077250003814697266, train_time=0.018543004989624023
[Epoch 0][Step 28], time=0.03101062774658203, ext_time=0.007908821105957031, train_time=0.017810821533203125
[Epoch 0][Step 29], time=0.031116724014282227, ext_time=0.007780790328979492, train_time=0.01802802085876465
[Epoch 0][Step 30], time=0.03009486198425293, ext_time=0.007916450500488281, train_time=0.016948699951171875
[Epoch 0][Step 31], time=0.030376911163330078, ext_time=0.008090496063232422, train_time=0.016911983489990234
[Epoch 0][Step 32], time=0.03110051155090332, ext_time=0.008158683776855469, train_time=0.017594099044799805
[Epoch 0][Step 33], time=0.031064510345458984, ext_time=0.007967233657836914, train_time=0.01774311065673828
[Epoch 0][Step 34], time=0.031168699264526367, ext_time=0.008014917373657227, train_time=0.01785755157470703
[Epoch 0][Step 35], time=0.030332326889038086, ext_time=0.008103370666503906, train_time=0.01697087287902832
[Epoch 0][Step 36], time=0.03058147430419922, ext_time=0.007987260818481445, train_time=0.017270803451538086
[Epoch 0][Step 37], time=0.030881643295288086, ext_time=0.007877349853515625, train_time=0.01768183708190918
[Epoch 0][Step 38], time=0.031187772750854492, ext_time=0.00799250602722168, train_time=0.01784515380859375
[Epoch 0][Step 39], time=0.03051924705505371, ext_time=0.007859945297241211, train_time=0.017264127731323242
[Epoch 0][Step 40], time=0.03338766098022461, ext_time=0.007785320281982422, train_time=0.020278215408325195
[Epoch 0][Step 41], time=0.030914306640625, ext_time=0.008063793182373047, train_time=0.017513036727905273
[Epoch 0][Step 42], time=0.030649662017822266, ext_time=0.008107185363769531, train_time=0.01722240447998047
[Epoch 0][Step 43], time=0.030313968658447266, ext_time=0.007731199264526367, train_time=0.017254114151000977
[Epoch 0][Step 44], time=0.03021836280822754, ext_time=0.008040428161621094, train_time=0.016755342483520508
[Epoch 0][Step 45], time=0.03124213218688965, ext_time=0.008010625839233398, train_time=0.017920732498168945
[Epoch 0][Step 46], time=0.030548095703125, ext_time=0.008208751678466797, train_time=0.01690220832824707
[Epoch 0][Step 47], time=0.03428959846496582, ext_time=0.008056402206420898, train_time=0.020815610885620117
[Epoch 0][Step 48], time=0.03076767921447754, ext_time=0.008100748062133789, train_time=0.017295122146606445
[Epoch 0][Step 49], time=0.03070235252380371, ext_time=0.00802469253540039, train_time=0.017239093780517578
[Epoch 0][Step 50], time=0.030214309692382812, ext_time=0.007798433303833008, train_time=0.017079830169677734
[Epoch 0][Step 51], time=0.030286550521850586, ext_time=0.007936954498291016, train_time=0.017026901245117188
[Epoch 0][Step 52], time=0.030806541442871094, ext_time=0.008128166198730469, train_time=0.017345905303955078
[Epoch 0][Step 53], time=0.030318737030029297, ext_time=0.008016824722290039, train_time=0.016948938369750977
[Epoch 0][Step 54], time=0.03084254264831543, ext_time=0.007720232009887695, train_time=0.01767563819885254
[Epoch 0][Step 55], time=0.030512571334838867, ext_time=0.008059978485107422, train_time=0.01705336570739746
[Epoch 0][Step 56], time=0.031167030334472656, ext_time=0.008136749267578125, train_time=0.017667293548583984
[Epoch 0][Step 57], time=0.030396461486816406, ext_time=0.008241415023803711, train_time=0.016831159591674805
[Epoch 0][Step 58], time=0.030813932418823242, ext_time=0.00803995132446289, train_time=0.017463207244873047
[Epoch 0][Step 59], time=0.030822277069091797, ext_time=0.008246898651123047, train_time=0.017177343368530273
[Epoch 0][Step 60], time=0.030668973922729492, ext_time=0.007936716079711914, train_time=0.017470359802246094
[Epoch 0][Step 61], time=0.03074479103088379, ext_time=0.008142948150634766, train_time=0.01725625991821289
[Epoch 0][Step 62], time=0.0303037166595459, ext_time=0.007777690887451172, train_time=0.01714038848876953
[Epoch 0][Step 63], time=0.030514240264892578, ext_time=0.007991790771484375, train_time=0.017271995544433594
[Epoch 0][Step 64], time=0.03058338165283203, ext_time=0.008162736892700195, train_time=0.017102718353271484
[Epoch 0][Step 65], time=0.03074049949645996, ext_time=0.0081024169921875, train_time=0.01735520362854004
[Epoch 0][Step 66], time=0.031186342239379883, ext_time=0.00813150405883789, train_time=0.017716646194458008
[Epoch 0][Step 67], time=0.03060293197631836, ext_time=0.007847309112548828, train_time=0.017436742782592773
[Epoch 0][Step 68], time=0.031235218048095703, ext_time=0.007925033569335938, train_time=0.018003463745117188
[Epoch 0][Step 69], time=0.030822038650512695, ext_time=0.008048295974731445, train_time=0.016252756118774414
[Epoch 0][Step 70], time=0.03093409538269043, ext_time=0.008034706115722656, train_time=0.017609596252441406
[Epoch 0][Step 71], time=0.030440330505371094, ext_time=0.007956743240356445, train_time=0.017153501510620117
[Epoch 0][Step 72], time=0.030635833740234375, ext_time=0.008031368255615234, train_time=0.017258167266845703
[Epoch 0][Step 73], time=0.03254103660583496, ext_time=0.007883787155151367, train_time=0.019292831420898438
[Epoch 0][Step 74], time=0.03071904182434082, ext_time=0.008318185806274414, train_time=0.01682138442993164
[Epoch 0][Step 75], time=0.030423641204833984, ext_time=0.007902860641479492, train_time=0.017239809036254883
[Epoch 0][Step 76], time=0.030986547470092773, ext_time=0.008315563201904297, train_time=0.017271757125854492
[Epoch 0][Step 77], time=0.0324862003326416, ext_time=0.007834196090698242, train_time=0.01936960220336914
[Epoch 0][Step 78], time=0.030628681182861328, ext_time=0.008030176162719727, train_time=0.01713395118713379
[Epoch 0][Step 79], time=0.0301055908203125, ext_time=0.007979154586791992, train_time=0.016796350479125977
[Epoch 0][Step 80], time=0.03049302101135254, ext_time=0.007918596267700195, train_time=0.017209291458129883
[Epoch 0][Step 81], time=0.030902624130249023, ext_time=0.008051156997680664, train_time=0.017475605010986328
[Epoch 0][Step 82], time=0.030832529067993164, ext_time=0.007986068725585938, train_time=0.017554283142089844
[Epoch 0][Step 83], time=0.03227972984313965, ext_time=0.007786750793457031, train_time=0.019281864166259766
[Epoch 0][Step 84], time=0.03092503547668457, ext_time=0.00799703598022461, train_time=0.017537355422973633
[Epoch 0][Step 85], time=0.030554771423339844, ext_time=0.007821083068847656, train_time=0.01738262176513672
[Epoch 0][Step 86], time=0.030565977096557617, ext_time=0.008078336715698242, train_time=0.01710343360900879
[Epoch 0][Step 87], time=0.03032970428466797, ext_time=0.008040428161621094, train_time=0.016947507858276367
[Epoch 0][Step 88], time=0.0306088924407959, ext_time=0.007759571075439453, train_time=0.017494916915893555
[Epoch 0][Step 89], time=0.030472993850708008, ext_time=0.007989645004272461, train_time=0.017137765884399414
[Epoch 0][Step 90], time=0.03072667121887207, ext_time=0.008062124252319336, train_time=0.017390012741088867
[Epoch 0][Step 91], time=0.031372785568237305, ext_time=0.007900714874267578, train_time=0.018088340759277344
[Epoch 0][Step 92], time=0.030552387237548828, ext_time=0.008058547973632812, train_time=0.017177820205688477
[Epoch 0][Step 93], time=0.0316472053527832, ext_time=0.00788259506225586, train_time=0.0184323787689209
[Epoch 0][Step 94], time=0.03124523162841797, ext_time=0.008273124694824219, train_time=0.017545223236083984
[Epoch 0][Step 95], time=0.030802011489868164, ext_time=0.00787210464477539, train_time=0.017581939697265625
[Epoch 0][Step 96], time=0.03028559684753418, ext_time=0.007976293563842773, train_time=0.017045974731445312
[Epoch 0][Step 97], time=0.03036022186279297, ext_time=0.008006572723388672, train_time=0.016968965530395508
[Epoch 0][Step 98], time=0.031341552734375, ext_time=0.007902383804321289, train_time=0.018044710159301758
[Epoch 0][Step 99], time=0.030949831008911133, ext_time=0.008131027221679688, train_time=0.017393827438354492
[Epoch 0][Step 100], time=0.030803203582763672, ext_time=0.00795292854309082, train_time=0.017425537109375
[Epoch 0][Step 101], time=0.030599355697631836, ext_time=0.008029937744140625, train_time=0.01719045639038086
[Epoch 0][Step 102], time=0.03389716148376465, ext_time=0.007993936538696289, train_time=0.020503759384155273
[Epoch 0][Step 103], time=0.030462265014648438, ext_time=0.007628440856933594, train_time=0.017504453659057617
[Epoch 0][Step 104], time=0.030803918838500977, ext_time=0.007972478866577148, train_time=0.017367124557495117
[Epoch 0][Step 105], time=0.030530929565429688, ext_time=0.0077784061431884766, train_time=0.01742696762084961
[Epoch 0][Step 106], time=0.03092813491821289, ext_time=0.007850408554077148, train_time=0.01781773567199707
[Epoch 0][Step 107], time=0.030698299407958984, ext_time=0.007946252822875977, train_time=0.017452478408813477
[Epoch 0][Step 108], time=0.030617952346801758, ext_time=0.007808685302734375, train_time=0.01744246482849121
[Epoch 0][Step 109], time=0.030853271484375, ext_time=0.007882833480834961, train_time=0.01759791374206543
[Epoch 0][Step 110], time=0.031137466430664062, ext_time=0.008151054382324219, train_time=0.017586469650268555
[Epoch 0][Step 111], time=0.030679702758789062, ext_time=0.007769584655761719, train_time=0.0175323486328125
[Epoch 0][Step 112], time=0.03052806854248047, ext_time=0.007897377014160156, train_time=0.017297029495239258
[Epoch 0][Step 113], time=0.03119802474975586, ext_time=0.008149147033691406, train_time=0.01749563217163086
[Epoch 0][Step 114], time=0.030239582061767578, ext_time=0.00773167610168457, train_time=0.01717829704284668
[Epoch 0][Step 115], time=0.030554533004760742, ext_time=0.008103370666503906, train_time=0.017079830169677734
[Epoch 0][Step 116], time=0.031043052673339844, ext_time=0.007955789566040039, train_time=0.01773524284362793
[Epoch 0][Step 117], time=0.030735015869140625, ext_time=0.007849693298339844, train_time=0.017566680908203125
[Epoch 0][Step 118], time=0.03057408332824707, ext_time=0.00794363021850586, train_time=0.017282485961914062
[Epoch 0][Step 119], time=0.03044605255126953, ext_time=0.008036613464355469, train_time=0.017119407653808594
[Epoch 0][Step 120], time=0.030654191970825195, ext_time=0.008127927780151367, train_time=0.01723170280456543
[Epoch 0][Step 121], time=0.030712366104125977, ext_time=0.007784128189086914, train_time=0.017642736434936523
[Epoch 0][Step 122], time=0.030425310134887695, ext_time=0.008143901824951172, train_time=0.017017841339111328
[Epoch 0][Step 123], time=0.03105640411376953, ext_time=0.007950305938720703, train_time=0.01772928237915039
[Epoch 0][Step 124], time=0.03057408332824707, ext_time=0.007836580276489258, train_time=0.017435789108276367
[Epoch 0][Step 125], time=0.03099346160888672, ext_time=0.007827520370483398, train_time=0.017854928970336914
[Epoch 0][Step 126], time=0.030828475952148438, ext_time=0.007724761962890625, train_time=0.017864465713500977
[Epoch 0][Step 127], time=0.030580520629882812, ext_time=0.007997989654541016, train_time=0.017259597778320312
[Epoch 0][Step 128], time=0.03056192398071289, ext_time=0.008237838745117188, train_time=0.01695728302001953
[Epoch 0][Step 129], time=0.0305025577545166, ext_time=0.007909297943115234, train_time=0.01718902587890625
[Epoch 0][Step 130], time=0.03117227554321289, ext_time=0.007935285568237305, train_time=0.017795801162719727
[Epoch 0][Step 131], time=0.030498266220092773, ext_time=0.007882356643676758, train_time=0.017277240753173828
[Epoch 0][Step 132], time=0.031180381774902344, ext_time=0.008021116256713867, train_time=0.01773357391357422
[Epoch 0][Step 133], time=0.030634164810180664, ext_time=0.008239507675170898, train_time=0.016783952713012695
[Epoch 0][Step 134], time=0.030714988708496094, ext_time=0.008154153823852539, train_time=0.01716303825378418
[Epoch 0][Step 135], time=0.030996322631835938, ext_time=0.00802469253540039, train_time=0.017663240432739258
[Epoch 0][Step 136], time=0.03079819679260254, ext_time=0.008085489273071289, train_time=0.017316818237304688
[Epoch 0][Step 137], time=0.030847549438476562, ext_time=0.008113384246826172, train_time=0.017394542694091797
[Epoch 0][Step 138], time=0.030727386474609375, ext_time=0.007710456848144531, train_time=0.017725467681884766
[Epoch 0][Step 139], time=0.030890941619873047, ext_time=0.007756471633911133, train_time=0.017837047576904297
[Epoch 0][Step 140], time=0.030640125274658203, ext_time=0.007904291152954102, train_time=0.01737070083618164
[Epoch 0][Step 141], time=0.030620813369750977, ext_time=0.00801539421081543, train_time=0.017200708389282227
[Epoch 0][Step 142], time=0.030305862426757812, ext_time=0.008024454116821289, train_time=0.01693868637084961
[Epoch 0][Step 143], time=0.030202627182006836, ext_time=0.007781505584716797, train_time=0.017160892486572266
[Epoch 0][Step 144], time=0.030452728271484375, ext_time=0.008037328720092773, train_time=0.017076969146728516
[Epoch 0][Step 145], time=0.030488014221191406, ext_time=0.008064031600952148, train_time=0.01711249351501465
[Epoch 0][Step 146], time=0.03074169158935547, ext_time=0.00795602798461914, train_time=0.01748967170715332
[Epoch 0][Step 147], time=0.03210878372192383, ext_time=0.00821375846862793, train_time=0.01698780059814453
[Epoch 0][Step 148], time=0.030781269073486328, ext_time=0.008057355880737305, train_time=0.017441987991333008
[Epoch 0][Step 149], time=0.030777454376220703, ext_time=0.008033037185668945, train_time=0.017361879348754883
[Epoch 0][Step 150], time=0.030772686004638672, ext_time=0.007735252380371094, train_time=0.017699718475341797
[Epoch 0][Step 151], time=0.031204700469970703, ext_time=0.007937192916870117, train_time=0.017936229705810547
[Epoch 0][Step 152], time=0.030900955200195312, ext_time=0.007923126220703125, train_time=0.017699003219604492
[Epoch 0][Step 153], time=0.03062582015991211, ext_time=0.008033275604248047, train_time=0.017091989517211914
[Epoch 0][Step 154], time=0.030383586883544922, ext_time=0.008083343505859375, train_time=0.016991615295410156
[Epoch 0][Step 155], time=0.030528783798217773, ext_time=0.007870674133300781, train_time=0.01733565330505371
[Epoch 0][Step 156], time=0.030480623245239258, ext_time=0.007805347442626953, train_time=0.01734447479248047
[Epoch 0][Step 157], time=0.030714988708496094, ext_time=0.008162736892700195, train_time=0.017180681228637695
[Epoch 0][Step 158], time=0.03250312805175781, ext_time=0.00792837142944336, train_time=0.019258499145507812
[Epoch 0][Step 159], time=0.03033733367919922, ext_time=0.008115530014038086, train_time=0.01678180694580078
[Epoch 0][Step 160], time=0.030585765838623047, ext_time=0.007991552352905273, train_time=0.01713252067565918
[Epoch 0][Step 161], time=0.030481338500976562, ext_time=0.008191108703613281, train_time=0.016852378845214844
[Epoch 0][Step 162], time=0.0310056209564209, ext_time=0.007845401763916016, train_time=0.017795085906982422
[Epoch 0][Step 163], time=0.03138017654418945, ext_time=0.007984399795532227, train_time=0.01793837547302246
[Epoch 0][Step 164], time=0.031093835830688477, ext_time=0.007802248001098633, train_time=0.017843246459960938
[Epoch 0][Step 165], time=0.03118157386779785, ext_time=0.007744789123535156, train_time=0.01797771453857422
[Epoch 0][Step 166], time=0.03036975860595703, ext_time=0.007930755615234375, train_time=0.01707148551940918
[Epoch 0][Step 167], time=0.033422231674194336, ext_time=0.008007287979125977, train_time=0.019968748092651367
[Epoch 0][Step 168], time=0.036466360092163086, ext_time=0.008057355880737305, train_time=0.022904157638549805
[Epoch 0][Step 169], time=0.03565168380737305, ext_time=0.007959365844726562, train_time=0.0221712589263916
[Epoch 0][Step 170], time=0.035628318786621094, ext_time=0.008037090301513672, train_time=0.02218151092529297
[Epoch 0][Step 171], time=0.036211252212524414, ext_time=0.007939338684082031, train_time=0.02284836769104004
[Epoch 0][Step 172], time=0.032944679260253906, ext_time=0.008187532424926758, train_time=0.019319534301757812
[Epoch 0][Step 173], time=0.0314176082611084, ext_time=0.007921934127807617, train_time=0.0180966854095459
[Epoch 0][Step 174], time=0.03141140937805176, ext_time=0.008043527603149414, train_time=0.018064260482788086
[Epoch 0][Step 175], time=0.030791044235229492, ext_time=0.008025169372558594, train_time=0.01741337776184082
[Epoch 0][Step 176], time=0.03196573257446289, ext_time=0.007916688919067383, train_time=0.01872110366821289
[Epoch 0][Step 177], time=0.031868934631347656, ext_time=0.007715463638305664, train_time=0.018808364868164062
[Epoch 0][Step 178], time=0.031110763549804688, ext_time=0.007780313491821289, train_time=0.017989635467529297
[Epoch 0][Step 179], time=0.03203082084655762, ext_time=0.00790095329284668, train_time=0.018828868865966797
[Epoch 0][Step 180], time=0.030837059020996094, ext_time=0.008058786392211914, train_time=0.017362117767333984
[Epoch 0][Step 181], time=0.03045821189880371, ext_time=0.008173942565917969, train_time=0.017009973526000977
[Epoch 0][Step 182], time=0.03070688247680664, ext_time=0.00816202163696289, train_time=0.017179012298583984
[Epoch 0][Step 183], time=0.030768632888793945, ext_time=0.0077669620513916016, train_time=0.01763629913330078
[Epoch 0][Step 184], time=0.030757665634155273, ext_time=0.008138656616210938, train_time=0.017348527908325195
[Epoch 0][Step 185], time=0.030785799026489258, ext_time=0.007942676544189453, train_time=0.0174257755279541
[Epoch 0][Step 186], time=0.030900001525878906, ext_time=0.007814407348632812, train_time=0.01778388023376465
[Epoch 0][Step 187], time=0.030854225158691406, ext_time=0.008122444152832031, train_time=0.017359495162963867
[Epoch 0][Step 188], time=0.030789613723754883, ext_time=0.007975578308105469, train_time=0.017463207244873047
[Epoch 0][Step 189], time=0.0309903621673584, ext_time=0.007980108261108398, train_time=0.017703771591186523
[Epoch 0][Step 190], time=0.030557632446289062, ext_time=0.007922887802124023, train_time=0.017322301864624023
[Epoch 0][Step 191], time=0.030941009521484375, ext_time=0.008143186569213867, train_time=0.01740097999572754
[Epoch 0][Step 192], time=0.030127525329589844, ext_time=0.007984161376953125, train_time=0.01678609848022461
[Epoch 0][Step 193], time=0.030414819717407227, ext_time=0.008017539978027344, train_time=0.017145872116088867
[Epoch 0][Step 194], time=0.03063035011291504, ext_time=0.007929801940917969, train_time=0.01728963851928711
[Epoch 0][Step 195], time=0.030892372131347656, ext_time=0.008125782012939453, train_time=0.01739811897277832
[Epoch 0][Step 196], time=0.030205488204956055, ext_time=0.007962703704833984, train_time=0.01689934730529785
[Epoch 0][Step 197], time=0.030255794525146484, ext_time=0.008011102676391602, train_time=0.016872882843017578
[Epoch 0][Step 198], time=0.030599117279052734, ext_time=0.00815272331237793, train_time=0.01708841323852539
[Epoch 0][Step 199], time=0.030889272689819336, ext_time=0.008111715316772461, train_time=0.01744675636291504
[Epoch 0][Step 200], time=0.03092360496520996, ext_time=0.007920026779174805, train_time=0.01764225959777832
[Epoch 0][Step 201], time=0.030323266983032227, ext_time=0.008055686950683594, train_time=0.016869306564331055
[Epoch 0][Step 202], time=0.03046584129333496, ext_time=0.00793910026550293, train_time=0.017149686813354492
[Epoch 0][Step 203], time=0.030484676361083984, ext_time=0.008086204528808594, train_time=0.016918182373046875
[Epoch 0][Step 204], time=0.03105950355529785, ext_time=0.007889747619628906, train_time=0.017852306365966797
[Epoch 0][Step 205], time=0.030315160751342773, ext_time=0.00779271125793457, train_time=0.017181873321533203
[Epoch 0][Step 206], time=0.03054189682006836, ext_time=0.008086204528808594, train_time=0.017096519470214844
[Epoch 0][Step 207], time=0.031011104583740234, ext_time=0.00784921646118164, train_time=0.017793893814086914
[Epoch 0][Step 208], time=0.03056192398071289, ext_time=0.00811147689819336, train_time=0.017076492309570312
[Epoch 0][Step 209], time=0.03179144859313965, ext_time=0.008251428604125977, train_time=0.01816701889038086
[Epoch 0][Step 210], time=0.031023740768432617, ext_time=0.00796961784362793, train_time=0.017642736434936523
[Epoch 0][Step 211], time=0.03080129623413086, ext_time=0.00830841064453125, train_time=0.017174482345581055
[Epoch 0][Step 212], time=0.030396699905395508, ext_time=0.007901191711425781, train_time=0.017160415649414062
[Epoch 0][Step 213], time=0.030968904495239258, ext_time=0.008131980895996094, train_time=0.017399072647094727
[Epoch 0][Step 214], time=0.030567169189453125, ext_time=0.007876396179199219, train_time=0.017242431640625
[Epoch 0][Step 215], time=0.030608654022216797, ext_time=0.008144855499267578, train_time=0.01711416244506836
[Epoch 0][Step 216], time=0.03150486946105957, ext_time=0.007777214050292969, train_time=0.01843714714050293
[Epoch 0][Step 217], time=0.0302581787109375, ext_time=0.008006572723388672, train_time=0.016956329345703125
[Epoch 0][Step 218], time=0.03077554702758789, ext_time=0.008100271224975586, train_time=0.01729559898376465
[Epoch 0][Step 219], time=0.030332088470458984, ext_time=0.007884979248046875, train_time=0.01708817481994629
[Epoch 0][Step 220], time=0.031034231185913086, ext_time=0.008023738861083984, train_time=0.017679929733276367
[Epoch 0][Step 221], time=0.03101634979248047, ext_time=0.00789022445678711, train_time=0.01783275604248047
[Epoch 0][Step 222], time=0.030810832977294922, ext_time=0.007816314697265625, train_time=0.01764678955078125
[Epoch 0][Step 223], time=0.03093552589416504, ext_time=0.007985591888427734, train_time=0.017635107040405273
[Epoch 0][Step 224], time=0.030865192413330078, ext_time=0.007959365844726562, train_time=0.017571449279785156
[Epoch 0][Step 225], time=0.030786514282226562, ext_time=0.007843494415283203, train_time=0.0176241397857666
[Epoch 0][Step 226], time=0.030431747436523438, ext_time=0.007766246795654297, train_time=0.017332077026367188
[Epoch 0][Step 227], time=0.030648469924926758, ext_time=0.00803232192993164, train_time=0.0172274112701416
[Epoch 0][Step 228], time=0.03058338165283203, ext_time=0.007981061935424805, train_time=0.017199277877807617
[Epoch 0][Step 229], time=0.03068399429321289, ext_time=0.008076667785644531, train_time=0.017252683639526367
[Epoch 0][Step 230], time=0.030933618545532227, ext_time=0.007939338684082031, train_time=0.017650365829467773
[Epoch 0][Step 231], time=0.03081345558166504, ext_time=0.007982730865478516, train_time=0.017508983612060547
[Epoch 0][Step 232], time=0.030457019805908203, ext_time=0.007926702499389648, train_time=0.017244815826416016
[Epoch 0][Step 233], time=0.030765056610107422, ext_time=0.00801992416381836, train_time=0.017344236373901367
[Epoch 0][Step 234], time=0.031085491180419922, ext_time=0.008160591125488281, train_time=0.017536163330078125
[Epoch 0][Step 235], time=0.03045368194580078, ext_time=0.007759571075439453, train_time=0.01728510856628418
[Epoch 0][Step 236], time=0.030596017837524414, ext_time=0.007982254028320312, train_time=0.01730656623840332
[Epoch 0][Step 237], time=0.030692577362060547, ext_time=0.008082389831542969, train_time=0.017208099365234375
[Epoch 0][Step 238], time=0.030815839767456055, ext_time=0.008254051208496094, train_time=0.01722860336303711
[Epoch 0][Step 239], time=0.030897855758666992, ext_time=0.008016824722290039, train_time=0.01751875877380371
[Epoch 0][Step 240], time=0.03032398223876953, ext_time=0.00794076919555664, train_time=0.017048358917236328
[Epoch 0][Step 241], time=0.030619144439697266, ext_time=0.007841825485229492, train_time=0.017469406127929688
[Epoch 0][Step 242], time=0.030529022216796875, ext_time=0.007946968078613281, train_time=0.017196178436279297
[Epoch 0][Step 243], time=0.030520200729370117, ext_time=0.008164167404174805, train_time=0.01700448989868164
[Epoch 0][Step 244], time=0.03071308135986328, ext_time=0.007904052734375, train_time=0.017504215240478516
[Epoch 0][Step 245], time=0.03074193000793457, ext_time=0.007897377014160156, train_time=0.01748514175415039
[Epoch 0][Step 246], time=0.03089141845703125, ext_time=0.008088111877441406, train_time=0.017359256744384766
[Epoch 0][Step 247], time=0.03076004981994629, ext_time=0.008100271224975586, train_time=0.017368793487548828
[Epoch 0][Step 248], time=0.030665159225463867, ext_time=0.00796055793762207, train_time=0.01742386817932129
[Epoch 0][Step 249], time=0.030561208724975586, ext_time=0.007965087890625, train_time=0.017304182052612305
[Epoch 0], time=8.89160704612732, loss=0.6931472420692444
[Epoch 1][Step 0], time=0.03156614303588867, ext_time=0.007951974868774414, train_time=0.018117666244506836
[Epoch 1][Step 1], time=0.03075575828552246, ext_time=0.007952451705932617, train_time=0.017379283905029297
[Epoch 1][Step 2], time=0.03085923194885254, ext_time=0.00813603401184082, train_time=0.017344236373901367
[Epoch 1][Step 3], time=0.030892610549926758, ext_time=0.007904767990112305, train_time=0.017611026763916016
[Epoch 1][Step 4], time=0.030627727508544922, ext_time=0.007983922958374023, train_time=0.01723647117614746
[Epoch 1][Step 5], time=0.030394792556762695, ext_time=0.00777745246887207, train_time=0.017264127731323242
[Epoch 1][Step 6], time=0.030533790588378906, ext_time=0.00788736343383789, train_time=0.017246246337890625
[Epoch 1][Step 7], time=0.0311429500579834, ext_time=0.008082389831542969, train_time=0.01765894889831543
[Epoch 1][Step 8], time=0.0306093692779541, ext_time=0.00826573371887207, train_time=0.017043352127075195
[Epoch 1][Step 9], time=0.030703306198120117, ext_time=0.008083581924438477, train_time=0.017244815826416016
[Epoch 1][Step 10], time=0.031035423278808594, ext_time=0.00793910026550293, train_time=0.017863750457763672
[Epoch 1][Step 11], time=0.03085184097290039, ext_time=0.00795602798461914, train_time=0.017528772354125977
[Epoch 1][Step 12], time=0.03100752830505371, ext_time=0.007919788360595703, train_time=0.017754554748535156
[Epoch 1][Step 13], time=0.03028559684753418, ext_time=0.008049726486206055, train_time=0.016910076141357422
[Epoch 1][Step 14], time=0.03063035011291504, ext_time=0.007688045501708984, train_time=0.017508983612060547
[Epoch 1][Step 15], time=0.030530452728271484, ext_time=0.007907867431640625, train_time=0.017238140106201172
[Epoch 1][Step 16], time=0.030655622482299805, ext_time=0.007804155349731445, train_time=0.017482757568359375
[Epoch 1][Step 17], time=0.030617237091064453, ext_time=0.00796365737915039, train_time=0.01724839210510254
[Epoch 1][Step 18], time=0.030834197998046875, ext_time=0.008116483688354492, train_time=0.017340421676635742
[Epoch 1][Step 19], time=0.030803680419921875, ext_time=0.008147001266479492, train_time=0.01732349395751953
[Epoch 1][Step 20], time=0.03139901161193848, ext_time=0.008380889892578125, train_time=0.01766180992126465
[Epoch 1][Step 21], time=0.030410051345825195, ext_time=0.008037090301513672, train_time=0.01702260971069336
[Epoch 1][Step 22], time=0.030552387237548828, ext_time=0.007945060729980469, train_time=0.0172116756439209
[Epoch 1][Step 23], time=0.030683279037475586, ext_time=0.008173704147338867, train_time=0.017203092575073242
[Epoch 1][Step 24], time=0.03071141242980957, ext_time=0.00799250602722168, train_time=0.017334938049316406
[Epoch 1][Step 25], time=0.030627727508544922, ext_time=0.008052587509155273, train_time=0.017167091369628906
[Epoch 1][Step 26], time=0.030313968658447266, ext_time=0.007777214050292969, train_time=0.017179250717163086
[Epoch 1][Step 27], time=0.031738996505737305, ext_time=0.007916927337646484, train_time=0.01835942268371582
[Epoch 1][Step 28], time=0.0306246280670166, ext_time=0.007938861846923828, train_time=0.01732659339904785
[Epoch 1][Step 29], time=0.03063225746154785, ext_time=0.0077114105224609375, train_time=0.017560243606567383
[Epoch 1][Step 30], time=0.030549049377441406, ext_time=0.0077457427978515625, train_time=0.017592668533325195
[Epoch 1][Step 31], time=0.030359745025634766, ext_time=0.007982730865478516, train_time=0.016968250274658203
[Epoch 1][Step 32], time=0.0307769775390625, ext_time=0.008138656616210938, train_time=0.017307519912719727
[Epoch 1][Step 33], time=0.031052827835083008, ext_time=0.008340597152709961, train_time=0.017253398895263672
[Epoch 1][Step 34], time=0.03069758415222168, ext_time=0.007913351058959961, train_time=0.01747608184814453
[Epoch 1][Step 35], time=0.03040909767150879, ext_time=0.008002996444702148, train_time=0.017115116119384766
[Epoch 1][Step 36], time=0.030376434326171875, ext_time=0.00794363021850586, train_time=0.017087697982788086
[Epoch 1][Step 37], time=0.030969858169555664, ext_time=0.007968425750732422, train_time=0.017562389373779297
[Epoch 1][Step 38], time=0.030150651931762695, ext_time=0.008068084716796875, train_time=0.016710281372070312
[Epoch 1][Step 39], time=0.034627676010131836, ext_time=0.007822751998901367, train_time=0.02140665054321289
[Epoch 1][Step 40], time=0.03060436248779297, ext_time=0.007723093032836914, train_time=0.017436742782592773
[Epoch 1][Step 41], time=0.03094959259033203, ext_time=0.007833242416381836, train_time=0.01784539222717285
[Epoch 1][Step 42], time=0.03059864044189453, ext_time=0.00792837142944336, train_time=0.017363548278808594
[Epoch 1][Step 43], time=0.030657291412353516, ext_time=0.007936477661132812, train_time=0.017319440841674805
[Epoch 1][Step 44], time=0.030825138092041016, ext_time=0.008097410202026367, train_time=0.017363548278808594
[Epoch 1][Step 45], time=0.031136035919189453, ext_time=0.008071660995483398, train_time=0.017736434936523438
[Epoch 1][Step 46], time=0.030602455139160156, ext_time=0.007931709289550781, train_time=0.017325162887573242
[Epoch 1][Step 47], time=0.03116464614868164, ext_time=0.007938623428344727, train_time=0.01785421371459961
[Epoch 1][Step 48], time=0.03016495704650879, ext_time=0.007872343063354492, train_time=0.017004966735839844
[Epoch 1][Step 49], time=0.030909299850463867, ext_time=0.008213043212890625, train_time=0.017318248748779297
[Epoch 1][Step 50], time=0.030581235885620117, ext_time=0.008111000061035156, train_time=0.017128944396972656
[Epoch 1][Step 51], time=0.030808210372924805, ext_time=0.007925748825073242, train_time=0.01754927635192871
[Epoch 1][Step 52], time=0.030985355377197266, ext_time=0.00807499885559082, train_time=0.01751422882080078
[Epoch 1][Step 53], time=0.030954599380493164, ext_time=0.00791621208190918, train_time=0.017688751220703125
[Epoch 1][Step 54], time=0.030394315719604492, ext_time=0.007857084274291992, train_time=0.01717209815979004
[Epoch 1][Step 55], time=0.03365135192871094, ext_time=0.00817108154296875, train_time=0.020145416259765625
[Epoch 1][Step 56], time=0.030954599380493164, ext_time=0.00786900520324707, train_time=0.01777815818786621
[Epoch 1][Step 57], time=0.03066420555114746, ext_time=0.008082866668701172, train_time=0.01726508140563965
[Epoch 1][Step 58], time=0.030699491500854492, ext_time=0.008083581924438477, train_time=0.017218828201293945
[Epoch 1][Step 59], time=0.031453847885131836, ext_time=0.008290529251098633, train_time=0.01729559898376465
[Epoch 1][Step 60], time=0.03151655197143555, ext_time=0.007807493209838867, train_time=0.018209457397460938
[Epoch 1][Step 61], time=0.030239343643188477, ext_time=0.008139371871948242, train_time=0.016728639602661133
[Epoch 1][Step 62], time=0.030675888061523438, ext_time=0.007863283157348633, train_time=0.01744818687438965
[Epoch 1][Step 63], time=0.03040623664855957, ext_time=0.008021354675292969, train_time=0.0171053409576416
[Epoch 1][Step 64], time=0.030432462692260742, ext_time=0.007891178131103516, train_time=0.017222166061401367
[Epoch 1][Step 65], time=0.030408382415771484, ext_time=0.00813603401184082, train_time=0.016941547393798828
[Epoch 1][Step 66], time=0.030532121658325195, ext_time=0.008100271224975586, train_time=0.01710033416748047
[Epoch 1][Step 67], time=0.032219886779785156, ext_time=0.007916927337646484, train_time=0.017353534698486328
[Epoch 1][Step 68], time=0.03061223030090332, ext_time=0.00810551643371582, train_time=0.017103910446166992
[Epoch 1][Step 69], time=0.03079366683959961, ext_time=0.008037328720092773, train_time=0.017328977584838867
[Epoch 1][Step 70], time=0.031064271926879883, ext_time=0.008036375045776367, train_time=0.01760697364807129
[Epoch 1][Step 71], time=0.03082728385925293, ext_time=0.007840871810913086, train_time=0.0176239013671875
[Epoch 1][Step 72], time=0.030332565307617188, ext_time=0.007880210876464844, train_time=0.01709461212158203
[Epoch 1][Step 73], time=0.030419588088989258, ext_time=0.007903337478637695, train_time=0.017129182815551758
[Epoch 1][Step 74], time=0.03184771537780762, ext_time=0.008126974105834961, train_time=0.018313884735107422
[Epoch 1][Step 75], time=0.03135180473327637, ext_time=0.008106708526611328, train_time=0.017833709716796875
[Epoch 1][Step 76], time=0.030658721923828125, ext_time=0.008234977722167969, train_time=0.01700305938720703
[Epoch 1][Step 77], time=0.030718564987182617, ext_time=0.008053064346313477, train_time=0.01727581024169922
[Epoch 1][Step 78], time=0.03161501884460449, ext_time=0.007925987243652344, train_time=0.018245220184326172
[Epoch 1][Step 79], time=0.030735492706298828, ext_time=0.008147716522216797, train_time=0.01694011688232422
[Epoch 1][Step 80], time=0.030439376831054688, ext_time=0.008016109466552734, train_time=0.017014265060424805
[Epoch 1][Step 81], time=0.030984878540039062, ext_time=0.00806570053100586, train_time=0.01746201515197754
[Epoch 1][Step 82], time=0.03103923797607422, ext_time=0.007935285568237305, train_time=0.017734050750732422
[Epoch 1][Step 83], time=0.030824661254882812, ext_time=0.007968425750732422, train_time=0.01754283905029297
[Epoch 1][Step 84], time=0.030907154083251953, ext_time=0.008064508438110352, train_time=0.017445087432861328
[Epoch 1][Step 85], time=0.03068065643310547, ext_time=0.00775146484375, train_time=0.017487764358520508
[Epoch 1][Step 86], time=0.031056642532348633, ext_time=0.008099079132080078, train_time=0.017365217208862305
[Epoch 1][Step 87], time=0.031519412994384766, ext_time=0.008061408996582031, train_time=0.017945289611816406
[Epoch 1][Step 88], time=0.031011343002319336, ext_time=0.007833003997802734, train_time=0.0176546573638916
[Epoch 1][Step 89], time=0.03096938133239746, ext_time=0.00794839859008789, train_time=0.01749134063720703
[Epoch 1][Step 90], time=0.03099989891052246, ext_time=0.008098125457763672, train_time=0.017342090606689453
[Epoch 1][Step 91], time=0.03177165985107422, ext_time=0.0076329708099365234, train_time=0.018714427947998047
[Epoch 1][Step 92], time=0.03058910369873047, ext_time=0.008141040802001953, train_time=0.016951799392700195
[Epoch 1][Step 93], time=0.030770301818847656, ext_time=0.00783085823059082, train_time=0.017518281936645508
[Epoch 1][Step 94], time=0.030811309814453125, ext_time=0.008307933807373047, train_time=0.017078399658203125
[Epoch 1][Step 95], time=0.030483722686767578, ext_time=0.00792384147644043, train_time=0.017107725143432617
[Epoch 1][Step 96], time=0.031282901763916016, ext_time=0.008258342742919922, train_time=0.017657756805419922
[Epoch 1][Step 97], time=0.03088092803955078, ext_time=0.00796818733215332, train_time=0.017467260360717773
[Epoch 1][Step 98], time=0.030765295028686523, ext_time=0.007923126220703125, train_time=0.017380952835083008
[Epoch 1][Step 99], time=0.030727863311767578, ext_time=0.008090734481811523, train_time=0.017237186431884766
[Epoch 1][Step 100], time=0.03024744987487793, ext_time=0.008043766021728516, train_time=0.0168149471282959
[Epoch 1][Step 101], time=0.030994176864624023, ext_time=0.008051633834838867, train_time=0.01759934425354004
[Epoch 1][Step 102], time=0.03208279609680176, ext_time=0.008265495300292969, train_time=0.01706862449645996
[Epoch 1][Step 103], time=0.03054213523864746, ext_time=0.007792234420776367, train_time=0.01739645004272461
[Epoch 1][Step 104], time=0.030603885650634766, ext_time=0.00804758071899414, train_time=0.017069578170776367
[Epoch 1][Step 105], time=0.030597448348999023, ext_time=0.00766444206237793, train_time=0.017615795135498047
[Epoch 1][Step 106], time=0.030420303344726562, ext_time=0.007951498031616211, train_time=0.017078876495361328
[Epoch 1][Step 107], time=0.03167557716369629, ext_time=0.007967710494995117, train_time=0.01831674575805664
[Epoch 1][Step 108], time=0.030618906021118164, ext_time=0.007884502410888672, train_time=0.017374277114868164
[Epoch 1][Step 109], time=0.030586957931518555, ext_time=0.00783085823059082, train_time=0.017332077026367188
[Epoch 1][Step 110], time=0.03118157386779785, ext_time=0.00813603401184082, train_time=0.01759505271911621
[Epoch 1][Step 111], time=0.030976295471191406, ext_time=0.007895708084106445, train_time=0.017694950103759766
[Epoch 1][Step 112], time=0.030890941619873047, ext_time=0.007811784744262695, train_time=0.017730712890625
[Epoch 1][Step 113], time=0.031089067459106445, ext_time=0.007884979248046875, train_time=0.017823457717895508
[Epoch 1][Step 114], time=0.030892610549926758, ext_time=0.007752180099487305, train_time=0.01775836944580078
[Epoch 1][Step 115], time=0.03045511245727539, ext_time=0.008125782012939453, train_time=0.016916275024414062
[Epoch 1][Step 116], time=0.032488346099853516, ext_time=0.008011341094970703, train_time=0.01905369758605957
[Epoch 1][Step 117], time=0.03137469291687012, ext_time=0.007966041564941406, train_time=0.018041133880615234
[Epoch 1][Step 118], time=0.031016111373901367, ext_time=0.007932186126708984, train_time=0.017684459686279297
[Epoch 1][Step 119], time=0.03070855140686035, ext_time=0.007941007614135742, train_time=0.01740431785583496
[Epoch 1][Step 120], time=0.03159141540527344, ext_time=0.008092403411865234, train_time=0.018125295639038086
[Epoch 1][Step 121], time=0.03028726577758789, ext_time=0.007830619812011719, train_time=0.01708817481994629
[Epoch 1][Step 122], time=0.030553579330444336, ext_time=0.008173942565917969, train_time=0.017014741897583008
[Epoch 1][Step 123], time=0.03043341636657715, ext_time=0.007866621017456055, train_time=0.01720404624938965
[Epoch 1][Step 124], time=0.030850887298583984, ext_time=0.007913351058959961, train_time=0.017515182495117188
[Epoch 1][Step 125], time=0.03025531768798828, ext_time=0.008063316345214844, train_time=0.016797304153442383
[Epoch 1][Step 126], time=0.030900239944458008, ext_time=0.00781869888305664, train_time=0.017702341079711914
[Epoch 1][Step 127], time=0.03035569190979004, ext_time=0.007971048355102539, train_time=0.01703476905822754
[Epoch 1][Step 128], time=0.03131556510925293, ext_time=0.008451223373413086, train_time=0.017395734786987305
[Epoch 1][Step 129], time=0.03081035614013672, ext_time=0.007917165756225586, train_time=0.017466306686401367
[Epoch 1][Step 130], time=0.0310361385345459, ext_time=0.0077669620513916016, train_time=0.017861604690551758
[Epoch 1][Step 131], time=0.030571937561035156, ext_time=0.007860660552978516, train_time=0.01729440689086914
[Epoch 1][Step 132], time=0.030884742736816406, ext_time=0.007910013198852539, train_time=0.01757955551147461
[Epoch 1][Step 133], time=0.03071737289428711, ext_time=0.008272886276245117, train_time=0.017067909240722656
[Epoch 1][Step 134], time=0.0310823917388916, ext_time=0.008070230484008789, train_time=0.01763772964477539
[Epoch 1][Step 135], time=0.030470848083496094, ext_time=0.007964849472045898, train_time=0.01716899871826172
[Epoch 1][Step 136], time=0.030701637268066406, ext_time=0.008119344711303711, train_time=0.017201662063598633
[Epoch 1][Step 137], time=0.030608177185058594, ext_time=0.008113861083984375, train_time=0.017017364501953125
[Epoch 1][Step 138], time=0.0321040153503418, ext_time=0.007841348648071289, train_time=0.018869876861572266
[Epoch 1][Step 139], time=0.03220486640930176, ext_time=0.007991313934326172, train_time=0.018777847290039062
[Epoch 1][Step 140], time=0.03142237663269043, ext_time=0.007858991622924805, train_time=0.018166303634643555
[Epoch 1][Step 141], time=0.03105902671813965, ext_time=0.008091211318969727, train_time=0.017529010772705078
[Epoch 1][Step 142], time=0.03172469139099121, ext_time=0.008050680160522461, train_time=0.018268346786499023
[Epoch 1][Step 143], time=0.030933141708374023, ext_time=0.007963180541992188, train_time=0.017622947692871094
[Epoch 1][Step 144], time=0.030722618103027344, ext_time=0.007864952087402344, train_time=0.017583370208740234
[Epoch 1][Step 145], time=0.031281232833862305, ext_time=0.008309125900268555, train_time=0.017635107040405273
[Epoch 1][Step 146], time=0.03143310546875, ext_time=0.00802159309387207, train_time=0.01802229881286621
[Epoch 1][Step 147], time=0.030212879180908203, ext_time=0.008225679397583008, train_time=0.016653776168823242
[Epoch 1][Step 148], time=0.03074026107788086, ext_time=0.008108854293823242, train_time=0.01720881462097168
[Epoch 1][Step 149], time=0.030792236328125, ext_time=0.007878780364990234, train_time=0.01762533187866211
[Epoch 1][Step 150], time=0.030925989151000977, ext_time=0.0077745914459228516, train_time=0.01777195930480957
[Epoch 1][Step 151], time=0.031023740768432617, ext_time=0.008012771606445312, train_time=0.017677783966064453
[Epoch 1][Step 152], time=0.03148150444030762, ext_time=0.00773167610168457, train_time=0.018505334854125977
[Epoch 1][Step 153], time=0.031024694442749023, ext_time=0.007970094680786133, train_time=0.017663955688476562
[Epoch 1][Step 154], time=0.03089165687561035, ext_time=0.008272647857666016, train_time=0.017283916473388672
[Epoch 1][Step 155], time=0.030872583389282227, ext_time=0.007915973663330078, train_time=0.017636775970458984
[Epoch 1][Step 156], time=0.031636714935302734, ext_time=0.007875919342041016, train_time=0.018410444259643555
[Epoch 1][Step 157], time=0.03095555305480957, ext_time=0.008029937744140625, train_time=0.01740717887878418
[Epoch 1][Step 158], time=0.0305478572845459, ext_time=0.007923603057861328, train_time=0.017306804656982422
[Epoch 1][Step 159], time=0.030805587768554688, ext_time=0.008057594299316406, train_time=0.01733851432800293
[Epoch 1][Step 160], time=0.031090736389160156, ext_time=0.0077936649322509766, train_time=0.017968416213989258
[Epoch 1][Step 161], time=0.030673742294311523, ext_time=0.008094072341918945, train_time=0.017152070999145508
[Epoch 1][Step 162], time=0.03066086769104004, ext_time=0.007943153381347656, train_time=0.01738882064819336
[Epoch 1][Step 163], time=0.030925512313842773, ext_time=0.007773637771606445, train_time=0.01784348487854004
[Epoch 1][Step 164], time=0.030899524688720703, ext_time=0.007688283920288086, train_time=0.017905473709106445
[Epoch 1][Step 165], time=0.030899763107299805, ext_time=0.00797128677368164, train_time=0.017528533935546875
[Epoch 1][Step 166], time=0.030288219451904297, ext_time=0.007970094680786133, train_time=0.017092466354370117
[Epoch 1][Step 167], time=0.030556440353393555, ext_time=0.008147001266479492, train_time=0.01708221435546875
[Epoch 1][Step 168], time=0.030501365661621094, ext_time=0.007918119430541992, train_time=0.01721787452697754
[Epoch 1][Step 169], time=0.030623674392700195, ext_time=0.007990360260009766, train_time=0.017252683639526367
[Epoch 1][Step 170], time=0.030820369720458984, ext_time=0.007904529571533203, train_time=0.017607450485229492
[Epoch 1][Step 171], time=0.03046131134033203, ext_time=0.007977008819580078, train_time=0.017141342163085938
[Epoch 1][Step 172], time=0.030698060989379883, ext_time=0.008135557174682617, train_time=0.017192602157592773
[Epoch 1][Step 173], time=0.030611515045166016, ext_time=0.007995843887329102, train_time=0.017267465591430664
[Epoch 1][Step 174], time=0.03049635887145996, ext_time=0.007975101470947266, train_time=0.017208099365234375
[Epoch 1][Step 175], time=0.030270099639892578, ext_time=0.0078067779541015625, train_time=0.017154932022094727
[Epoch 1][Step 176], time=0.03075432777404785, ext_time=0.008012533187866211, train_time=0.01739668846130371
[Epoch 1][Step 177], time=0.030898332595825195, ext_time=0.007944107055664062, train_time=0.017554759979248047
[Epoch 1][Step 178], time=0.030404090881347656, ext_time=0.007837057113647461, train_time=0.017180442810058594
[Epoch 1][Step 179], time=0.03155112266540527, ext_time=0.007921457290649414, train_time=0.018289566040039062
[Epoch 1][Step 180], time=0.031232833862304688, ext_time=0.008230447769165039, train_time=0.0175626277923584
[Epoch 1][Step 181], time=0.030226707458496094, ext_time=0.008133888244628906, train_time=0.01681685447692871
[Epoch 1][Step 182], time=0.03033161163330078, ext_time=0.008044719696044922, train_time=0.016910076141357422
[Epoch 1][Step 183], time=0.0304410457611084, ext_time=0.007771730422973633, train_time=0.01735973358154297
[Epoch 1][Step 184], time=0.03053903579711914, ext_time=0.008086919784545898, train_time=0.017214536666870117
[Epoch 1][Step 185], time=0.03057122230529785, ext_time=0.008016109466552734, train_time=0.017169475555419922
[Epoch 1][Step 186], time=0.030398130416870117, ext_time=0.007732868194580078, train_time=0.01728987693786621
[Epoch 1][Step 187], time=0.030850887298583984, ext_time=0.008191108703613281, train_time=0.017308950424194336
[Epoch 1][Step 188], time=0.03086709976196289, ext_time=0.008110761642456055, train_time=0.017461299896240234
[Epoch 1][Step 189], time=0.03081822395324707, ext_time=0.008031368255615234, train_time=0.017457962036132812
[Epoch 1][Step 190], time=0.030764341354370117, ext_time=0.007956266403198242, train_time=0.017547130584716797
[Epoch 1][Step 191], time=0.030581951141357422, ext_time=0.008139371871948242, train_time=0.01709914207458496
[Epoch 1][Step 192], time=0.03063488006591797, ext_time=0.007848501205444336, train_time=0.01738286018371582
[Epoch 1][Step 193], time=0.032164812088012695, ext_time=0.008063316345214844, train_time=0.018698930740356445
[Epoch 1][Step 194], time=0.030906200408935547, ext_time=0.007931947708129883, train_time=0.01756429672241211
[Epoch 1][Step 195], time=0.03076338768005371, ext_time=0.008004188537597656, train_time=0.017368316650390625
[Epoch 1][Step 196], time=0.031151294708251953, ext_time=0.008063077926635742, train_time=0.017334699630737305
[Epoch 1][Step 197], time=0.03089284896850586, ext_time=0.008094310760498047, train_time=0.01747918128967285
[Epoch 1][Step 198], time=0.030395984649658203, ext_time=0.008234500885009766, train_time=0.016757965087890625
[Epoch 1][Step 199], time=0.030599594116210938, ext_time=0.008171558380126953, train_time=0.017055511474609375
[Epoch 1][Step 200], time=0.030630111694335938, ext_time=0.007894754409790039, train_time=0.017353296279907227
[Epoch 1][Step 201], time=0.030303478240966797, ext_time=0.007985115051269531, train_time=0.016920804977416992
[Epoch 1][Step 202], time=0.03041529655456543, ext_time=0.007974386215209961, train_time=0.017096519470214844
[Epoch 1][Step 203], time=0.030860424041748047, ext_time=0.007970333099365234, train_time=0.017508268356323242
[Epoch 1][Step 204], time=0.030394792556762695, ext_time=0.007905721664428711, train_time=0.01711249351501465
[Epoch 1][Step 205], time=0.030498743057250977, ext_time=0.007918357849121094, train_time=0.017229318618774414
[Epoch 1][Step 206], time=0.030666589736938477, ext_time=0.008002996444702148, train_time=0.017307043075561523
[Epoch 1][Step 207], time=0.030328989028930664, ext_time=0.007886409759521484, train_time=0.017086029052734375
[Epoch 1][Step 208], time=0.030805587768554688, ext_time=0.007683753967285156, train_time=0.017819881439208984
[Epoch 1][Step 209], time=0.03079056739807129, ext_time=0.008270025253295898, train_time=0.017184019088745117
[Epoch 1][Step 210], time=0.030405282974243164, ext_time=0.008038043975830078, train_time=0.01700425148010254
[Epoch 1][Step 211], time=0.030916690826416016, ext_time=0.008095979690551758, train_time=0.0175933837890625
[Epoch 1][Step 212], time=0.030664920806884766, ext_time=0.007919549942016602, train_time=0.017392396926879883
[Epoch 1][Step 213], time=0.02995014190673828, ext_time=0.007887125015258789, train_time=0.016699790954589844
[Epoch 1][Step 214], time=0.030692100524902344, ext_time=0.007717609405517578, train_time=0.017566680908203125
[Epoch 1][Step 215], time=0.03074336051940918, ext_time=0.007977962493896484, train_time=0.01738882064819336
[Epoch 1][Step 216], time=0.030645370483398438, ext_time=0.007766008377075195, train_time=0.017462730407714844
[Epoch 1][Step 217], time=0.030475854873657227, ext_time=0.007929801940917969, train_time=0.017212629318237305
[Epoch 1][Step 218], time=0.030231237411499023, ext_time=0.008161306381225586, train_time=0.016703128814697266
[Epoch 1][Step 219], time=0.030587196350097656, ext_time=0.007739543914794922, train_time=0.017512083053588867
[Epoch 1][Step 220], time=0.031287431716918945, ext_time=0.00788426399230957, train_time=0.018087148666381836
[Epoch 1][Step 221], time=0.030521869659423828, ext_time=0.008069753646850586, train_time=0.017084121704101562
[Epoch 1][Step 222], time=0.03156566619873047, ext_time=0.007715702056884766, train_time=0.018560171127319336
[Epoch 1][Step 223], time=0.030819177627563477, ext_time=0.008054733276367188, train_time=0.017389774322509766
[Epoch 1][Step 224], time=0.03034067153930664, ext_time=0.007980108261108398, train_time=0.01703810691833496
[Epoch 1][Step 225], time=0.03158164024353027, ext_time=0.007999897003173828, train_time=0.018193960189819336
[Epoch 1][Step 226], time=0.03065180778503418, ext_time=0.007913589477539062, train_time=0.017365455627441406
[Epoch 1][Step 227], time=0.030478954315185547, ext_time=0.0079803466796875, train_time=0.017133712768554688
[Epoch 1][Step 228], time=0.030359268188476562, ext_time=0.008002519607543945, train_time=0.01694941520690918
[Epoch 1][Step 229], time=0.030992507934570312, ext_time=0.00810694694519043, train_time=0.017554044723510742
[Epoch 1][Step 230], time=0.031019210815429688, ext_time=0.008172750473022461, train_time=0.017369985580444336
[Epoch 1][Step 231], time=0.030648231506347656, ext_time=0.008180618286132812, train_time=0.017084598541259766
[Epoch 1][Step 232], time=0.030292034149169922, ext_time=0.008011102676391602, train_time=0.01701045036315918
[Epoch 1][Step 233], time=0.030931949615478516, ext_time=0.007876873016357422, train_time=0.01769876480102539
[Epoch 1][Step 234], time=0.030483484268188477, ext_time=0.00808858871459961, train_time=0.016971826553344727
[Epoch 1][Step 235], time=0.0305938720703125, ext_time=0.007691144943237305, train_time=0.017473459243774414
[Epoch 1][Step 236], time=0.030408859252929688, ext_time=0.00793766975402832, train_time=0.01715683937072754
[Epoch 1][Step 237], time=0.032004594802856445, ext_time=0.008057832717895508, train_time=0.01694512367248535
[Epoch 1][Step 238], time=0.031234264373779297, ext_time=0.008190155029296875, train_time=0.017726421356201172
[Epoch 1][Step 239], time=0.030488014221191406, ext_time=0.0080413818359375, train_time=0.01704263687133789
[Epoch 1][Step 240], time=0.030727386474609375, ext_time=0.008096456527709961, train_time=0.01724982261657715
[Epoch 1][Step 241], time=0.031070232391357422, ext_time=0.007715940475463867, train_time=0.018046140670776367
[Epoch 1][Step 242], time=0.03053879737854004, ext_time=0.00787663459777832, train_time=0.017266035079956055
[Epoch 1][Step 243], time=0.030900955200195312, ext_time=0.008178234100341797, train_time=0.01733088493347168
[Epoch 1][Step 244], time=0.030269145965576172, ext_time=0.00806117057800293, train_time=0.016833066940307617
[Epoch 1][Step 245], time=0.030632734298706055, ext_time=0.008063077926635742, train_time=0.017139911651611328
[Epoch 1][Step 246], time=0.030986785888671875, ext_time=0.007997989654541016, train_time=0.017614364624023438
[Epoch 1][Step 247], time=0.03109288215637207, ext_time=0.008192062377929688, train_time=0.017516374588012695
[Epoch 1][Step 248], time=0.03081226348876953, ext_time=0.008038759231567383, train_time=0.017360210418701172
[Epoch 1][Step 249], time=0.031154870986938477, ext_time=0.008065223693847656, train_time=0.01769089698791504
[Epoch 1], time=7.728678464889526, loss=0.6931472420692444
[Epoch 2][Step 0], time=0.03100299835205078, ext_time=0.007930755615234375, train_time=0.01772141456604004
[Epoch 2][Step 1], time=0.03014516830444336, ext_time=0.007934331893920898, train_time=0.01688098907470703
[Epoch 2][Step 2], time=0.030559778213500977, ext_time=0.008081674575805664, train_time=0.01712942123413086
[Epoch 2][Step 3], time=0.030616283416748047, ext_time=0.007883310317993164, train_time=0.017360448837280273
[Epoch 2][Step 4], time=0.030869722366333008, ext_time=0.007951498031616211, train_time=0.017560958862304688
[Epoch 2][Step 5], time=0.031520843505859375, ext_time=0.00805044174194336, train_time=0.018010377883911133
[Epoch 2][Step 6], time=0.03110504150390625, ext_time=0.007889986038208008, train_time=0.017845630645751953
[Epoch 2][Step 7], time=0.03077101707458496, ext_time=0.007909774780273438, train_time=0.01742243766784668
[Epoch 2][Step 8], time=0.030324697494506836, ext_time=0.008220672607421875, train_time=0.01658463478088379
[Epoch 2][Step 9], time=0.030995845794677734, ext_time=0.00793766975402832, train_time=0.017601490020751953
[Epoch 2][Step 10], time=0.030717849731445312, ext_time=0.008095979690551758, train_time=0.01717686653137207
[Epoch 2][Step 11], time=0.03283524513244629, ext_time=0.007931947708129883, train_time=0.019478321075439453
[Epoch 2][Step 12], time=0.03226137161254883, ext_time=0.008222103118896484, train_time=0.01841139793395996
[Epoch 2][Step 13], time=0.031119108200073242, ext_time=0.008003473281860352, train_time=0.01761651039123535
[Epoch 2][Step 14], time=0.030997276306152344, ext_time=0.0076830387115478516, train_time=0.017949819564819336
[Epoch 2][Step 15], time=0.030895233154296875, ext_time=0.007859945297241211, train_time=0.017618179321289062
[Epoch 2][Step 16], time=0.030710935592651367, ext_time=0.008066177368164062, train_time=0.017239809036254883
[Epoch 2][Step 17], time=0.030306577682495117, ext_time=0.007929086685180664, train_time=0.017055749893188477
[Epoch 2][Step 18], time=0.030407190322875977, ext_time=0.008288145065307617, train_time=0.016659021377563477
[Epoch 2][Step 19], time=0.030629396438598633, ext_time=0.008237600326538086, train_time=0.01700758934020996
[Epoch 2][Step 20], time=0.030817508697509766, ext_time=0.008391141891479492, train_time=0.017107248306274414
[Epoch 2][Step 21], time=0.0308988094329834, ext_time=0.007962465286254883, train_time=0.01754927635192871
[Epoch 2][Step 22], time=0.030694246292114258, ext_time=0.007901668548583984, train_time=0.017399072647094727
[Epoch 2][Step 23], time=0.030667781829833984, ext_time=0.008114814758300781, train_time=0.017180442810058594
[Epoch 2][Step 24], time=0.0302276611328125, ext_time=0.007857561111450195, train_time=0.01705002784729004
[Epoch 2][Step 25], time=0.030333518981933594, ext_time=0.007908344268798828, train_time=0.017093658447265625
[Epoch 2][Step 26], time=0.03040313720703125, ext_time=0.007882118225097656, train_time=0.017102718353271484
[Epoch 2][Step 27], time=0.03098464012145996, ext_time=0.00789499282836914, train_time=0.017630577087402344
[Epoch 2][Step 28], time=0.030495166778564453, ext_time=0.007854461669921875, train_time=0.01726508140563965
[Epoch 2][Step 29], time=0.03092050552368164, ext_time=0.0078582763671875, train_time=0.01772141456604004
[Epoch 2][Step 30], time=0.030309438705444336, ext_time=0.007981061935424805, train_time=0.017000198364257812
[Epoch 2][Step 31], time=0.03080296516418457, ext_time=0.008052587509155273, train_time=0.01740884780883789
[Epoch 2][Step 32], time=0.03247404098510742, ext_time=0.008037090301513672, train_time=0.019126176834106445
[Epoch 2][Step 33], time=0.030919790267944336, ext_time=0.008000850677490234, train_time=0.01755070686340332
[Epoch 2][Step 34], time=0.03076934814453125, ext_time=0.007991552352905273, train_time=0.017491579055786133
[Epoch 2][Step 35], time=0.03080439567565918, ext_time=0.007960319519042969, train_time=0.017528295516967773
[Epoch 2][Step 36], time=0.03302741050720215, ext_time=0.008355140686035156, train_time=0.018797636032104492
[Epoch 2][Step 37], time=0.030462980270385742, ext_time=0.00786733627319336, train_time=0.017197847366333008
[Epoch 2][Step 38], time=0.031037330627441406, ext_time=0.00793313980102539, train_time=0.01777052879333496
[Epoch 2][Step 39], time=0.03189897537231445, ext_time=0.007875204086303711, train_time=0.018546104431152344
[Epoch 2][Step 40], time=0.03137087821960449, ext_time=0.007736921310424805, train_time=0.018263816833496094
[Epoch 2][Step 41], time=0.03046894073486328, ext_time=0.008029699325561523, train_time=0.017084836959838867
[Epoch 2][Step 42], time=0.030284404754638672, ext_time=0.008015871047973633, train_time=0.01698446273803711
[Epoch 2][Step 43], time=0.030670881271362305, ext_time=0.007781505584716797, train_time=0.017549514770507812
[Epoch 2][Step 44], time=0.030692100524902344, ext_time=0.007997274398803711, train_time=0.017345905303955078
[Epoch 2][Step 45], time=0.030536890029907227, ext_time=0.00805211067199707, train_time=0.01720595359802246
[Epoch 2][Step 46], time=0.030987024307250977, ext_time=0.008165836334228516, train_time=0.017439603805541992
[Epoch 2][Step 47], time=0.031307220458984375, ext_time=0.007868051528930664, train_time=0.018042564392089844
[Epoch 2][Step 48], time=0.03016042709350586, ext_time=0.007857561111450195, train_time=0.016961336135864258
[Epoch 2][Step 49], time=0.030303001403808594, ext_time=0.007973670959472656, train_time=0.017073869705200195
[Epoch 2][Step 50], time=0.030671119689941406, ext_time=0.008020877838134766, train_time=0.01726531982421875
[Epoch 2][Step 51], time=0.030530452728271484, ext_time=0.008034229278564453, train_time=0.01717686653137207
[Epoch 2][Step 52], time=0.0310516357421875, ext_time=0.008034467697143555, train_time=0.017660140991210938
[Epoch 2][Step 53], time=0.030997276306152344, ext_time=0.008164405822753906, train_time=0.017465591430664062
[Epoch 2][Step 54], time=0.03223776817321777, ext_time=0.007762432098388672, train_time=0.019124269485473633
[Epoch 2][Step 55], time=0.030815601348876953, ext_time=0.008129358291625977, train_time=0.01730942726135254
[Epoch 2][Step 56], time=0.03055882453918457, ext_time=0.008151769638061523, train_time=0.017054319381713867
[Epoch 2][Step 57], time=0.03067159652709961, ext_time=0.008227109909057617, train_time=0.017071008682250977
[Epoch 2][Step 58], time=0.030292749404907227, ext_time=0.008016586303710938, train_time=0.016931533813476562
[Epoch 2][Step 59], time=0.030541181564331055, ext_time=0.00813603401184082, train_time=0.01701807975769043
[Epoch 2][Step 60], time=0.030480146408081055, ext_time=0.00784158706665039, train_time=0.01733255386352539
[Epoch 2][Step 61], time=0.030857324600219727, ext_time=0.008268594741821289, train_time=0.017152786254882812
[Epoch 2][Step 62], time=0.030376672744750977, ext_time=0.007843255996704102, train_time=0.01708364486694336
[Epoch 2][Step 63], time=0.030266523361206055, ext_time=0.008144140243530273, train_time=0.01680135726928711
[Epoch 2][Step 64], time=0.03158092498779297, ext_time=0.007784366607666016, train_time=0.018477439880371094
[Epoch 2][Step 65], time=0.030969619750976562, ext_time=0.008151054382324219, train_time=0.01741766929626465
[Epoch 2][Step 66], time=0.030841588973999023, ext_time=0.008077144622802734, train_time=0.01740288734436035
[Epoch 2][Step 67], time=0.030563831329345703, ext_time=0.00789022445678711, train_time=0.01731705665588379
[Epoch 2][Step 68], time=0.030703067779541016, ext_time=0.00777745246887207, train_time=0.017590045928955078
[Epoch 2][Step 69], time=0.030270814895629883, ext_time=0.007943868637084961, train_time=0.016991615295410156
[Epoch 2][Step 70], time=0.030979156494140625, ext_time=0.0078887939453125, train_time=0.017795085906982422
[Epoch 2][Step 71], time=0.03065204620361328, ext_time=0.008013010025024414, train_time=0.017331600189208984
[Epoch 2][Step 72], time=0.030622243881225586, ext_time=0.00798654556274414, train_time=0.017304658889770508
[Epoch 2][Step 73], time=0.030629634857177734, ext_time=0.007839441299438477, train_time=0.017435312271118164
[Epoch 2][Step 74], time=0.03080129623413086, ext_time=0.008172273635864258, train_time=0.01724839210510254
[Epoch 2][Step 75], time=0.030541181564331055, ext_time=0.008053064346313477, train_time=0.017179250717163086
[Epoch 2][Step 76], time=0.031035661697387695, ext_time=0.008245468139648438, train_time=0.0173952579498291
[Epoch 2][Step 77], time=0.030594825744628906, ext_time=0.007976770401000977, train_time=0.01734638214111328
[Epoch 2][Step 78], time=0.030833959579467773, ext_time=0.008017778396606445, train_time=0.017435073852539062
[Epoch 2][Step 79], time=0.030793428421020508, ext_time=0.00809478759765625, train_time=0.017389774322509766
[Epoch 2][Step 80], time=0.030354738235473633, ext_time=0.008042335510253906, train_time=0.0169680118560791
[Epoch 2][Step 81], time=0.03109002113342285, ext_time=0.008055686950683594, train_time=0.017623186111450195
[Epoch 2][Step 82], time=0.031054019927978516, ext_time=0.008085012435913086, train_time=0.017687559127807617
[Epoch 2][Step 83], time=0.030304908752441406, ext_time=0.007856369018554688, train_time=0.01711130142211914
[Epoch 2][Step 84], time=0.03155970573425293, ext_time=0.007983922958374023, train_time=0.018172502517700195
[Epoch 2][Step 85], time=0.030776262283325195, ext_time=0.00783228874206543, train_time=0.017630338668823242
[Epoch 2][Step 86], time=0.03137373924255371, ext_time=0.007929325103759766, train_time=0.0181276798248291
[Epoch 2][Step 87], time=0.0302886962890625, ext_time=0.008002042770385742, train_time=0.01695108413696289
[Epoch 2][Step 88], time=0.030426025390625, ext_time=0.007756710052490234, train_time=0.017241954803466797
[Epoch 2][Step 89], time=0.030482769012451172, ext_time=0.007964134216308594, train_time=0.017138242721557617
[Epoch 2][Step 90], time=0.030742883682250977, ext_time=0.008197546005249023, train_time=0.017173290252685547
[Epoch 2][Step 91], time=0.030823230743408203, ext_time=0.00778508186340332, train_time=0.017627716064453125
[Epoch 2][Step 92], time=0.030599594116210938, ext_time=0.008049249649047852, train_time=0.017205476760864258
[Epoch 2][Step 93], time=0.030724525451660156, ext_time=0.007987737655639648, train_time=0.01734614372253418
[Epoch 2][Step 94], time=0.03075885772705078, ext_time=0.008110761642456055, train_time=0.017326831817626953
[Epoch 2][Step 95], time=0.030996322631835938, ext_time=0.00793766975402832, train_time=0.017659664154052734
[Epoch 2][Step 96], time=0.031164169311523438, ext_time=0.008275985717773438, train_time=0.017537832260131836
[Epoch 2][Step 97], time=0.03020477294921875, ext_time=0.007988214492797852, train_time=0.016881227493286133
[Epoch 2][Step 98], time=0.030806779861450195, ext_time=0.007890939712524414, train_time=0.017527103424072266
[Epoch 2][Step 99], time=0.031319618225097656, ext_time=0.007984399795532227, train_time=0.01799154281616211
[Epoch 2][Step 100], time=0.0314028263092041, ext_time=0.007814407348632812, train_time=0.01823568344116211
[Epoch 2][Step 101], time=0.031282663345336914, ext_time=0.008056879043579102, train_time=0.017831802368164062
[Epoch 2][Step 102], time=0.03070545196533203, ext_time=0.008074045181274414, train_time=0.017207860946655273
[Epoch 2][Step 103], time=0.030178546905517578, ext_time=0.007758378982543945, train_time=0.017086505889892578
[Epoch 2][Step 104], time=0.030719757080078125, ext_time=0.007860422134399414, train_time=0.017461538314819336
[Epoch 2][Step 105], time=0.030613422393798828, ext_time=0.007696628570556641, train_time=0.017643451690673828
[Epoch 2][Step 106], time=0.030464887619018555, ext_time=0.00785064697265625, train_time=0.017313003540039062
[Epoch 2][Step 107], time=0.03033161163330078, ext_time=0.008029699325561523, train_time=0.017018556594848633
[Epoch 2][Step 108], time=0.030816316604614258, ext_time=0.007929563522338867, train_time=0.017581462860107422
[Epoch 2][Step 109], time=0.031148195266723633, ext_time=0.008000850677490234, train_time=0.017740964889526367
[Epoch 2][Step 110], time=0.030715465545654297, ext_time=0.00820469856262207, train_time=0.017132043838500977
[Epoch 2][Step 111], time=0.03085637092590332, ext_time=0.007676601409912109, train_time=0.01785135269165039
[Epoch 2][Step 112], time=0.030582666397094727, ext_time=0.007828950881958008, train_time=0.017369985580444336
[Epoch 2][Step 113], time=0.03029942512512207, ext_time=0.007825374603271484, train_time=0.01717519760131836
[Epoch 2][Step 114], time=0.03255200386047363, ext_time=0.00774836540222168, train_time=0.019488811492919922
[Epoch 2][Step 115], time=0.030600309371948242, ext_time=0.007956981658935547, train_time=0.017324209213256836
[Epoch 2][Step 116], time=0.030987262725830078, ext_time=0.007928133010864258, train_time=0.017716407775878906
[Epoch 2][Step 117], time=0.030811786651611328, ext_time=0.0079193115234375, train_time=0.017549991607666016
[Epoch 2][Step 118], time=0.03100752830505371, ext_time=0.00794363021850586, train_time=0.017757892608642578
[Epoch 2][Step 119], time=0.030585527420043945, ext_time=0.008182048797607422, train_time=0.016911983489990234
[Epoch 2][Step 120], time=0.030622243881225586, ext_time=0.008090496063232422, train_time=0.017239809036254883
[Epoch 2][Step 121], time=0.030808448791503906, ext_time=0.007608652114868164, train_time=0.017908096313476562
[Epoch 2][Step 122], time=0.03068089485168457, ext_time=0.007973194122314453, train_time=0.01743173599243164
[Epoch 2][Step 123], time=0.030583620071411133, ext_time=0.007996797561645508, train_time=0.017200946807861328
[Epoch 2][Step 124], time=0.029999494552612305, ext_time=0.007911205291748047, train_time=0.01676011085510254
[Epoch 2][Step 125], time=0.030188322067260742, ext_time=0.007929086685180664, train_time=0.01699233055114746
[Epoch 2][Step 126], time=0.030256986618041992, ext_time=0.007977008819580078, train_time=0.01691436767578125
[Epoch 2][Step 127], time=0.030655622482299805, ext_time=0.008063554763793945, train_time=0.01727461814880371
[Epoch 2][Step 128], time=0.03111577033996582, ext_time=0.008365392684936523, train_time=0.01737380027770996
[Epoch 2][Step 129], time=0.02999114990234375, ext_time=0.007817506790161133, train_time=0.01673102378845215
[Epoch 2][Step 130], time=0.030150651931762695, ext_time=0.007840871810913086, train_time=0.017012834548950195
[Epoch 2][Step 131], time=0.03047466278076172, ext_time=0.007808208465576172, train_time=0.017334938049316406
[Epoch 2][Step 132], time=0.030630111694335938, ext_time=0.007927417755126953, train_time=0.017374515533447266
[Epoch 2][Step 133], time=0.03055119514465332, ext_time=0.008220434188842773, train_time=0.01703166961669922
[Epoch 2][Step 134], time=0.030728816986083984, ext_time=0.008029699325561523, train_time=0.017383098602294922
[Epoch 2][Step 135], time=0.031017065048217773, ext_time=0.007908344268798828, train_time=0.017823457717895508
[Epoch 2][Step 136], time=0.030582666397094727, ext_time=0.008048295974731445, train_time=0.017184019088745117
[Epoch 2][Step 137], time=0.031638383865356445, ext_time=0.008030414581298828, train_time=0.018285036087036133
[Epoch 2][Step 138], time=0.030898332595825195, ext_time=0.007938146591186523, train_time=0.017573833465576172
[Epoch 2][Step 139], time=0.03076481819152832, ext_time=0.007994413375854492, train_time=0.017465591430664062
[Epoch 2][Step 140], time=0.03035426139831543, ext_time=0.007869243621826172, train_time=0.017147064208984375
[Epoch 2][Step 141], time=0.03064560890197754, ext_time=0.008020877838134766, train_time=0.01726245880126953
[Epoch 2][Step 142], time=0.03178715705871582, ext_time=0.008156776428222656, train_time=0.018256664276123047
[Epoch 2][Step 143], time=0.030461549758911133, ext_time=0.008015632629394531, train_time=0.01706695556640625
[Epoch 2][Step 144], time=0.030396699905395508, ext_time=0.007990121841430664, train_time=0.017108678817749023
[Epoch 2][Step 145], time=0.030655622482299805, ext_time=0.008156061172485352, train_time=0.017171382904052734
[Epoch 2][Step 146], time=0.031720638275146484, ext_time=0.007992029190063477, train_time=0.018410444259643555
[Epoch 2][Step 147], time=0.031206607818603516, ext_time=0.008139610290527344, train_time=0.017220020294189453
[Epoch 2][Step 148], time=0.03052520751953125, ext_time=0.008142709732055664, train_time=0.017037630081176758
[Epoch 2][Step 149], time=0.030627727508544922, ext_time=0.007959365844726562, train_time=0.01734137535095215
[Epoch 2][Step 150], time=0.03049302101135254, ext_time=0.00775146484375, train_time=0.017410993576049805
[Epoch 2][Step 151], time=0.03078460693359375, ext_time=0.007915496826171875, train_time=0.017586708068847656
[Epoch 2][Step 152], time=0.030901432037353516, ext_time=0.007953405380249023, train_time=0.017577648162841797
[Epoch 2][Step 153], time=0.03046560287475586, ext_time=0.007976770401000977, train_time=0.017060518264770508
[Epoch 2][Step 154], time=0.031148910522460938, ext_time=0.008239984512329102, train_time=0.017589330673217773
[Epoch 2][Step 155], time=0.030610084533691406, ext_time=0.008142948150634766, train_time=0.01705312728881836
[Epoch 2][Step 156], time=0.031086206436157227, ext_time=0.007887601852416992, train_time=0.017875194549560547
[Epoch 2][Step 157], time=0.03218889236450195, ext_time=0.007932424545288086, train_time=0.017282962799072266
[Epoch 2][Step 158], time=0.0308682918548584, ext_time=0.007730007171630859, train_time=0.017939090728759766
[Epoch 2][Step 159], time=0.03066253662109375, ext_time=0.008013010025024414, train_time=0.0172882080078125
[Epoch 2][Step 160], time=0.03041863441467285, ext_time=0.007984638214111328, train_time=0.017076969146728516
[Epoch 2][Step 161], time=0.030982017517089844, ext_time=0.008025169372558594, train_time=0.01763629913330078
[Epoch 2][Step 162], time=0.0311124324798584, ext_time=0.008014202117919922, train_time=0.017733335494995117
[Epoch 2][Step 163], time=0.030591964721679688, ext_time=0.007795095443725586, train_time=0.01745295524597168
[Epoch 2][Step 164], time=0.030539274215698242, ext_time=0.007819414138793945, train_time=0.017416715621948242
[Epoch 2][Step 165], time=0.030535221099853516, ext_time=0.0076982975006103516, train_time=0.017529964447021484
[Epoch 2][Step 166], time=0.030423879623413086, ext_time=0.008063793182373047, train_time=0.01712632179260254
[Epoch 2][Step 167], time=0.03226518630981445, ext_time=0.008002042770385742, train_time=0.018975496292114258
[Epoch 2][Step 168], time=0.03045797348022461, ext_time=0.008056163787841797, train_time=0.016932249069213867
[Epoch 2][Step 169], time=0.0305783748626709, ext_time=0.0078105926513671875, train_time=0.017423152923583984
[Epoch 2][Step 170], time=0.0307769775390625, ext_time=0.00800943374633789, train_time=0.017436504364013672
[Epoch 2][Step 171], time=0.03045201301574707, ext_time=0.007984638214111328, train_time=0.017168045043945312
[Epoch 2][Step 172], time=0.03038787841796875, ext_time=0.008234977722167969, train_time=0.016804933547973633
[Epoch 2][Step 173], time=0.030369043350219727, ext_time=0.008052349090576172, train_time=0.016973257064819336
[Epoch 2][Step 174], time=0.03056788444519043, ext_time=0.008049726486206055, train_time=0.017204999923706055
[Epoch 2][Step 175], time=0.030400991439819336, ext_time=0.007899999618530273, train_time=0.017142534255981445
[Epoch 2][Step 176], time=0.031221866607666016, ext_time=0.007976770401000977, train_time=0.01783585548400879
[Epoch 2][Step 177], time=0.030725479125976562, ext_time=0.007902383804321289, train_time=0.017484664916992188
[Epoch 2][Step 178], time=0.030609846115112305, ext_time=0.007741451263427734, train_time=0.017572879791259766
[Epoch 2][Step 179], time=0.030483245849609375, ext_time=0.008075714111328125, train_time=0.01708054542541504
[Epoch 2][Step 180], time=0.030666112899780273, ext_time=0.007995367050170898, train_time=0.01728057861328125
[Epoch 2][Step 181], time=0.030130863189697266, ext_time=0.008141279220581055, train_time=0.01674962043762207
[Epoch 2][Step 182], time=0.030783653259277344, ext_time=0.008064746856689453, train_time=0.01733708381652832
[Epoch 2][Step 183], time=0.03027820587158203, ext_time=0.007790803909301758, train_time=0.01716446876525879
[Epoch 2][Step 184], time=0.03114628791809082, ext_time=0.008030891418457031, train_time=0.017847537994384766
[Epoch 2][Step 185], time=0.03090691566467285, ext_time=0.007761478424072266, train_time=0.017745256423950195
[Epoch 2][Step 186], time=0.030702590942382812, ext_time=0.007950067520141602, train_time=0.017284870147705078
[Epoch 2][Step 187], time=0.03064584732055664, ext_time=0.008084535598754883, train_time=0.017232418060302734
[Epoch 2][Step 188], time=0.03076910972595215, ext_time=0.00793004035949707, train_time=0.017481088638305664
[Epoch 2][Step 189], time=0.030308008193969727, ext_time=0.007975339889526367, train_time=0.017034053802490234
[Epoch 2][Step 190], time=0.030608177185058594, ext_time=0.008081912994384766, train_time=0.01723623275756836
[Epoch 2][Step 191], time=0.030568599700927734, ext_time=0.008153200149536133, train_time=0.017069578170776367
[Epoch 2][Step 192], time=0.030677080154418945, ext_time=0.007685422897338867, train_time=0.017705440521240234
[Epoch 2][Step 193], time=0.030908823013305664, ext_time=0.00819540023803711, train_time=0.017398834228515625
[Epoch 2][Step 194], time=0.030730724334716797, ext_time=0.008015632629394531, train_time=0.01732611656188965
[Epoch 2][Step 195], time=0.030692100524902344, ext_time=0.008068561553955078, train_time=0.01723504066467285
[Epoch 2][Step 196], time=0.03052234649658203, ext_time=0.007879018783569336, train_time=0.017244338989257812
[Epoch 2][Step 197], time=0.031508445739746094, ext_time=0.008012533187866211, train_time=0.018149375915527344
[Epoch 2][Step 198], time=0.03074932098388672, ext_time=0.008194684982299805, train_time=0.01715254783630371
[Epoch 2][Step 199], time=0.030891895294189453, ext_time=0.008092403411865234, train_time=0.017513036727905273
[Epoch 2][Step 200], time=0.03081369400024414, ext_time=0.007885456085205078, train_time=0.01755666732788086
[Epoch 2][Step 201], time=0.030238866806030273, ext_time=0.008059978485107422, train_time=0.016780376434326172
[Epoch 2][Step 202], time=0.031308889389038086, ext_time=0.008250236511230469, train_time=0.017622709274291992
[Epoch 2][Step 203], time=0.031081199645996094, ext_time=0.008219480514526367, train_time=0.01735520362854004
[Epoch 2][Step 204], time=0.0307924747467041, ext_time=0.00787496566772461, train_time=0.017546892166137695
[Epoch 2][Step 205], time=0.031487226486206055, ext_time=0.007935047149658203, train_time=0.018169164657592773
[Epoch 2][Step 206], time=0.031023502349853516, ext_time=0.008182525634765625, train_time=0.01735711097717285
[Epoch 2][Step 207], time=0.03037285804748535, ext_time=0.007747650146484375, train_time=0.017215251922607422
[Epoch 2][Step 208], time=0.03114938735961914, ext_time=0.007843732833862305, train_time=0.017900705337524414
[Epoch 2][Step 209], time=0.030768156051635742, ext_time=0.008429288864135742, train_time=0.016918182373046875
[Epoch 2][Step 210], time=0.030605792999267578, ext_time=0.008029460906982422, train_time=0.017172574996948242
[Epoch 2][Step 211], time=0.03061985969543457, ext_time=0.008201360702514648, train_time=0.01702594757080078
[Epoch 2][Step 212], time=0.03479194641113281, ext_time=0.007951974868774414, train_time=0.021388769149780273
[Epoch 2][Step 213], time=0.03147435188293457, ext_time=0.007899045944213867, train_time=0.018138885498046875
[Epoch 2][Step 214], time=0.031571388244628906, ext_time=0.007699728012084961, train_time=0.01845240592956543
[Epoch 2][Step 215], time=0.03191733360290527, ext_time=0.008128643035888672, train_time=0.018398523330688477
[Epoch 2][Step 216], time=0.03106093406677246, ext_time=0.007830619812011719, train_time=0.01787567138671875
[Epoch 2][Step 217], time=0.031255245208740234, ext_time=0.007960081100463867, train_time=0.017925739288330078
[Epoch 2][Step 218], time=0.031668901443481445, ext_time=0.008143901824951172, train_time=0.018196821212768555
[Epoch 2][Step 219], time=0.030992746353149414, ext_time=0.008093595504760742, train_time=0.017483234405517578
[Epoch 2][Step 220], time=0.03087472915649414, ext_time=0.008182048797607422, train_time=0.017285585403442383
[Epoch 2][Step 221], time=0.031047582626342773, ext_time=0.00788259506225586, train_time=0.01783919334411621
[Epoch 2][Step 222], time=0.03129172325134277, ext_time=0.007814645767211914, train_time=0.01813983917236328
[Epoch 2][Step 223], time=0.03182363510131836, ext_time=0.008025646209716797, train_time=0.018436193466186523
[Epoch 2][Step 224], time=0.03152918815612793, ext_time=0.008116960525512695, train_time=0.018052339553833008
[Epoch 2][Step 225], time=0.0314023494720459, ext_time=0.007893085479736328, train_time=0.018180131912231445
[Epoch 2][Step 226], time=0.031024456024169922, ext_time=0.007817506790161133, train_time=0.017870187759399414
[Epoch 2][Step 227], time=0.03145742416381836, ext_time=0.008036375045776367, train_time=0.018007278442382812
[Epoch 2][Step 228], time=0.031531333923339844, ext_time=0.008149385452270508, train_time=0.017939090728759766
[Epoch 2][Step 229], time=0.03152894973754883, ext_time=0.00811004638671875, train_time=0.018086671829223633
[Epoch 2][Step 230], time=0.03114914894104004, ext_time=0.008017301559448242, train_time=0.017755985260009766
[Epoch 2][Step 231], time=0.03129410743713379, ext_time=0.008076667785644531, train_time=0.017907381057739258
[Epoch 2][Step 232], time=0.03089451789855957, ext_time=0.007884979248046875, train_time=0.017707109451293945
[Epoch 2][Step 233], time=0.03158903121948242, ext_time=0.008062124252319336, train_time=0.018170595169067383
[Epoch 2][Step 234], time=0.03151750564575195, ext_time=0.008128881454467773, train_time=0.018030881881713867
[Epoch 2][Step 235], time=0.03120875358581543, ext_time=0.007811069488525391, train_time=0.017988204956054688
[Epoch 2][Step 236], time=0.030962467193603516, ext_time=0.007918596267700195, train_time=0.017697572708129883
[Epoch 2][Step 237], time=0.03117084503173828, ext_time=0.008257865905761719, train_time=0.01750469207763672
[Epoch 2][Step 238], time=0.030901670455932617, ext_time=0.008222579956054688, train_time=0.017400264739990234
[Epoch 2][Step 239], time=0.03142666816711426, ext_time=0.007948875427246094, train_time=0.018068313598632812
[Epoch 2][Step 240], time=0.03124094009399414, ext_time=0.007975101470947266, train_time=0.017833471298217773
[Epoch 2][Step 241], time=0.03121471405029297, ext_time=0.00796651840209961, train_time=0.01785588264465332
[Epoch 2][Step 242], time=0.03112483024597168, ext_time=0.008035898208618164, train_time=0.01770949363708496
[Epoch 2][Step 243], time=0.03241229057312012, ext_time=0.008155107498168945, train_time=0.018927574157714844
[Epoch 2][Step 244], time=0.0314488410949707, ext_time=0.007933616638183594, train_time=0.018162012100219727
[Epoch 2][Step 245], time=0.0313723087310791, ext_time=0.007907629013061523, train_time=0.018102645874023438
[Epoch 2][Step 246], time=0.031045198440551758, ext_time=0.00783848762512207, train_time=0.017853975296020508
[Epoch 2][Step 247], time=0.0305938720703125, ext_time=0.008114099502563477, train_time=0.017110586166381836
[Epoch 2][Step 248], time=0.03193473815917969, ext_time=0.007950782775878906, train_time=0.01862049102783203
[Epoch 2][Step 249], time=0.0319972038269043, ext_time=0.008090972900390625, train_time=0.018579721450805664
[Epoch 2], time=7.740047216415405, loss=0.6931472420692444
[Epoch 3][Step 0], time=0.03112339973449707, ext_time=0.007759809494018555, train_time=0.01801323890686035
[Epoch 3][Step 1], time=0.031546831130981445, ext_time=0.008030414581298828, train_time=0.01812911033630371
[Epoch 3][Step 2], time=0.03180527687072754, ext_time=0.008165121078491211, train_time=0.018231630325317383
[Epoch 3][Step 3], time=0.0320131778717041, ext_time=0.007858514785766602, train_time=0.01877617835998535
[Epoch 3][Step 4], time=0.03126692771911621, ext_time=0.007841110229492188, train_time=0.018155574798583984
[Epoch 3][Step 5], time=0.03102421760559082, ext_time=0.007870912551879883, train_time=0.01778125762939453
[Epoch 3][Step 6], time=0.0315861701965332, ext_time=0.007807493209838867, train_time=0.018480300903320312
[Epoch 3][Step 7], time=0.031264305114746094, ext_time=0.008008480072021484, train_time=0.017888307571411133
[Epoch 3][Step 8], time=0.031133651733398438, ext_time=0.008086442947387695, train_time=0.01759481430053711
[Epoch 3][Step 9], time=0.03158235549926758, ext_time=0.007915258407592773, train_time=0.018317222595214844
[Epoch 3][Step 10], time=0.031000137329101562, ext_time=0.007967233657836914, train_time=0.01760578155517578
[Epoch 3][Step 11], time=0.031487464904785156, ext_time=0.008060455322265625, train_time=0.018001556396484375
[Epoch 3][Step 12], time=0.03127574920654297, ext_time=0.00801396369934082, train_time=0.0178678035736084
[Epoch 3][Step 13], time=0.03133225440979004, ext_time=0.008103609085083008, train_time=0.01787400245666504
[Epoch 3][Step 14], time=0.03144025802612305, ext_time=0.0078012943267822266, train_time=0.018242359161376953
[Epoch 3][Step 15], time=0.030948162078857422, ext_time=0.007950305938720703, train_time=0.017557144165039062
[Epoch 3][Step 16], time=0.03173351287841797, ext_time=0.007922887802124023, train_time=0.018417835235595703
[Epoch 3][Step 17], time=0.030774831771850586, ext_time=0.0077190399169921875, train_time=0.017767667770385742
[Epoch 3][Step 18], time=0.03100895881652832, ext_time=0.008098840713500977, train_time=0.01747274398803711
[Epoch 3][Step 19], time=0.031453847885131836, ext_time=0.008234500885009766, train_time=0.017810344696044922
[Epoch 3][Step 20], time=0.031395673751831055, ext_time=0.008404970169067383, train_time=0.017751455307006836
[Epoch 3][Step 21], time=0.031313419342041016, ext_time=0.00804591178894043, train_time=0.017876625061035156
[Epoch 3][Step 22], time=0.03138375282287598, ext_time=0.008011341094970703, train_time=0.017914533615112305
[Epoch 3][Step 23], time=0.03194093704223633, ext_time=0.008015871047973633, train_time=0.018559932708740234
[Epoch 3][Step 24], time=0.03103923797607422, ext_time=0.007781267166137695, train_time=0.017929553985595703
[Epoch 3][Step 25], time=0.030929088592529297, ext_time=0.007837533950805664, train_time=0.017748355865478516
[Epoch 3][Step 26], time=0.031371116638183594, ext_time=0.007911920547485352, train_time=0.018082380294799805
[Epoch 3][Step 27], time=0.03183865547180176, ext_time=0.008183717727661133, train_time=0.018222808837890625
[Epoch 3][Step 28], time=0.03163266181945801, ext_time=0.007842779159545898, train_time=0.018264293670654297
[Epoch 3][Step 29], time=0.03275561332702637, ext_time=0.007758140563964844, train_time=0.01956796646118164
[Epoch 3][Step 30], time=0.03207254409790039, ext_time=0.008019447326660156, train_time=0.018718481063842773
[Epoch 3][Step 31], time=0.03196406364440918, ext_time=0.007965564727783203, train_time=0.018614768981933594
[Epoch 3][Step 32], time=0.03150057792663574, ext_time=0.007968664169311523, train_time=0.018190383911132812
[Epoch 3][Step 33], time=0.03120112419128418, ext_time=0.008119344711303711, train_time=0.017636775970458984
[Epoch 3][Step 34], time=0.03168773651123047, ext_time=0.007975339889526367, train_time=0.018370866775512695
[Epoch 3][Step 35], time=0.03191328048706055, ext_time=0.008028745651245117, train_time=0.018576383590698242
[Epoch 3][Step 36], time=0.03213930130004883, ext_time=0.007999181747436523, train_time=0.01876688003540039
[Epoch 3][Step 37], time=0.030691146850585938, ext_time=0.007927179336547852, train_time=0.017357826232910156
[Epoch 3][Step 38], time=0.031016826629638672, ext_time=0.007807731628417969, train_time=0.017871856689453125
[Epoch 3][Step 39], time=0.032086849212646484, ext_time=0.00802159309387207, train_time=0.01856088638305664
[Epoch 3][Step 40], time=0.031069040298461914, ext_time=0.007699012756347656, train_time=0.018039464950561523
[Epoch 3][Step 41], time=0.031059980392456055, ext_time=0.008040428161621094, train_time=0.017714500427246094
[Epoch 3][Step 42], time=0.03095388412475586, ext_time=0.0079803466796875, train_time=0.01763606071472168
[Epoch 3][Step 43], time=0.03141188621520996, ext_time=0.007802724838256836, train_time=0.018280029296875
[Epoch 3][Step 44], time=0.031748294830322266, ext_time=0.007858991622924805, train_time=0.018557310104370117
[Epoch 3][Step 45], time=0.03102254867553711, ext_time=0.008195161819458008, train_time=0.01751112937927246
[Epoch 3][Step 46], time=0.031030654907226562, ext_time=0.008046150207519531, train_time=0.017630815505981445
[Epoch 3][Step 47], time=0.03179574012756348, ext_time=0.007911443710327148, train_time=0.01849079132080078
[Epoch 3][Step 48], time=0.031218528747558594, ext_time=0.007953882217407227, train_time=0.017935752868652344
[Epoch 3][Step 49], time=0.03283858299255371, ext_time=0.008064031600952148, train_time=0.019490718841552734
[Epoch 3][Step 50], time=0.031632184982299805, ext_time=0.007882356643676758, train_time=0.01837635040283203
[Epoch 3][Step 51], time=0.03129100799560547, ext_time=0.007811784744262695, train_time=0.018199682235717773
[Epoch 3][Step 52], time=0.03215909004211426, ext_time=0.007927179336547852, train_time=0.018915176391601562
[Epoch 3][Step 53], time=0.03166007995605469, ext_time=0.007973909378051758, train_time=0.018274784088134766
[Epoch 3][Step 54], time=0.031093597412109375, ext_time=0.0077762603759765625, train_time=0.01797795295715332
[Epoch 3][Step 55], time=0.031015396118164062, ext_time=0.008186101913452148, train_time=0.017427682876586914
[Epoch 3][Step 56], time=0.030785322189331055, ext_time=0.007906675338745117, train_time=0.01751875877380371
[Epoch 3][Step 57], time=0.030980587005615234, ext_time=0.008034467697143555, train_time=0.017602920532226562
[Epoch 3][Step 58], time=0.03143429756164551, ext_time=0.007983684539794922, train_time=0.018074750900268555
[Epoch 3][Step 59], time=0.03190326690673828, ext_time=0.008035659790039062, train_time=0.01850748062133789
[Epoch 3][Step 60], time=0.030451536178588867, ext_time=0.007794380187988281, train_time=0.01723933219909668
[Epoch 3][Step 61], time=0.030974388122558594, ext_time=0.008051156997680664, train_time=0.017502546310424805
[Epoch 3][Step 62], time=0.03142046928405762, ext_time=0.0077784061431884766, train_time=0.018212318420410156
[Epoch 3][Step 63], time=0.03133893013000488, ext_time=0.008142709732055664, train_time=0.017899274826049805
[Epoch 3][Step 64], time=0.031180620193481445, ext_time=0.007851839065551758, train_time=0.01799154281616211
[Epoch 3][Step 65], time=0.031856536865234375, ext_time=0.008296728134155273, train_time=0.01806473731994629
[Epoch 3][Step 66], time=0.030956745147705078, ext_time=0.00816488265991211, train_time=0.01710033416748047
[Epoch 3][Step 67], time=0.031154155731201172, ext_time=0.007877349853515625, train_time=0.017879486083984375
[Epoch 3][Step 68], time=0.031579017639160156, ext_time=0.007886409759521484, train_time=0.018261432647705078
[Epoch 3][Step 69], time=0.03290271759033203, ext_time=0.008043289184570312, train_time=0.019451379776000977
[Epoch 3][Step 70], time=0.03105616569519043, ext_time=0.007805347442626953, train_time=0.01791095733642578
[Epoch 3][Step 71], time=0.030664920806884766, ext_time=0.007929563522338867, train_time=0.01723480224609375
[Epoch 3][Step 72], time=0.030428647994995117, ext_time=0.0077359676361083984, train_time=0.01741313934326172
[Epoch 3][Step 73], time=0.029926776885986328, ext_time=0.007886886596679688, train_time=0.01666426658630371
[Epoch 3][Step 74], time=0.030835390090942383, ext_time=0.008264780044555664, train_time=0.017153263092041016
[Epoch 3][Step 75], time=0.030268192291259766, ext_time=0.008018732070922852, train_time=0.016822099685668945
[Epoch 3][Step 76], time=0.031189441680908203, ext_time=0.008325815200805664, train_time=0.01736927032470703
[Epoch 3][Step 77], time=0.032154083251953125, ext_time=0.007991313934326172, train_time=0.017147541046142578
[Epoch 3][Step 78], time=0.03110361099243164, ext_time=0.008071660995483398, train_time=0.017479419708251953
[Epoch 3][Step 79], time=0.031125307083129883, ext_time=0.00817418098449707, train_time=0.017475366592407227
[Epoch 3][Step 80], time=0.03069448471069336, ext_time=0.008228540420532227, train_time=0.016947031021118164
[Epoch 3][Step 81], time=0.030800342559814453, ext_time=0.00796055793762207, train_time=0.017296314239501953
[Epoch 3][Step 82], time=0.031022310256958008, ext_time=0.007988214492797852, train_time=0.017589092254638672
[Epoch 3][Step 83], time=0.031087160110473633, ext_time=0.00797891616821289, train_time=0.017634868621826172
[Epoch 3][Step 84], time=0.03078293800354004, ext_time=0.008118629455566406, train_time=0.017125368118286133
[Epoch 3][Step 85], time=0.030318737030029297, ext_time=0.007801055908203125, train_time=0.017058134078979492
[Epoch 3][Step 86], time=0.030817508697509766, ext_time=0.008151531219482422, train_time=0.017238855361938477
[Epoch 3][Step 87], time=0.030417680740356445, ext_time=0.007861137390136719, train_time=0.017239093780517578
[Epoch 3][Step 88], time=0.03071427345275879, ext_time=0.007796287536621094, train_time=0.017497777938842773
[Epoch 3][Step 89], time=0.030460596084594727, ext_time=0.0077359676361083984, train_time=0.017379283905029297
[Epoch 3][Step 90], time=0.030178308486938477, ext_time=0.008064031600952148, train_time=0.016674041748046875
[Epoch 3][Step 91], time=0.031148195266723633, ext_time=0.007874727249145508, train_time=0.017965316772460938
[Epoch 3][Step 92], time=0.030550718307495117, ext_time=0.008091926574707031, train_time=0.01711249351501465
[Epoch 3][Step 93], time=0.03199410438537598, ext_time=0.007898330688476562, train_time=0.018680572509765625
[Epoch 3][Step 94], time=0.0314936637878418, ext_time=0.008247613906860352, train_time=0.01705145835876465
[Epoch 3][Step 95], time=0.0315251350402832, ext_time=0.007800579071044922, train_time=0.01843881607055664
[Epoch 3][Step 96], time=0.031854867935180664, ext_time=0.00819087028503418, train_time=0.01839280128479004
[Epoch 3][Step 97], time=0.031252384185791016, ext_time=0.007933378219604492, train_time=0.01795172691345215
[Epoch 3][Step 98], time=0.03010106086730957, ext_time=0.007956266403198242, train_time=0.016790390014648438
[Epoch 3][Step 99], time=0.03053569793701172, ext_time=0.008051872253417969, train_time=0.017155885696411133
[Epoch 3][Step 100], time=0.030194759368896484, ext_time=0.008079290390014648, train_time=0.016660690307617188
[Epoch 3][Step 101], time=0.030661821365356445, ext_time=0.008017539978027344, train_time=0.01723337173461914
[Epoch 3][Step 102], time=0.03101062774658203, ext_time=0.008181095123291016, train_time=0.01736307144165039
[Epoch 3][Step 103], time=0.0300595760345459, ext_time=0.007640361785888672, train_time=0.017067909240722656
[Epoch 3][Step 104], time=0.0307767391204834, ext_time=0.007710933685302734, train_time=0.01769399642944336
[Epoch 3][Step 105], time=0.030463218688964844, ext_time=0.007694721221923828, train_time=0.017394304275512695
[Epoch 3][Step 106], time=0.030378341674804688, ext_time=0.008090019226074219, train_time=0.016925573348999023
[Epoch 3][Step 107], time=0.030494213104248047, ext_time=0.008001565933227539, train_time=0.017131805419921875
[Epoch 3][Step 108], time=0.03042292594909668, ext_time=0.007818222045898438, train_time=0.017292022705078125
[Epoch 3][Step 109], time=0.030766010284423828, ext_time=0.008168220520019531, train_time=0.0171964168548584
[Epoch 3][Step 110], time=0.030783891677856445, ext_time=0.008042335510253906, train_time=0.017426729202270508
[Epoch 3][Step 111], time=0.03020000457763672, ext_time=0.0076715946197509766, train_time=0.0171663761138916
[Epoch 3][Step 112], time=0.030465364456176758, ext_time=0.007829904556274414, train_time=0.01727914810180664
[Epoch 3][Step 113], time=0.030628442764282227, ext_time=0.007907390594482422, train_time=0.017368078231811523
[Epoch 3][Step 114], time=0.031041622161865234, ext_time=0.007655620574951172, train_time=0.018125295639038086
[Epoch 3][Step 115], time=0.030170202255249023, ext_time=0.007955789566040039, train_time=0.016842126846313477
[Epoch 3][Step 116], time=0.03066253662109375, ext_time=0.00811314582824707, train_time=0.017165422439575195
[Epoch 3][Step 117], time=0.03200793266296387, ext_time=0.007984161376953125, train_time=0.018633604049682617
[Epoch 3][Step 118], time=0.03387641906738281, ext_time=0.007950305938720703, train_time=0.020487070083618164
[Epoch 3][Step 119], time=0.03501486778259277, ext_time=0.008209705352783203, train_time=0.020044803619384766
[Epoch 3][Step 120], time=0.03302955627441406, ext_time=0.008034944534301758, train_time=0.018953800201416016
[Epoch 3][Step 121], time=0.0334775447845459, ext_time=0.007668018341064453, train_time=0.020429372787475586
[Epoch 3][Step 122], time=0.03188323974609375, ext_time=0.008235454559326172, train_time=0.01825094223022461
[Epoch 3][Step 123], time=0.030428171157836914, ext_time=0.008008003234863281, train_time=0.017036914825439453
[Epoch 3][Step 124], time=0.031111478805541992, ext_time=0.007964372634887695, train_time=0.01770758628845215
[Epoch 3][Step 125], time=0.03061389923095703, ext_time=0.007940292358398438, train_time=0.0171356201171875
[Epoch 3][Step 126], time=0.03027653694152832, ext_time=0.007844924926757812, train_time=0.01706409454345703
[Epoch 3][Step 127], time=0.031105518341064453, ext_time=0.008064746856689453, train_time=0.01766490936279297
[Epoch 3][Step 128], time=0.03087472915649414, ext_time=0.008201360702514648, train_time=0.017277002334594727
[Epoch 3][Step 129], time=0.03113579750061035, ext_time=0.007889032363891602, train_time=0.017846107482910156
[Epoch 3][Step 130], time=0.03059530258178711, ext_time=0.00792551040649414, train_time=0.016321420669555664
[Epoch 3][Step 131], time=0.030458450317382812, ext_time=0.007964611053466797, train_time=0.01709604263305664
[Epoch 3][Step 132], time=0.030750274658203125, ext_time=0.007989168167114258, train_time=0.017357587814331055
[Epoch 3][Step 133], time=0.030549049377441406, ext_time=0.008262157440185547, train_time=0.01688361167907715
[Epoch 3][Step 134], time=0.030658483505249023, ext_time=0.00804281234741211, train_time=0.017189741134643555
[Epoch 3][Step 135], time=0.03121662139892578, ext_time=0.008023977279663086, train_time=0.01787877082824707
[Epoch 3][Step 136], time=0.03123164176940918, ext_time=0.007978200912475586, train_time=0.017911434173583984
[Epoch 3][Step 137], time=0.030610322952270508, ext_time=0.008073806762695312, train_time=0.017138957977294922
[Epoch 3][Step 138], time=0.03080439567565918, ext_time=0.007893085479736328, train_time=0.01756596565246582
[Epoch 3][Step 139], time=0.030561208724975586, ext_time=0.008114814758300781, train_time=0.01700592041015625
[Epoch 3][Step 140], time=0.030498981475830078, ext_time=0.007969141006469727, train_time=0.017086505889892578
[Epoch 3][Step 141], time=0.030574560165405273, ext_time=0.007999420166015625, train_time=0.017222166061401367
[Epoch 3][Step 142], time=0.03471493721008301, ext_time=0.008101940155029297, train_time=0.0212094783782959
[Epoch 3][Step 143], time=0.031526803970336914, ext_time=0.0078089237213134766, train_time=0.018299579620361328
[Epoch 3][Step 144], time=0.030476808547973633, ext_time=0.007923126220703125, train_time=0.01724100112915039
[Epoch 3][Step 145], time=0.030707359313964844, ext_time=0.008260488510131836, train_time=0.017071962356567383
[Epoch 3][Step 146], time=0.03099989891052246, ext_time=0.0078084468841552734, train_time=0.017945051193237305
[Epoch 3][Step 147], time=0.030521631240844727, ext_time=0.008121013641357422, train_time=0.017090797424316406
[Epoch 3][Step 148], time=0.03058314323425293, ext_time=0.007994413375854492, train_time=0.0172579288482666
[Epoch 3][Step 149], time=0.03064584732055664, ext_time=0.007980585098266602, train_time=0.01734471321105957
[Epoch 3][Step 150], time=0.03068828582763672, ext_time=0.0076885223388671875, train_time=0.017699003219604492
[Epoch 3][Step 151], time=0.030890464782714844, ext_time=0.008008718490600586, train_time=0.01754927635192871
[Epoch 3][Step 152], time=0.030491113662719727, ext_time=0.007940530776977539, train_time=0.017270326614379883
[Epoch 3][Step 153], time=0.030893564224243164, ext_time=0.008109092712402344, train_time=0.01738715171813965
[Epoch 3][Step 154], time=0.030729293823242188, ext_time=0.008324146270751953, train_time=0.01703476905822754
[Epoch 3][Step 155], time=0.030600786209106445, ext_time=0.007982730865478516, train_time=0.01725172996520996
[Epoch 3][Step 156], time=0.030562162399291992, ext_time=0.007786989212036133, train_time=0.01747441291809082
[Epoch 3][Step 157], time=0.03075098991394043, ext_time=0.00795745849609375, train_time=0.017498493194580078
[Epoch 3][Step 158], time=0.031017541885375977, ext_time=0.0077822208404541016, train_time=0.017971038818359375
[Epoch 3][Step 159], time=0.031572580337524414, ext_time=0.008062362670898438, train_time=0.018152713775634766
[Epoch 3][Step 160], time=0.030634164810180664, ext_time=0.007871150970458984, train_time=0.01733708381652832
[Epoch 3][Step 161], time=0.030623912811279297, ext_time=0.008112430572509766, train_time=0.017135143280029297
[Epoch 3][Step 162], time=0.03066110610961914, ext_time=0.007972240447998047, train_time=0.017347335815429688
[Epoch 3][Step 163], time=0.030926227569580078, ext_time=0.007824897766113281, train_time=0.01768803596496582
[Epoch 3][Step 164], time=0.02997565269470215, ext_time=0.0077838897705078125, train_time=0.016751527786254883
[Epoch 3][Step 165], time=0.030632972717285156, ext_time=0.00789499282836914, train_time=0.017319440841674805
[Epoch 3][Step 166], time=0.03021836280822754, ext_time=0.007919073104858398, train_time=0.01702117919921875
[Epoch 3][Step 167], time=0.03101658821105957, ext_time=0.008180618286132812, train_time=0.01742243766784668
[Epoch 3][Step 168], time=0.03060460090637207, ext_time=0.007940530776977539, train_time=0.017281055450439453
[Epoch 3][Step 169], time=0.030544042587280273, ext_time=0.007862329483032227, train_time=0.017280101776123047
[Epoch 3][Step 170], time=0.030528545379638672, ext_time=0.008078813552856445, train_time=0.017151594161987305
[Epoch 3][Step 171], time=0.035207509994506836, ext_time=0.008097410202026367, train_time=0.02174234390258789
[Epoch 3][Step 172], time=0.03290271759033203, ext_time=0.008266687393188477, train_time=0.019203901290893555
[Epoch 3][Step 173], time=0.03148794174194336, ext_time=0.008229255676269531, train_time=0.017851591110229492
[Epoch 3][Step 174], time=0.030626296997070312, ext_time=0.008030891418457031, train_time=0.01728510856628418
[Epoch 3][Step 175], time=0.030310392379760742, ext_time=0.007978439331054688, train_time=0.016943931579589844
[Epoch 3][Step 176], time=0.030380725860595703, ext_time=0.007881879806518555, train_time=0.017189741134643555
[Epoch 3][Step 177], time=0.03063201904296875, ext_time=0.007902145385742188, train_time=0.017395734786987305
[Epoch 3][Step 178], time=0.030736923217773438, ext_time=0.008014202117919922, train_time=0.01739358901977539
[Epoch 3][Step 179], time=0.030695438385009766, ext_time=0.007927179336547852, train_time=0.0174105167388916
[Epoch 3][Step 180], time=0.030905723571777344, ext_time=0.007882118225097656, train_time=0.01764702796936035
[Epoch 3][Step 181], time=0.030425548553466797, ext_time=0.008211135864257812, train_time=0.016919374465942383
[Epoch 3][Step 182], time=0.03060293197631836, ext_time=0.008057117462158203, train_time=0.017198801040649414
[Epoch 3][Step 183], time=0.031447649002075195, ext_time=0.007919073104858398, train_time=0.018192291259765625
[Epoch 3][Step 184], time=0.030520200729370117, ext_time=0.008298397064208984, train_time=0.016773462295532227
[Epoch 3][Step 185], time=0.031065940856933594, ext_time=0.007843971252441406, train_time=0.01783919334411621
[Epoch 3][Step 186], time=0.030385732650756836, ext_time=0.007878303527832031, train_time=0.017135143280029297
[Epoch 3][Step 187], time=0.03054523468017578, ext_time=0.008170843124389648, train_time=0.017041444778442383
[Epoch 3][Step 188], time=0.03047776222229004, ext_time=0.008080005645751953, train_time=0.0170137882232666
[Epoch 3][Step 189], time=0.030502796173095703, ext_time=0.008026599884033203, train_time=0.017182350158691406
[Epoch 3][Step 190], time=0.030389785766601562, ext_time=0.008001089096069336, train_time=0.017055034637451172
[Epoch 3][Step 191], time=0.03038930892944336, ext_time=0.008087158203125, train_time=0.0168914794921875
[Epoch 3][Step 192], time=0.030294418334960938, ext_time=0.007946968078613281, train_time=0.016934633255004883
[Epoch 3][Step 193], time=0.03069138526916504, ext_time=0.008079290390014648, train_time=0.01720142364501953
[Epoch 3][Step 194], time=0.030565977096557617, ext_time=0.007931709289550781, train_time=0.017282962799072266
[Epoch 3][Step 195], time=0.030918359756469727, ext_time=0.008075714111328125, train_time=0.017430782318115234
[Epoch 3][Step 196], time=0.03038644790649414, ext_time=0.008057594299316406, train_time=0.017017126083374023
[Epoch 3][Step 197], time=0.030165672302246094, ext_time=0.008033514022827148, train_time=0.016825199127197266
[Epoch 3][Step 198], time=0.03118133544921875, ext_time=0.008278369903564453, train_time=0.0175936222076416
[Epoch 3][Step 199], time=0.030605792999267578, ext_time=0.008018732070922852, train_time=0.017308950424194336
[Epoch 3][Step 200], time=0.030709266662597656, ext_time=0.007977962493896484, train_time=0.017327547073364258
[Epoch 3][Step 201], time=0.03092813491821289, ext_time=0.00818181037902832, train_time=0.017359495162963867
[Epoch 3][Step 202], time=0.032785892486572266, ext_time=0.008045196533203125, train_time=0.019422531127929688
[Epoch 3][Step 203], time=0.03143167495727539, ext_time=0.008040666580200195, train_time=0.017701387405395508
[Epoch 3][Step 204], time=0.03156542778015137, ext_time=0.007872819900512695, train_time=0.018346548080444336
[Epoch 3][Step 205], time=0.030933141708374023, ext_time=0.0079803466796875, train_time=0.017551898956298828
[Epoch 3][Step 206], time=0.030847787857055664, ext_time=0.00809931755065918, train_time=0.017342567443847656
[Epoch 3][Step 207], time=0.030484914779663086, ext_time=0.008030176162719727, train_time=0.017025470733642578
[Epoch 3][Step 208], time=0.030690431594848633, ext_time=0.007795095443725586, train_time=0.01755237579345703
[Epoch 3][Step 209], time=0.03058910369873047, ext_time=0.008215665817260742, train_time=0.017032623291015625
[Epoch 3][Step 210], time=0.03028106689453125, ext_time=0.007949113845825195, train_time=0.01702284812927246
[Epoch 3][Step 211], time=0.030521631240844727, ext_time=0.008197546005249023, train_time=0.01704573631286621
[Epoch 3][Step 212], time=0.030270814895629883, ext_time=0.00785207748413086, train_time=0.017026901245117188
[Epoch 3][Step 213], time=0.030529022216796875, ext_time=0.007880926132202148, train_time=0.017275094985961914
[Epoch 3][Step 214], time=0.030948400497436523, ext_time=0.007803916931152344, train_time=0.017729520797729492
[Epoch 3][Step 215], time=0.030675649642944336, ext_time=0.00812077522277832, train_time=0.017087936401367188
[Epoch 3][Step 216], time=0.03073859214782715, ext_time=0.00779414176940918, train_time=0.01762843132019043
[Epoch 3][Step 217], time=0.03102254867553711, ext_time=0.007991790771484375, train_time=0.017697572708129883
[Epoch 3][Step 218], time=0.030504465103149414, ext_time=0.008032560348510742, train_time=0.017125368118286133
[Epoch 3][Step 219], time=0.0305635929107666, ext_time=0.007834196090698242, train_time=0.017330408096313477
[Epoch 3][Step 220], time=0.030718088150024414, ext_time=0.008217573165893555, train_time=0.017159461975097656
[Epoch 3][Step 221], time=0.031028270721435547, ext_time=0.007901906967163086, train_time=0.017838001251220703
[Epoch 3][Step 222], time=0.03050827980041504, ext_time=0.007942438125610352, train_time=0.017164230346679688
[Epoch 3][Step 223], time=0.030805587768554688, ext_time=0.008135557174682617, train_time=0.017111778259277344
[Epoch 3][Step 224], time=0.030833721160888672, ext_time=0.007999181747436523, train_time=0.017509937286376953
[Epoch 3][Step 225], time=0.030689001083374023, ext_time=0.007986068725585938, train_time=0.017375469207763672
[Epoch 3][Step 226], time=0.030800342559814453, ext_time=0.007911443710327148, train_time=0.01749873161315918
[Epoch 3][Step 227], time=0.030837535858154297, ext_time=0.007964134216308594, train_time=0.017520904541015625
[Epoch 3][Step 228], time=0.030783653259277344, ext_time=0.007860660552978516, train_time=0.01751089096069336
[Epoch 3][Step 229], time=0.030930280685424805, ext_time=0.008140087127685547, train_time=0.017452239990234375
[Epoch 3][Step 230], time=0.03100109100341797, ext_time=0.008058786392211914, train_time=0.01760268211364746
[Epoch 3][Step 231], time=0.03071737289428711, ext_time=0.008062362670898438, train_time=0.017345190048217773
[Epoch 3][Step 232], time=0.030542373657226562, ext_time=0.008123159408569336, train_time=0.01712203025817871
[Epoch 3][Step 233], time=0.030345916748046875, ext_time=0.008046388626098633, train_time=0.016914844512939453
[Epoch 3][Step 234], time=0.03052210807800293, ext_time=0.008156538009643555, train_time=0.01695108413696289
[Epoch 3][Step 235], time=0.030353784561157227, ext_time=0.007716655731201172, train_time=0.017217159271240234
[Epoch 3][Step 236], time=0.03059864044189453, ext_time=0.008008241653442383, train_time=0.01729750633239746
[Epoch 3][Step 237], time=0.03048992156982422, ext_time=0.008096694946289062, train_time=0.01704573631286621
[Epoch 3][Step 238], time=0.03040003776550293, ext_time=0.008254528045654297, train_time=0.016849756240844727
[Epoch 3][Step 239], time=0.030706405639648438, ext_time=0.007905006408691406, train_time=0.017444372177124023
[Epoch 3][Step 240], time=0.030383586883544922, ext_time=0.00794839859008789, train_time=0.017065763473510742
[Epoch 3][Step 241], time=0.03098130226135254, ext_time=0.007806539535522461, train_time=0.017913103103637695
[Epoch 3][Step 242], time=0.03072977066040039, ext_time=0.007906913757324219, train_time=0.017453670501708984
[Epoch 3][Step 243], time=0.030585765838623047, ext_time=0.008020877838134766, train_time=0.017175912857055664
[Epoch 3][Step 244], time=0.030930757522583008, ext_time=0.007901430130004883, train_time=0.01769256591796875
[Epoch 3][Step 245], time=0.030545473098754883, ext_time=0.007941722869873047, train_time=0.017256975173950195
[Epoch 3][Step 246], time=0.03012394905090332, ext_time=0.0077667236328125, train_time=0.01699376106262207
[Epoch 3][Step 247], time=0.03230023384094238, ext_time=0.008132457733154297, train_time=0.01708078384399414
[Epoch 3][Step 248], time=0.030633211135864258, ext_time=0.008032798767089844, train_time=0.017139911651611328
[Epoch 3][Step 249], time=0.03059983253479004, ext_time=0.008059263229370117, train_time=0.017129182815551758
[Epoch 3], time=7.776955604553223, loss=0.6931472420692444
    [Step(average) Profiler Level 1 E3 S999]
        L1  sample           0.005399 | send           0.000000
        L1  recv             0.000000 | copy           0.007947 | convert time 0.000000 | train  0.017587
        L1  feature nbytes  479.31 MB | label nbytes 0.00 Bytes
        L1  id nbytes      0.00 Bytes | graph nbytes 0.00 Bytes
        L1  miss nbytes      84.80 MB | remote nbytes  295.43 MB
        L1  num nodes               0 | num samples           0
        L1  seq duration     0.000000 | refresh duration   0.000000
    [Step(average) Profiler Level 2 E3 S999]
        L2  shuffle     0.000000 | core sample  0.000000 | id remap        0.000000
        L2  graph copy  0.000000 | id copy      0.000000 | cache feat copy 0.007947
        L2  last layer sample time 0.000000 | size 0.000000
    [Step(average) Profiler Level 3 E3 S999]
        L3  khop sample coo  0.000000 | khop sort coo      0.000000 | khop count edge     0.000000 | khop compact edge 0.000000
        L3  walk sample coo  0.000000 | walk topk total    0.000000 | walk topk step1     0.000000 | walk topk step2   0.000000
        L3  walk topk step3  0.000000 | walk topk step4    0.000000 | walk topk step5     0.000000
        L3  walk topk step6  0.000000 | walk topk step7    0.000000
        L3  remap unique     0.000000 | remap populate     0.000000 | remap mapnode       0.000000 | remap mapedge     0.000000
        L3  cache get_index  0.000691 | cache copy_index   0.000000 | cache extract_miss  0.000000
        L3  cache copy_miss  0.000000 | cache combine_miss 0.007210 | cache combine cache 0.000278 | cache combine remote 0.002610
        L3  label extract  0.000000
    [Profiler Level Percentiles E3 S999]
        p50.00_tail_logl2featcopy=0.007945
        p90.00_tail_logl2featcopy=0.008138
        p95.00_tail_logl2featcopy=0.008187
        p99.00_tail_logl2featcopy=0.008308
        p99.90_tail_logl2featcopy=0.010865
[CUDA] cuda: usage: 14.62 GB
worker 1 running with pid=31103
loading train edge idx from disk
loading train edge idx from disk done
tensor([ 367470406, 3158702471, 3196913887,  537616058, 2622541626, 2707306334,
        2288750783,  341639546, 2394912536,   38094375,  701084300, 1665128055,
        3225579545,  811343571,  534157746,  726851972, 1000854521, 1061370191,
         597404666,  526478766,  499672205, 1382980281, 1363464091,  971316959,
        1643305663, 1559556869,  792051811, 2593715952, 2627476216,  869058904,
        1279512108,  281028249, 2848334841, 1142277951, 1624797255, 1682408139,
         514723102,  756902533, 1190696744, 1515340461,  396873136, 3079813016,
         574876927,   31156367,  833957351, 1664434120,  774080817, 2850247945,
         655998496,  888602410,  350570870,  850355735,   69778231,  638128676,
        1443388341, 1479712286, 2858804367,  550628163,  198023098, 2583590303,
        2518492873,    2593795, 2722269746,  659106604, 1369497066,  461650496,
         645516367, 3053389785,  148119355,  792250187, 1401047469, 1545651011,
        1827797263, 1275030316, 2075895474, 2919804301, 2493902937,  112768749,
          11701078,  726712463,  404737965,  786261376,  934911988,  757583227,
        1135493038, 3162165660, 1144120843, 2861906075,  226440368, 1866677628,
         329488287,   67449549, 1840253021,  973854642,  422444545, 3025516425,
         133597469,  981523193, 2348166713,  306896793])
Rank=1, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.008925, per step: 0.000036
presamping
presamping takes 14.062094688415527
worker 2 running with pid=31104
loading train edge idx from disk
loading train edge idx from disk done
tensor([ 367470406, 3158702471, 3196913887,  537616058, 2622541626, 2707306334,
        2288750783,  341639546, 2394912536,   38094375,  701084300, 1665128055,
        3225579545,  811343571,  534157746,  726851972, 1000854521, 1061370191,
         597404666,  526478766,  499672205, 1382980281, 1363464091,  971316959,
        1643305663, 1559556869,  792051811, 2593715952, 2627476216,  869058904,
        1279512108,  281028249, 2848334841, 1142277951, 1624797255, 1682408139,
         514723102,  756902533, 1190696744, 1515340461,  396873136, 3079813016,
         574876927,   31156367,  833957351, 1664434120,  774080817, 2850247945,
         655998496,  888602410,  350570870,  850355735,   69778231,  638128676,
        1443388341, 1479712286, 2858804367,  550628163,  198023098, 2583590303,
        2518492873,    2593795, 2722269746,  659106604, 1369497066,  461650496,
         645516367, 3053389785,  148119355,  792250187, 1401047469, 1545651011,
        1827797263, 1275030316, 2075895474, 2919804301, 2493902937,  112768749,
          11701078,  726712463,  404737965,  786261376,  934911988,  757583227,
        1135493038, 3162165660, 1144120843, 2861906075,  226440368, 1866677628,
         329488287,   67449549, 1840253021,  973854642,  422444545, 3025516425,
         133597469,  981523193, 2348166713,  306896793])
Rank=2, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.007784, per step: 0.000031
presamping
presamping takes 14.201148271560669
worker 3 running with pid=31105
loading train edge idx from disk
loading train edge idx from disk done
tensor([ 367470406, 3158702471, 3196913887,  537616058, 2622541626, 2707306334,
        2288750783,  341639546, 2394912536,   38094375,  701084300, 1665128055,
        3225579545,  811343571,  534157746,  726851972, 1000854521, 1061370191,
         597404666,  526478766,  499672205, 1382980281, 1363464091,  971316959,
        1643305663, 1559556869,  792051811, 2593715952, 2627476216,  869058904,
        1279512108,  281028249, 2848334841, 1142277951, 1624797255, 1682408139,
         514723102,  756902533, 1190696744, 1515340461,  396873136, 3079813016,
         574876927,   31156367,  833957351, 1664434120,  774080817, 2850247945,
         655998496,  888602410,  350570870,  850355735,   69778231,  638128676,
        1443388341, 1479712286, 2858804367,  550628163,  198023098, 2583590303,
        2518492873,    2593795, 2722269746,  659106604, 1369497066,  461650496,
         645516367, 3053389785,  148119355,  792250187, 1401047469, 1545651011,
        1827797263, 1275030316, 2075895474, 2919804301, 2493902937,  112768749,
          11701078,  726712463,  404737965,  786261376,  934911988,  757583227,
        1135493038, 3162165660, 1144120843, 2861906075,  226440368, 1866677628,
         329488287,   67449549, 1840253021,  973854642,  422444545, 3025516425,
         133597469,  981523193, 2348166713,  306896793])
Rank=3, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.007607, per step: 0.000030
presamping
presamping takes 14.996476650238037
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   69381 KB |    1005 MB |    3632 GB |    3632 GB |
|       from large pool |   57674 KB |     992 MB |    3590 GB |    3590 GB |
|       from small pool |   11707 KB |      21 MB |      41 GB |      41 GB |
|---------------------------------------------------------------------------|
| Active memory         |   69381 KB |    1005 MB |    3632 GB |    3632 GB |
|       from large pool |   57674 KB |     992 MB |    3590 GB |    3590 GB |
|       from small pool |   11707 KB |      21 MB |      41 GB |      41 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    3754 MB |    3754 MB |    3754 MB |       0 B  |
|       from large pool |    3722 MB |    3722 MB |    3722 MB |       0 B  |
|       from small pool |      32 MB |      32 MB |      32 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  534778 KB |    1420 MB |    2908 GB |    2908 GB |
|       from large pool |  523957 KB |    1409 MB |    2864 GB |    2864 GB |
|       from small pool |   10821 KB |      17 MB |      44 GB |      44 GB |
|---------------------------------------------------------------------------|
| Allocations           |      69    |      99    |  320297    |  320228    |
|       from large pool |      13    |      24    |   94512    |   94499    |
|       from small pool |      56    |      79    |  225785    |  225729    |
|---------------------------------------------------------------------------|
| Active allocs         |      69    |      99    |  320297    |  320228    |
|       from large pool |      13    |      24    |   94512    |   94499    |
|       from small pool |      56    |      79    |  225785    |  225729    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      32    |      32    |      32    |       0    |
|       from large pool |      16    |      16    |      16    |       0    |
|       from small pool |      16    |      16    |      16    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      34    |      52    |  120311    |  120277    |
|       from large pool |       8    |      18    |   50269    |   50261    |
|       from small pool |      26    |      40    |   70042    |   70016    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[TRAIN_TIME] train time is 32.138746 seconds
[EPOCH_TIME] 8.034686 seconds, maybe large due to not enough epoch skipped.
[EPOCH_TIME] 7.758631 seconds

