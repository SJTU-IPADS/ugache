succeed=True
[CUDA] cuda: usage: 5.50 GB
0 :  {link #0 : 1}, {link #1 : 2}, {link #2 : 3},
1 :  {link #0 : 2}, {link #1 : 3}, {link #2 : 0},
2 :  {link #0 : 3}, {link #1 : 0}, {link #2 : 1},
3 :  {link #0 : 0}, {link #1 : 1}, {link #2 : 2},
0 :  {link #0 : 1}, {link #1 : 2}, {link #2 : 3},
1 :  {link #0 : 2}, {link #1 : 3}, {link #2 : 0},
2 :  {link #0 : 3}, {link #1 : 0}, {link #2 : 1},
3 :  {link #0 : 0}, {link #1 : 1}, {link #2 : 2},
0 :  {link #0 : 1}, {link #1 : 2}, {link #2 : 3},
1 :  {link #0 : 2}, {link #1 : 3}, {link #2 : 0},
2 :  {link #0 : 3}, {link #1 : 0}, {link #2 : 1},
3 :  {link #0 : 0}, {link #1 : 1}, {link #2 : 2},
0 : local 80, cpu 0 {link #0 : g1 0}, {link #1 : g2 0}, {link #2 : g3 0},
1 : local 80, cpu 0 {link #0 : g2 0}, {link #1 : g3 0}, {link #2 : g0 0},
2 : local 80, cpu 0 {link #0 : g3 0}, {link #1 : g0 0}, {link #2 : g1 0},
3 : local 80, cpu 0 {link #0 : g0 0}, {link #1 : g1 0}, {link #2 : g2 0},
0 : local 80, cpu 0 {link #0 : g1 0}, {link #1 : g2 0}, {link #2 : g3 0},
1 : local 80, cpu 0 {link #0 : g2 0}, {link #1 : g3 0}, {link #2 : g0 0},
2 : local 80, cpu 0 {link #0 : g3 0}, {link #1 : g0 0}, {link #2 : g1 0},
3 : local 80, cpu 0 {link #0 : g0 0}, {link #1 : g1 0}, {link #2 : g2 0},
0 : local 80, cpu 0 {link #0 : g1 0}, {link #1 : g2 0}, {link #2 : g3 0},
1 : local 80, cpu 0 {link #0 : g2 0}, {link #1 : g3 0}, {link #2 : g0 0},
2 : local 80, cpu 0 {link #0 : g3 0}, {link #1 : g0 0}, {link #2 : g1 0},
3 : local 80, cpu 0 {link #0 : g0 0}, {link #1 : g1 0}, {link #2 : g2 0},
0 :  {link #0 : 1}, {link #1 : 2}, {link #2 : 3},
1 :  {link #0 : 2}, {link #1 : 3}, {link #2 : 0},
2 :  {link #0 : 3}, {link #1 : 0}, {link #2 : 1},
3 :  {link #0 : 0}, {link #1 : 1}, {link #2 : 2},
0 : local 80, cpu 0 {link #0 : g1 0}, {link #1 : g2 0}, {link #2 : g3 0},
1 : local 80, cpu 0 {link #0 : g2 0}, {link #1 : g3 0}, {link #2 : g0 0},
2 : local 80, cpu 0 {link #0 : g3 0}, {link #1 : g0 0}, {link #2 : g1 0},
3 : local 80, cpu 0 {link #0 : g0 0}, {link #1 : g1 0}, {link #2 : g2 0},
coll_cache:optimal_rep_storage=0.08
coll_cache:optimal_part_storage=0
coll_cache:optimal_cpu_storage=0.92
coll_cache:optimal_local_storage=0.08
coll_cache:optimal_remote_storage=0
coll_cache:optimal_local_rate=0.450581
coll_cache:optimal_remote_rate=0
coll_cache:optimal_cpu_rate=0.549419
z=31692.3
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=4605878272
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=4605878272
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=4605878272
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=4605878272
worker 0 running with pid=47450
config:eval_tsp="2023-08-06 18:55:21"
config:num_worker=4
config:num_intra_size=4
config:root_dir=/datasets_gnn/wholegraph
config:graph_name=ogbn-papers100M
config:epochs=4
config:batchsize=500
config:skip_epoch=2
config:local_step=250
config:presc_epoch=2
config:neighbors=15,10,5
config:hiddensize=256
config:num_layer=3
config:model=gcn
config:framework=dgl
config:dataloaderworkers=0
config:dropout=0.5
config:weight_decay=0.0005
config:lr=0.003
config:use_nccl=False
config:use_amp=True
config:use_collcache=True
config:cache_percentage=0.08
config:cache_policy=rep
config:omp_thread_num=40
config:unsupervised=True
config:classnum=172
config:global_barrier=<multiprocessing.synchronize.Barrier object at 0x7f85f5852820>
config:worker_id=0
creating_intra_node_communicator root=0, local_size=4, world_size=4
loading train edge idx from disk
loading train edge idx from disk done
tensor([ 367470406, 3158702471, 3196913887,  537616058, 2622541626, 2707306334,
        2288750783,  341639546, 2394912536,   38094375,  701084300, 1665128055,
        3225579545,  811343571,  534157746,  726851972, 1000854521, 1061370191,
         597404666,  526478766,  499672205, 1382980281, 1363464091,  971316959,
        1643305663, 1559556869,  792051811, 2593715952, 2627476216,  869058904,
        1279512108,  281028249, 2848334841, 1142277951, 1624797255, 1682408139,
         514723102,  756902533, 1190696744, 1515340461,  396873136, 3079813016,
         574876927,   31156367,  833957351, 1664434120,  774080817, 2850247945,
         655998496,  888602410,  350570870,  850355735,   69778231,  638128676,
        1443388341, 1479712286, 2858804367,  550628163,  198023098, 2583590303,
        2518492873,    2593795, 2722269746,  659106604, 1369497066,  461650496,
         645516367, 3053389785,  148119355,  792250187, 1401047469, 1545651011,
        1827797263, 1275030316, 2075895474, 2919804301, 2493902937,  112768749,
          11701078,  726712463,  404737965,  786261376,  934911988,  757583227,
        1135493038, 3162165660, 1144120843, 2861906075,  226440368, 1866677628,
         329488287,   67449549, 1840253021,  973854642,  422444545, 3025516425,
         133597469,  981523193, 2348166713,  306896793])
Rank=0, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.007288, per step: 0.000029
epoch=4 total_steps=1000
presamping
presamping takes 14.652222633361816
start training...
[Epoch 0][Step 0], time=1.1535873413085938, ext_time=0.02609872817993164, train_time=1.1190340518951416
[Epoch 0][Step 1], time=0.05316519737243652, ext_time=0.023744821548461914, train_time=0.0230405330657959
[Epoch 0][Step 2], time=0.04683351516723633, ext_time=0.023576021194458008, train_time=0.017434120178222656
[Epoch 0][Step 3], time=0.04660367965698242, ext_time=0.02350616455078125, train_time=0.0175473690032959
[Epoch 0][Step 4], time=0.04620480537414551, ext_time=0.022893667221069336, train_time=0.017762422561645508
[Epoch 0][Step 5], time=0.04884195327758789, ext_time=0.02375173568725586, train_time=0.019455432891845703
[Epoch 0][Step 6], time=0.04653143882751465, ext_time=0.023182153701782227, train_time=0.017828941345214844
[Epoch 0][Step 7], time=0.04694199562072754, ext_time=0.023578643798828125, train_time=0.017849206924438477
[Epoch 0][Step 8], time=0.04656982421875, ext_time=0.0232391357421875, train_time=0.017792463302612305
[Epoch 0][Step 9], time=0.04709649085998535, ext_time=0.023495912551879883, train_time=0.01801776885986328
[Epoch 0][Step 10], time=0.048305511474609375, ext_time=0.023688077926635742, train_time=0.019049644470214844
[Epoch 0][Step 11], time=0.04913783073425293, ext_time=0.023517847061157227, train_time=0.017910242080688477
[Epoch 0][Step 12], time=0.04852128028869629, ext_time=0.024053096771240234, train_time=0.01880645751953125
[Epoch 0][Step 13], time=0.04692506790161133, ext_time=0.022948026657104492, train_time=0.01851344108581543
[Epoch 0][Step 14], time=0.04708456993103027, ext_time=0.023377180099487305, train_time=0.018129587173461914
[Epoch 0][Step 15], time=0.04942750930786133, ext_time=0.02384781837463379, train_time=0.01984882354736328
[Epoch 0][Step 16], time=0.04701542854309082, ext_time=0.023459434509277344, train_time=0.017941713333129883
[Epoch 0][Step 17], time=0.04607868194580078, ext_time=0.022869586944580078, train_time=0.017740249633789062
[Epoch 0][Step 18], time=0.0476076602935791, ext_time=0.02393507957458496, train_time=0.018005847930908203
[Epoch 0][Step 19], time=0.04710817337036133, ext_time=0.02373981475830078, train_time=0.017818689346313477
[Epoch 0][Step 20], time=0.04756450653076172, ext_time=0.023669004440307617, train_time=0.018433570861816406
[Epoch 0][Step 21], time=0.047022104263305664, ext_time=0.023659706115722656, train_time=0.017807960510253906
[Epoch 0][Step 22], time=0.04723405838012695, ext_time=0.023807287216186523, train_time=0.017862319946289062
[Epoch 0][Step 23], time=0.04724240303039551, ext_time=0.023834228515625, train_time=0.017848730087280273
[Epoch 0][Step 24], time=0.04700350761413574, ext_time=0.023285388946533203, train_time=0.01818680763244629
[Epoch 0][Step 25], time=0.04742693901062012, ext_time=0.023554325103759766, train_time=0.018147945404052734
[Epoch 0][Step 26], time=0.046690940856933594, ext_time=0.023247241973876953, train_time=0.017890214920043945
[Epoch 0][Step 27], time=0.047625064849853516, ext_time=0.02385091781616211, train_time=0.01809096336364746
[Epoch 0][Step 28], time=0.04702949523925781, ext_time=0.023585081100463867, train_time=0.017864227294921875
[Epoch 0][Step 29], time=0.04685330390930176, ext_time=0.0231173038482666, train_time=0.018225431442260742
[Epoch 0][Step 30], time=0.04768514633178711, ext_time=0.023781538009643555, train_time=0.018277406692504883
[Epoch 0][Step 31], time=0.048656463623046875, ext_time=0.023676633834838867, train_time=0.01928114891052246
[Epoch 0][Step 32], time=0.04712414741516113, ext_time=0.023708820343017578, train_time=0.01790785789489746
[Epoch 0][Step 33], time=0.0478212833404541, ext_time=0.024011611938476562, train_time=0.0180661678314209
[Epoch 0][Step 34], time=0.04677224159240723, ext_time=0.023405790328979492, train_time=0.017782926559448242
[Epoch 0][Step 35], time=0.04640531539916992, ext_time=0.023008108139038086, train_time=0.0179750919342041
[Epoch 0][Step 36], time=0.04674077033996582, ext_time=0.023386240005493164, train_time=0.017749547958374023
[Epoch 0][Step 37], time=0.046822309494018555, ext_time=0.023393630981445312, train_time=0.017841577529907227
[Epoch 0][Step 38], time=0.047655582427978516, ext_time=0.023570775985717773, train_time=0.01858663558959961
[Epoch 0][Step 39], time=0.047597408294677734, ext_time=0.023906469345092773, train_time=0.017964839935302734
[Epoch 0][Step 40], time=0.0470883846282959, ext_time=0.02330756187438965, train_time=0.018222332000732422
[Epoch 0][Step 41], time=0.04788684844970703, ext_time=0.023542165756225586, train_time=0.018439531326293945
[Epoch 0][Step 42], time=0.046843528747558594, ext_time=0.02337956428527832, train_time=0.017838478088378906
[Epoch 0][Step 43], time=0.0468752384185791, ext_time=0.02346014976501465, train_time=0.01785445213317871
[Epoch 0][Step 44], time=0.046895742416381836, ext_time=0.023554325103759766, train_time=0.0178070068359375
[Epoch 0][Step 45], time=0.04678702354431152, ext_time=0.023524999618530273, train_time=0.01774883270263672
[Epoch 0][Step 46], time=0.04758477210998535, ext_time=0.024039268493652344, train_time=0.017944812774658203
[Epoch 0][Step 47], time=0.04807019233703613, ext_time=0.023701190948486328, train_time=0.01873183250427246
[Epoch 0][Step 48], time=0.04689645767211914, ext_time=0.023529767990112305, train_time=0.017819881439208984
[Epoch 0][Step 49], time=0.046677350997924805, ext_time=0.023370742797851562, train_time=0.017782211303710938
[Epoch 0][Step 50], time=0.04684185981750488, ext_time=0.023508310317993164, train_time=0.017783403396606445
[Epoch 0][Step 51], time=0.046499013900756836, ext_time=0.023158788681030273, train_time=0.017847299575805664
[Epoch 0][Step 52], time=0.04685163497924805, ext_time=0.02349066734313965, train_time=0.01779341697692871
[Epoch 0][Step 53], time=0.04702019691467285, ext_time=0.02350306510925293, train_time=0.01793956756591797
[Epoch 0][Step 54], time=0.04645228385925293, ext_time=0.023283958435058594, train_time=0.0176699161529541
[Epoch 0][Step 55], time=0.04731941223144531, ext_time=0.02391362190246582, train_time=0.017836570739746094
[Epoch 0][Step 56], time=0.04682493209838867, ext_time=0.02350902557373047, train_time=0.017797231674194336
[Epoch 0][Step 57], time=0.047377824783325195, ext_time=0.023478269577026367, train_time=0.018414974212646484
[Epoch 0][Step 58], time=0.046791791915893555, ext_time=0.02334737777709961, train_time=0.017857789993286133
[Epoch 0][Step 59], time=0.04695487022399902, ext_time=0.02355194091796875, train_time=0.017806529998779297
[Epoch 0][Step 60], time=0.046721696853637695, ext_time=0.023285388946533203, train_time=0.01789402961730957
[Epoch 0][Step 61], time=0.047495126724243164, ext_time=0.02373671531677246, train_time=0.018110990524291992
[Epoch 0][Step 62], time=0.047600507736206055, ext_time=0.02381157875061035, train_time=0.01818084716796875
[Epoch 0][Step 63], time=0.04630637168884277, ext_time=0.023235559463500977, train_time=0.017598867416381836
[Epoch 0][Step 64], time=0.04691791534423828, ext_time=0.02340078353881836, train_time=0.01798105239868164
[Epoch 0][Step 65], time=0.04688668251037598, ext_time=0.023565053939819336, train_time=0.01776599884033203
[Epoch 0][Step 66], time=0.047066450119018555, ext_time=0.023685216903686523, train_time=0.01783013343811035
[Epoch 0][Step 67], time=0.04696059226989746, ext_time=0.02327108383178711, train_time=0.018167972564697266
[Epoch 0][Step 68], time=0.04700660705566406, ext_time=0.023544788360595703, train_time=0.017801523208618164
[Epoch 0][Step 69], time=0.046488285064697266, ext_time=0.023243188858032227, train_time=0.017721176147460938
[Epoch 0][Step 70], time=0.048166751861572266, ext_time=0.02343606948852539, train_time=0.019179344177246094
[Epoch 0][Step 71], time=0.04678964614868164, ext_time=0.023555755615234375, train_time=0.017706632614135742
[Epoch 0][Step 72], time=0.046401023864746094, ext_time=0.023471355438232422, train_time=0.017396926879882812
[Epoch 0][Step 73], time=0.046501874923706055, ext_time=0.023310422897338867, train_time=0.017644882202148438
[Epoch 0][Step 74], time=0.04680299758911133, ext_time=0.023351669311523438, train_time=0.017957448959350586
[Epoch 0][Step 75], time=0.04709339141845703, ext_time=0.02349853515625, train_time=0.017960071563720703
[Epoch 0][Step 76], time=0.04698467254638672, ext_time=0.0236968994140625, train_time=0.01775979995727539
[Epoch 0][Step 77], time=0.04688262939453125, ext_time=0.0236203670501709, train_time=0.017746448516845703
[Epoch 0][Step 78], time=0.04987382888793945, ext_time=0.025139808654785156, train_time=0.019118070602416992
[Epoch 0][Step 79], time=0.047332048416137695, ext_time=0.0229489803314209, train_time=0.01875591278076172
[Epoch 0][Step 80], time=0.04689288139343262, ext_time=0.023422718048095703, train_time=0.01792597770690918
[Epoch 0][Step 81], time=0.04739856719970703, ext_time=0.0236971378326416, train_time=0.01812291145324707
[Epoch 0][Step 82], time=0.04723310470581055, ext_time=0.0232086181640625, train_time=0.01849055290222168
[Epoch 0][Step 83], time=0.04654264450073242, ext_time=0.023122549057006836, train_time=0.01794910430908203
[Epoch 0][Step 84], time=0.04738259315490723, ext_time=0.023818016052246094, train_time=0.017956256866455078
[Epoch 0][Step 85], time=0.04665827751159668, ext_time=0.023262739181518555, train_time=0.017859220504760742
[Epoch 0][Step 86], time=0.04685187339782715, ext_time=0.023473024368286133, train_time=0.017821788787841797
[Epoch 0][Step 87], time=0.04677939414978027, ext_time=0.023517847061157227, train_time=0.01773977279663086
[Epoch 0][Step 88], time=0.04705381393432617, ext_time=0.023569345474243164, train_time=0.017889976501464844
[Epoch 0][Step 89], time=0.0460360050201416, ext_time=0.022805213928222656, train_time=0.017788410186767578
[Epoch 0][Step 90], time=0.047713518142700195, ext_time=0.024115800857543945, train_time=0.01794719696044922
[Epoch 0][Step 91], time=0.0467228889465332, ext_time=0.023180007934570312, train_time=0.01802968978881836
[Epoch 0][Step 92], time=0.047135353088378906, ext_time=0.023558855056762695, train_time=0.01797175407409668
[Epoch 0][Step 93], time=0.04676628112792969, ext_time=0.023362159729003906, train_time=0.01783299446105957
[Epoch 0][Step 94], time=0.047835588455200195, ext_time=0.02378106117248535, train_time=0.018140554428100586
[Epoch 0][Step 95], time=0.0466008186340332, ext_time=0.023388147354125977, train_time=0.01768803596496582
[Epoch 0][Step 96], time=0.047200679779052734, ext_time=0.023518800735473633, train_time=0.018136978149414062
[Epoch 0][Step 97], time=0.04844498634338379, ext_time=0.024146318435668945, train_time=0.01862168312072754
[Epoch 0][Step 98], time=0.04716658592224121, ext_time=0.02367854118347168, train_time=0.017863750457763672
[Epoch 0][Step 99], time=0.04715275764465332, ext_time=0.02340865135192871, train_time=0.01818108558654785
[Epoch 0][Step 100], time=0.04777884483337402, ext_time=0.0236661434173584, train_time=0.01838517189025879
[Epoch 0][Step 101], time=0.04803180694580078, ext_time=0.024010181427001953, train_time=0.018311023712158203
[Epoch 0][Step 102], time=0.04735064506530762, ext_time=0.02350783348083496, train_time=0.018193960189819336
[Epoch 0][Step 103], time=0.047042131423950195, ext_time=0.023424386978149414, train_time=0.017944812774658203
[Epoch 0][Step 104], time=0.04674053192138672, ext_time=0.023302793502807617, train_time=0.017868518829345703
[Epoch 0][Step 105], time=0.046819210052490234, ext_time=0.023090362548828125, train_time=0.018174409866333008
[Epoch 0][Step 106], time=0.04648137092590332, ext_time=0.0231015682220459, train_time=0.017902612686157227
[Epoch 0][Step 107], time=0.046742916107177734, ext_time=0.023412704467773438, train_time=0.01770639419555664
[Epoch 0][Step 108], time=0.04692864418029785, ext_time=0.023409605026245117, train_time=0.017902612686157227
[Epoch 0][Step 109], time=0.0471501350402832, ext_time=0.023685455322265625, train_time=0.017893552780151367
[Epoch 0][Step 110], time=0.047013044357299805, ext_time=0.023594379425048828, train_time=0.017899274826049805
[Epoch 0][Step 111], time=0.046965837478637695, ext_time=0.023462533950805664, train_time=0.017876386642456055
[Epoch 0][Step 112], time=0.04776740074157715, ext_time=0.02308368682861328, train_time=0.01918935775756836
[Epoch 0][Step 113], time=0.049895524978637695, ext_time=0.023784160614013672, train_time=0.020545005798339844
[Epoch 0][Step 114], time=0.04706311225891113, ext_time=0.02311563491821289, train_time=0.01844477653503418
[Epoch 0][Step 115], time=0.04724550247192383, ext_time=0.02377605438232422, train_time=0.017791748046875
[Epoch 0][Step 116], time=0.046448707580566406, ext_time=0.02317023277282715, train_time=0.017793655395507812
[Epoch 0][Step 117], time=0.047089576721191406, ext_time=0.02356886863708496, train_time=0.017969608306884766
[Epoch 0][Step 118], time=0.04994320869445801, ext_time=0.025005102157592773, train_time=0.019277572631835938
[Epoch 0][Step 119], time=0.04726409912109375, ext_time=0.02362680435180664, train_time=0.017950773239135742
[Epoch 0][Step 120], time=0.046660423278808594, ext_time=0.02341485023498535, train_time=0.017729520797729492
[Epoch 0][Step 121], time=0.04673409461975098, ext_time=0.023317813873291016, train_time=0.017851829528808594
[Epoch 0][Step 122], time=0.04705643653869629, ext_time=0.02372884750366211, train_time=0.017781972885131836
[Epoch 0][Step 123], time=0.04865241050720215, ext_time=0.02359485626220703, train_time=0.019519329071044922
[Epoch 0][Step 124], time=0.04616951942443848, ext_time=0.023071765899658203, train_time=0.017613649368286133
[Epoch 0][Step 125], time=0.04636716842651367, ext_time=0.023134946823120117, train_time=0.01772928237915039
[Epoch 0][Step 126], time=0.04671120643615723, ext_time=0.023255109786987305, train_time=0.017937421798706055
[Epoch 0][Step 127], time=0.047049760818481445, ext_time=0.023432493209838867, train_time=0.01807093620300293
[Epoch 0][Step 128], time=0.04668736457824707, ext_time=0.023546218872070312, train_time=0.017661571502685547
[Epoch 0][Step 129], time=0.04708266258239746, ext_time=0.023618698120117188, train_time=0.017852783203125
[Epoch 0][Step 130], time=0.04636859893798828, ext_time=0.02321648597717285, train_time=0.01767587661743164
[Epoch 0][Step 131], time=0.04661989212036133, ext_time=0.02315497398376465, train_time=0.017940044403076172
[Epoch 0][Step 132], time=0.04726386070251465, ext_time=0.023473739624023438, train_time=0.018225669860839844
[Epoch 0][Step 133], time=0.047925710678100586, ext_time=0.023848772048950195, train_time=0.018141746520996094
[Epoch 0][Step 134], time=0.04714655876159668, ext_time=0.023637771606445312, train_time=0.017906904220581055
[Epoch 0][Step 135], time=0.04709911346435547, ext_time=0.023648500442504883, train_time=0.017883777618408203
[Epoch 0][Step 136], time=0.046881914138793945, ext_time=0.02361011505126953, train_time=0.017735004425048828
[Epoch 0][Step 137], time=0.04741549491882324, ext_time=0.02370309829711914, train_time=0.01811671257019043
[Epoch 0][Step 138], time=0.04717087745666504, ext_time=0.023459196090698242, train_time=0.01802849769592285
[Epoch 0][Step 139], time=0.04713082313537598, ext_time=0.023466110229492188, train_time=0.01809382438659668
[Epoch 0][Step 140], time=0.047089576721191406, ext_time=0.023598432540893555, train_time=0.017869949340820312
[Epoch 0][Step 141], time=0.04712033271789551, ext_time=0.02362823486328125, train_time=0.017941951751708984
[Epoch 0][Step 142], time=0.047148704528808594, ext_time=0.023658037185668945, train_time=0.0179290771484375
[Epoch 0][Step 143], time=0.04699373245239258, ext_time=0.02351832389831543, train_time=0.017892837524414062
[Epoch 0][Step 144], time=0.04675912857055664, ext_time=0.023443937301635742, train_time=0.01776576042175293
[Epoch 0][Step 145], time=0.047248125076293945, ext_time=0.023897886276245117, train_time=0.017803192138671875
[Epoch 0][Step 146], time=0.04695463180541992, ext_time=0.02366781234741211, train_time=0.017740964889526367
[Epoch 0][Step 147], time=0.04803729057312012, ext_time=0.023102283477783203, train_time=0.01801753044128418
[Epoch 0][Step 148], time=0.04691433906555176, ext_time=0.023482322692871094, train_time=0.017821550369262695
[Epoch 0][Step 149], time=0.04665517807006836, ext_time=0.02327275276184082, train_time=0.017839431762695312
[Epoch 0][Step 150], time=0.046478271484375, ext_time=0.023123502731323242, train_time=0.017870426177978516
[Epoch 0][Step 151], time=0.04758882522583008, ext_time=0.024005651473999023, train_time=0.0179598331451416
[Epoch 0][Step 152], time=0.046872854232788086, ext_time=0.022999286651611328, train_time=0.018401145935058594
[Epoch 0][Step 153], time=0.04734373092651367, ext_time=0.02366328239440918, train_time=0.01801896095275879
[Epoch 0][Step 154], time=0.046913862228393555, ext_time=0.023559093475341797, train_time=0.01781749725341797
[Epoch 0][Step 155], time=0.04702329635620117, ext_time=0.023628711700439453, train_time=0.01784658432006836
[Epoch 0][Step 156], time=0.04682326316833496, ext_time=0.023453950881958008, train_time=0.017809629440307617
[Epoch 0][Step 157], time=0.04679608345031738, ext_time=0.023360013961791992, train_time=0.01791667938232422
[Epoch 0][Step 158], time=0.046382904052734375, ext_time=0.023149967193603516, train_time=0.017642498016357422
[Epoch 0][Step 159], time=0.04719185829162598, ext_time=0.023718595504760742, train_time=0.017870187759399414
[Epoch 0][Step 160], time=0.04699563980102539, ext_time=0.023539066314697266, train_time=0.017861604690551758
[Epoch 0][Step 161], time=0.04699373245239258, ext_time=0.02360367774963379, train_time=0.0178377628326416
[Epoch 0][Step 162], time=0.048662662506103516, ext_time=0.023814678192138672, train_time=0.01924610137939453
[Epoch 0][Step 163], time=0.0468747615814209, ext_time=0.02328324317932129, train_time=0.017862319946289062
[Epoch 0][Step 164], time=0.04685044288635254, ext_time=0.023513317108154297, train_time=0.01777172088623047
[Epoch 0][Step 165], time=0.04677414894104004, ext_time=0.023128747940063477, train_time=0.01811981201171875
[Epoch 0][Step 166], time=0.0468292236328125, ext_time=0.023306608200073242, train_time=0.018001317977905273
[Epoch 0][Step 167], time=0.04735302925109863, ext_time=0.023680925369262695, train_time=0.018141984939575195
[Epoch 0][Step 168], time=0.046611785888671875, ext_time=0.02331066131591797, train_time=0.017772436141967773
[Epoch 0][Step 169], time=0.04918026924133301, ext_time=0.023997068405151367, train_time=0.019500017166137695
[Epoch 0][Step 170], time=0.04718327522277832, ext_time=0.023468494415283203, train_time=0.018095970153808594
[Epoch 0][Step 171], time=0.04678821563720703, ext_time=0.023665428161621094, train_time=0.017483234405517578
[Epoch 0][Step 172], time=0.047202110290527344, ext_time=0.02379322052001953, train_time=0.01787710189819336
[Epoch 0][Step 173], time=0.047159671783447266, ext_time=0.023447275161743164, train_time=0.018159866333007812
[Epoch 0][Step 174], time=0.04666590690612793, ext_time=0.023183345794677734, train_time=0.0180206298828125
[Epoch 0][Step 175], time=0.047385215759277344, ext_time=0.023802518844604492, train_time=0.017899036407470703
[Epoch 0][Step 176], time=0.04727458953857422, ext_time=0.023719072341918945, train_time=0.017962217330932617
[Epoch 0][Step 177], time=0.04662466049194336, ext_time=0.023173809051513672, train_time=0.017915010452270508
[Epoch 0][Step 178], time=0.04642200469970703, ext_time=0.023214101791381836, train_time=0.017696857452392578
[Epoch 0][Step 179], time=0.047902584075927734, ext_time=0.023491859436035156, train_time=0.018864154815673828
[Epoch 0][Step 180], time=0.04749870300292969, ext_time=0.023573637008666992, train_time=0.01810288429260254
[Epoch 0][Step 181], time=0.046999216079711914, ext_time=0.02358865737915039, train_time=0.017896413803100586
[Epoch 0][Step 182], time=0.046983957290649414, ext_time=0.023466110229492188, train_time=0.018006086349487305
[Epoch 0][Step 183], time=0.047180891036987305, ext_time=0.023365497589111328, train_time=0.018215179443359375
[Epoch 0][Step 184], time=0.046730756759643555, ext_time=0.02328205108642578, train_time=0.017981529235839844
[Epoch 0][Step 185], time=0.04667854309082031, ext_time=0.02319622039794922, train_time=0.017993688583374023
[Epoch 0][Step 186], time=0.047646284103393555, ext_time=0.023072004318237305, train_time=0.019022464752197266
[Epoch 0][Step 187], time=0.0464785099029541, ext_time=0.02309131622314453, train_time=0.01790761947631836
[Epoch 0][Step 188], time=0.04682207107543945, ext_time=0.02333831787109375, train_time=0.017951488494873047
[Epoch 0][Step 189], time=0.04680991172790527, ext_time=0.023565292358398438, train_time=0.017724990844726562
[Epoch 0][Step 190], time=0.04716968536376953, ext_time=0.023864030838012695, train_time=0.017773866653442383
[Epoch 0][Step 191], time=0.04716658592224121, ext_time=0.02360701560974121, train_time=0.018017292022705078
[Epoch 0][Step 192], time=0.046799421310424805, ext_time=0.023384809494018555, train_time=0.01780843734741211
[Epoch 0][Step 193], time=0.04708075523376465, ext_time=0.023683547973632812, train_time=0.01783275604248047
[Epoch 0][Step 194], time=0.046804189682006836, ext_time=0.02344202995300293, train_time=0.017835140228271484
[Epoch 0][Step 195], time=0.04724907875061035, ext_time=0.023798227310180664, train_time=0.017882108688354492
[Epoch 0][Step 196], time=0.04636240005493164, ext_time=0.02316594123840332, train_time=0.017681121826171875
[Epoch 0][Step 197], time=0.04692792892456055, ext_time=0.023395538330078125, train_time=0.018015623092651367
[Epoch 0][Step 198], time=0.047530412673950195, ext_time=0.02396106719970703, train_time=0.017910242080688477
[Epoch 0][Step 199], time=0.04678988456726074, ext_time=0.023395538330078125, train_time=0.01789069175720215
[Epoch 0][Step 200], time=0.04658150672912598, ext_time=0.023289918899536133, train_time=0.017764568328857422
[Epoch 0][Step 201], time=0.047129154205322266, ext_time=0.023668766021728516, train_time=0.017886877059936523
[Epoch 0][Step 202], time=0.04715991020202637, ext_time=0.023681163787841797, train_time=0.017896175384521484
[Epoch 0][Step 203], time=0.04784893989562988, ext_time=0.023929357528686523, train_time=0.018227815628051758
[Epoch 0][Step 204], time=0.04737043380737305, ext_time=0.023690462112426758, train_time=0.017993450164794922
[Epoch 0][Step 205], time=0.046759605407714844, ext_time=0.023402690887451172, train_time=0.017815589904785156
[Epoch 0][Step 206], time=0.04722142219543457, ext_time=0.02362656593322754, train_time=0.018096923828125
[Epoch 0][Step 207], time=0.046277761459350586, ext_time=0.023291349411010742, train_time=0.01709151268005371
[Epoch 0][Step 208], time=0.04589414596557617, ext_time=0.02326488494873047, train_time=0.017304420471191406
[Epoch 0][Step 209], time=0.04689288139343262, ext_time=0.023659944534301758, train_time=0.01775217056274414
[Epoch 0][Step 210], time=0.04713129997253418, ext_time=0.023611068725585938, train_time=0.01813673973083496
[Epoch 0][Step 211], time=0.046517133712768555, ext_time=0.023778200149536133, train_time=0.017393112182617188
[Epoch 0][Step 212], time=0.046886444091796875, ext_time=0.023474693298339844, train_time=0.018036365509033203
[Epoch 0][Step 213], time=0.04584074020385742, ext_time=0.023569583892822266, train_time=0.016884326934814453
[Epoch 0][Step 214], time=0.04715108871459961, ext_time=0.02361154556274414, train_time=0.01813030242919922
[Epoch 0][Step 215], time=0.047150373458862305, ext_time=0.02357959747314453, train_time=0.018262624740600586
[Epoch 0][Step 216], time=0.04693126678466797, ext_time=0.02350783348083496, train_time=0.01805877685546875
[Epoch 0][Step 217], time=0.046586036682128906, ext_time=0.023639917373657227, train_time=0.017586946487426758
[Epoch 0][Step 218], time=0.04665017127990723, ext_time=0.023818016052246094, train_time=0.01746201515197754
[Epoch 0][Step 219], time=0.04713797569274902, ext_time=0.02328801155090332, train_time=0.018497228622436523
[Epoch 0][Step 220], time=0.04693722724914551, ext_time=0.023360729217529297, train_time=0.018265247344970703
[Epoch 0][Step 221], time=0.04652142524719238, ext_time=0.023705005645751953, train_time=0.0174405574798584
[Epoch 0][Step 222], time=0.04715609550476074, ext_time=0.023613691329956055, train_time=0.01812601089477539
[Epoch 0][Step 223], time=0.04671645164489746, ext_time=0.02365875244140625, train_time=0.017720460891723633
[Epoch 0][Step 224], time=0.04701876640319824, ext_time=0.023559093475341797, train_time=0.01811075210571289
[Epoch 0][Step 225], time=0.04697585105895996, ext_time=0.023210763931274414, train_time=0.01842212677001953
[Epoch 0][Step 226], time=0.04766368865966797, ext_time=0.0233306884765625, train_time=0.018955707550048828
[Epoch 0][Step 227], time=0.04658365249633789, ext_time=0.023717164993286133, train_time=0.01724863052368164
[Epoch 0][Step 228], time=0.046814680099487305, ext_time=0.023529052734375, train_time=0.017925262451171875
[Epoch 0][Step 229], time=0.04669952392578125, ext_time=0.02366018295288086, train_time=0.017704010009765625
[Epoch 0][Step 230], time=0.04749584197998047, ext_time=0.02361750602722168, train_time=0.018477916717529297
[Epoch 0][Step 231], time=0.046616554260253906, ext_time=0.023287296295166016, train_time=0.01802229881286621
[Epoch 0][Step 232], time=0.046227455139160156, ext_time=0.0235598087310791, train_time=0.01732802391052246
[Epoch 0][Step 233], time=0.0464787483215332, ext_time=0.023432016372680664, train_time=0.01772475242614746
[Epoch 0][Step 234], time=0.046767473220825195, ext_time=0.023608684539794922, train_time=0.017778396606445312
[Epoch 0][Step 235], time=0.0464787483215332, ext_time=0.02342820167541504, train_time=0.017683029174804688
[Epoch 0][Step 236], time=0.04687023162841797, ext_time=0.02378368377685547, train_time=0.017687082290649414
[Epoch 0][Step 237], time=0.04644584655761719, ext_time=0.023519515991210938, train_time=0.01759958267211914
[Epoch 0][Step 238], time=0.04654526710510254, ext_time=0.02345752716064453, train_time=0.01776289939880371
[Epoch 0][Step 239], time=0.0472867488861084, ext_time=0.023266315460205078, train_time=0.018681049346923828
[Epoch 0][Step 240], time=0.04731249809265137, ext_time=0.023566484451293945, train_time=0.01838064193725586
[Epoch 0][Step 241], time=0.04659104347229004, ext_time=0.022979736328125, train_time=0.018301963806152344
[Epoch 0][Step 242], time=0.04658794403076172, ext_time=0.023456335067749023, train_time=0.017807960510253906
[Epoch 0][Step 243], time=0.047302961349487305, ext_time=0.023933887481689453, train_time=0.0179598331451416
[Epoch 0][Step 244], time=0.04659318923950195, ext_time=0.023149490356445312, train_time=0.0180971622467041
[Epoch 0][Step 245], time=0.04782891273498535, ext_time=0.023632287979125977, train_time=0.018800735473632812
[Epoch 0][Step 246], time=0.046671152114868164, ext_time=0.023759126663208008, train_time=0.017499923706054688
[Epoch 0][Step 247], time=0.04665803909301758, ext_time=0.023507356643676758, train_time=0.017838239669799805
[Epoch 0][Step 248], time=0.04648566246032715, ext_time=0.023377656936645508, train_time=0.017705917358398438
[Epoch 0][Step 249], time=0.04632425308227539, ext_time=0.02344369888305664, train_time=0.01753997802734375
[Epoch 0], time=12.903141498565674, loss=0.6931472420692444
[Epoch 1][Step 0], time=0.04633617401123047, ext_time=0.023555517196655273, train_time=0.017405986785888672
[Epoch 1][Step 1], time=0.046060800552368164, ext_time=0.023286104202270508, train_time=0.01748800277709961
[Epoch 1][Step 2], time=0.046643733978271484, ext_time=0.023466110229492188, train_time=0.01785421371459961
[Epoch 1][Step 3], time=0.04671931266784668, ext_time=0.02376413345336914, train_time=0.01755213737487793
[Epoch 1][Step 4], time=0.04588055610656738, ext_time=0.023087024688720703, train_time=0.017490625381469727
[Epoch 1][Step 5], time=0.04677081108093262, ext_time=0.02329564094543457, train_time=0.01804637908935547
[Epoch 1][Step 6], time=0.046135902404785156, ext_time=0.0233762264251709, train_time=0.01739645004272461
[Epoch 1][Step 7], time=0.04601311683654785, ext_time=0.02356886863708496, train_time=0.017106056213378906
[Epoch 1][Step 8], time=0.04625368118286133, ext_time=0.023664474487304688, train_time=0.017218589782714844
[Epoch 1][Step 9], time=0.04651236534118652, ext_time=0.023396015167236328, train_time=0.01773834228515625
[Epoch 1][Step 10], time=0.04618692398071289, ext_time=0.023749828338623047, train_time=0.017090797424316406
[Epoch 1][Step 11], time=0.04680609703063965, ext_time=0.02331376075744629, train_time=0.018131732940673828
[Epoch 1][Step 12], time=0.046759843826293945, ext_time=0.0238034725189209, train_time=0.017592430114746094
[Epoch 1][Step 13], time=0.04642963409423828, ext_time=0.023505687713623047, train_time=0.017525911331176758
[Epoch 1][Step 14], time=0.04914140701293945, ext_time=0.02315831184387207, train_time=0.020572900772094727
[Epoch 1][Step 15], time=0.046361684799194336, ext_time=0.02355504035949707, train_time=0.017405271530151367
[Epoch 1][Step 16], time=0.04675936698913574, ext_time=0.02369093894958496, train_time=0.017627954483032227
[Epoch 1][Step 17], time=0.0470428466796875, ext_time=0.02320575714111328, train_time=0.018503665924072266
[Epoch 1][Step 18], time=0.046486854553222656, ext_time=0.023929834365844727, train_time=0.01718735694885254
[Epoch 1][Step 19], time=0.04633021354675293, ext_time=0.023909330368041992, train_time=0.01702260971069336
[Epoch 1][Step 20], time=0.04601311683654785, ext_time=0.02389836311340332, train_time=0.01674938201904297
[Epoch 1][Step 21], time=0.046262502670288086, ext_time=0.023709774017333984, train_time=0.0171663761138916
[Epoch 1][Step 22], time=0.04804563522338867, ext_time=0.023683547973632812, train_time=0.01894855499267578
[Epoch 1][Step 23], time=0.04608511924743652, ext_time=0.023560762405395508, train_time=0.017162561416625977
[Epoch 1][Step 24], time=0.04663872718811035, ext_time=0.02338266372680664, train_time=0.017878055572509766
[Epoch 1][Step 25], time=0.04689478874206543, ext_time=0.02325916290283203, train_time=0.01824641227722168
[Epoch 1][Step 26], time=0.04587602615356445, ext_time=0.023392677307128906, train_time=0.0170743465423584
[Epoch 1][Step 27], time=0.046794891357421875, ext_time=0.02373218536376953, train_time=0.017458200454711914
[Epoch 1][Step 28], time=0.04609942436218262, ext_time=0.023355484008789062, train_time=0.017373323440551758
[Epoch 1][Step 29], time=0.04600715637207031, ext_time=0.02328181266784668, train_time=0.01739048957824707
[Epoch 1][Step 30], time=0.04635810852050781, ext_time=0.02332782745361328, train_time=0.01770329475402832
[Epoch 1][Step 31], time=0.046443939208984375, ext_time=0.023749351501464844, train_time=0.017292499542236328
[Epoch 1][Step 32], time=0.04618215560913086, ext_time=0.0236814022064209, train_time=0.017201662063598633
[Epoch 1][Step 33], time=0.04703021049499512, ext_time=0.023864030838012695, train_time=0.017825841903686523
[Epoch 1][Step 34], time=0.046208858489990234, ext_time=0.02348160743713379, train_time=0.017235994338989258
[Epoch 1][Step 35], time=0.04626774787902832, ext_time=0.023326635360717773, train_time=0.017656326293945312
[Epoch 1][Step 36], time=0.046854496002197266, ext_time=0.023855924606323242, train_time=0.01763606071472168
[Epoch 1][Step 37], time=0.046453237533569336, ext_time=0.02331256866455078, train_time=0.017803430557250977
[Epoch 1][Step 38], time=0.046231985092163086, ext_time=0.023488283157348633, train_time=0.01740097999572754
[Epoch 1][Step 39], time=0.0464019775390625, ext_time=0.02377605438232422, train_time=0.01721811294555664
[Epoch 1][Step 40], time=0.0464017391204834, ext_time=0.02308487892150879, train_time=0.018019914627075195
[Epoch 1][Step 41], time=0.04666447639465332, ext_time=0.02337479591369629, train_time=0.017992019653320312
[Epoch 1][Step 42], time=0.04653811454772949, ext_time=0.023488283157348633, train_time=0.017673492431640625
[Epoch 1][Step 43], time=0.046521663665771484, ext_time=0.02361607551574707, train_time=0.017498254776000977
[Epoch 1][Step 44], time=0.04677772521972656, ext_time=0.023531675338745117, train_time=0.01792740821838379
[Epoch 1][Step 45], time=0.04608011245727539, ext_time=0.023482084274291992, train_time=0.0173032283782959
[Epoch 1][Step 46], time=0.04630732536315918, ext_time=0.02378225326538086, train_time=0.017166852951049805
[Epoch 1][Step 47], time=0.046408653259277344, ext_time=0.02370309829711914, train_time=0.0173187255859375
[Epoch 1][Step 48], time=0.04635000228881836, ext_time=0.02346944808959961, train_time=0.017566680908203125
[Epoch 1][Step 49], time=0.04628729820251465, ext_time=0.023529767990112305, train_time=0.017386674880981445
[Epoch 1][Step 50], time=0.0467987060546875, ext_time=0.023621559143066406, train_time=0.01777791976928711
[Epoch 1][Step 51], time=0.04601097106933594, ext_time=0.023183107376098633, train_time=0.01748800277709961
[Epoch 1][Step 52], time=0.04677391052246094, ext_time=0.023383378982543945, train_time=0.018117189407348633
[Epoch 1][Step 53], time=0.046425819396972656, ext_time=0.023606538772583008, train_time=0.017422914505004883
[Epoch 1][Step 54], time=0.04694104194641113, ext_time=0.02337336540222168, train_time=0.018208742141723633
[Epoch 1][Step 55], time=0.04633378982543945, ext_time=0.023515939712524414, train_time=0.017516374588012695
[Epoch 1][Step 56], time=0.04649090766906738, ext_time=0.02330946922302246, train_time=0.01787424087524414
[Epoch 1][Step 57], time=0.046381235122680664, ext_time=0.023522138595581055, train_time=0.01752328872680664
[Epoch 1][Step 58], time=0.04590272903442383, ext_time=0.0234067440032959, train_time=0.01719975471496582
[Epoch 1][Step 59], time=0.04639124870300293, ext_time=0.023417949676513672, train_time=0.017537355422973633
[Epoch 1][Step 60], time=0.04626917839050293, ext_time=0.023137569427490234, train_time=0.017791271209716797
[Epoch 1][Step 61], time=0.04590177536010742, ext_time=0.023417949676513672, train_time=0.017147541046142578
[Epoch 1][Step 62], time=0.045827388763427734, ext_time=0.023348331451416016, train_time=0.01717090606689453
[Epoch 1][Step 63], time=0.04621767997741699, ext_time=0.023472070693969727, train_time=0.017459630966186523
[Epoch 1][Step 64], time=0.04665350914001465, ext_time=0.02317214012145996, train_time=0.018195390701293945
[Epoch 1][Step 65], time=0.04604029655456543, ext_time=0.02364349365234375, train_time=0.017059803009033203
[Epoch 1][Step 66], time=0.04632449150085449, ext_time=0.0235292911529541, train_time=0.017494916915893555
[Epoch 1][Step 67], time=0.048406362533569336, ext_time=0.023335695266723633, train_time=0.01772022247314453
[Epoch 1][Step 68], time=0.046196699142456055, ext_time=0.023262977600097656, train_time=0.01758122444152832
[Epoch 1][Step 69], time=0.04911041259765625, ext_time=0.022997140884399414, train_time=0.020817995071411133
[Epoch 1][Step 70], time=0.046263933181762695, ext_time=0.02328968048095703, train_time=0.01767754554748535
[Epoch 1][Step 71], time=0.04605817794799805, ext_time=0.02317667007446289, train_time=0.01754593849182129
[Epoch 1][Step 72], time=0.04642486572265625, ext_time=0.023849010467529297, train_time=0.017191648483276367
[Epoch 1][Step 73], time=0.04631829261779785, ext_time=0.02283763885498047, train_time=0.018207788467407227
[Epoch 1][Step 74], time=0.046298980712890625, ext_time=0.023836851119995117, train_time=0.0170896053314209
[Epoch 1][Step 75], time=0.04603981971740723, ext_time=0.023632287979125977, train_time=0.01706695556640625
[Epoch 1][Step 76], time=0.0470433235168457, ext_time=0.023997783660888672, train_time=0.017675399780273438
[Epoch 1][Step 77], time=0.04647254943847656, ext_time=0.023213863372802734, train_time=0.01779794692993164
[Epoch 1][Step 78], time=0.04615330696105957, ext_time=0.02338433265686035, train_time=0.017420291900634766
[Epoch 1][Step 79], time=0.04597663879394531, ext_time=0.02326822280883789, train_time=0.017436742782592773
[Epoch 1][Step 80], time=0.04623675346374512, ext_time=0.023497343063354492, train_time=0.01735830307006836
[Epoch 1][Step 81], time=0.04857802391052246, ext_time=0.0235140323638916, train_time=0.019669055938720703
[Epoch 1][Step 82], time=0.04661870002746582, ext_time=0.023266077041625977, train_time=0.017989158630371094
[Epoch 1][Step 83], time=0.04660797119140625, ext_time=0.02343606948852539, train_time=0.017839670181274414
[Epoch 1][Step 84], time=0.047574520111083984, ext_time=0.02361297607421875, train_time=0.018602848052978516
[Epoch 1][Step 85], time=0.04600787162780762, ext_time=0.023102998733520508, train_time=0.017514944076538086
[Epoch 1][Step 86], time=0.04638242721557617, ext_time=0.02293682098388672, train_time=0.01813817024230957
[Epoch 1][Step 87], time=0.04589509963989258, ext_time=0.023195743560791016, train_time=0.017409801483154297
[Epoch 1][Step 88], time=0.04590344429016113, ext_time=0.02328634262084961, train_time=0.01727128028869629
[Epoch 1][Step 89], time=0.04605722427368164, ext_time=0.023308277130126953, train_time=0.01741170883178711
[Epoch 1][Step 90], time=0.04656338691711426, ext_time=0.023665428161621094, train_time=0.01751995086669922
[Epoch 1][Step 91], time=0.048127174377441406, ext_time=0.023270130157470703, train_time=0.019464492797851562
[Epoch 1][Step 92], time=0.04663443565368652, ext_time=0.023711442947387695, train_time=0.01746368408203125
[Epoch 1][Step 93], time=0.04717707633972168, ext_time=0.023468017578125, train_time=0.018347501754760742
[Epoch 1][Step 94], time=0.04680371284484863, ext_time=0.02347087860107422, train_time=0.01789379119873047
[Epoch 1][Step 95], time=0.046816349029541016, ext_time=0.02348637580871582, train_time=0.017995834350585938
[Epoch 1][Step 96], time=0.04655051231384277, ext_time=0.023465633392333984, train_time=0.01776742935180664
[Epoch 1][Step 97], time=0.04626655578613281, ext_time=0.02344679832458496, train_time=0.01750040054321289
[Epoch 1][Step 98], time=0.04634284973144531, ext_time=0.023784875869750977, train_time=0.017181396484375
[Epoch 1][Step 99], time=0.04658699035644531, ext_time=0.02353358268737793, train_time=0.01771092414855957
[Epoch 1][Step 100], time=0.04842495918273926, ext_time=0.02385258674621582, train_time=0.019151926040649414
[Epoch 1][Step 101], time=0.04892253875732422, ext_time=0.023703813552856445, train_time=0.019858360290527344
[Epoch 1][Step 102], time=0.046794891357421875, ext_time=0.02356576919555664, train_time=0.017548561096191406
[Epoch 1][Step 103], time=0.04619026184082031, ext_time=0.02293562889099121, train_time=0.017870664596557617
[Epoch 1][Step 104], time=0.04585909843444824, ext_time=0.023220062255859375, train_time=0.017309188842773438
[Epoch 1][Step 105], time=0.04687356948852539, ext_time=0.023048877716064453, train_time=0.018495798110961914
[Epoch 1][Step 106], time=0.04800581932067871, ext_time=0.02351975440979004, train_time=0.01912403106689453
[Epoch 1][Step 107], time=0.04659628868103027, ext_time=0.023332834243774414, train_time=0.01797652244567871
[Epoch 1][Step 108], time=0.04654669761657715, ext_time=0.023183107376098633, train_time=0.01800370216369629
[Epoch 1][Step 109], time=0.045893192291259766, ext_time=0.023541927337646484, train_time=0.017018795013427734
[Epoch 1][Step 110], time=0.04622840881347656, ext_time=0.023730039596557617, train_time=0.017171859741210938
[Epoch 1][Step 111], time=0.0465238094329834, ext_time=0.02348470687866211, train_time=0.017644643783569336
[Epoch 1][Step 112], time=0.0464022159576416, ext_time=0.02308940887451172, train_time=0.0180203914642334
[Epoch 1][Step 113], time=0.046785593032836914, ext_time=0.023575544357299805, train_time=0.017847537994384766
[Epoch 1][Step 114], time=0.046337127685546875, ext_time=0.022974014282226562, train_time=0.018095016479492188
[Epoch 1][Step 115], time=0.04613494873046875, ext_time=0.023379087448120117, train_time=0.017454862594604492
[Epoch 1][Step 116], time=0.0464625358581543, ext_time=0.02358555793762207, train_time=0.017528772354125977
[Epoch 1][Step 117], time=0.04669618606567383, ext_time=0.02338242530822754, train_time=0.018049001693725586
[Epoch 1][Step 118], time=0.04693007469177246, ext_time=0.023514747619628906, train_time=0.01801443099975586
[Epoch 1][Step 119], time=0.046027183532714844, ext_time=0.023133516311645508, train_time=0.017604351043701172
[Epoch 1][Step 120], time=0.04702949523925781, ext_time=0.023452043533325195, train_time=0.01825881004333496
[Epoch 1][Step 121], time=0.04638791084289551, ext_time=0.02336573600769043, train_time=0.017667531967163086
[Epoch 1][Step 122], time=0.04686594009399414, ext_time=0.023915529251098633, train_time=0.01758122444152832
[Epoch 1][Step 123], time=0.04618334770202637, ext_time=0.023489952087402344, train_time=0.017322063446044922
[Epoch 1][Step 124], time=0.04642033576965332, ext_time=0.02349376678466797, train_time=0.017529964447021484
[Epoch 1][Step 125], time=0.046662092208862305, ext_time=0.023198843002319336, train_time=0.01813530921936035
[Epoch 1][Step 126], time=0.0461580753326416, ext_time=0.02360677719116211, train_time=0.017139673233032227
[Epoch 1][Step 127], time=0.04672837257385254, ext_time=0.023549795150756836, train_time=0.017859220504760742
[Epoch 1][Step 128], time=0.04607200622558594, ext_time=0.023893356323242188, train_time=0.016859769821166992
[Epoch 1][Step 129], time=0.04649543762207031, ext_time=0.02345585823059082, train_time=0.01769876480102539
[Epoch 1][Step 130], time=0.04656195640563965, ext_time=0.023295164108276367, train_time=0.01794576644897461
[Epoch 1][Step 131], time=0.046363115310668945, ext_time=0.023331642150878906, train_time=0.017635583877563477
[Epoch 1][Step 132], time=0.046549081802368164, ext_time=0.02360701560974121, train_time=0.017545461654663086
[Epoch 1][Step 133], time=0.046965837478637695, ext_time=0.02434515953063965, train_time=0.01721501350402832
[Epoch 1][Step 134], time=0.0463559627532959, ext_time=0.0238797664642334, train_time=0.017110824584960938
[Epoch 1][Step 135], time=0.04648756980895996, ext_time=0.023593664169311523, train_time=0.017545461654663086
[Epoch 1][Step 136], time=0.04683828353881836, ext_time=0.02380084991455078, train_time=0.017668724060058594
[Epoch 1][Step 137], time=0.04628729820251465, ext_time=0.02380681037902832, train_time=0.017127513885498047
[Epoch 1][Step 138], time=0.04627251625061035, ext_time=0.0232388973236084, train_time=0.017713069915771484
[Epoch 1][Step 139], time=0.04647397994995117, ext_time=0.0235445499420166, train_time=0.017583608627319336
[Epoch 1][Step 140], time=0.04658031463623047, ext_time=0.023576974868774414, train_time=0.01762247085571289
[Epoch 1][Step 141], time=0.046697378158569336, ext_time=0.02376103401184082, train_time=0.017522573471069336
[Epoch 1][Step 142], time=0.04729032516479492, ext_time=0.02397632598876953, train_time=0.017836332321166992
[Epoch 1][Step 143], time=0.04638385772705078, ext_time=0.023555994033813477, train_time=0.01746821403503418
[Epoch 1][Step 144], time=0.04623126983642578, ext_time=0.02306652069091797, train_time=0.017924070358276367
[Epoch 1][Step 145], time=0.047020912170410156, ext_time=0.023941993713378906, train_time=0.01772475242614746
[Epoch 1][Step 146], time=0.04605984687805176, ext_time=0.02321028709411621, train_time=0.0175778865814209
[Epoch 1][Step 147], time=0.04605269432067871, ext_time=0.02336907386779785, train_time=0.017368078231811523
[Epoch 1][Step 148], time=0.04584693908691406, ext_time=0.023360729217529297, train_time=0.01720881462097168
[Epoch 1][Step 149], time=0.04629373550415039, ext_time=0.022927284240722656, train_time=0.018082380294799805
[Epoch 1][Step 150], time=0.046227455139160156, ext_time=0.02338576316833496, train_time=0.017507076263427734
[Epoch 1][Step 151], time=0.04655957221984863, ext_time=0.023731231689453125, train_time=0.017466306686401367
[Epoch 1][Step 152], time=0.04812359809875488, ext_time=0.023110151290893555, train_time=0.019718647003173828
[Epoch 1][Step 153], time=0.04645681381225586, ext_time=0.023579120635986328, train_time=0.017417430877685547
[Epoch 1][Step 154], time=0.04631495475769043, ext_time=0.02357935905456543, train_time=0.01732039451599121
[Epoch 1][Step 155], time=0.04626655578613281, ext_time=0.023519515991210938, train_time=0.017370223999023438
[Epoch 1][Step 156], time=0.04596114158630371, ext_time=0.02337169647216797, train_time=0.017231464385986328
[Epoch 1][Step 157], time=0.04650402069091797, ext_time=0.023486614227294922, train_time=0.017641067504882812
[Epoch 1][Step 158], time=0.04909920692443848, ext_time=0.022870302200317383, train_time=0.02087569236755371
[Epoch 1][Step 159], time=0.046861886978149414, ext_time=0.023391008377075195, train_time=0.018088817596435547
[Epoch 1][Step 160], time=0.04701566696166992, ext_time=0.023438692092895508, train_time=0.018186569213867188
[Epoch 1][Step 161], time=0.046211957931518555, ext_time=0.023652076721191406, train_time=0.01721668243408203
[Epoch 1][Step 162], time=0.04641127586364746, ext_time=0.02325725555419922, train_time=0.017836809158325195
[Epoch 1][Step 163], time=0.04702472686767578, ext_time=0.023906469345092773, train_time=0.01765155792236328
[Epoch 1][Step 164], time=0.04750537872314453, ext_time=0.023029088973999023, train_time=0.019121646881103516
[Epoch 1][Step 165], time=0.04612851142883301, ext_time=0.02330756187438965, train_time=0.01745438575744629
[Epoch 1][Step 166], time=0.04639387130737305, ext_time=0.023143291473388672, train_time=0.018003463745117188
[Epoch 1][Step 167], time=0.04604172706604004, ext_time=0.023406267166137695, train_time=0.017284154891967773
[Epoch 1][Step 168], time=0.04609251022338867, ext_time=0.023439884185791016, train_time=0.0173032283782959
[Epoch 1][Step 169], time=0.04638957977294922, ext_time=0.023439884185791016, train_time=0.017568588256835938
[Epoch 1][Step 170], time=0.04683184623718262, ext_time=0.023235321044921875, train_time=0.018337011337280273
[Epoch 1][Step 171], time=0.046553850173950195, ext_time=0.023453235626220703, train_time=0.01774430274963379
[Epoch 1][Step 172], time=0.04747128486633301, ext_time=0.023850202560424805, train_time=0.018248796463012695
[Epoch 1][Step 173], time=0.046517133712768555, ext_time=0.023464202880859375, train_time=0.017722606658935547
[Epoch 1][Step 174], time=0.04648756980895996, ext_time=0.023386240005493164, train_time=0.017694950103759766
[Epoch 1][Step 175], time=0.04639911651611328, ext_time=0.023536205291748047, train_time=0.017530441284179688
[Epoch 1][Step 176], time=0.04690051078796387, ext_time=0.023391246795654297, train_time=0.018065452575683594
[Epoch 1][Step 177], time=0.04650473594665527, ext_time=0.02366018295288086, train_time=0.017436504364013672
[Epoch 1][Step 178], time=0.04618573188781738, ext_time=0.02297496795654297, train_time=0.01794266700744629
[Epoch 1][Step 179], time=0.04604840278625488, ext_time=0.02347397804260254, train_time=0.01722121238708496
[Epoch 1][Step 180], time=0.04623150825500488, ext_time=0.02372598648071289, train_time=0.01711297035217285
[Epoch 1][Step 181], time=0.04602789878845215, ext_time=0.023357152938842773, train_time=0.01742243766784668
[Epoch 1][Step 182], time=0.04707789421081543, ext_time=0.023556232452392578, train_time=0.01818394660949707
[Epoch 1][Step 183], time=0.049093008041381836, ext_time=0.02343297004699707, train_time=0.02024388313293457
[Epoch 1][Step 184], time=0.045832157135009766, ext_time=0.023311853408813477, train_time=0.017058610916137695
[Epoch 1][Step 185], time=0.0463414192199707, ext_time=0.02320241928100586, train_time=0.017852783203125
[Epoch 1][Step 186], time=0.04626727104187012, ext_time=0.023525714874267578, train_time=0.01733541488647461
[Epoch 1][Step 187], time=0.0461735725402832, ext_time=0.023061275482177734, train_time=0.017865657806396484
[Epoch 1][Step 188], time=0.04671144485473633, ext_time=0.02350759506225586, train_time=0.01782393455505371
[Epoch 1][Step 189], time=0.04661226272583008, ext_time=0.023524761199951172, train_time=0.017728090286254883
[Epoch 1][Step 190], time=0.04697132110595703, ext_time=0.023711681365966797, train_time=0.017900705337524414
[Epoch 1][Step 191], time=0.046514272689819336, ext_time=0.023871898651123047, train_time=0.017218828201293945
[Epoch 1][Step 192], time=0.04651236534118652, ext_time=0.023393869400024414, train_time=0.017719507217407227
[Epoch 1][Step 193], time=0.047122955322265625, ext_time=0.02381277084350586, train_time=0.017879486083984375
[Epoch 1][Step 194], time=0.04784202575683594, ext_time=0.02352142333984375, train_time=0.018849849700927734
[Epoch 1][Step 195], time=0.046669721603393555, ext_time=0.023923873901367188, train_time=0.017277002334594727
[Epoch 1][Step 196], time=0.047211408615112305, ext_time=0.023560047149658203, train_time=0.018244028091430664
[Epoch 1][Step 197], time=0.046430110931396484, ext_time=0.023118019104003906, train_time=0.01803874969482422
[Epoch 1][Step 198], time=0.04635310173034668, ext_time=0.023847103118896484, train_time=0.017122507095336914
[Epoch 1][Step 199], time=0.0461885929107666, ext_time=0.0236968994140625, train_time=0.01717662811279297
[Epoch 1][Step 200], time=0.04667830467224121, ext_time=0.023616790771484375, train_time=0.017669677734375
[Epoch 1][Step 201], time=0.046353816986083984, ext_time=0.023773670196533203, train_time=0.017055273056030273
[Epoch 1][Step 202], time=0.04633808135986328, ext_time=0.02372908592224121, train_time=0.01723337173461914
[Epoch 1][Step 203], time=0.04714012145996094, ext_time=0.023957252502441406, train_time=0.01774001121520996
[Epoch 1][Step 204], time=0.04688000679016113, ext_time=0.023410558700561523, train_time=0.018056154251098633
[Epoch 1][Step 205], time=0.04604506492614746, ext_time=0.0234677791595459, train_time=0.017234325408935547
[Epoch 1][Step 206], time=0.04628133773803711, ext_time=0.023455381393432617, train_time=0.017491817474365234
[Epoch 1][Step 207], time=0.046323537826538086, ext_time=0.023478031158447266, train_time=0.01744818687438965
[Epoch 1][Step 208], time=0.04725074768066406, ext_time=0.023351430892944336, train_time=0.017355918884277344
[Epoch 1][Step 209], time=0.047820329666137695, ext_time=0.023424386978149414, train_time=0.019068241119384766
[Epoch 1][Step 210], time=0.04659128189086914, ext_time=0.02375960350036621, train_time=0.01745891571044922
[Epoch 1][Step 211], time=0.04616498947143555, ext_time=0.023337841033935547, train_time=0.01756119728088379
[Epoch 1][Step 212], time=0.046234846115112305, ext_time=0.023485422134399414, train_time=0.01735973358154297
[Epoch 1][Step 213], time=0.046460866928100586, ext_time=0.023523569107055664, train_time=0.017568111419677734
[Epoch 1][Step 214], time=0.0469205379486084, ext_time=0.02346324920654297, train_time=0.018063783645629883
[Epoch 1][Step 215], time=0.0464932918548584, ext_time=0.023746967315673828, train_time=0.0173799991607666
[Epoch 1][Step 216], time=0.046386003494262695, ext_time=0.02332901954650879, train_time=0.01770496368408203
[Epoch 1][Step 217], time=0.04627847671508789, ext_time=0.0234835147857666, train_time=0.01751255989074707
[Epoch 1][Step 218], time=0.04671478271484375, ext_time=0.023470163345336914, train_time=0.017967939376831055
[Epoch 1][Step 219], time=0.04646921157836914, ext_time=0.023367881774902344, train_time=0.017754077911376953
[Epoch 1][Step 220], time=0.04653644561767578, ext_time=0.023571491241455078, train_time=0.01760697364807129
[Epoch 1][Step 221], time=0.046076297760009766, ext_time=0.02328038215637207, train_time=0.017482757568359375
[Epoch 1][Step 222], time=0.04647946357727051, ext_time=0.023079633712768555, train_time=0.018100738525390625
[Epoch 1][Step 223], time=0.046904563903808594, ext_time=0.02368330955505371, train_time=0.017859935760498047
[Epoch 1][Step 224], time=0.04664444923400879, ext_time=0.023453235626220703, train_time=0.017863988876342773
[Epoch 1][Step 225], time=0.04669356346130371, ext_time=0.023644685745239258, train_time=0.017641067504882812
[Epoch 1][Step 226], time=0.046762943267822266, ext_time=0.02335190773010254, train_time=0.018053293228149414
[Epoch 1][Step 227], time=0.046560049057006836, ext_time=0.0236666202545166, train_time=0.01747751235961914
[Epoch 1][Step 228], time=0.04715991020202637, ext_time=0.02310776710510254, train_time=0.01875019073486328
[Epoch 1][Step 229], time=0.046601057052612305, ext_time=0.023839950561523438, train_time=0.01739192008972168
[Epoch 1][Step 230], time=0.04720735549926758, ext_time=0.023731470108032227, train_time=0.018043041229248047
[Epoch 1][Step 231], time=0.04847121238708496, ext_time=0.023360490798950195, train_time=0.01978588104248047
[Epoch 1][Step 232], time=0.046244144439697266, ext_time=0.023632049560546875, train_time=0.017232418060302734
[Epoch 1][Step 233], time=0.04684162139892578, ext_time=0.0238649845123291, train_time=0.01756453514099121
[Epoch 1][Step 234], time=0.04643821716308594, ext_time=0.02340078353881836, train_time=0.017689228057861328
[Epoch 1][Step 235], time=0.046613216400146484, ext_time=0.023072004318237305, train_time=0.01813530921936035
[Epoch 1][Step 236], time=0.046274423599243164, ext_time=0.02381277084350586, train_time=0.017112255096435547
[Epoch 1][Step 237], time=0.04804110527038574, ext_time=0.0234375, train_time=0.01769256591796875
[Epoch 1][Step 238], time=0.04640650749206543, ext_time=0.023705720901489258, train_time=0.017375469207763672
[Epoch 1][Step 239], time=0.04693913459777832, ext_time=0.023575544357299805, train_time=0.01794600486755371
[Epoch 1][Step 240], time=0.046684980392456055, ext_time=0.023782730102539062, train_time=0.017446517944335938
[Epoch 1][Step 241], time=0.0471494197845459, ext_time=0.02289295196533203, train_time=0.018962383270263672
[Epoch 1][Step 242], time=0.04623913764953613, ext_time=0.023665904998779297, train_time=0.01720738410949707
[Epoch 1][Step 243], time=0.046380043029785156, ext_time=0.023824453353881836, train_time=0.017197847366333008
[Epoch 1][Step 244], time=0.04679608345031738, ext_time=0.023401498794555664, train_time=0.018018722534179688
[Epoch 1][Step 245], time=0.046614885330200195, ext_time=0.02358245849609375, train_time=0.017589807510375977
[Epoch 1][Step 246], time=0.04716920852661133, ext_time=0.023370981216430664, train_time=0.01842522621154785
[Epoch 1][Step 247], time=0.04709172248840332, ext_time=0.023537635803222656, train_time=0.018244028091430664
[Epoch 1][Step 248], time=0.04642677307128906, ext_time=0.02355194091796875, train_time=0.017511844635009766
[Epoch 1][Step 249], time=0.046628475189208984, ext_time=0.023682832717895508, train_time=0.017557859420776367
[Epoch 1], time=11.669345378875732, loss=0.6931472420692444
[Epoch 2][Step 0], time=0.04643416404724121, ext_time=0.02352428436279297, train_time=0.017487049102783203
[Epoch 2][Step 1], time=0.04657268524169922, ext_time=0.02381157875061035, train_time=0.017389774322509766
[Epoch 2][Step 2], time=0.04775500297546387, ext_time=0.02346324920654297, train_time=0.018932819366455078
[Epoch 2][Step 3], time=0.04624342918395996, ext_time=0.023624181747436523, train_time=0.017199039459228516
[Epoch 2][Step 4], time=0.04641842842102051, ext_time=0.023221492767333984, train_time=0.01787543296813965
[Epoch 2][Step 5], time=0.047139644622802734, ext_time=0.02315497398376465, train_time=0.018657207489013672
[Epoch 2][Step 6], time=0.0469975471496582, ext_time=0.02298903465270996, train_time=0.018669605255126953
[Epoch 2][Step 7], time=0.04630708694458008, ext_time=0.023613929748535156, train_time=0.017226457595825195
[Epoch 2][Step 8], time=0.04564499855041504, ext_time=0.023276567459106445, train_time=0.017046451568603516
[Epoch 2][Step 9], time=0.046796321868896484, ext_time=0.023581743240356445, train_time=0.017850637435913086
[Epoch 2][Step 10], time=0.046086788177490234, ext_time=0.023427248001098633, train_time=0.017314434051513672
[Epoch 2][Step 11], time=0.04681539535522461, ext_time=0.023404836654663086, train_time=0.018016338348388672
[Epoch 2][Step 12], time=0.047022342681884766, ext_time=0.02346968650817871, train_time=0.018108606338500977
[Epoch 2][Step 13], time=0.046251535415649414, ext_time=0.023437976837158203, train_time=0.017398834228515625
[Epoch 2][Step 14], time=0.0467836856842041, ext_time=0.02327561378479004, train_time=0.01813530921936035
[Epoch 2][Step 15], time=0.046541452407836914, ext_time=0.023245573043823242, train_time=0.017960786819458008
[Epoch 2][Step 16], time=0.04654097557067871, ext_time=0.023523569107055664, train_time=0.01764655113220215
[Epoch 2][Step 17], time=0.04614591598510742, ext_time=0.023155927658081055, train_time=0.017656326293945312
[Epoch 2][Step 18], time=0.046712398529052734, ext_time=0.024086475372314453, train_time=0.01717686653137207
[Epoch 2][Step 19], time=0.04647994041442871, ext_time=0.023431777954101562, train_time=0.017730712890625
[Epoch 2][Step 20], time=0.046063899993896484, ext_time=0.023706674575805664, train_time=0.017006874084472656
[Epoch 2][Step 21], time=0.04602670669555664, ext_time=0.023528099060058594, train_time=0.017165422439575195
[Epoch 2][Step 22], time=0.04625582695007324, ext_time=0.023602962493896484, train_time=0.01727914810180664
[Epoch 2][Step 23], time=0.046466827392578125, ext_time=0.023663043975830078, train_time=0.01748371124267578
[Epoch 2][Step 24], time=0.04614520072937012, ext_time=0.023510217666625977, train_time=0.017261981964111328
[Epoch 2][Step 25], time=0.04943037033081055, ext_time=0.023488521575927734, train_time=0.02057027816772461
[Epoch 2][Step 26], time=0.045926809310913086, ext_time=0.02313542366027832, train_time=0.017422199249267578
[Epoch 2][Step 27], time=0.04653310775756836, ext_time=0.023558616638183594, train_time=0.01755833625793457
[Epoch 2][Step 28], time=0.04634666442871094, ext_time=0.023151636123657227, train_time=0.01790595054626465
[Epoch 2][Step 29], time=0.04684019088745117, ext_time=0.02343273162841797, train_time=0.017972469329833984
[Epoch 2][Step 30], time=0.046269893646240234, ext_time=0.023500680923461914, train_time=0.01740431785583496
[Epoch 2][Step 31], time=0.04762721061706543, ext_time=0.023656845092773438, train_time=0.01858353614807129
[Epoch 2][Step 32], time=0.04719686508178711, ext_time=0.023630380630493164, train_time=0.018062353134155273
[Epoch 2][Step 33], time=0.04655146598815918, ext_time=0.02366328239440918, train_time=0.01750469207763672
[Epoch 2][Step 34], time=0.04642987251281738, ext_time=0.02346968650817871, train_time=0.017612218856811523
[Epoch 2][Step 35], time=0.04681110382080078, ext_time=0.023224353790283203, train_time=0.018282413482666016
[Epoch 2][Step 36], time=0.04696154594421387, ext_time=0.023522377014160156, train_time=0.018127918243408203
[Epoch 2][Step 37], time=0.04641890525817871, ext_time=0.023646116256713867, train_time=0.017374753952026367
[Epoch 2][Step 38], time=0.04633688926696777, ext_time=0.023445844650268555, train_time=0.017570972442626953
[Epoch 2][Step 39], time=0.046926021575927734, ext_time=0.02389240264892578, train_time=0.017619609832763672
[Epoch 2][Step 40], time=0.04711771011352539, ext_time=0.02291131019592285, train_time=0.018926620483398438
[Epoch 2][Step 41], time=0.04671955108642578, ext_time=0.023360729217529297, train_time=0.018059968948364258
[Epoch 2][Step 42], time=0.04595470428466797, ext_time=0.02300238609313965, train_time=0.017670154571533203
[Epoch 2][Step 43], time=0.046448707580566406, ext_time=0.023298263549804688, train_time=0.017743587493896484
[Epoch 2][Step 44], time=0.046772003173828125, ext_time=0.023416996002197266, train_time=0.018024206161499023
[Epoch 2][Step 45], time=0.046720266342163086, ext_time=0.02320384979248047, train_time=0.01821112632751465
[Epoch 2][Step 46], time=0.046405792236328125, ext_time=0.023695945739746094, train_time=0.017230510711669922
[Epoch 2][Step 47], time=0.0476531982421875, ext_time=0.02356553077697754, train_time=0.01867198944091797
[Epoch 2][Step 48], time=0.04616427421569824, ext_time=0.023280620574951172, train_time=0.017577409744262695
[Epoch 2][Step 49], time=0.0460207462310791, ext_time=0.02347421646118164, train_time=0.01723957061767578
[Epoch 2][Step 50], time=0.046502113342285156, ext_time=0.02319645881652832, train_time=0.01798844337463379
[Epoch 2][Step 51], time=0.04603838920593262, ext_time=0.02314472198486328, train_time=0.017564058303833008
[Epoch 2][Step 52], time=0.04670381546020508, ext_time=0.023587703704833984, train_time=0.017746686935424805
[Epoch 2][Step 53], time=0.047096967697143555, ext_time=0.023351430892944336, train_time=0.018358469009399414
[Epoch 2][Step 54], time=0.04648447036743164, ext_time=0.023467540740966797, train_time=0.017673492431640625
[Epoch 2][Step 55], time=0.04670143127441406, ext_time=0.02364349365234375, train_time=0.01769232749938965
[Epoch 2][Step 56], time=0.04661417007446289, ext_time=0.023811817169189453, train_time=0.01743602752685547
[Epoch 2][Step 57], time=0.04634428024291992, ext_time=0.023792266845703125, train_time=0.0171511173248291
[Epoch 2][Step 58], time=0.04616808891296387, ext_time=0.023654699325561523, train_time=0.01712179183959961
[Epoch 2][Step 59], time=0.04619479179382324, ext_time=0.023313283920288086, train_time=0.017571210861206055
[Epoch 2][Step 60], time=0.04623866081237793, ext_time=0.022925376892089844, train_time=0.018007755279541016
[Epoch 2][Step 61], time=0.04653048515319824, ext_time=0.0237886905670166, train_time=0.01734304428100586
[Epoch 2][Step 62], time=0.04720139503479004, ext_time=0.02393484115600586, train_time=0.017778873443603516
[Epoch 2][Step 63], time=0.04684138298034668, ext_time=0.023278236389160156, train_time=0.018311500549316406
[Epoch 2][Step 64], time=0.04730582237243652, ext_time=0.023287057876586914, train_time=0.017655611038208008
[Epoch 2][Step 65], time=0.04656481742858887, ext_time=0.02322101593017578, train_time=0.017876625061035156
[Epoch 2][Step 66], time=0.04753279685974121, ext_time=0.02381420135498047, train_time=0.01818251609802246
[Epoch 2][Step 67], time=0.0468449592590332, ext_time=0.023184537887573242, train_time=0.018117427825927734
[Epoch 2][Step 68], time=0.04648900032043457, ext_time=0.02324843406677246, train_time=0.0176849365234375
[Epoch 2][Step 69], time=0.047019243240356445, ext_time=0.02365875244140625, train_time=0.01783013343811035
[Epoch 2][Step 70], time=0.04681754112243652, ext_time=0.023490190505981445, train_time=0.01779460906982422
[Epoch 2][Step 71], time=0.04677891731262207, ext_time=0.023471593856811523, train_time=0.017767906188964844
[Epoch 2][Step 72], time=0.04697704315185547, ext_time=0.023685932159423828, train_time=0.017764806747436523
[Epoch 2][Step 73], time=0.04760909080505371, ext_time=0.02369070053100586, train_time=0.01830291748046875
[Epoch 2][Step 74], time=0.04767107963562012, ext_time=0.023928403854370117, train_time=0.018125057220458984
[Epoch 2][Step 75], time=0.04744839668273926, ext_time=0.023802757263183594, train_time=0.018073081970214844
[Epoch 2][Step 76], time=0.04776787757873535, ext_time=0.024211406707763672, train_time=0.017937660217285156
[Epoch 2][Step 77], time=0.04691028594970703, ext_time=0.02329230308532715, train_time=0.018121719360351562
[Epoch 2][Step 78], time=0.047271013259887695, ext_time=0.023752450942993164, train_time=0.0179288387298584
[Epoch 2][Step 79], time=0.04636549949645996, ext_time=0.02321171760559082, train_time=0.017693758010864258
[Epoch 2][Step 80], time=0.04757356643676758, ext_time=0.02385997772216797, train_time=0.018030881881713867
[Epoch 2][Step 81], time=0.047008514404296875, ext_time=0.02348613739013672, train_time=0.017914772033691406
[Epoch 2][Step 82], time=0.04659700393676758, ext_time=0.023322105407714844, train_time=0.01779627799987793
[Epoch 2][Step 83], time=0.046686649322509766, ext_time=0.02327442169189453, train_time=0.0178530216217041
[Epoch 2][Step 84], time=0.046981096267700195, ext_time=0.023495912551879883, train_time=0.017868995666503906
[Epoch 2][Step 85], time=0.04644656181335449, ext_time=0.023182153701782227, train_time=0.017719507217407227
[Epoch 2][Step 86], time=0.04665374755859375, ext_time=0.023327350616455078, train_time=0.017785310745239258
[Epoch 2][Step 87], time=0.047072410583496094, ext_time=0.023313045501708984, train_time=0.0182802677154541
[Epoch 2][Step 88], time=0.04685235023498535, ext_time=0.02317047119140625, train_time=0.01798725128173828
[Epoch 2][Step 89], time=0.0467381477355957, ext_time=0.023393869400024414, train_time=0.017790555953979492
[Epoch 2][Step 90], time=0.04657578468322754, ext_time=0.02342367172241211, train_time=0.017659664154052734
[Epoch 2][Step 91], time=0.04663586616516113, ext_time=0.02332305908203125, train_time=0.01776432991027832
[Epoch 2][Step 92], time=0.04642081260681152, ext_time=0.023336172103881836, train_time=0.01759505271911621
[Epoch 2][Step 93], time=0.04702639579772949, ext_time=0.02334284782409668, train_time=0.018180131912231445
[Epoch 2][Step 94], time=0.04711198806762695, ext_time=0.02382969856262207, train_time=0.017757177352905273
[Epoch 2][Step 95], time=0.04668164253234863, ext_time=0.023410558700561523, train_time=0.01779651641845703
[Epoch 2][Step 96], time=0.04682278633117676, ext_time=0.02347588539123535, train_time=0.017872333526611328
[Epoch 2][Step 97], time=0.04669690132141113, ext_time=0.023450851440429688, train_time=0.017690420150756836
[Epoch 2][Step 98], time=0.04701423645019531, ext_time=0.023471832275390625, train_time=0.018003463745117188
[Epoch 2][Step 99], time=0.047217369079589844, ext_time=0.023511648178100586, train_time=0.018128633499145508
[Epoch 2][Step 100], time=0.0478968620300293, ext_time=0.023819684982299805, train_time=0.01845240592956543
[Epoch 2][Step 101], time=0.047406911849975586, ext_time=0.023647785186767578, train_time=0.01818060874938965
[Epoch 2][Step 102], time=0.047122955322265625, ext_time=0.023623228073120117, train_time=0.017867088317871094
[Epoch 2][Step 103], time=0.046602487564086914, ext_time=0.02321457862854004, train_time=0.017817020416259766
[Epoch 2][Step 104], time=0.0471041202545166, ext_time=0.023528337478637695, train_time=0.017976999282836914
[Epoch 2][Step 105], time=0.04669594764709473, ext_time=0.023201465606689453, train_time=0.01794743537902832
[Epoch 2][Step 106], time=0.04694986343383789, ext_time=0.023513078689575195, train_time=0.017871856689453125
[Epoch 2][Step 107], time=0.046844482421875, ext_time=0.02360057830810547, train_time=0.01772594451904297
[Epoch 2][Step 108], time=0.04622650146484375, ext_time=0.02295708656311035, train_time=0.017792940139770508
[Epoch 2][Step 109], time=0.04622173309326172, ext_time=0.023044586181640625, train_time=0.01770639419555664
[Epoch 2][Step 110], time=0.047426462173461914, ext_time=0.023796558380126953, train_time=0.018059730529785156
[Epoch 2][Step 111], time=0.04692983627319336, ext_time=0.02341914176940918, train_time=0.01790785789489746
[Epoch 2][Step 112], time=0.04655051231384277, ext_time=0.023289203643798828, train_time=0.01775074005126953
[Epoch 2][Step 113], time=0.04705977439880371, ext_time=0.023604154586791992, train_time=0.01788949966430664
[Epoch 2][Step 114], time=0.04642319679260254, ext_time=0.023094654083251953, train_time=0.017758846282958984
[Epoch 2][Step 115], time=0.0465085506439209, ext_time=0.02346205711364746, train_time=0.01748943328857422
[Epoch 2][Step 116], time=0.04676342010498047, ext_time=0.023078441619873047, train_time=0.01812434196472168
[Epoch 2][Step 117], time=0.046883583068847656, ext_time=0.023448705673217773, train_time=0.01790761947631836
[Epoch 2][Step 118], time=0.04687237739562988, ext_time=0.023411989212036133, train_time=0.01791858673095703
[Epoch 2][Step 119], time=0.04736065864562988, ext_time=0.02379894256591797, train_time=0.018008708953857422
[Epoch 2][Step 120], time=0.04661679267883301, ext_time=0.023401498794555664, train_time=0.01775074005126953
[Epoch 2][Step 121], time=0.046872615814208984, ext_time=0.023453235626220703, train_time=0.017853498458862305
[Epoch 2][Step 122], time=0.04730081558227539, ext_time=0.023957252502441406, train_time=0.01779937744140625
[Epoch 2][Step 123], time=0.04657483100891113, ext_time=0.023434877395629883, train_time=0.01765298843383789
[Epoch 2][Step 124], time=0.046747446060180664, ext_time=0.02343583106994629, train_time=0.01777505874633789
[Epoch 2][Step 125], time=0.04629158973693848, ext_time=0.023070812225341797, train_time=0.017687082290649414
[Epoch 2][Step 126], time=0.0466616153717041, ext_time=0.023362398147583008, train_time=0.017762184143066406
[Epoch 2][Step 127], time=0.047473907470703125, ext_time=0.02401876449584961, train_time=0.017872333526611328
[Epoch 2][Step 128], time=0.046849727630615234, ext_time=0.02364945411682129, train_time=0.017652034759521484
[Epoch 2][Step 129], time=0.048937082290649414, ext_time=0.024136781692504883, train_time=0.019148826599121094
[Epoch 2][Step 130], time=0.04662370681762695, ext_time=0.023208141326904297, train_time=0.017754793167114258
[Epoch 2][Step 131], time=0.04691290855407715, ext_time=0.023434877395629883, train_time=0.017889022827148438
[Epoch 2][Step 132], time=0.04644322395324707, ext_time=0.02319812774658203, train_time=0.017726659774780273
[Epoch 2][Step 133], time=0.047350406646728516, ext_time=0.023987293243408203, train_time=0.017797231674194336
[Epoch 2][Step 134], time=0.046885013580322266, ext_time=0.023632049560546875, train_time=0.017729759216308594
[Epoch 2][Step 135], time=0.04674792289733887, ext_time=0.023487329483032227, train_time=0.017747879028320312
[Epoch 2][Step 136], time=0.04722857475280762, ext_time=0.023801088333129883, train_time=0.017887115478515625
[Epoch 2][Step 137], time=0.04657864570617676, ext_time=0.023450613021850586, train_time=0.017649412155151367
[Epoch 2][Step 138], time=0.046602725982666016, ext_time=0.023282766342163086, train_time=0.0178372859954834
[Epoch 2][Step 139], time=0.046964168548583984, ext_time=0.023285865783691406, train_time=0.018147945404052734
[Epoch 2][Step 140], time=0.04664921760559082, ext_time=0.02336740493774414, train_time=0.017780065536499023
[Epoch 2][Step 141], time=0.04694867134094238, ext_time=0.023673295974731445, train_time=0.01775336265563965
[Epoch 2][Step 142], time=0.04660367965698242, ext_time=0.023375749588012695, train_time=0.017709016799926758
[Epoch 2][Step 143], time=0.0474848747253418, ext_time=0.023562192916870117, train_time=0.018405437469482422
[Epoch 2][Step 144], time=0.04668903350830078, ext_time=0.023400545120239258, train_time=0.017741680145263672
[Epoch 2][Step 145], time=0.04699110984802246, ext_time=0.02379631996154785, train_time=0.01769423484802246
[Epoch 2][Step 146], time=0.0464017391204834, ext_time=0.0233004093170166, train_time=0.017609596252441406
[Epoch 2][Step 147], time=0.04652810096740723, ext_time=0.0233004093170166, train_time=0.01773238182067871
[Epoch 2][Step 148], time=0.046560049057006836, ext_time=0.023189306259155273, train_time=0.01786637306213379
[Epoch 2][Step 149], time=0.0458371639251709, ext_time=0.02312445640563965, train_time=0.01717519760131836
[Epoch 2][Step 150], time=0.04636740684509277, ext_time=0.023261070251464844, train_time=0.017560958862304688
[Epoch 2][Step 151], time=0.04659271240234375, ext_time=0.02330636978149414, train_time=0.017801523208618164
[Epoch 2][Step 152], time=0.04691362380981445, ext_time=0.023224353790283203, train_time=0.018201112747192383
[Epoch 2][Step 153], time=0.04699993133544922, ext_time=0.02361011505126953, train_time=0.017841100692749023
[Epoch 2][Step 154], time=0.04718899726867676, ext_time=0.02350902557373047, train_time=0.01814126968383789
[Epoch 2][Step 155], time=0.04736661911010742, ext_time=0.023640155792236328, train_time=0.01818537712097168
[Epoch 2][Step 156], time=0.04648113250732422, ext_time=0.023126840591430664, train_time=0.017893552780151367
[Epoch 2][Step 157], time=0.04886603355407715, ext_time=0.023592233657836914, train_time=0.017968416213989258
[Epoch 2][Step 158], time=0.04621076583862305, ext_time=0.023036718368530273, train_time=0.01764082908630371
[Epoch 2][Step 159], time=0.04652714729309082, ext_time=0.023278236389160156, train_time=0.01774001121520996
[Epoch 2][Step 160], time=0.04651308059692383, ext_time=0.023522138595581055, train_time=0.017441987991333008
[Epoch 2][Step 161], time=0.04634428024291992, ext_time=0.023465871810913086, train_time=0.017362117767333984
[Epoch 2][Step 162], time=0.04724264144897461, ext_time=0.023589134216308594, train_time=0.018114566802978516
[Epoch 2][Step 163], time=0.04696297645568848, ext_time=0.023318052291870117, train_time=0.01808619499206543
[Epoch 2][Step 164], time=0.04649829864501953, ext_time=0.022999286651611328, train_time=0.018030643463134766
[Epoch 2][Step 165], time=0.04785275459289551, ext_time=0.023318052291870117, train_time=0.019011735916137695
[Epoch 2][Step 166], time=0.04649996757507324, ext_time=0.023438215255737305, train_time=0.017595291137695312
[Epoch 2][Step 167], time=0.047040462493896484, ext_time=0.023474454879760742, train_time=0.018040895462036133
[Epoch 2][Step 168], time=0.04704999923706055, ext_time=0.023412227630615234, train_time=0.01806807518005371
[Epoch 2][Step 169], time=0.046707868576049805, ext_time=0.02337503433227539, train_time=0.017765283584594727
[Epoch 2][Step 170], time=0.04626345634460449, ext_time=0.0232241153717041, train_time=0.017580509185791016
[Epoch 2][Step 171], time=0.0464940071105957, ext_time=0.023255109786987305, train_time=0.01777362823486328
[Epoch 2][Step 172], time=0.04665327072143555, ext_time=0.02344059944152832, train_time=0.017680644989013672
[Epoch 2][Step 173], time=0.046880483627319336, ext_time=0.02358245849609375, train_time=0.017757177352905273
[Epoch 2][Step 174], time=0.04709362983703613, ext_time=0.023464441299438477, train_time=0.01809072494506836
[Epoch 2][Step 175], time=0.04748678207397461, ext_time=0.02377486228942871, train_time=0.018167734146118164
[Epoch 2][Step 176], time=0.04674410820007324, ext_time=0.02307891845703125, train_time=0.018200159072875977
[Epoch 2][Step 177], time=0.046929359436035156, ext_time=0.02355670928955078, train_time=0.017810821533203125
[Epoch 2][Step 178], time=0.04653310775756836, ext_time=0.023305177688598633, train_time=0.017709016799926758
[Epoch 2][Step 179], time=0.04653644561767578, ext_time=0.023298263549804688, train_time=0.017711877822875977
[Epoch 2][Step 180], time=0.04744410514831543, ext_time=0.02366805076599121, train_time=0.01821160316467285
[Epoch 2][Step 181], time=0.04672646522521973, ext_time=0.02357339859008789, train_time=0.01767444610595703
[Epoch 2][Step 182], time=0.04688310623168945, ext_time=0.023474454879760742, train_time=0.01784682273864746
[Epoch 2][Step 183], time=0.04755234718322754, ext_time=0.023550748825073242, train_time=0.01833963394165039
[Epoch 2][Step 184], time=0.04649233818054199, ext_time=0.023340463638305664, train_time=0.017691850662231445
[Epoch 2][Step 185], time=0.046376943588256836, ext_time=0.023250579833984375, train_time=0.017613649368286133
[Epoch 2][Step 186], time=0.04665994644165039, ext_time=0.023320436477661133, train_time=0.017720699310302734
[Epoch 2][Step 187], time=0.04601168632507324, ext_time=0.02323603630065918, train_time=0.017282962799072266
[Epoch 2][Step 188], time=0.047176361083984375, ext_time=0.023175716400146484, train_time=0.018499374389648438
[Epoch 2][Step 189], time=0.046520233154296875, ext_time=0.023354530334472656, train_time=0.017660856246948242
[Epoch 2][Step 190], time=0.0467677116394043, ext_time=0.0236051082611084, train_time=0.01767706871032715
[Epoch 2][Step 191], time=0.04708743095397949, ext_time=0.02375340461730957, train_time=0.017783641815185547
[Epoch 2][Step 192], time=0.04818534851074219, ext_time=0.023408889770507812, train_time=0.019207000732421875
[Epoch 2][Step 193], time=0.046981096267700195, ext_time=0.023520231246948242, train_time=0.017938852310180664
[Epoch 2][Step 194], time=0.047051191329956055, ext_time=0.023586750030517578, train_time=0.017877817153930664
[Epoch 2][Step 195], time=0.04756307601928711, ext_time=0.023773193359375, train_time=0.01820230484008789
[Epoch 2][Step 196], time=0.047164201736450195, ext_time=0.023526668548583984, train_time=0.018041610717773438
[Epoch 2][Step 197], time=0.047396183013916016, ext_time=0.023746013641357422, train_time=0.01804184913635254
[Epoch 2][Step 198], time=0.04694628715515137, ext_time=0.023525238037109375, train_time=0.017864465713500977
[Epoch 2][Step 199], time=0.046894073486328125, ext_time=0.023564577102661133, train_time=0.017821788787841797
[Epoch 2][Step 200], time=0.04681825637817383, ext_time=0.02338266372680664, train_time=0.01783132553100586
[Epoch 2][Step 201], time=0.04681110382080078, ext_time=0.02355647087097168, train_time=0.017689943313598633
[Epoch 2][Step 202], time=0.04644036293029785, ext_time=0.023205041885375977, train_time=0.017754316329956055
[Epoch 2][Step 203], time=0.04691672325134277, ext_time=0.02355813980102539, train_time=0.01781010627746582
[Epoch 2][Step 204], time=0.04663562774658203, ext_time=0.023327112197875977, train_time=0.017786264419555664
[Epoch 2][Step 205], time=0.04765176773071289, ext_time=0.023865699768066406, train_time=0.018153667449951172
[Epoch 2][Step 206], time=0.046864986419677734, ext_time=0.02335357666015625, train_time=0.018024921417236328
[Epoch 2][Step 207], time=0.046823978424072266, ext_time=0.023236989974975586, train_time=0.018057584762573242
[Epoch 2][Step 208], time=0.046776533126831055, ext_time=0.023494958877563477, train_time=0.017725229263305664
[Epoch 2][Step 209], time=0.04693126678466797, ext_time=0.02370429039001465, train_time=0.017717599868774414
[Epoch 2][Step 210], time=0.04736971855163574, ext_time=0.023910999298095703, train_time=0.017879724502563477
[Epoch 2][Step 211], time=0.0464327335357666, ext_time=0.023324966430664062, train_time=0.017638206481933594
[Epoch 2][Step 212], time=0.04670357704162598, ext_time=0.023270845413208008, train_time=0.01792430877685547
[Epoch 2][Step 213], time=0.04700946807861328, ext_time=0.023382186889648438, train_time=0.01806354522705078
[Epoch 2][Step 214], time=0.04666566848754883, ext_time=0.023240327835083008, train_time=0.017784833908081055
[Epoch 2][Step 215], time=0.04648637771606445, ext_time=0.02322554588317871, train_time=0.017747163772583008
[Epoch 2][Step 216], time=0.04642987251281738, ext_time=0.02312493324279785, train_time=0.017781496047973633
[Epoch 2][Step 217], time=0.04670119285583496, ext_time=0.023198604583740234, train_time=0.017976999282836914
[Epoch 2][Step 218], time=0.0472567081451416, ext_time=0.02371954917907715, train_time=0.017955780029296875
[Epoch 2][Step 219], time=0.04700613021850586, ext_time=0.02348923683166504, train_time=0.01795053482055664
[Epoch 2][Step 220], time=0.046767234802246094, ext_time=0.023372173309326172, train_time=0.01788926124572754
[Epoch 2][Step 221], time=0.047010183334350586, ext_time=0.023412227630615234, train_time=0.01804947853088379
[Epoch 2][Step 222], time=0.04711651802062988, ext_time=0.023324012756347656, train_time=0.018199682235717773
[Epoch 2][Step 223], time=0.04711318016052246, ext_time=0.023432016372680664, train_time=0.018093109130859375
[Epoch 2][Step 224], time=0.046753644943237305, ext_time=0.02348637580871582, train_time=0.017717838287353516
[Epoch 2][Step 225], time=0.04613327980041504, ext_time=0.023106098175048828, train_time=0.01753067970275879
[Epoch 2][Step 226], time=0.04653573036193848, ext_time=0.023347139358520508, train_time=0.017631053924560547
[Epoch 2][Step 227], time=0.048612356185913086, ext_time=0.023853302001953125, train_time=0.019180774688720703
[Epoch 2][Step 228], time=0.04770970344543457, ext_time=0.023916959762573242, train_time=0.017968416213989258
[Epoch 2][Step 229], time=0.046860694885253906, ext_time=0.023562192916870117, train_time=0.017784833908081055
[Epoch 2][Step 230], time=0.04732370376586914, ext_time=0.023844003677368164, train_time=0.017896175384521484
[Epoch 2][Step 231], time=0.04796648025512695, ext_time=0.023435115814208984, train_time=0.019023656845092773
[Epoch 2][Step 232], time=0.04676651954650879, ext_time=0.023455142974853516, train_time=0.017815589904785156
[Epoch 2][Step 233], time=0.04724884033203125, ext_time=0.02366185188293457, train_time=0.018007755279541016
[Epoch 2][Step 234], time=0.047360897064208984, ext_time=0.023663043975830078, train_time=0.01808786392211914
[Epoch 2][Step 235], time=0.04646801948547363, ext_time=0.023175716400146484, train_time=0.017764806747436523
[Epoch 2][Step 236], time=0.046727657318115234, ext_time=0.02340102195739746, train_time=0.01785898208618164
[Epoch 2][Step 237], time=0.047293663024902344, ext_time=0.023579120635986328, train_time=0.01818704605102539
[Epoch 2][Step 238], time=0.047148704528808594, ext_time=0.02349114418029785, train_time=0.018086671829223633
[Epoch 2][Step 239], time=0.04703927040100098, ext_time=0.023576021194458008, train_time=0.017850160598754883
[Epoch 2][Step 240], time=0.0470118522644043, ext_time=0.023547649383544922, train_time=0.01788020133972168
[Epoch 2][Step 241], time=0.047719478607177734, ext_time=0.023088455200195312, train_time=0.0180666446685791
[Epoch 2][Step 242], time=0.04694247245788574, ext_time=0.023564577102661133, train_time=0.017778873443603516
[Epoch 2][Step 243], time=0.047032833099365234, ext_time=0.023738384246826172, train_time=0.01776123046875
[Epoch 2][Step 244], time=0.04624819755554199, ext_time=0.023162841796875, train_time=0.017609596252441406
[Epoch 2][Step 245], time=0.047473907470703125, ext_time=0.023883819580078125, train_time=0.017971515655517578
[Epoch 2][Step 246], time=0.04667377471923828, ext_time=0.023136138916015625, train_time=0.018002748489379883
[Epoch 2][Step 247], time=0.04686284065246582, ext_time=0.023597002029418945, train_time=0.017745494842529297
[Epoch 2][Step 248], time=0.04683828353881836, ext_time=0.02353811264038086, train_time=0.017762184143066406
[Epoch 2][Step 249], time=0.046766042709350586, ext_time=0.023336410522460938, train_time=0.017965316772460938
[Epoch 2], time=11.72937822341919, loss=0.6931472420692444
[Epoch 3][Step 0], time=0.047593116760253906, ext_time=0.02364325523376465, train_time=0.018320798873901367
[Epoch 3][Step 1], time=0.04707503318786621, ext_time=0.023442506790161133, train_time=0.0180661678314209
[Epoch 3][Step 2], time=0.0472719669342041, ext_time=0.023577213287353516, train_time=0.018143892288208008
[Epoch 3][Step 3], time=0.04653573036193848, ext_time=0.023183822631835938, train_time=0.017833709716796875
[Epoch 3][Step 4], time=0.04617905616760254, ext_time=0.02306532859802246, train_time=0.017653703689575195
[Epoch 3][Step 5], time=0.04721498489379883, ext_time=0.023394107818603516, train_time=0.01818680763244629
[Epoch 3][Step 6], time=0.046689748764038086, ext_time=0.02322530746459961, train_time=0.01790022850036621
[Epoch 3][Step 7], time=0.04693198204040527, ext_time=0.023585796356201172, train_time=0.01776719093322754
[Epoch 3][Step 8], time=0.0464167594909668, ext_time=0.02323126792907715, train_time=0.017677783966064453
[Epoch 3][Step 9], time=0.04710721969604492, ext_time=0.02354264259338379, train_time=0.018007278442382812
[Epoch 3][Step 10], time=0.047231435775756836, ext_time=0.02369832992553711, train_time=0.017940521240234375
[Epoch 3][Step 11], time=0.04682612419128418, ext_time=0.023508548736572266, train_time=0.017774343490600586
[Epoch 3][Step 12], time=0.04712367057800293, ext_time=0.02372908592224121, train_time=0.017858266830444336
[Epoch 3][Step 13], time=0.04688119888305664, ext_time=0.02343010902404785, train_time=0.017923593521118164
[Epoch 3][Step 14], time=0.04705023765563965, ext_time=0.023412704467773438, train_time=0.018004417419433594
[Epoch 3][Step 15], time=0.046671390533447266, ext_time=0.02330780029296875, train_time=0.017821788787841797
[Epoch 3][Step 16], time=0.04697823524475098, ext_time=0.023493289947509766, train_time=0.017894506454467773
[Epoch 3][Step 17], time=0.046534061431884766, ext_time=0.023319005966186523, train_time=0.017706871032714844
[Epoch 3][Step 18], time=0.048104286193847656, ext_time=0.023622751235961914, train_time=0.018925189971923828
[Epoch 3][Step 19], time=0.04783916473388672, ext_time=0.023863554000854492, train_time=0.018318653106689453
[Epoch 3][Step 20], time=0.047023773193359375, ext_time=0.023651123046875, train_time=0.017934799194335938
[Epoch 3][Step 21], time=0.04720568656921387, ext_time=0.02375340461730957, train_time=0.017885923385620117
[Epoch 3][Step 22], time=0.04683947563171387, ext_time=0.023525476455688477, train_time=0.017774343490600586
[Epoch 3][Step 23], time=0.04743647575378418, ext_time=0.023766517639160156, train_time=0.01813507080078125
[Epoch 3][Step 24], time=0.04663372039794922, ext_time=0.023344039916992188, train_time=0.017733097076416016
[Epoch 3][Step 25], time=0.04672384262084961, ext_time=0.02342510223388672, train_time=0.01775836944580078
[Epoch 3][Step 26], time=0.04758644104003906, ext_time=0.02382183074951172, train_time=0.018098115921020508
[Epoch 3][Step 27], time=0.04674649238586426, ext_time=0.023236513137817383, train_time=0.01793050765991211
[Epoch 3][Step 28], time=0.04636025428771973, ext_time=0.023227214813232422, train_time=0.017655372619628906
[Epoch 3][Step 29], time=0.04702496528625488, ext_time=0.02343010902404785, train_time=0.01799464225769043
[Epoch 3][Step 30], time=0.046445369720458984, ext_time=0.023056745529174805, train_time=0.01790142059326172
[Epoch 3][Step 31], time=0.047986745834350586, ext_time=0.0240476131439209, train_time=0.01829075813293457
[Epoch 3][Step 32], time=0.04730534553527832, ext_time=0.023557662963867188, train_time=0.018187999725341797
[Epoch 3][Step 33], time=0.047688961029052734, ext_time=0.023710012435913086, train_time=0.0182187557220459
[Epoch 3][Step 34], time=0.04752206802368164, ext_time=0.02375030517578125, train_time=0.01811504364013672
[Epoch 3][Step 35], time=0.04682183265686035, ext_time=0.023159503936767578, train_time=0.01810765266418457
[Epoch 3][Step 36], time=0.04757070541381836, ext_time=0.023748397827148438, train_time=0.018220901489257812
[Epoch 3][Step 37], time=0.04732918739318848, ext_time=0.023571252822875977, train_time=0.01815938949584961
[Epoch 3][Step 38], time=0.04697608947753906, ext_time=0.0237119197845459, train_time=0.017651796340942383
[Epoch 3][Step 39], time=0.04719376564025879, ext_time=0.02382516860961914, train_time=0.01778554916381836
[Epoch 3][Step 40], time=0.04686093330383301, ext_time=0.0230257511138916, train_time=0.01834392547607422
[Epoch 3][Step 41], time=0.0466458797454834, ext_time=0.023159503936767578, train_time=0.01804637908935547
[Epoch 3][Step 42], time=0.04637026786804199, ext_time=0.02307438850402832, train_time=0.017807960510253906
[Epoch 3][Step 43], time=0.047275543212890625, ext_time=0.023701906204223633, train_time=0.01799488067626953
[Epoch 3][Step 44], time=0.04770922660827637, ext_time=0.023612499237060547, train_time=0.018543004989624023
[Epoch 3][Step 45], time=0.04757285118103027, ext_time=0.023745298385620117, train_time=0.018254995346069336
[Epoch 3][Step 46], time=0.048664093017578125, ext_time=0.024277687072753906, train_time=0.01867079734802246
[Epoch 3][Step 47], time=0.047536611557006836, ext_time=0.024007081985473633, train_time=0.017848730087280273
[Epoch 3][Step 48], time=0.04649543762207031, ext_time=0.02330493927001953, train_time=0.01770305633544922
[Epoch 3][Step 49], time=0.04735422134399414, ext_time=0.023543119430541992, train_time=0.018245458602905273
[Epoch 3][Step 50], time=0.047617435455322266, ext_time=0.02367234230041504, train_time=0.018270254135131836
[Epoch 3][Step 51], time=0.046471357345581055, ext_time=0.023218870162963867, train_time=0.017703771591186523
[Epoch 3][Step 52], time=0.047281503677368164, ext_time=0.023844480514526367, train_time=0.017862319946289062
[Epoch 3][Step 53], time=0.04652857780456543, ext_time=0.02324676513671875, train_time=0.017759084701538086
[Epoch 3][Step 54], time=0.04654431343078613, ext_time=0.023204803466796875, train_time=0.01782512664794922
[Epoch 3][Step 55], time=0.04746675491333008, ext_time=0.024001359939575195, train_time=0.017895221710205078
[Epoch 3][Step 56], time=0.046502113342285156, ext_time=0.023493051528930664, train_time=0.01755070686340332
[Epoch 3][Step 57], time=0.04691267013549805, ext_time=0.02366471290588379, train_time=0.017736196517944336
[Epoch 3][Step 58], time=0.04723191261291504, ext_time=0.023549556732177734, train_time=0.01815009117126465
[Epoch 3][Step 59], time=0.04706287384033203, ext_time=0.02367544174194336, train_time=0.017828702926635742
[Epoch 3][Step 60], time=0.04692578315734863, ext_time=0.023384809494018555, train_time=0.017981767654418945
[Epoch 3][Step 61], time=0.047071218490600586, ext_time=0.023572444915771484, train_time=0.017887592315673828
[Epoch 3][Step 62], time=0.047580718994140625, ext_time=0.023685693740844727, train_time=0.018291234970092773
[Epoch 3][Step 63], time=0.04643440246582031, ext_time=0.023084163665771484, train_time=0.0178530216217041
[Epoch 3][Step 64], time=0.046628713607788086, ext_time=0.023279190063476562, train_time=0.017835140228271484
[Epoch 3][Step 65], time=0.047298431396484375, ext_time=0.02365422248840332, train_time=0.018095970153808594
[Epoch 3][Step 66], time=0.04690384864807129, ext_time=0.023328065872192383, train_time=0.018036603927612305
[Epoch 3][Step 67], time=0.047003984451293945, ext_time=0.023326873779296875, train_time=0.01812005043029785
[Epoch 3][Step 68], time=0.046983957290649414, ext_time=0.023413896560668945, train_time=0.017976999282836914
[Epoch 3][Step 69], time=0.04706239700317383, ext_time=0.02345132827758789, train_time=0.017986059188842773
[Epoch 3][Step 70], time=0.046628475189208984, ext_time=0.023270368576049805, train_time=0.01784992218017578
[Epoch 3][Step 71], time=0.047187089920043945, ext_time=0.023710012435913086, train_time=0.01788163185119629
[Epoch 3][Step 72], time=0.04648447036743164, ext_time=0.02337479591369629, train_time=0.01762676239013672
[Epoch 3][Step 73], time=0.04661870002746582, ext_time=0.02326202392578125, train_time=0.017808198928833008
[Epoch 3][Step 74], time=0.04930567741394043, ext_time=0.023531436920166016, train_time=0.02026963233947754
[Epoch 3][Step 75], time=0.04699444770812988, ext_time=0.023387432098388672, train_time=0.01793360710144043
[Epoch 3][Step 76], time=0.04757523536682129, ext_time=0.024100542068481445, train_time=0.017874956130981445
[Epoch 3][Step 77], time=0.04910469055175781, ext_time=0.023312091827392578, train_time=0.018654823303222656
[Epoch 3][Step 78], time=0.04746842384338379, ext_time=0.023859500885009766, train_time=0.017975330352783203
[Epoch 3][Step 79], time=0.04682302474975586, ext_time=0.02355504035949707, train_time=0.017740964889526367
[Epoch 3][Step 80], time=0.047179222106933594, ext_time=0.02382040023803711, train_time=0.01779007911682129
[Epoch 3][Step 81], time=0.046962738037109375, ext_time=0.02368307113647461, train_time=0.01771378517150879
[Epoch 3][Step 82], time=0.04654574394226074, ext_time=0.023352384567260742, train_time=0.017696380615234375
[Epoch 3][Step 83], time=0.0463106632232666, ext_time=0.023138761520385742, train_time=0.01767730712890625
[Epoch 3][Step 84], time=0.047858238220214844, ext_time=0.023915767669677734, train_time=0.01832413673400879
[Epoch 3][Step 85], time=0.046811580657958984, ext_time=0.023430585861206055, train_time=0.01780843734741211
[Epoch 3][Step 86], time=0.04671144485473633, ext_time=0.023401260375976562, train_time=0.017771244049072266
[Epoch 3][Step 87], time=0.04655599594116211, ext_time=0.02338242530822754, train_time=0.017686128616333008
[Epoch 3][Step 88], time=0.04780316352844238, ext_time=0.023751258850097656, train_time=0.018467426300048828
[Epoch 3][Step 89], time=0.04647064208984375, ext_time=0.023253440856933594, train_time=0.017671823501586914
[Epoch 3][Step 90], time=0.04734444618225098, ext_time=0.023802518844604492, train_time=0.01792740821838379
[Epoch 3][Step 91], time=0.047081708908081055, ext_time=0.023447751998901367, train_time=0.018070220947265625
[Epoch 3][Step 92], time=0.047060251235961914, ext_time=0.023436307907104492, train_time=0.018084287643432617
[Epoch 3][Step 93], time=0.04729866981506348, ext_time=0.023528099060058594, train_time=0.018218517303466797
[Epoch 3][Step 94], time=0.04711151123046875, ext_time=0.023724079132080078, train_time=0.017798900604248047
[Epoch 3][Step 95], time=0.047243356704711914, ext_time=0.02385258674621582, train_time=0.01782822608947754
[Epoch 3][Step 96], time=0.047206878662109375, ext_time=0.02347278594970703, train_time=0.0182340145111084
[Epoch 3][Step 97], time=0.04695272445678711, ext_time=0.023372411727905273, train_time=0.01797795295715332
[Epoch 3][Step 98], time=0.047371864318847656, ext_time=0.02371668815612793, train_time=0.018080949783325195
[Epoch 3][Step 99], time=0.046975135803222656, ext_time=0.023511409759521484, train_time=0.017925500869750977
[Epoch 3][Step 100], time=0.04688072204589844, ext_time=0.02345728874206543, train_time=0.017815351486206055
[Epoch 3][Step 101], time=0.04736471176147461, ext_time=0.02361750602722168, train_time=0.018162012100219727
[Epoch 3][Step 102], time=0.04768180847167969, ext_time=0.02363443374633789, train_time=0.0184171199798584
[Epoch 3][Step 103], time=0.0472712516784668, ext_time=0.02327275276184082, train_time=0.018305063247680664
[Epoch 3][Step 104], time=0.04656815528869629, ext_time=0.023278236389160156, train_time=0.01775050163269043
[Epoch 3][Step 105], time=0.04651808738708496, ext_time=0.023066043853759766, train_time=0.017954349517822266
[Epoch 3][Step 106], time=0.04707002639770508, ext_time=0.023471355438232422, train_time=0.018088102340698242
[Epoch 3][Step 107], time=0.04719257354736328, ext_time=0.023523330688476562, train_time=0.018155813217163086
[Epoch 3][Step 108], time=0.046431779861450195, ext_time=0.023144960403442383, train_time=0.017731428146362305
[Epoch 3][Step 109], time=0.047125816345214844, ext_time=0.023488998413085938, train_time=0.018088340759277344
[Epoch 3][Step 110], time=0.04723620414733887, ext_time=0.023698091506958008, train_time=0.018010854721069336
[Epoch 3][Step 111], time=0.04697775840759277, ext_time=0.02294325828552246, train_time=0.018488645553588867
[Epoch 3][Step 112], time=0.04680681228637695, ext_time=0.02344679832458496, train_time=0.017795562744140625
[Epoch 3][Step 113], time=0.04725909233093262, ext_time=0.023810863494873047, train_time=0.01785111427307129
[Epoch 3][Step 114], time=0.04694199562072754, ext_time=0.023401498794555664, train_time=0.01799774169921875
[Epoch 3][Step 115], time=0.04701638221740723, ext_time=0.023473501205444336, train_time=0.01802515983581543
[Epoch 3][Step 116], time=0.047206878662109375, ext_time=0.023399829864501953, train_time=0.0182950496673584
[Epoch 3][Step 117], time=0.04692816734313965, ext_time=0.023481130599975586, train_time=0.017874956130981445
[Epoch 3][Step 118], time=0.047029972076416016, ext_time=0.023788928985595703, train_time=0.017647981643676758
[Epoch 3][Step 119], time=0.04648637771606445, ext_time=0.023146867752075195, train_time=0.017857789993286133
[Epoch 3][Step 120], time=0.051009178161621094, ext_time=0.023488521575927734, train_time=0.021984100341796875
[Epoch 3][Step 121], time=0.04662036895751953, ext_time=0.02323627471923828, train_time=0.017868995666503906
[Epoch 3][Step 122], time=0.04719376564025879, ext_time=0.023635149002075195, train_time=0.018039941787719727
[Epoch 3][Step 123], time=0.04732942581176758, ext_time=0.023596525192260742, train_time=0.018183469772338867
[Epoch 3][Step 124], time=0.047235965728759766, ext_time=0.023476123809814453, train_time=0.018152475357055664
[Epoch 3][Step 125], time=0.04608869552612305, ext_time=0.023075342178344727, train_time=0.017527103424072266
[Epoch 3][Step 126], time=0.04681730270385742, ext_time=0.02325153350830078, train_time=0.018047332763671875
[Epoch 3][Step 127], time=0.04729342460632324, ext_time=0.02374100685119629, train_time=0.017989397048950195
[Epoch 3][Step 128], time=0.04738116264343262, ext_time=0.02385115623474121, train_time=0.017983198165893555
[Epoch 3][Step 129], time=0.0469660758972168, ext_time=0.023561954498291016, train_time=0.017848730087280273
[Epoch 3][Step 130], time=0.04739952087402344, ext_time=0.023691177368164062, train_time=0.018127918243408203
[Epoch 3][Step 131], time=0.04680132865905762, ext_time=0.0233609676361084, train_time=0.017804384231567383
[Epoch 3][Step 132], time=0.04677939414978027, ext_time=0.02335953712463379, train_time=0.01784038543701172
[Epoch 3][Step 133], time=0.04735231399536133, ext_time=0.02385711669921875, train_time=0.01797032356262207
[Epoch 3][Step 134], time=0.046628713607788086, ext_time=0.023375511169433594, train_time=0.01779007911682129
[Epoch 3][Step 135], time=0.04706120491027832, ext_time=0.0230405330657959, train_time=0.018578529357910156
[Epoch 3][Step 136], time=0.04691195487976074, ext_time=0.023497819900512695, train_time=0.017856121063232422
[Epoch 3][Step 137], time=0.04653120040893555, ext_time=0.0233004093170166, train_time=0.01771688461303711
[Epoch 3][Step 138], time=0.04650402069091797, ext_time=0.023283720016479492, train_time=0.017689228057861328
[Epoch 3][Step 139], time=0.04640054702758789, ext_time=0.023202180862426758, train_time=0.01768803596496582
[Epoch 3][Step 140], time=0.047116994857788086, ext_time=0.02368903160095215, train_time=0.017840147018432617
[Epoch 3][Step 141], time=0.04725337028503418, ext_time=0.023850202560424805, train_time=0.017841815948486328
[Epoch 3][Step 142], time=0.046881675720214844, ext_time=0.02353978157043457, train_time=0.017808914184570312
[Epoch 3][Step 143], time=0.0474092960357666, ext_time=0.02388143539428711, train_time=0.017928600311279297
[Epoch 3][Step 144], time=0.046366214752197266, ext_time=0.02294754981994629, train_time=0.01801466941833496
[Epoch 3][Step 145], time=0.04744243621826172, ext_time=0.02402210235595703, train_time=0.017818212509155273
[Epoch 3][Step 146], time=0.04693102836608887, ext_time=0.023487091064453125, train_time=0.017926454544067383
[Epoch 3][Step 147], time=0.04670977592468262, ext_time=0.02342534065246582, train_time=0.017752885818481445
[Epoch 3][Step 148], time=0.046874284744262695, ext_time=0.023558855056762695, train_time=0.017786502838134766
[Epoch 3][Step 149], time=0.047081947326660156, ext_time=0.023595571517944336, train_time=0.01790928840637207
[Epoch 3][Step 150], time=0.04659676551818848, ext_time=0.023052692413330078, train_time=0.01806473731994629
[Epoch 3][Step 151], time=0.04692435264587402, ext_time=0.02340531349182129, train_time=0.018024921417236328
[Epoch 3][Step 152], time=0.047086477279663086, ext_time=0.0234525203704834, train_time=0.01810312271118164
[Epoch 3][Step 153], time=0.04646563529968262, ext_time=0.023192882537841797, train_time=0.017775535583496094
[Epoch 3][Step 154], time=0.04692506790161133, ext_time=0.02359294891357422, train_time=0.0177915096282959
[Epoch 3][Step 155], time=0.04712796211242676, ext_time=0.023723125457763672, train_time=0.01785731315612793
[Epoch 3][Step 156], time=0.04689979553222656, ext_time=0.0236055850982666, train_time=0.017754793167114258
[Epoch 3][Step 157], time=0.04664015769958496, ext_time=0.022990703582763672, train_time=0.018210411071777344
[Epoch 3][Step 158], time=0.046219587326049805, ext_time=0.022960424423217773, train_time=0.017791748046875
[Epoch 3][Step 159], time=0.04649043083190918, ext_time=0.023168325424194336, train_time=0.01775217056274414
[Epoch 3][Step 160], time=0.04713892936706543, ext_time=0.023613929748535156, train_time=0.01797032356262207
[Epoch 3][Step 161], time=0.0470125675201416, ext_time=0.02367115020751953, train_time=0.01778721809387207
[Epoch 3][Step 162], time=0.04690074920654297, ext_time=0.02356243133544922, train_time=0.017796754837036133
[Epoch 3][Step 163], time=0.04678845405578613, ext_time=0.023464441299438477, train_time=0.01779341697692871
[Epoch 3][Step 164], time=0.046495914459228516, ext_time=0.0233004093170166, train_time=0.017676115036010742
[Epoch 3][Step 165], time=0.04700112342834473, ext_time=0.023249149322509766, train_time=0.018207311630249023
[Epoch 3][Step 166], time=0.04654693603515625, ext_time=0.02346038818359375, train_time=0.017623424530029297
[Epoch 3][Step 167], time=0.04715418815612793, ext_time=0.023592472076416016, train_time=0.018043994903564453
[Epoch 3][Step 168], time=0.04640603065490723, ext_time=0.023157119750976562, train_time=0.017712831497192383
[Epoch 3][Step 169], time=0.04684257507324219, ext_time=0.023375988006591797, train_time=0.017887592315673828
[Epoch 3][Step 170], time=0.0467679500579834, ext_time=0.022963762283325195, train_time=0.018357276916503906
[Epoch 3][Step 171], time=0.04674530029296875, ext_time=0.023433923721313477, train_time=0.01775503158569336
[Epoch 3][Step 172], time=0.05067563056945801, ext_time=0.02409839630126953, train_time=0.019123554229736328
[Epoch 3][Step 173], time=0.04693293571472168, ext_time=0.023222923278808594, train_time=0.01810431480407715
[Epoch 3][Step 174], time=0.046210527420043945, ext_time=0.022894620895385742, train_time=0.017817020416259766
[Epoch 3][Step 175], time=0.04677414894104004, ext_time=0.02361321449279785, train_time=0.017611265182495117
[Epoch 3][Step 176], time=0.04640650749206543, ext_time=0.023259878158569336, train_time=0.01761794090270996
[Epoch 3][Step 177], time=0.046843528747558594, ext_time=0.02359795570373535, train_time=0.017684221267700195
[Epoch 3][Step 178], time=0.04694342613220215, ext_time=0.02355194091796875, train_time=0.017827272415161133
[Epoch 3][Step 179], time=0.046599388122558594, ext_time=0.02327752113342285, train_time=0.017793893814086914
[Epoch 3][Step 180], time=0.04705929756164551, ext_time=0.023660898208618164, train_time=0.017830610275268555
[Epoch 3][Step 181], time=0.04665875434875488, ext_time=0.023378372192382812, train_time=0.0178525447845459
[Epoch 3][Step 182], time=0.047304391860961914, ext_time=0.023726701736450195, train_time=0.018008947372436523
[Epoch 3][Step 183], time=0.04633975028991699, ext_time=0.023096084594726562, train_time=0.01770615577697754
[Epoch 3][Step 184], time=0.04643607139587402, ext_time=0.023067712783813477, train_time=0.017953872680664062
[Epoch 3][Step 185], time=0.046885013580322266, ext_time=0.023496627807617188, train_time=0.01781630516052246
[Epoch 3][Step 186], time=0.0481867790222168, ext_time=0.0231325626373291, train_time=0.018157243728637695
[Epoch 3][Step 187], time=0.04680180549621582, ext_time=0.023329973220825195, train_time=0.017929553985595703
[Epoch 3][Step 188], time=0.046853065490722656, ext_time=0.023432016372680664, train_time=0.017879486083984375
[Epoch 3][Step 189], time=0.047060489654541016, ext_time=0.0236661434173584, train_time=0.017828941345214844
[Epoch 3][Step 190], time=0.04651999473571777, ext_time=0.0234377384185791, train_time=0.01761031150817871
[Epoch 3][Step 191], time=0.04737591743469238, ext_time=0.02387404441833496, train_time=0.017911434173583984
[Epoch 3][Step 192], time=0.0465545654296875, ext_time=0.02330946922302246, train_time=0.017731904983520508
[Epoch 3][Step 193], time=0.04699087142944336, ext_time=0.023610353469848633, train_time=0.017813682556152344
[Epoch 3][Step 194], time=0.04683876037597656, ext_time=0.023476600646972656, train_time=0.017787694931030273
[Epoch 3][Step 195], time=0.047075748443603516, ext_time=0.023668289184570312, train_time=0.01783466339111328
[Epoch 3][Step 196], time=0.04662632942199707, ext_time=0.023412466049194336, train_time=0.017702579498291016
[Epoch 3][Step 197], time=0.046649932861328125, ext_time=0.023398160934448242, train_time=0.017740726470947266
[Epoch 3][Step 198], time=0.04770517349243164, ext_time=0.024059057235717773, train_time=0.01799488067626953
[Epoch 3][Step 199], time=0.04711413383483887, ext_time=0.023679256439208984, train_time=0.01789116859436035
[Epoch 3][Step 200], time=0.04708218574523926, ext_time=0.023401737213134766, train_time=0.018008708953857422
[Epoch 3][Step 201], time=0.04710650444030762, ext_time=0.023355484008789062, train_time=0.01819777488708496
[Epoch 3][Step 202], time=0.04732990264892578, ext_time=0.02382802963256836, train_time=0.01790595054626465
[Epoch 3][Step 203], time=0.04734349250793457, ext_time=0.023746728897094727, train_time=0.01802349090576172
[Epoch 3][Step 204], time=0.04682183265686035, ext_time=0.023266077041625977, train_time=0.017957687377929688
[Epoch 3][Step 205], time=0.04746675491333008, ext_time=0.023610830307006836, train_time=0.018213510513305664
[Epoch 3][Step 206], time=0.047162771224975586, ext_time=0.023581981658935547, train_time=0.017945051193237305
[Epoch 3][Step 207], time=0.047013044357299805, ext_time=0.023528099060058594, train_time=0.01787424087524414
[Epoch 3][Step 208], time=0.046636343002319336, ext_time=0.02335953712463379, train_time=0.017745018005371094
[Epoch 3][Step 209], time=0.047008514404296875, ext_time=0.02367377281188965, train_time=0.017771244049072266
[Epoch 3][Step 210], time=0.04633188247680664, ext_time=0.02322864532470703, train_time=0.01763129234313965
[Epoch 3][Step 211], time=0.046651601791381836, ext_time=0.02354574203491211, train_time=0.01764225959777832
[Epoch 3][Step 212], time=0.046844482421875, ext_time=0.023456096649169922, train_time=0.017826080322265625
[Epoch 3][Step 213], time=0.04793715476989746, ext_time=0.0238802433013916, train_time=0.018442153930664062
[Epoch 3][Step 214], time=0.048891544342041016, ext_time=0.02398228645324707, train_time=0.01917862892150879
[Epoch 3][Step 215], time=0.047902822494506836, ext_time=0.02408289909362793, train_time=0.01818561553955078
[Epoch 3][Step 216], time=0.046794891357421875, ext_time=0.023324012756347656, train_time=0.01788783073425293
[Epoch 3][Step 217], time=0.04642534255981445, ext_time=0.023151159286499023, train_time=0.01780986785888672
[Epoch 3][Step 218], time=0.046608686447143555, ext_time=0.023471832275390625, train_time=0.017655134201049805
[Epoch 3][Step 219], time=0.04712653160095215, ext_time=0.023626089096069336, train_time=0.017908573150634766
[Epoch 3][Step 220], time=0.0471041202545166, ext_time=0.02367687225341797, train_time=0.01786518096923828
[Epoch 3][Step 221], time=0.0464015007019043, ext_time=0.02326488494873047, train_time=0.017653703689575195
[Epoch 3][Step 222], time=0.04642319679260254, ext_time=0.023242950439453125, train_time=0.01768207550048828
[Epoch 3][Step 223], time=0.048182010650634766, ext_time=0.023675203323364258, train_time=0.018945693969726562
[Epoch 3][Step 224], time=0.04743003845214844, ext_time=0.023970842361450195, train_time=0.01786208152770996
[Epoch 3][Step 225], time=0.046746253967285156, ext_time=0.02343130111694336, train_time=0.017772674560546875
[Epoch 3][Step 226], time=0.04639148712158203, ext_time=0.023169755935668945, train_time=0.017712831497192383
[Epoch 3][Step 227], time=0.04764413833618164, ext_time=0.023718595504760742, train_time=0.018349409103393555
[Epoch 3][Step 228], time=0.04737496376037598, ext_time=0.023570537567138672, train_time=0.018191814422607422
[Epoch 3][Step 229], time=0.04712843894958496, ext_time=0.023612260818481445, train_time=0.018002986907958984
[Epoch 3][Step 230], time=0.04691767692565918, ext_time=0.023567914962768555, train_time=0.017824649810791016
[Epoch 3][Step 231], time=0.04684877395629883, ext_time=0.023581266403198242, train_time=0.017746686935424805
[Epoch 3][Step 232], time=0.047040700912475586, ext_time=0.023637056350708008, train_time=0.01786637306213379
[Epoch 3][Step 233], time=0.046672821044921875, ext_time=0.023688554763793945, train_time=0.017397403717041016
[Epoch 3][Step 234], time=0.04679560661315918, ext_time=0.023767948150634766, train_time=0.01745319366455078
[Epoch 3][Step 235], time=0.046346426010131836, ext_time=0.02307295799255371, train_time=0.01775813102722168
[Epoch 3][Step 236], time=0.04741477966308594, ext_time=0.024043560028076172, train_time=0.017810344696044922
[Epoch 3][Step 237], time=0.04723715782165527, ext_time=0.02352452278137207, train_time=0.018195629119873047
[Epoch 3][Step 238], time=0.04659390449523926, ext_time=0.023430824279785156, train_time=0.01768946647644043
[Epoch 3][Step 239], time=0.04732561111450195, ext_time=0.02370476722717285, train_time=0.017992258071899414
[Epoch 3][Step 240], time=0.04650449752807617, ext_time=0.023194551467895508, train_time=0.01777195930480957
[Epoch 3][Step 241], time=0.04661846160888672, ext_time=0.02310776710510254, train_time=0.018010854721069336
[Epoch 3][Step 242], time=0.04683542251586914, ext_time=0.023434162139892578, train_time=0.017801284790039062
[Epoch 3][Step 243], time=0.04704165458679199, ext_time=0.02371048927307129, train_time=0.017780542373657227
[Epoch 3][Step 244], time=0.046689510345458984, ext_time=0.02320551872253418, train_time=0.01798701286315918
[Epoch 3][Step 245], time=0.0474550724029541, ext_time=0.02364206314086914, train_time=0.018256664276123047
[Epoch 3][Step 246], time=0.04661703109741211, ext_time=0.023001909255981445, train_time=0.018120288848876953
[Epoch 3][Step 247], time=0.04859471321105957, ext_time=0.023792505264282227, train_time=0.01784515380859375
[Epoch 3][Step 248], time=0.04637432098388672, ext_time=0.023092985153198242, train_time=0.017843961715698242
[Epoch 3][Step 249], time=0.04691314697265625, ext_time=0.02332329750061035, train_time=0.01805257797241211
[Epoch 3], time=11.778939962387085, loss=0.6931472420692444
    [Step(average) Profiler Level 1 E3 S999]
        L1  sample           0.005415 | send           0.000000
        L1  recv             0.000000 | copy           0.023396 | convert time 0.000000 | train  0.018031
        L1  feature nbytes  479.13 MB | label nbytes 0.00 Bytes
        L1  id nbytes      0.00 Bytes | graph nbytes 0.00 Bytes
        L1  miss nbytes    0.00 Bytes | remote nbytes 0.00 Bytes
        L1  num nodes               0 | num samples           0
        L1  seq duration     0.000000 | refresh duration   0.000000
    [Step(average) Profiler Level 2 E3 S999]
        L2  shuffle     0.000000 | core sample  0.000000 | id remap        0.000000
        L2  graph copy  0.000000 | id copy      0.000000 | cache feat copy 0.023396
        L2  last layer sample time 0.000000 | size 0.000000
    [Step(average) Profiler Level 3 E3 S999]
        L3  khop sample coo  0.000000 | khop sort coo      0.000000 | khop count edge     0.000000 | khop compact edge 0.000000
        L3  walk sample coo  0.000000 | walk topk total    0.000000 | walk topk step1     0.000000 | walk topk step2   0.000000
        L3  walk topk step3  0.000000 | walk topk step4    0.000000 | walk topk step5     0.000000
        L3  walk topk step6  0.000000 | walk topk step7    0.000000
        L3  remap unique     0.000000 | remap populate     0.000000 | remap mapnode       0.000000 | remap mapedge     0.000000
        L3  cache get_index  0.000618 | cache copy_index   0.000000 | cache extract_miss  0.000000
        L3  cache copy_miss  0.000000 | cache combine_miss 0.000000 | cache combine cache 0.022740 | cache combine remote 0.000000
        L3  label extract  0.000000
    [Profiler Level Percentiles E3 S999]
        p50.00_tail_logl2featcopy=0.023405
        p90.00_tail_logl2featcopy=0.023742
        p95.00_tail_logl2featcopy=0.023841
        p99.00_tail_logl2featcopy=0.024020
        p99.90_tail_logl2featcopy=0.026186
[CUDA] cuda: usage: 14.25 GB
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   77221 KB |    1014 MB |    3630 GB |    3630 GB |
|       from large pool |   65582 KB |    1001 MB |    3588 GB |    3588 GB |
|       from small pool |   11639 KB |      21 MB |      41 GB |      41 GB |
|---------------------------------------------------------------------------|
| Active memory         |   77221 KB |    1014 MB |    3630 GB |    3630 GB |
|       from large pool |   65582 KB |    1001 MB |    3588 GB |    3588 GB |
|       from small pool |   11639 KB |      21 MB |      41 GB |      41 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    3566 MB |    3566 MB |    3566 MB |       0 B  |
|       from large pool |    3536 MB |    3536 MB |    3536 MB |       0 B  |
|       from small pool |      30 MB |      30 MB |      30 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  780891 KB |    1628 MB |    3289 GB |    3289 GB |
|       from large pool |  770002 KB |    1621 MB |    3246 GB |    3245 GB |
|       from small pool |   10889 KB |      17 MB |      43 GB |      43 GB |
|---------------------------------------------------------------------------|
| Allocations           |      69    |      99    |  320299    |  320230    |
|       from large pool |      13    |      24    |   94514    |   94501    |
|       from small pool |      56    |      79    |  225785    |  225729    |
|---------------------------------------------------------------------------|
| Active allocs         |      69    |      99    |  320299    |  320230    |
|       from large pool |      13    |      24    |   94514    |   94501    |
|       from small pool |      56    |      79    |  225785    |  225729    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      30    |      30    |      30    |       0    |
|       from large pool |      15    |      15    |      15    |       0    |
|       from small pool |      15    |      15    |      15    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      37    |      48    |  113881    |  113844    |
|       from large pool |      10    |      17    |   49384    |   49374    |
|       from small pool |      27    |      38    |   64497    |   64470    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[TRAIN_TIME] train time is 48.089018 seconds
[EPOCH_TIME] 12.022255 seconds, maybe large due to not enough epoch skipped.
[EPOCH_TIME] 11.754288 seconds
worker 3 running with pid=47455
loading train edge idx from disk
loading train edge idx from disk done
tensor([ 367470406, 3158702471, 3196913887,  537616058, 2622541626, 2707306334,
        2288750783,  341639546, 2394912536,   38094375,  701084300, 1665128055,
        3225579545,  811343571,  534157746,  726851972, 1000854521, 1061370191,
         597404666,  526478766,  499672205, 1382980281, 1363464091,  971316959,
        1643305663, 1559556869,  792051811, 2593715952, 2627476216,  869058904,
        1279512108,  281028249, 2848334841, 1142277951, 1624797255, 1682408139,
         514723102,  756902533, 1190696744, 1515340461,  396873136, 3079813016,
         574876927,   31156367,  833957351, 1664434120,  774080817, 2850247945,
         655998496,  888602410,  350570870,  850355735,   69778231,  638128676,
        1443388341, 1479712286, 2858804367,  550628163,  198023098, 2583590303,
        2518492873,    2593795, 2722269746,  659106604, 1369497066,  461650496,
         645516367, 3053389785,  148119355,  792250187, 1401047469, 1545651011,
        1827797263, 1275030316, 2075895474, 2919804301, 2493902937,  112768749,
          11701078,  726712463,  404737965,  786261376,  934911988,  757583227,
        1135493038, 3162165660, 1144120843, 2861906075,  226440368, 1866677628,
         329488287,   67449549, 1840253021,  973854642,  422444545, 3025516425,
         133597469,  981523193, 2348166713,  306896793])
Rank=3, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.007310, per step: 0.000029
presamping
presamping takes 15.506067276000977
worker 1 running with pid=47452
loading train edge idx from disk
loading train edge idx from disk done
tensor([ 367470406, 3158702471, 3196913887,  537616058, 2622541626, 2707306334,
        2288750783,  341639546, 2394912536,   38094375,  701084300, 1665128055,
        3225579545,  811343571,  534157746,  726851972, 1000854521, 1061370191,
         597404666,  526478766,  499672205, 1382980281, 1363464091,  971316959,
        1643305663, 1559556869,  792051811, 2593715952, 2627476216,  869058904,
        1279512108,  281028249, 2848334841, 1142277951, 1624797255, 1682408139,
         514723102,  756902533, 1190696744, 1515340461,  396873136, 3079813016,
         574876927,   31156367,  833957351, 1664434120,  774080817, 2850247945,
         655998496,  888602410,  350570870,  850355735,   69778231,  638128676,
        1443388341, 1479712286, 2858804367,  550628163,  198023098, 2583590303,
        2518492873,    2593795, 2722269746,  659106604, 1369497066,  461650496,
         645516367, 3053389785,  148119355,  792250187, 1401047469, 1545651011,
        1827797263, 1275030316, 2075895474, 2919804301, 2493902937,  112768749,
          11701078,  726712463,  404737965,  786261376,  934911988,  757583227,
        1135493038, 3162165660, 1144120843, 2861906075,  226440368, 1866677628,
         329488287,   67449549, 1840253021,  973854642,  422444545, 3025516425,
         133597469,  981523193, 2348166713,  306896793])
Rank=1, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.011273, per step: 0.000045
presamping
presamping takes 12.872874021530151
worker 2 running with pid=47453
loading train edge idx from disk
loading train edge idx from disk done
tensor([ 367470406, 3158702471, 3196913887,  537616058, 2622541626, 2707306334,
        2288750783,  341639546, 2394912536,   38094375,  701084300, 1665128055,
        3225579545,  811343571,  534157746,  726851972, 1000854521, 1061370191,
         597404666,  526478766,  499672205, 1382980281, 1363464091,  971316959,
        1643305663, 1559556869,  792051811, 2593715952, 2627476216,  869058904,
        1279512108,  281028249, 2848334841, 1142277951, 1624797255, 1682408139,
         514723102,  756902533, 1190696744, 1515340461,  396873136, 3079813016,
         574876927,   31156367,  833957351, 1664434120,  774080817, 2850247945,
         655998496,  888602410,  350570870,  850355735,   69778231,  638128676,
        1443388341, 1479712286, 2858804367,  550628163,  198023098, 2583590303,
        2518492873,    2593795, 2722269746,  659106604, 1369497066,  461650496,
         645516367, 3053389785,  148119355,  792250187, 1401047469, 1545651011,
        1827797263, 1275030316, 2075895474, 2919804301, 2493902937,  112768749,
          11701078,  726712463,  404737965,  786261376,  934911988,  757583227,
        1135493038, 3162165660, 1144120843, 2861906075,  226440368, 1866677628,
         329488287,   67449549, 1840253021,  973854642,  422444545, 3025516425,
         133597469,  981523193, 2348166713,  306896793])
Rank=2, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.007832, per step: 0.000031
presamping
presamping takes 16.779853105545044

