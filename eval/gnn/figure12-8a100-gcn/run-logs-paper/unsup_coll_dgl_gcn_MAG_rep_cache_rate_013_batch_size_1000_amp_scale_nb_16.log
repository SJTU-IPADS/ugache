succeed=True
[CUDA] cuda: usage: 6.56 GB
0 :  {link #0 : 1}, {link #1 : 2}, {link #2 : 3}, {link #3 : 4}, {link #4 : 5}, {link #5 : 6}, {link #6 : 7},
1 :  {link #0 : 2}, {link #1 : 3}, {link #2 : 4}, {link #3 : 5}, {link #4 : 6}, {link #5 : 7}, {link #6 : 0},
2 :  {link #0 : 3}, {link #1 : 4}, {link #2 : 5}, {link #3 : 6}, {link #4 : 7}, {link #5 : 0}, {link #6 : 1},
3 :  {link #0 : 4}, {link #1 : 5}, {link #2 : 6}, {link #3 : 7}, {link #4 : 0}, {link #5 : 1}, {link #6 : 2},
4 :  {link #0 : 5}, {link #1 : 6}, {link #2 : 7}, {link #3 : 0}, {link #4 : 1}, {link #5 : 2}, {link #6 : 3},
5 :  {link #0 : 6}, {link #1 : 7}, {link #2 : 0}, {link #3 : 1}, {link #4 : 2}, {link #5 : 3}, {link #6 : 4},
6 :  {link #0 : 7}, {link #1 : 0}, {link #2 : 1}, {link #3 : 2}, {link #4 : 3}, {link #5 : 4}, {link #6 : 5},
7 :  {link #0 : 0}, {link #1 : 1}, {link #2 : 2}, {link #3 : 3}, {link #4 : 4}, {link #5 : 5}, {link #6 : 6},
0 : local 108, cpu 0 {link #0 : g1 0}, {link #1 : g2 0}, {link #2 : g3 0}, {link #3 : g4 0}, {link #4 : g5 0}, {link #5 : g6 0}, {link #6 : g7 0},
1 : local 108, cpu 0 {link #0 : g2 0}, {link #1 : g3 0}, {link #2 : g4 0}, {link #3 : g5 0}, {link #4 : g6 0}, {link #5 : g7 0}, {link #6 : g0 0},
2 : local 108, cpu 0 {link #0 : g3 0}, {link #1 : g4 0}, {link #2 : g5 0}, {link #3 : g6 0}, {link #4 : g7 0}, {link #5 : g0 0}, {link #6 : g1 0},
3 : local 108, cpu 0 {link #0 : g4 0}, {link #1 : g5 0}, {link #2 : g6 0}, {link #3 : g7 0}, {link #4 : g0 0}, {link #5 : g1 0}, {link #6 : g2 0},
4 : local 108, cpu 0 {link #0 : g5 0}, {link #1 : g6 0}, {link #2 : g7 0}, {link #3 : g0 0}, {link #4 : g1 0}, {link #5 : g2 0}, {link #6 : g3 0},
5 : local 108, cpu 0 {link #0 : g6 0}, {link #1 : g7 0}, {link #2 : g0 0}, {link #3 : g1 0}, {link #4 : g2 0}, {link #5 : g3 0}, {link #6 : g4 0},
6 : local 108, cpu 0 {link #0 : g7 0}, {link #1 : g0 0}, {link #2 : g1 0}, {link #3 : g2 0}, {link #4 : g3 0}, {link #5 : g4 0}, {link #6 : g5 0},
7 : local 108, cpu 0 {link #0 : g0 0}, {link #1 : g1 0}, {link #2 : g2 0}, {link #3 : g3 0}, {link #4 : g4 0}, {link #5 : g5 0}, {link #6 : g6 0},
0 :  {link #0 : 1}, {link #1 : 2}, {link #2 : 3}, {link #3 : 4}, {link #4 : 5}, {link #5 : 6}, {link #6 : 7},
1 :  {link #0 : 2}, {link #1 : 3}, {link #2 : 4}, {link #3 : 5}, {link #4 : 6}, {link #5 : 7}, {link #6 : 0},
2 :  {link #0 : 3}, {link #1 : 4}, {link #2 : 5}, {link #3 : 6}, {link #4 : 7}, {link #5 : 0}, {link #6 : 1},
3 :  {link #0 : 4}, {link #1 : 5}, {link #2 : 6}, {link #3 : 7}, {link #4 : 0}, {link #5 : 1}, {link #6 : 2},
4 :  {link #0 : 5}, {link #1 : 6}, {link #2 : 7}, {link #3 : 0}, {link #4 : 1}, {link #5 : 2}, {link #6 : 3},
5 :  {link #0 : 6}, {link #1 : 7}, {link #2 : 0}, {link #3 : 1}, {link #4 : 2}, {link #5 : 3}, {link #6 : 4},
6 :  {link #0 : 7}, {link #1 : 0}, {link #2 : 1}, {link #3 : 2}, {link #4 : 3}, {link #5 : 4}, {link #6 : 5},
7 :  {link #0 : 0}, {link #1 : 1}, {link #2 : 2}, {link #3 : 3}, {link #4 : 4}, {link #5 : 5}, {link #6 : 6},
0 : local 108, cpu 0 {link #0 : g1 0}, {link #1 : g2 0}, {link #2 : g3 0}, {link #3 : g4 0}, {link #4 : g5 0}, {link #5 : g6 0}, {link #6 : g7 0},
1 : local 108, cpu 0 {link #0 : g2 0}, {link #1 : g3 0}, {link #2 : g4 0}, {link #3 : g5 0}, {link #4 : g6 0}, {link #5 : g7 0}, {link #6 : g0 0},
2 : local 108, cpu 0 {link #0 : g3 0}, {link #1 : g4 0}, {link #2 : g5 0}, {link #3 : g6 0}, {link #4 : g7 0}, {link #5 : g0 0}, {link #6 : g1 0},
3 : local 108, cpu 0 {link #0 : g4 0}, {link #1 : g5 0}, {link #2 : g6 0}, {link #3 : g7 0}, {link #4 : g0 0}, {link #5 : g1 0}, {link #6 : g2 0},
4 : local 108, cpu 0 {link #0 : g5 0}, {link #1 : g6 0}, {link #2 : g7 0}, {link #3 : g0 0}, {link #4 : g1 0}, {link #5 : g2 0}, {link #6 : g3 0},
5 : local 108, cpu 0 {link #0 : g6 0}, {link #1 : g7 0}, {link #2 : g0 0}, {link #3 : g1 0}, {link #4 : g2 0}, {link #5 : g3 0}, {link #6 : g4 0},
6 : local 108, cpu 0 {link #0 : g7 0}, {link #1 : g0 0}, {link #2 : g1 0}, {link #3 : g2 0}, {link #4 : g3 0}, {link #5 : g4 0}, {link #6 : g5 0},
7 : local 108, cpu 0 {link #0 : g0 0}, {link #1 : g1 0}, {link #2 : g2 0}, {link #3 : g3 0}, {link #4 : g4 0}, {link #5 : g5 0}, {link #6 : g6 0},
0 :  {link #0 : 1}, {link #1 : 2}, {link #2 : 3}, {link #3 : 4}, {link #4 : 5}, {link #5 : 6}, {link #6 : 7},
1 :  {link #0 : 2}, {link #1 : 3}, {link #2 : 4}, {link #3 : 5}, {link #4 : 6}, {link #5 : 7}, {link #6 : 0},
2 :  {link #0 : 3}, {link #1 : 4}, {link #2 : 5}, {link #3 : 6}, {link #4 : 7}, {link #5 : 0}, {link #6 : 1},
3 :  {link #0 : 4}, {link #1 : 5}, {link #2 : 6}, {link #3 : 7}, {link #4 : 0}, {link #5 : 1}, {link #6 : 2},
4 :  {link #0 : 5}, {link #1 : 6}, {link #2 : 7}, {link #3 : 0}, {link #4 : 1}, {link #5 : 2}, {link #6 : 3},
5 :  {link #0 : 6}, {link #1 : 7}, {link #2 : 0}, {link #3 : 1}, {link #4 : 2}, {link #5 : 3}, {link #6 : 4},
6 :  {link #0 : 7}, {link #1 : 0}, {link #2 : 1}, {link #3 : 2}, {link #4 : 3}, {link #5 : 4}, {link #6 : 5},
7 :  {link #0 : 0}, {link #1 : 1}, {link #2 : 2}, {link #3 : 3}, {link #4 : 4}, {link #5 : 5}, {link #6 : 6},
0 : local 108, cpu 0 {link #0 : g1 0}, {link #1 : g2 0}, {link #2 : g3 0}, {link #3 : g4 0}, {link #4 : g5 0}, {link #5 : g6 0}, {link #6 : g7 0},
1 : local 108, cpu 0 {link #0 : g2 0}, {link #1 : g3 0}, {link #2 : g4 0}, {link #3 : g5 0}, {link #4 : g6 0}, {link #5 : g7 0}, {link #6 : g0 0},
2 : local 108, cpu 0 {link #0 : g3 0}, {link #1 : g4 0}, {link #2 : g5 0}, {link #3 : g6 0}, {link #4 : g7 0}, {link #5 : g0 0}, {link #6 : g1 0},
3 : local 108, cpu 0 {link #0 : g4 0}, {link #1 : g5 0}, {link #2 : g6 0}, {link #3 : g7 0}, {link #4 : g0 0}, {link #5 : g1 0}, {link #6 : g2 0},
4 : local 108, cpu 0 {link #0 : g5 0}, {link #1 : g6 0}, {link #2 : g7 0}, {link #3 : g0 0}, {link #4 : g1 0}, {link #5 : g2 0}, {link #6 : g3 0},
5 : local 108, cpu 0 {link #0 : g6 0}, {link #1 : g7 0}, {link #2 : g0 0}, {link #3 : g1 0}, {link #4 : g2 0}, {link #5 : g3 0}, {link #6 : g4 0},
6 : local 108, cpu 0 {link #0 : g7 0}, {link #1 : g0 0}, {link #2 : g1 0}, {link #3 : g2 0}, {link #4 : g3 0}, {link #5 : g4 0}, {link #6 : g5 0},
7 : local 108, cpu 0 {link #0 : g0 0}, {link #1 : g1 0}, {link #2 : g2 0}, {link #3 : g3 0}, {link #4 : g4 0}, {link #5 : g5 0}, {link #6 : g6 0},
0 :  {link #0 : 1}, {link #1 : 2}, {link #2 : 3}, {link #3 : 4}, {link #4 : 5}, {link #5 : 6}, {link #6 : 7},
1 :  {link #0 : 2}, {link #1 : 3}, {link #2 : 4}, {link #3 : 5}, {link #4 : 6}, {link #5 : 7}, {link #6 : 0},
2 :  {link #0 : 3}, {link #1 : 4}, {link #2 : 5}, {link #3 : 6}, {link #4 : 7}, {link #5 : 0}, {link #6 : 1},
3 :  {link #0 : 4}, {link #1 : 5}, {link #2 : 6}, {link #3 : 7}, {link #4 : 0}, {link #5 : 1}, {link #6 : 2},
4 :  {link #0 : 5}, {link #1 : 6}, {link #2 : 7}, {link #3 : 0}, {link #4 : 1}, {link #5 : 2}, {link #6 : 3},
5 :  {link #0 : 6}, {link #1 : 7}, {link #2 : 0}, {link #3 : 1}, {link #4 : 2}, {link #5 : 3}, {link #6 : 4},
6 :  {link #0 : 7}, {link #1 : 0}, {link #2 : 1}, {link #3 : 2}, {link #4 : 3}, {link #5 : 4}, {link #6 : 5},
7 :  {link #0 : 0}, {link #1 : 1}, {link #2 : 2}, {link #3 : 3}, {link #4 : 4}, {link #5 : 5}, {link #6 : 6},
0 : local 108, cpu 0 {link #0 : g1 0}, {link #1 : g2 0}, {link #2 : g3 0}, {link #3 : g4 0}, {link #4 : g5 0}, {link #5 : g6 0}, {link #6 : g7 0},
1 : local 108, cpu 0 {link #0 : g2 0}, {link #1 : g3 0}, {link #2 : g4 0}, {link #3 : g5 0}, {link #4 : g6 0}, {link #5 : g7 0}, {link #6 : g0 0},
2 : local 108, cpu 0 {link #0 : g3 0}, {link #1 : g4 0}, {link #2 : g5 0}, {link #3 : g6 0}, {link #4 : g7 0}, {link #5 : g0 0}, {link #6 : g1 0},
3 : local 108, cpu 0 {link #0 : g4 0}, {link #1 : g5 0}, {link #2 : g6 0}, {link #3 : g7 0}, {link #4 : g0 0}, {link #5 : g1 0}, {link #6 : g2 0},
4 : local 108, cpu 0 {link #0 : g5 0}, {link #1 : g6 0}, {link #2 : g7 0}, {link #3 : g0 0}, {link #4 : g1 0}, {link #5 : g2 0}, {link #6 : g3 0},
5 : local 108, cpu 0 {link #0 : g6 0}, {link #1 : g7 0}, {link #2 : g0 0}, {link #3 : g1 0}, {link #4 : g2 0}, {link #5 : g3 0}, {link #6 : g4 0},
6 : local 108, cpu 0 {link #0 : g7 0}, {link #1 : g0 0}, {link #2 : g1 0}, {link #3 : g2 0}, {link #4 : g3 0}, {link #5 : g4 0}, {link #6 : g5 0},
7 : local 108, cpu 0 {link #0 : g0 0}, {link #1 : g1 0}, {link #2 : g2 0}, {link #3 : g3 0}, {link #4 : g4 0}, {link #5 : g5 0}, {link #6 : g6 0},
0 :  {link #0 : 1}, {link #1 : 2}, {link #2 : 3}, {link #3 : 4}, {link #4 : 5}, {link #5 : 6}, {link #6 : 7},
1 :  {link #0 : 2}, {link #1 : 3}, {link #2 : 4}, {link #3 : 5}, {link #4 : 6}, {link #5 : 7}, {link #6 : 0},
2 :  {link #0 : 3}, {link #1 : 4}, {link #2 : 5}, {link #3 : 6}, {link #4 : 7}, {link #5 : 0}, {link #6 : 1},
3 :  {link #0 : 4}, {link #1 : 5}, {link #2 : 6}, {link #3 : 7}, {link #4 : 0}, {link #5 : 1}, {link #6 : 2},
4 :  {link #0 : 5}, {link #1 : 6}, {link #2 : 7}, {link #3 : 0}, {link #4 : 1}, {link #5 : 2}, {link #6 : 3},
5 :  {link #0 : 6}, {link #1 : 7}, {link #2 : 0}, {link #3 : 1}, {link #4 : 2}, {link #5 : 3}, {link #6 : 4},
6 :  {link #0 : 7}, {link #1 : 0}, {link #2 : 1}, {link #3 : 2}, {link #4 : 3}, {link #5 : 4}, {link #6 : 5},
7 :  {link #0 : 0}, {link #1 : 1}, {link #2 : 2}, {link #3 : 3}, {link #4 : 4}, {link #5 : 5}, {link #6 : 6},
0 : local 108, cpu 0 {link #0 : g1 0}, {link #1 : g2 0}, {link #2 : g3 0}, {link #3 : g4 0}, {link #4 : g5 0}, {link #5 : g6 0}, {link #6 : g7 0},
1 : local 108, cpu 0 {link #0 : g2 0}, {link #1 : g3 0}, {link #2 : g4 0}, {link #3 : g5 0}, {link #4 : g6 0}, {link #5 : g7 0}, {link #6 : g0 0},
2 : local 108, cpu 0 {link #0 : g3 0}, {link #1 : g4 0}, {link #2 : g5 0}, {link #3 : g6 0}, {link #4 : g7 0}, {link #5 : g0 0}, {link #6 : g1 0},
3 : local 108, cpu 0 {link #0 : g4 0}, {link #1 : g5 0}, {link #2 : g6 0}, {link #3 : g7 0}, {link #4 : g0 0}, {link #5 : g1 0}, {link #6 : g2 0},
4 : local 108, cpu 0 {link #0 : g5 0}, {link #1 : g6 0}, {link #2 : g7 0}, {link #3 : g0 0}, {link #4 : g1 0}, {link #5 : g2 0}, {link #6 : g3 0},
5 : local 108, cpu 0 {link #0 : g6 0}, {link #1 : g7 0}, {link #2 : g0 0}, {link #3 : g1 0}, {link #4 : g2 0}, {link #5 : g3 0}, {link #6 : g4 0},
6 : local 108, cpu 0 {link #0 : g7 0}, {link #1 : g0 0}, {link #2 : g1 0}, {link #3 : g2 0}, {link #4 : g3 0}, {link #5 : g4 0}, {link #6 : g5 0},
7 : local 108, cpu 0 {link #0 : g0 0}, {link #1 : g1 0}, {link #2 : g2 0}, {link #3 : g3 0}, {link #4 : g4 0}, {link #5 : g5 0}, {link #6 : g6 0},
0 :  {link #0 : 1}, {link #1 : 2}, {link #2 : 3}, {link #3 : 4}, {link #4 : 5}, {link #5 : 6}, {link #6 : 7},
1 :  {link #0 : 2}, {link #1 : 3}, {link #2 : 4}, {link #3 : 5}, {link #4 : 6}, {link #5 : 7}, {link #6 : 0},
2 :  {link #0 : 3}, {link #1 : 4}, {link #2 : 5}, {link #3 : 6}, {link #4 : 7}, {link #5 : 0}, {link #6 : 1},
3 :  {link #0 : 4}, {link #1 : 5}, {link #2 : 6}, {link #3 : 7}, {link #4 : 0}, {link #5 : 1}, {link #6 : 2},
4 :  {link #0 : 5}, {link #1 : 6}, {link #2 : 7}, {link #3 : 0}, {link #4 : 1}, {link #5 : 2}, {link #6 : 3},
5 :  {link #0 : 6}, {link #1 : 7}, {link #2 : 0}, {link #3 : 1}, {link #4 : 2}, {link #5 : 3}, {link #6 : 4},
6 :  {link #0 : 7}, {link #1 : 0}, {link #2 : 1}, {link #3 : 2}, {link #4 : 3}, {link #5 : 4}, {link #6 : 5},
7 :  {link #0 : 0}, {link #1 : 1}, {link #2 : 2}, {link #3 : 3}, {link #4 : 4}, {link #5 : 5}, {link #6 : 6},
0 : local 108, cpu 0 {link #0 : g1 0}, {link #1 : g2 0}, {link #2 : g3 0}, {link #3 : g4 0}, {link #4 : g5 0}, {link #5 : g6 0}, {link #6 : g7 0},
1 : local 108, cpu 0 {link #0 : g2 0}, {link #1 : g3 0}, {link #2 : g4 0}, {link #3 : g5 0}, {link #4 : g6 0}, {link #5 : g7 0}, {link #6 : g0 0},
2 : local 108, cpu 0 {link #0 : g3 0}, {link #1 : g4 0}, {link #2 : g5 0}, {link #3 : g6 0}, {link #4 : g7 0}, {link #5 : g0 0}, {link #6 : g1 0},
3 : local 108, cpu 0 {link #0 : g4 0}, {link #1 : g5 0}, {link #2 : g6 0}, {link #3 : g7 0}, {link #4 : g0 0}, {link #5 : g1 0}, {link #6 : g2 0},
4 : local 108, cpu 0 {link #0 : g5 0}, {link #1 : g6 0}, {link #2 : g7 0}, {link #3 : g0 0}, {link #4 : g1 0}, {link #5 : g2 0}, {link #6 : g3 0},
5 : local 108, cpu 0 {link #0 : g6 0}, {link #1 : g7 0}, {link #2 : g0 0}, {link #3 : g1 0}, {link #4 : g2 0}, {link #5 : g3 0}, {link #6 : g4 0},
6 : local 108, cpu 0 {link #0 : g7 0}, {link #1 : g0 0}, {link #2 : g1 0}, {link #3 : g2 0}, {link #4 : g3 0}, {link #5 : g4 0}, {link #6 : g5 0},
7 : local 108, cpu 0 {link #0 : g0 0}, {link #1 : g1 0}, {link #2 : g2 0}, {link #3 : g3 0}, {link #4 : g4 0}, {link #5 : g5 0}, {link #6 : g6 0},
0 :  {link #0 : 1}, {link #1 : 2}, {link #2 : 3}, {link #3 : 4}, {link #4 : 5}, {link #5 : 6}, {link #6 : 7},
1 :  {link #0 : 2}, {link #1 : 3}, {link #2 : 4}, {link #3 : 5}, {link #4 : 6}, {link #5 : 7}, {link #6 : 0},
2 :  {link #0 : 3}, {link #1 : 4}, {link #2 : 5}, {link #3 : 6}, {link #4 : 7}, {link #5 : 0}, {link #6 : 1},
3 :  {link #0 : 4}, {link #1 : 5}, {link #2 : 6}, {link #3 : 7}, {link #4 : 0}, {link #5 : 1}, {link #6 : 2},
4 :  {link #0 : 5}, {link #1 : 6}, {link #2 : 7}, {link #3 : 0}, {link #4 : 1}, {link #5 : 2}, {link #6 : 3},
5 :  {link #0 : 6}, {link #1 : 7}, {link #2 : 0}, {link #3 : 1}, {link #4 : 2}, {link #5 : 3}, {link #6 : 4},
6 :  {link #0 : 7}, {link #1 : 0}, {link #2 : 1}, {link #3 : 2}, {link #4 : 3}, {link #5 : 4}, {link #6 : 5},
7 :  {link #0 : 0}, {link #1 : 1}, {link #2 : 2}, {link #3 : 3}, {link #4 : 4}, {link #5 : 5}, {link #6 : 6},
0 : local 108, cpu 0 {link #0 : g1 0}, {link #1 : g2 0}, {link #2 : g3 0}, {link #3 : g4 0}, {link #4 : g5 0}, {link #5 : g6 0}, {link #6 : g7 0},
1 : local 108, cpu 0 {link #0 : g2 0}, {link #1 : g3 0}, {link #2 : g4 0}, {link #3 : g5 0}, {link #4 : g6 0}, {link #5 : g7 0}, {link #6 : g0 0},
2 : local 108, cpu 0 {link #0 : g3 0}, {link #1 : g4 0}, {link #2 : g5 0}, {link #3 : g6 0}, {link #4 : g7 0}, {link #5 : g0 0}, {link #6 : g1 0},
3 : local 108, cpu 0 {link #0 : g4 0}, {link #1 : g5 0}, {link #2 : g6 0}, {link #3 : g7 0}, {link #4 : g0 0}, {link #5 : g1 0}, {link #6 : g2 0},
4 : local 108, cpu 0 {link #0 : g5 0}, {link #1 : g6 0}, {link #2 : g7 0}, {link #3 : g0 0}, {link #4 : g1 0}, {link #5 : g2 0}, {link #6 : g3 0},
5 : local 108, cpu 0 {link #0 : g6 0}, {link #1 : g7 0}, {link #2 : g0 0}, {link #3 : g1 0}, {link #4 : g2 0}, {link #5 : g3 0}, {link #6 : g4 0},
6 : local 108, cpu 0 {link #0 : g7 0}, {link #1 : g0 0}, {link #2 : g1 0}, {link #3 : g2 0}, {link #4 : g3 0}, {link #5 : g4 0}, {link #6 : g5 0},
7 : local 108, cpu 0 {link #0 : g0 0}, {link #1 : g1 0}, {link #2 : g2 0}, {link #3 : g3 0}, {link #4 : g4 0}, {link #5 : g5 0}, {link #6 : g6 0},
0 :  {link #0 : 1}, {link #1 : 2}, {link #2 : 3}, {link #3 : 4}, {link #4 : 5}, {link #5 : 6}, {link #6 : 7},
1 :  {link #0 : 2}, {link #1 : 3}, {link #2 : 4}, {link #3 : 5}, {link #4 : 6}, {link #5 : 7}, {link #6 : 0},
2 :  {link #0 : 3}, {link #1 : 4}, {link #2 : 5}, {link #3 : 6}, {link #4 : 7}, {link #5 : 0}, {link #6 : 1},
3 :  {link #0 : 4}, {link #1 : 5}, {link #2 : 6}, {link #3 : 7}, {link #4 : 0}, {link #5 : 1}, {link #6 : 2},
4 :  {link #0 : 5}, {link #1 : 6}, {link #2 : 7}, {link #3 : 0}, {link #4 : 1}, {link #5 : 2}, {link #6 : 3},
5 :  {link #0 : 6}, {link #1 : 7}, {link #2 : 0}, {link #3 : 1}, {link #4 : 2}, {link #5 : 3}, {link #6 : 4},
6 :  {link #0 : 7}, {link #1 : 0}, {link #2 : 1}, {link #3 : 2}, {link #4 : 3}, {link #5 : 4}, {link #6 : 5},
7 :  {link #0 : 0}, {link #1 : 1}, {link #2 : 2}, {link #3 : 3}, {link #4 : 4}, {link #5 : 5}, {link #6 : 6},
0 : local 108, cpu 0 {link #0 : g1 0}, {link #1 : g2 0}, {link #2 : g3 0}, {link #3 : g4 0}, {link #4 : g5 0}, {link #5 : g6 0}, {link #6 : g7 0},
1 : local 108, cpu 0 {link #0 : g2 0}, {link #1 : g3 0}, {link #2 : g4 0}, {link #3 : g5 0}, {link #4 : g6 0}, {link #5 : g7 0}, {link #6 : g0 0},
2 : local 108, cpu 0 {link #0 : g3 0}, {link #1 : g4 0}, {link #2 : g5 0}, {link #3 : g6 0}, {link #4 : g7 0}, {link #5 : g0 0}, {link #6 : g1 0},
3 : local 108, cpu 0 {link #0 : g4 0}, {link #1 : g5 0}, {link #2 : g6 0}, {link #3 : g7 0}, {link #4 : g0 0}, {link #5 : g1 0}, {link #6 : g2 0},
4 : local 108, cpu 0 {link #0 : g5 0}, {link #1 : g6 0}, {link #2 : g7 0}, {link #3 : g0 0}, {link #4 : g1 0}, {link #5 : g2 0}, {link #6 : g3 0},
5 : local 108, cpu 0 {link #0 : g6 0}, {link #1 : g7 0}, {link #2 : g0 0}, {link #3 : g1 0}, {link #4 : g2 0}, {link #5 : g3 0}, {link #6 : g4 0},
6 : local 108, cpu 0 {link #0 : g7 0}, {link #1 : g0 0}, {link #2 : g1 0}, {link #3 : g2 0}, {link #4 : g3 0}, {link #5 : g4 0}, {link #6 : g5 0},
7 : local 108, cpu 0 {link #0 : g0 0}, {link #1 : g1 0}, {link #2 : g2 0}, {link #3 : g3 0}, {link #4 : g4 0}, {link #5 : g5 0}, {link #6 : g6 0},
coll_cache:optimal_rep_storage=0.13
coll_cache:optimal_part_storage=0
coll_cache:optimal_cpu_storage=0.87
coll_cache:optimal_local_storage=0.13
coll_cache:optimal_remote_storage=0
coll_cache:optimal_local_rate=0.799361
coll_cache:optimal_remote_rate=0
coll_cache:optimal_cpu_rate=0.200639
z=48711.5
test_result:init:feat_nbytes=375030526464
test_result:init:cache_nbytes=49128998400
test_result:init:feat_nbytes=375030526464
test_result:init:cache_nbytes=49128998400
test_result:init:feat_nbytes=375030526464
test_result:init:cache_nbytes=49128998400
test_result:init:feat_nbytes=375030526464
test_result:init:cache_nbytes=49128998400
test_result:init:feat_nbytes=375030526464
test_result:init:cache_nbytes=49128998400
test_result:init:feat_nbytes=375030526464
test_result:init:cache_nbytes=49128998400
test_result:init:feat_nbytes=375030526464
test_result:init:cache_nbytes=49128998400
test_result:init:feat_nbytes=375030526464
test_result:init:cache_nbytes=49128998400
worker 0 running with pid=61408
config:eval_tsp="2023-08-06 19:04:29"
config:num_worker=8
config:num_intra_size=8
config:root_dir=/datasets_gnn/wholegraph
config:graph_name=mag240m-homo
config:epochs=4
config:batchsize=1000
config:skip_epoch=2
config:local_step=250
config:presc_epoch=2
config:neighbors=15,10,5
config:hiddensize=256
config:num_layer=3
config:model=gcn
config:framework=dgl
config:dataloaderworkers=0
config:dropout=0.5
config:weight_decay=0.0005
config:lr=0.003
config:use_nccl=False
config:use_amp=True
config:use_collcache=True
config:cache_percentage=0.13
config:cache_policy=rep
config:omp_thread_num=56
config:unsupervised=True
config:classnum=153
config:global_barrier=<multiprocessing.synchronize.Barrier object at 0x7f435679b970>
config:worker_id=0
creating_intra_node_communicator root=0, local_size=8, world_size=8
loading train edge idx from disk
loading train edge idx from disk done
tensor([ 367470406, 3158702471, 3196913887,  311268946, 2622541626, 2707306334,
        2288750783,  341639546, 2394912536, 3266219078,  474737188, 1665128055,
        3225579545,  584996459,  307810634,  726851972, 1000854521, 1061370191,
         371057554,  526478766,  273325093, 1382980281, 1363464091,  971316959,
        1643305663, 1559556869,  792051811, 2593715952, 2627476216,  642711792,
        1279512108,  281028249, 2848334841, 1142277951, 1624797255, 1682408139,
         288375990,  530555421, 1190696744, 1515340461,  396873136, 3079813016,
         574876927,   31156367,  607610239, 1664434120,  774080817, 2850247945,
         655998496,  888602410,  350570870,  624008623,   69778231,  638128676,
        1443388341, 1479712286, 2858804367,  550628163,  198023098, 2583590303,
        2518492873,    2593795, 2722269746,  659106604, 1369497066,  235303384,
         645516367, 3053389785, 3376243999,  792250187, 1401047469, 1545651011,
        1827797263, 1275030316, 2075895474, 2919804301, 2493902937,  112768749,
          11701078,  500365351,  404737965,  786261376,  934911988,  757583227,
        1135493038, 3162165660, 1144120843, 2861906075,      93256, 1866677628,
         103141175, 3295574170, 1840253021,  747507530,  196097433, 3025516425,
         133597469,  755176081, 2348166713,   80549681])
Rank=0, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.008993, per step: 0.000036
epoch=4 total_steps=1000
presamping
presamping takes 20.139203786849976
start training...
[Epoch 0][Step 0], time=1.8054533004760742, ext_time=0.05690145492553711, train_time=1.7416448593139648
[Epoch 0][Step 1], time=0.11333751678466797, ext_time=0.040763139724731445, train_time=0.06658053398132324
[Epoch 0][Step 2], time=0.09727859497070312, ext_time=0.03999972343444824, train_time=0.052205801010131836
[Epoch 0][Step 3], time=0.08311700820922852, ext_time=0.03989076614379883, train_time=0.03820514678955078
[Epoch 0][Step 4], time=0.09415984153747559, ext_time=0.04082608222961426, train_time=0.04832148551940918
[Epoch 0][Step 5], time=0.08550095558166504, ext_time=0.04037594795227051, train_time=0.04010319709777832
[Epoch 0][Step 6], time=0.08681249618530273, ext_time=0.039048194885253906, train_time=0.0428464412689209
[Epoch 0][Step 7], time=0.08594894409179688, ext_time=0.04036235809326172, train_time=0.04057788848876953
[Epoch 0][Step 8], time=0.08495330810546875, ext_time=0.039557695388793945, train_time=0.04042863845825195
[Epoch 0][Step 9], time=0.3005208969116211, ext_time=0.0404818058013916, train_time=0.2550346851348877
[Epoch 0][Step 10], time=0.0877385139465332, ext_time=0.04065060615539551, train_time=0.04199576377868652
[Epoch 0][Step 11], time=0.08340573310852051, ext_time=0.039588212966918945, train_time=0.03884601593017578
[Epoch 0][Step 12], time=0.08379626274108887, ext_time=0.040524959564208984, train_time=0.03829383850097656
[Epoch 0][Step 13], time=0.08277583122253418, ext_time=0.039994001388549805, train_time=0.037741899490356445
[Epoch 0][Step 14], time=0.09865808486938477, ext_time=0.04078221321105957, train_time=0.0528101921081543
[Epoch 0][Step 15], time=0.08404088020324707, ext_time=0.04016685485839844, train_time=0.03889942169189453
[Epoch 0][Step 16], time=0.08290553092956543, ext_time=0.03948235511779785, train_time=0.038446903228759766
[Epoch 0][Step 17], time=0.278186559677124, ext_time=0.03980112075805664, train_time=0.2334272861480713
[Epoch 0][Step 18], time=0.0839235782623291, ext_time=0.040465593338012695, train_time=0.03847646713256836
[Epoch 0][Step 19], time=0.08287286758422852, ext_time=0.0400547981262207, train_time=0.03785586357116699
[Epoch 0][Step 20], time=0.08324456214904785, ext_time=0.0393214225769043, train_time=0.038951873779296875
[Epoch 0][Step 21], time=0.08794760704040527, ext_time=0.04092288017272949, train_time=0.04196286201477051
[Epoch 0][Step 22], time=0.08292078971862793, ext_time=0.04055047035217285, train_time=0.03737688064575195
[Epoch 0][Step 23], time=0.08270812034606934, ext_time=0.04005694389343262, train_time=0.03770732879638672
[Epoch 0][Step 24], time=0.0828554630279541, ext_time=0.04029130935668945, train_time=0.03763437271118164
[Epoch 0][Step 25], time=0.08351659774780273, ext_time=0.04076194763183594, train_time=0.03775930404663086
[Epoch 0][Step 26], time=0.08354568481445312, ext_time=0.04080629348754883, train_time=0.037705183029174805
[Epoch 0][Step 27], time=0.08546781539916992, ext_time=0.040407419204711914, train_time=0.04003190994262695
[Epoch 0][Step 28], time=0.09244036674499512, ext_time=0.04097175598144531, train_time=0.046407461166381836
[Epoch 0][Step 29], time=0.08332538604736328, ext_time=0.04043865203857422, train_time=0.03786826133728027
[Epoch 0][Step 30], time=0.08344149589538574, ext_time=0.039563894271850586, train_time=0.03890085220336914
[Epoch 0][Step 31], time=0.08290672302246094, ext_time=0.03957509994506836, train_time=0.0383913516998291
[Epoch 0][Step 32], time=0.08282279968261719, ext_time=0.039891958236694336, train_time=0.03799080848693848
[Epoch 0][Step 33], time=0.08291244506835938, ext_time=0.03853940963745117, train_time=0.03943157196044922
[Epoch 0][Step 34], time=0.08283019065856934, ext_time=0.03993368148803711, train_time=0.03798675537109375
[Epoch 0][Step 35], time=0.08271408081054688, ext_time=0.03986334800720215, train_time=0.03793978691101074
[Epoch 0][Step 36], time=0.08246922492980957, ext_time=0.04030013084411621, train_time=0.037189483642578125
[Epoch 0][Step 37], time=0.083343505859375, ext_time=0.03996729850769043, train_time=0.038399457931518555
[Epoch 0][Step 38], time=0.08184337615966797, ext_time=0.03972458839416504, train_time=0.03719925880432129
[Epoch 0][Step 39], time=0.08263158798217773, ext_time=0.03951764106750488, train_time=0.03819704055786133
[Epoch 0][Step 40], time=0.08280062675476074, ext_time=0.039576053619384766, train_time=0.03820943832397461
[Epoch 0][Step 41], time=0.0832834243774414, ext_time=0.03996753692626953, train_time=0.038285255432128906
[Epoch 0][Step 42], time=0.08323907852172852, ext_time=0.04041337966918945, train_time=0.03776812553405762
[Epoch 0][Step 43], time=0.08136606216430664, ext_time=0.03942108154296875, train_time=0.03704643249511719
[Epoch 0][Step 44], time=0.08350276947021484, ext_time=0.0407559871673584, train_time=0.03769421577453613
[Epoch 0][Step 45], time=0.08359909057617188, ext_time=0.040435791015625, train_time=0.0381622314453125
[Epoch 0][Step 46], time=0.08281111717224121, ext_time=0.039556264877319336, train_time=0.03831124305725098
[Epoch 0][Step 47], time=0.30130481719970703, ext_time=0.03990483283996582, train_time=0.25646233558654785
[Epoch 0][Step 48], time=0.1202859878540039, ext_time=0.039969682693481445, train_time=0.07527446746826172
[Epoch 0][Step 49], time=0.08434796333312988, ext_time=0.040299415588378906, train_time=0.03905344009399414
[Epoch 0][Step 50], time=0.08322834968566895, ext_time=0.03920388221740723, train_time=0.039037227630615234
[Epoch 0][Step 51], time=0.08826780319213867, ext_time=0.04012417793273926, train_time=0.04312729835510254
[Epoch 0][Step 52], time=0.0822458267211914, ext_time=0.03943490982055664, train_time=0.03785395622253418
[Epoch 0][Step 53], time=0.08328771591186523, ext_time=0.040490150451660156, train_time=0.03776431083679199
[Epoch 0][Step 54], time=0.08336400985717773, ext_time=0.040148019790649414, train_time=0.03826117515563965
[Epoch 0][Step 55], time=0.08636856079101562, ext_time=0.04028820991516113, train_time=0.04111313819885254
[Epoch 0][Step 56], time=0.08251690864562988, ext_time=0.040322065353393555, train_time=0.037268877029418945
[Epoch 0][Step 57], time=0.5910682678222656, ext_time=0.039309024810791016, train_time=0.5468428134918213
[Epoch 0][Step 58], time=0.08263993263244629, ext_time=0.03994560241699219, train_time=0.03739738464355469
[Epoch 0][Step 59], time=0.08331489562988281, ext_time=0.0391688346862793, train_time=0.03913617134094238
[Epoch 0][Step 60], time=0.0820624828338623, ext_time=0.03954601287841797, train_time=0.037532806396484375
[Epoch 0][Step 61], time=0.08298754692077637, ext_time=0.04018354415893555, train_time=0.03783607482910156
[Epoch 0][Step 62], time=0.08281087875366211, ext_time=0.04037332534790039, train_time=0.03740811347961426
[Epoch 0][Step 63], time=0.08287477493286133, ext_time=0.03927493095397949, train_time=0.03869152069091797
[Epoch 0][Step 64], time=0.08405137062072754, ext_time=0.03981757164001465, train_time=0.039327144622802734
[Epoch 0][Step 65], time=0.0835716724395752, ext_time=0.040868520736694336, train_time=0.03766632080078125
[Epoch 0][Step 66], time=0.08297157287597656, ext_time=0.04015970230102539, train_time=0.037316083908081055
[Epoch 0][Step 67], time=0.08321404457092285, ext_time=0.03976297378540039, train_time=0.03846430778503418
[Epoch 0][Step 68], time=0.08396339416503906, ext_time=0.03990745544433594, train_time=0.03912615776062012
[Epoch 0][Step 69], time=0.08302021026611328, ext_time=0.03959369659423828, train_time=0.03849530220031738
[Epoch 0][Step 70], time=0.08330965042114258, ext_time=0.040769338607788086, train_time=0.03757286071777344
[Epoch 0][Step 71], time=0.08263611793518066, ext_time=0.03965616226196289, train_time=0.03802680969238281
[Epoch 0][Step 72], time=0.08290362358093262, ext_time=0.040465593338012695, train_time=0.03747105598449707
[Epoch 0][Step 73], time=0.08380770683288574, ext_time=0.04046797752380371, train_time=0.038355112075805664
[Epoch 0][Step 74], time=0.08245182037353516, ext_time=0.04007744789123535, train_time=0.03737235069274902
[Epoch 0][Step 75], time=0.08284163475036621, ext_time=0.04010295867919922, train_time=0.03775930404663086
[Epoch 0][Step 76], time=0.0830087661743164, ext_time=0.04016399383544922, train_time=0.03781723976135254
[Epoch 0][Step 77], time=0.08309555053710938, ext_time=0.04048967361450195, train_time=0.03759908676147461
[Epoch 0][Step 78], time=0.08647608757019043, ext_time=0.04026985168457031, train_time=0.04126310348510742
[Epoch 0][Step 79], time=0.08268952369689941, ext_time=0.03978562355041504, train_time=0.038033246994018555
[Epoch 0][Step 80], time=0.08274149894714355, ext_time=0.039867401123046875, train_time=0.03797316551208496
[Epoch 0][Step 81], time=0.08216261863708496, ext_time=0.039246559143066406, train_time=0.038038015365600586
[Epoch 0][Step 82], time=0.08272409439086914, ext_time=0.04001450538635254, train_time=0.03768157958984375
[Epoch 0][Step 83], time=0.08405113220214844, ext_time=0.040712833404541016, train_time=0.03832840919494629
[Epoch 0][Step 84], time=0.08284568786621094, ext_time=0.04048609733581543, train_time=0.03739356994628906
[Epoch 0][Step 85], time=0.08565020561218262, ext_time=0.0402219295501709, train_time=0.04045724868774414
[Epoch 0][Step 86], time=0.0822896957397461, ext_time=0.03955507278442383, train_time=0.03777503967285156
[Epoch 0][Step 87], time=0.0824429988861084, ext_time=0.03958582878112793, train_time=0.03795742988586426
[Epoch 0][Step 88], time=0.08249592781066895, ext_time=0.03967165946960449, train_time=0.03791022300720215
[Epoch 0][Step 89], time=0.08223533630371094, ext_time=0.039838552474975586, train_time=0.03742790222167969
[Epoch 0][Step 90], time=0.08318734169006348, ext_time=0.04049348831176758, train_time=0.0376734733581543
[Epoch 0][Step 91], time=0.08304023742675781, ext_time=0.040534257888793945, train_time=0.03750157356262207
[Epoch 0][Step 92], time=0.08358383178710938, ext_time=0.04030323028564453, train_time=0.038324594497680664
[Epoch 0][Step 93], time=0.08255314826965332, ext_time=0.03972053527832031, train_time=0.03785586357116699
[Epoch 0][Step 94], time=0.08295822143554688, ext_time=0.03936028480529785, train_time=0.03863525390625
[Epoch 0][Step 95], time=0.08261942863464355, ext_time=0.03958702087402344, train_time=0.0380856990814209
[Epoch 0][Step 96], time=0.08355951309204102, ext_time=0.04010820388793945, train_time=0.038468360900878906
[Epoch 0][Step 97], time=0.606816291809082, ext_time=0.03979921340942383, train_time=0.5619423389434814
[Epoch 0][Step 98], time=0.08317708969116211, ext_time=0.039467811584472656, train_time=0.03868889808654785
[Epoch 0][Step 99], time=0.0842752456665039, ext_time=0.039786338806152344, train_time=0.03951692581176758
[Epoch 0][Step 100], time=0.08266019821166992, ext_time=0.03851723670959473, train_time=0.03920483589172363
[Epoch 0][Step 101], time=0.08327317237854004, ext_time=0.03977775573730469, train_time=0.03855633735656738
[Epoch 0][Step 102], time=0.0836477279663086, ext_time=0.04060840606689453, train_time=0.03801321983337402
[Epoch 0][Step 103], time=0.08745193481445312, ext_time=0.04034996032714844, train_time=0.04202699661254883
[Epoch 0][Step 104], time=0.08302688598632812, ext_time=0.0399019718170166, train_time=0.038062334060668945
[Epoch 0][Step 105], time=0.08282160758972168, ext_time=0.04002213478088379, train_time=0.03781461715698242
[Epoch 0][Step 106], time=0.08274579048156738, ext_time=0.040259599685668945, train_time=0.03749561309814453
[Epoch 0][Step 107], time=0.08272457122802734, ext_time=0.03995251655578613, train_time=0.03780651092529297
[Epoch 0][Step 108], time=0.0831289291381836, ext_time=0.03942561149597168, train_time=0.0387578010559082
[Epoch 0][Step 109], time=0.08250570297241211, ext_time=0.0398714542388916, train_time=0.03769373893737793
[Epoch 0][Step 110], time=0.08377718925476074, ext_time=0.04067802429199219, train_time=0.038073062896728516
[Epoch 0][Step 111], time=0.0833432674407959, ext_time=0.04034590721130371, train_time=0.03802847862243652
[Epoch 0][Step 112], time=0.08222556114196777, ext_time=0.03956151008605957, train_time=0.037680625915527344
[Epoch 0][Step 113], time=0.0821828842163086, ext_time=0.03959989547729492, train_time=0.03766131401062012
[Epoch 0][Step 114], time=0.0861666202545166, ext_time=0.04070425033569336, train_time=0.04041481018066406
[Epoch 0][Step 115], time=0.08305478096008301, ext_time=0.039296865463256836, train_time=0.03882908821105957
[Epoch 0][Step 116], time=0.08256793022155762, ext_time=0.03965926170349121, train_time=0.03795170783996582
[Epoch 0][Step 117], time=0.08263802528381348, ext_time=0.040259361267089844, train_time=0.037387847900390625
[Epoch 0][Step 118], time=0.08245682716369629, ext_time=0.03970932960510254, train_time=0.0377352237701416
[Epoch 0][Step 119], time=0.08320236206054688, ext_time=0.04041314125061035, train_time=0.03780245780944824
[Epoch 0][Step 120], time=0.4032096862792969, ext_time=0.040506601333618164, train_time=0.3576674461364746
[Epoch 0][Step 121], time=0.0830390453338623, ext_time=0.040456295013427734, train_time=0.03759598731994629
[Epoch 0][Step 122], time=0.08375692367553711, ext_time=0.03960466384887695, train_time=0.039206743240356445
[Epoch 0][Step 123], time=0.09098029136657715, ext_time=0.04011058807373047, train_time=0.04588890075683594
[Epoch 0][Step 124], time=0.09636640548706055, ext_time=0.0397646427154541, train_time=0.038961172103881836
[Epoch 0][Step 125], time=0.08289408683776855, ext_time=0.04107499122619629, train_time=0.03690147399902344
[Epoch 0][Step 126], time=0.08257913589477539, ext_time=0.04004335403442383, train_time=0.03760027885437012
[Epoch 0][Step 127], time=0.08790206909179688, ext_time=0.039821624755859375, train_time=0.04314303398132324
[Epoch 0][Step 128], time=0.08300375938415527, ext_time=0.04012656211853027, train_time=0.0378873348236084
[Epoch 0][Step 129], time=0.08278656005859375, ext_time=0.039991140365600586, train_time=0.03786063194274902
[Epoch 0][Step 130], time=0.08231306076049805, ext_time=0.03972363471984863, train_time=0.03762531280517578
[Epoch 0][Step 131], time=0.08246302604675293, ext_time=0.039481163024902344, train_time=0.038012027740478516
[Epoch 0][Step 132], time=0.08257579803466797, ext_time=0.039528608322143555, train_time=0.03811955451965332
[Epoch 0][Step 133], time=0.08227825164794922, ext_time=0.03942370414733887, train_time=0.03787112236022949
[Epoch 0][Step 134], time=0.08291339874267578, ext_time=0.04034781455993652, train_time=0.03750252723693848
[Epoch 0][Step 135], time=0.0833137035369873, ext_time=0.040770769119262695, train_time=0.03750181198120117
[Epoch 0][Step 136], time=0.08345246315002441, ext_time=0.03810930252075195, train_time=0.040505170822143555
[Epoch 0][Step 137], time=0.08334803581237793, ext_time=0.0406498908996582, train_time=0.0377655029296875
[Epoch 0][Step 138], time=0.08267474174499512, ext_time=0.03947949409484863, train_time=0.038204193115234375
[Epoch 0][Step 139], time=0.08313822746276855, ext_time=0.040128469467163086, train_time=0.038016557693481445
[Epoch 0][Step 140], time=0.08292937278747559, ext_time=0.03934621810913086, train_time=0.03870224952697754
[Epoch 0][Step 141], time=0.08422470092773438, ext_time=0.040735721588134766, train_time=0.03847336769104004
[Epoch 0][Step 142], time=0.08298969268798828, ext_time=0.040155887603759766, train_time=0.037873268127441406
[Epoch 0][Step 143], time=0.08220553398132324, ext_time=0.040108442306518555, train_time=0.037145376205444336
[Epoch 0][Step 144], time=0.08368420600891113, ext_time=0.03989243507385254, train_time=0.038840532302856445
[Epoch 0][Step 145], time=0.08334946632385254, ext_time=0.04088091850280762, train_time=0.03744006156921387
[Epoch 0][Step 146], time=0.08427214622497559, ext_time=0.04003715515136719, train_time=0.03931021690368652
[Epoch 0][Step 147], time=0.08341431617736816, ext_time=0.04014730453491211, train_time=0.03827404975891113
[Epoch 0][Step 148], time=0.08276128768920898, ext_time=0.0402066707611084, train_time=0.037595272064208984
[Epoch 0][Step 149], time=0.08243250846862793, ext_time=0.03999018669128418, train_time=0.03753018379211426
[Epoch 0][Step 150], time=0.0841822624206543, ext_time=0.03949761390686035, train_time=0.03971266746520996
[Epoch 0][Step 151], time=0.08406662940979004, ext_time=0.04102730751037598, train_time=0.03797721862792969
[Epoch 0][Step 152], time=0.08226227760314941, ext_time=0.03943896293640137, train_time=0.03783369064331055
[Epoch 0][Step 153], time=0.08341073989868164, ext_time=0.04000997543334961, train_time=0.03844261169433594
[Epoch 0][Step 154], time=0.08312630653381348, ext_time=0.03917527198791504, train_time=0.03793764114379883
[Epoch 0][Step 155], time=0.08265328407287598, ext_time=0.03959012031555176, train_time=0.03814244270324707
[Epoch 0][Step 156], time=0.08239316940307617, ext_time=0.04007363319396973, train_time=0.037337541580200195
[Epoch 0][Step 157], time=0.08269357681274414, ext_time=0.03976011276245117, train_time=0.03802967071533203
[Epoch 0][Step 158], time=0.0830237865447998, ext_time=0.04011869430541992, train_time=0.03795576095581055
[Epoch 0][Step 159], time=0.08369016647338867, ext_time=0.03887653350830078, train_time=0.03990626335144043
[Epoch 0][Step 160], time=0.0827493667602539, ext_time=0.039602041244506836, train_time=0.03815436363220215
[Epoch 0][Step 161], time=0.08278584480285645, ext_time=0.04046797752380371, train_time=0.03736138343811035
[Epoch 0][Step 162], time=0.08324170112609863, ext_time=0.04043269157409668, train_time=0.03780102729797363
[Epoch 0][Step 163], time=0.08332300186157227, ext_time=0.04010939598083496, train_time=0.038237571716308594
[Epoch 0][Step 164], time=0.08342528343200684, ext_time=0.039006948471069336, train_time=0.03952980041503906
[Epoch 0][Step 165], time=0.0819854736328125, ext_time=0.03979945182800293, train_time=0.03721117973327637
[Epoch 0][Step 166], time=0.08205199241638184, ext_time=0.03994250297546387, train_time=0.03715872764587402
[Epoch 0][Step 167], time=0.0833885669708252, ext_time=0.04064655303955078, train_time=0.037737131118774414
[Epoch 0][Step 168], time=0.08241534233093262, ext_time=0.039723873138427734, train_time=0.037732601165771484
[Epoch 0][Step 169], time=0.0834507942199707, ext_time=0.0401918888092041, train_time=0.03820061683654785
[Epoch 0][Step 170], time=0.08356761932373047, ext_time=0.03948712348937988, train_time=0.03913283348083496
[Epoch 0][Step 171], time=0.08288836479187012, ext_time=0.04047131538391113, train_time=0.03742504119873047
[Epoch 0][Step 172], time=0.08218860626220703, ext_time=0.03896594047546387, train_time=0.038308143615722656
[Epoch 0][Step 173], time=0.083343505859375, ext_time=0.04022860527038574, train_time=0.03813648223876953
[Epoch 0][Step 174], time=0.08278703689575195, ext_time=0.04012322425842285, train_time=0.03769969940185547
[Epoch 0][Step 175], time=0.08333420753479004, ext_time=0.039531707763671875, train_time=0.038881540298461914
[Epoch 0][Step 176], time=0.08360505104064941, ext_time=0.04076361656188965, train_time=0.03794264793395996
[Epoch 0][Step 177], time=0.08260822296142578, ext_time=0.039721012115478516, train_time=0.03794407844543457
[Epoch 0][Step 178], time=0.0823211669921875, ext_time=0.03978896141052246, train_time=0.03760957717895508
[Epoch 0][Step 179], time=0.0830531120300293, ext_time=0.04041552543640137, train_time=0.037633419036865234
[Epoch 0][Step 180], time=0.08310151100158691, ext_time=0.04011893272399902, train_time=0.03799271583557129
[Epoch 0][Step 181], time=0.0839693546295166, ext_time=0.04096555709838867, train_time=0.03796529769897461
[Epoch 0][Step 182], time=0.08240079879760742, ext_time=0.03957962989807129, train_time=0.03787970542907715
[Epoch 0][Step 183], time=0.08357667922973633, ext_time=0.040805816650390625, train_time=0.03772592544555664
[Epoch 0][Step 184], time=0.08243298530578613, ext_time=0.040174245834350586, train_time=0.037331581115722656
[Epoch 0][Step 185], time=0.08317708969116211, ext_time=0.04013776779174805, train_time=0.03809690475463867
[Epoch 0][Step 186], time=0.08286762237548828, ext_time=0.03982186317443848, train_time=0.038094282150268555
[Epoch 0][Step 187], time=0.08258700370788574, ext_time=0.03964424133300781, train_time=0.03802633285522461
[Epoch 0][Step 188], time=0.08285880088806152, ext_time=0.03931784629821777, train_time=0.03863358497619629
[Epoch 0][Step 189], time=0.08293652534484863, ext_time=0.03901386260986328, train_time=0.03892636299133301
[Epoch 0][Step 190], time=0.08262395858764648, ext_time=0.03954052925109863, train_time=0.03813743591308594
[Epoch 0][Step 191], time=0.08414793014526367, ext_time=0.04063677787780762, train_time=0.038453102111816406
[Epoch 0][Step 192], time=0.08264970779418945, ext_time=0.03919577598571777, train_time=0.03845643997192383
[Epoch 0][Step 193], time=0.08243298530578613, ext_time=0.0394291877746582, train_time=0.03805112838745117
[Epoch 0][Step 194], time=0.08267474174499512, ext_time=0.04017138481140137, train_time=0.03750038146972656
[Epoch 0][Step 195], time=0.08271551132202148, ext_time=0.04015374183654785, train_time=0.03756976127624512
[Epoch 0][Step 196], time=0.08257055282592773, ext_time=0.04023408889770508, train_time=0.03734636306762695
[Epoch 0][Step 197], time=0.08268475532531738, ext_time=0.0387420654296875, train_time=0.038953304290771484
[Epoch 0][Step 198], time=0.08290362358093262, ext_time=0.03957390785217285, train_time=0.0384526252746582
[Epoch 0][Step 199], time=0.08274316787719727, ext_time=0.03992056846618652, train_time=0.0379023551940918
[Epoch 0][Step 200], time=0.08350610733032227, ext_time=0.04084658622741699, train_time=0.03768181800842285
[Epoch 0][Step 201], time=0.08324503898620605, ext_time=0.03983473777770996, train_time=0.038474082946777344
[Epoch 0][Step 202], time=0.08338379859924316, ext_time=0.04002046585083008, train_time=0.038429975509643555
[Epoch 0][Step 203], time=0.08255720138549805, ext_time=0.03977489471435547, train_time=0.03784966468811035
[Epoch 0][Step 204], time=0.08340835571289062, ext_time=0.04035472869873047, train_time=0.03809022903442383
[Epoch 0][Step 205], time=0.08185291290283203, ext_time=0.03888845443725586, train_time=0.03697824478149414
[Epoch 0][Step 206], time=0.08366966247558594, ext_time=0.039847612380981445, train_time=0.03886890411376953
[Epoch 0][Step 207], time=0.08386421203613281, ext_time=0.039853811264038086, train_time=0.03905797004699707
[Epoch 0][Step 208], time=0.0826871395111084, ext_time=0.03980517387390137, train_time=0.03793072700500488
[Epoch 0][Step 209], time=0.08300089836120605, ext_time=0.04041886329650879, train_time=0.03763389587402344
[Epoch 0][Step 210], time=0.08296632766723633, ext_time=0.039689064025878906, train_time=0.0382993221282959
[Epoch 0][Step 211], time=0.0831153392791748, ext_time=0.04015851020812988, train_time=0.037970542907714844
[Epoch 0][Step 212], time=0.08461117744445801, ext_time=0.04051804542541504, train_time=0.03910017013549805
[Epoch 0][Step 213], time=0.08354640007019043, ext_time=0.040549278259277344, train_time=0.03795742988586426
[Epoch 0][Step 214], time=0.08213615417480469, ext_time=0.0396270751953125, train_time=0.03755068778991699
[Epoch 0][Step 215], time=0.08285093307495117, ext_time=0.040718793869018555, train_time=0.03716015815734863
[Epoch 0][Step 216], time=0.08358216285705566, ext_time=0.040311574935913086, train_time=0.03831958770751953
[Epoch 0][Step 217], time=0.08301591873168945, ext_time=0.040291547775268555, train_time=0.03774619102478027
[Epoch 0][Step 218], time=0.08205151557922363, ext_time=0.03974556922912598, train_time=0.037412405014038086
[Epoch 0][Step 219], time=0.08251738548278809, ext_time=0.03991055488586426, train_time=0.03760647773742676
[Epoch 0][Step 220], time=0.08218765258789062, ext_time=0.039786577224731445, train_time=0.037450551986694336
[Epoch 0][Step 221], time=0.08193731307983398, ext_time=0.03976106643676758, train_time=0.037210702896118164
[Epoch 0][Step 222], time=0.08208036422729492, ext_time=0.039505958557128906, train_time=0.037607669830322266
[Epoch 0][Step 223], time=0.08695578575134277, ext_time=0.039743900299072266, train_time=0.0422670841217041
[Epoch 0][Step 224], time=0.08249282836914062, ext_time=0.03948712348937988, train_time=0.03811836242675781
[Epoch 0][Step 225], time=0.08293581008911133, ext_time=0.04047703742980957, train_time=0.03745436668395996
[Epoch 0][Step 226], time=0.08255672454833984, ext_time=0.04000687599182129, train_time=0.03761482238769531
[Epoch 0][Step 227], time=0.08196830749511719, ext_time=0.03986835479736328, train_time=0.03714561462402344
[Epoch 0][Step 228], time=0.08333849906921387, ext_time=0.04049873352050781, train_time=0.03789258003234863
[Epoch 0][Step 229], time=0.08284950256347656, ext_time=0.039719581604003906, train_time=0.038173675537109375
[Epoch 0][Step 230], time=0.08287310600280762, ext_time=0.040381669998168945, train_time=0.03746819496154785
[Epoch 0][Step 231], time=0.08254766464233398, ext_time=0.039223432540893555, train_time=0.03844785690307617
[Epoch 0][Step 232], time=0.08265447616577148, ext_time=0.039568424224853516, train_time=0.03805708885192871
[Epoch 0][Step 233], time=0.08248782157897949, ext_time=0.03892946243286133, train_time=0.03858184814453125
[Epoch 0][Step 234], time=0.08324241638183594, ext_time=0.04018068313598633, train_time=0.03799796104431152
[Epoch 0][Step 235], time=0.08214521408081055, ext_time=0.0399165153503418, train_time=0.03726482391357422
[Epoch 0][Step 236], time=0.08356142044067383, ext_time=0.04011416435241699, train_time=0.0384829044342041
[Epoch 0][Step 237], time=0.083740234375, ext_time=0.04021477699279785, train_time=0.03859829902648926
[Epoch 0][Step 238], time=0.08205509185791016, ext_time=0.03985142707824707, train_time=0.03718876838684082
[Epoch 0][Step 239], time=0.08253097534179688, ext_time=0.03946208953857422, train_time=0.03812742233276367
[Epoch 0][Step 240], time=0.08324146270751953, ext_time=0.04050612449645996, train_time=0.037735700607299805
[Epoch 0][Step 241], time=0.08320474624633789, ext_time=0.04075932502746582, train_time=0.037427425384521484
[Epoch 0][Step 242], time=0.08350801467895508, ext_time=0.04009222984313965, train_time=0.03847002983093262
[Epoch 0][Step 243], time=0.08263206481933594, ext_time=0.04013371467590332, train_time=0.0375363826751709
[Epoch 0][Step 244], time=0.08313989639282227, ext_time=0.0405421257019043, train_time=0.03756117820739746
[Epoch 0][Step 245], time=0.08261489868164062, ext_time=0.04021000862121582, train_time=0.03742480278015137
[Epoch 0][Step 246], time=0.08281159400939941, ext_time=0.03950047492980957, train_time=0.038416147232055664
[Epoch 0][Step 247], time=0.08331608772277832, ext_time=0.0402982234954834, train_time=0.0380396842956543
[Epoch 0][Step 248], time=0.08278155326843262, ext_time=0.03958320617675781, train_time=0.038205862045288086
[Epoch 0][Step 249], time=0.08344197273254395, ext_time=0.04011344909667969, train_time=0.038298845291137695
[Epoch 0], time=24.659403085708618, loss=nan
[Epoch 1][Step 0], time=0.08279180526733398, ext_time=0.03957867622375488, train_time=0.038263797760009766
[Epoch 1][Step 1], time=0.08372354507446289, ext_time=0.04055333137512207, train_time=0.03810000419616699
[Epoch 1][Step 2], time=0.08236885070800781, ext_time=0.03978157043457031, train_time=0.03762078285217285
[Epoch 1][Step 3], time=0.0834965705871582, ext_time=0.04032301902770996, train_time=0.03817391395568848
[Epoch 1][Step 4], time=0.08301281929016113, ext_time=0.04066324234008789, train_time=0.03738570213317871
[Epoch 1][Step 5], time=0.08265042304992676, ext_time=0.0403599739074707, train_time=0.037312984466552734
[Epoch 1][Step 6], time=0.3982541561126709, ext_time=0.03900027275085449, train_time=0.3543260097503662
[Epoch 1][Step 7], time=0.08358192443847656, ext_time=0.040111541748046875, train_time=0.03850054740905762
[Epoch 1][Step 8], time=0.0835118293762207, ext_time=0.039576053619384766, train_time=0.0390315055847168
[Epoch 1][Step 9], time=0.08341288566589355, ext_time=0.039707183837890625, train_time=0.03875374794006348
[Epoch 1][Step 10], time=0.08298349380493164, ext_time=0.04059648513793945, train_time=0.03743577003479004
[Epoch 1][Step 11], time=0.08337068557739258, ext_time=0.03981375694274902, train_time=0.03858470916748047
[Epoch 1][Step 12], time=0.08306479454040527, ext_time=0.040369272232055664, train_time=0.03734707832336426
[Epoch 1][Step 13], time=0.08286738395690918, ext_time=0.04037737846374512, train_time=0.03752875328063965
[Epoch 1][Step 14], time=0.08369684219360352, ext_time=0.0406649112701416, train_time=0.037985801696777344
[Epoch 1][Step 15], time=0.08381009101867676, ext_time=0.04088282585144043, train_time=0.03789949417114258
[Epoch 1][Step 16], time=0.08333253860473633, ext_time=0.03969526290893555, train_time=0.0386812686920166
[Epoch 1][Step 17], time=0.08390998840332031, ext_time=0.03994870185852051, train_time=0.038954734802246094
[Epoch 1][Step 18], time=0.0827174186706543, ext_time=0.039571285247802734, train_time=0.03827261924743652
[Epoch 1][Step 19], time=0.08267617225646973, ext_time=0.04011726379394531, train_time=0.03759026527404785
[Epoch 1][Step 20], time=0.08258557319641113, ext_time=0.039977312088012695, train_time=0.037598609924316406
[Epoch 1][Step 21], time=0.08284902572631836, ext_time=0.04044055938720703, train_time=0.03743863105773926
[Epoch 1][Step 22], time=0.08327126502990723, ext_time=0.040877580642700195, train_time=0.03740882873535156
[Epoch 1][Step 23], time=0.08277368545532227, ext_time=0.04036211967468262, train_time=0.03743386268615723
[Epoch 1][Step 24], time=0.08292818069458008, ext_time=0.039964914321899414, train_time=0.0380403995513916
[Epoch 1][Step 25], time=0.08325648307800293, ext_time=0.04019641876220703, train_time=0.03809213638305664
[Epoch 1][Step 26], time=0.08401632308959961, ext_time=0.040842533111572266, train_time=0.03809857368469238
[Epoch 1][Step 27], time=0.08314657211303711, ext_time=0.03994464874267578, train_time=0.03820085525512695
[Epoch 1][Step 28], time=0.0883016586303711, ext_time=0.0406336784362793, train_time=0.04273056983947754
[Epoch 1][Step 29], time=0.08327722549438477, ext_time=0.04037189483642578, train_time=0.03787517547607422
[Epoch 1][Step 30], time=0.08229351043701172, ext_time=0.039211273193359375, train_time=0.03813290596008301
[Epoch 1][Step 31], time=0.08273625373840332, ext_time=0.03995466232299805, train_time=0.03778505325317383
[Epoch 1][Step 32], time=0.08328938484191895, ext_time=0.04001569747924805, train_time=0.03834986686706543
[Epoch 1][Step 33], time=0.08301901817321777, ext_time=0.0404515266418457, train_time=0.037662506103515625
[Epoch 1][Step 34], time=0.08302617073059082, ext_time=0.0398862361907959, train_time=0.03821301460266113
[Epoch 1][Step 35], time=0.08291053771972656, ext_time=0.03972792625427246, train_time=0.03829622268676758
[Epoch 1][Step 36], time=0.0828101634979248, ext_time=0.040212392807006836, train_time=0.037590742111206055
[Epoch 1][Step 37], time=0.08324027061462402, ext_time=0.03971099853515625, train_time=0.03859353065490723
[Epoch 1][Step 38], time=0.08209609985351562, ext_time=0.03960847854614258, train_time=0.03755617141723633
[Epoch 1][Step 39], time=0.08295392990112305, ext_time=0.039403438568115234, train_time=0.03863644599914551
[Epoch 1][Step 40], time=0.08261299133300781, ext_time=0.040155887603759766, train_time=0.037470102310180664
[Epoch 1][Step 41], time=0.08353066444396973, ext_time=0.039807796478271484, train_time=0.03871726989746094
[Epoch 1][Step 42], time=0.08264827728271484, ext_time=0.03994035720825195, train_time=0.03769040107727051
[Epoch 1][Step 43], time=0.08256912231445312, ext_time=0.0391697883605957, train_time=0.038507938385009766
[Epoch 1][Step 44], time=0.0947728157043457, ext_time=0.040640830993652344, train_time=0.0431973934173584
[Epoch 1][Step 45], time=0.0836946964263916, ext_time=0.04049229621887207, train_time=0.03821420669555664
[Epoch 1][Step 46], time=0.08301854133605957, ext_time=0.0400547981262207, train_time=0.03800678253173828
[Epoch 1][Step 47], time=0.0827491283416748, ext_time=0.03957080841064453, train_time=0.03826284408569336
[Epoch 1][Step 48], time=0.08275818824768066, ext_time=0.04034590721130371, train_time=0.03741765022277832
[Epoch 1][Step 49], time=0.08441281318664551, ext_time=0.03977179527282715, train_time=0.03968358039855957
[Epoch 1][Step 50], time=0.08284306526184082, ext_time=0.03907895088195801, train_time=0.03879404067993164
[Epoch 1][Step 51], time=0.08339333534240723, ext_time=0.039565086364746094, train_time=0.038870811462402344
[Epoch 1][Step 52], time=0.08233237266540527, ext_time=0.03934741020202637, train_time=0.038016557693481445
[Epoch 1][Step 53], time=0.08284926414489746, ext_time=0.04030323028564453, train_time=0.03755927085876465
[Epoch 1][Step 54], time=0.08294177055358887, ext_time=0.039751529693603516, train_time=0.038260459899902344
[Epoch 1][Step 55], time=0.08237457275390625, ext_time=0.039908647537231445, train_time=0.0375370979309082
[Epoch 1][Step 56], time=0.08279252052307129, ext_time=0.03971123695373535, train_time=0.03819847106933594
[Epoch 1][Step 57], time=0.08258652687072754, ext_time=0.03987598419189453, train_time=0.037729740142822266
[Epoch 1][Step 58], time=0.08380270004272461, ext_time=0.04007577896118164, train_time=0.03878331184387207
[Epoch 1][Step 59], time=0.08332562446594238, ext_time=0.03953719139099121, train_time=0.03885030746459961
[Epoch 1][Step 60], time=0.08227205276489258, ext_time=0.0396575927734375, train_time=0.03760576248168945
[Epoch 1][Step 61], time=0.08256363868713379, ext_time=0.04012775421142578, train_time=0.03745532035827637
[Epoch 1][Step 62], time=0.08258533477783203, ext_time=0.03960728645324707, train_time=0.03806328773498535
[Epoch 1][Step 63], time=0.08425736427307129, ext_time=0.039403438568115234, train_time=0.0399324893951416
[Epoch 1][Step 64], time=0.08302855491638184, ext_time=0.03954005241394043, train_time=0.038596153259277344
[Epoch 1][Step 65], time=0.08392071723937988, ext_time=0.04118227958679199, train_time=0.037689924240112305
[Epoch 1][Step 66], time=0.08284902572631836, ext_time=0.040219783782958984, train_time=0.037635087966918945
[Epoch 1][Step 67], time=0.08289813995361328, ext_time=0.03980827331542969, train_time=0.03816103935241699
[Epoch 1][Step 68], time=0.08301424980163574, ext_time=0.040067434310913086, train_time=0.03796720504760742
[Epoch 1][Step 69], time=0.08302688598632812, ext_time=0.039710044860839844, train_time=0.03838372230529785
[Epoch 1][Step 70], time=0.08378124237060547, ext_time=0.041036128997802734, train_time=0.03778815269470215
[Epoch 1][Step 71], time=0.08310294151306152, ext_time=0.03952670097351074, train_time=0.03857278823852539
[Epoch 1][Step 72], time=0.08292555809020996, ext_time=0.0407259464263916, train_time=0.03724956512451172
[Epoch 1][Step 73], time=0.08346343040466309, ext_time=0.04045677185058594, train_time=0.03798627853393555
[Epoch 1][Step 74], time=0.08226680755615234, ext_time=0.03990483283996582, train_time=0.03739190101623535
[Epoch 1][Step 75], time=0.08265495300292969, ext_time=0.03995084762573242, train_time=0.03766965866088867
[Epoch 1][Step 76], time=0.08338332176208496, ext_time=0.04064798355102539, train_time=0.03771519660949707
[Epoch 1][Step 77], time=0.08304119110107422, ext_time=0.04041886329650879, train_time=0.03766989707946777
[Epoch 1][Step 78], time=0.08280539512634277, ext_time=0.04021120071411133, train_time=0.03757500648498535
[Epoch 1][Step 79], time=0.08276009559631348, ext_time=0.03925299644470215, train_time=0.03865170478820801
[Epoch 1][Step 80], time=0.08241677284240723, ext_time=0.03935503959655762, train_time=0.03817868232727051
[Epoch 1][Step 81], time=0.08277177810668945, ext_time=0.03920578956604004, train_time=0.038668155670166016
[Epoch 1][Step 82], time=0.08263611793518066, ext_time=0.03981590270996094, train_time=0.03783679008483887
[Epoch 1][Step 83], time=0.0837700366973877, ext_time=0.039922237396240234, train_time=0.03888440132141113
[Epoch 1][Step 84], time=0.08253645896911621, ext_time=0.040289878845214844, train_time=0.03729557991027832
[Epoch 1][Step 85], time=0.08322286605834961, ext_time=0.04026150703430176, train_time=0.038022518157958984
[Epoch 1][Step 86], time=0.0843052864074707, ext_time=0.04025006294250488, train_time=0.03905606269836426
[Epoch 1][Step 87], time=0.0820460319519043, ext_time=0.039560556411743164, train_time=0.03755807876586914
[Epoch 1][Step 88], time=0.08262848854064941, ext_time=0.03970599174499512, train_time=0.03802633285522461
[Epoch 1][Step 89], time=0.08301568031311035, ext_time=0.03908085823059082, train_time=0.03892636299133301
[Epoch 1][Step 90], time=0.08284902572631836, ext_time=0.04031491279602051, train_time=0.03755450248718262
[Epoch 1][Step 91], time=0.08348798751831055, ext_time=0.04073166847229004, train_time=0.03774762153625488
[Epoch 1][Step 92], time=0.08294129371643066, ext_time=0.03978562355041504, train_time=0.038239479064941406
[Epoch 1][Step 93], time=0.08253121376037598, ext_time=0.03936052322387695, train_time=0.03816103935241699
[Epoch 1][Step 94], time=0.08262372016906738, ext_time=0.03949308395385742, train_time=0.0381929874420166
[Epoch 1][Step 95], time=0.08290529251098633, ext_time=0.0392606258392334, train_time=0.038728952407836914
[Epoch 1][Step 96], time=0.08309817314147949, ext_time=0.04017329216003418, train_time=0.03797459602355957
[Epoch 1][Step 97], time=0.08270001411437988, ext_time=0.0398707389831543, train_time=0.03780531883239746
[Epoch 1][Step 98], time=0.08260703086853027, ext_time=0.039708614349365234, train_time=0.03793644905090332
[Epoch 1][Step 99], time=0.08396410942077637, ext_time=0.039597511291503906, train_time=0.039394378662109375
[Epoch 1][Step 100], time=0.08284497261047363, ext_time=0.040435791015625, train_time=0.03744053840637207
[Epoch 1][Step 101], time=0.08343195915222168, ext_time=0.040502309799194336, train_time=0.03793191909790039
[Epoch 1][Step 102], time=0.08399057388305664, ext_time=0.040491342544555664, train_time=0.038495540618896484
[Epoch 1][Step 103], time=0.08347368240356445, ext_time=0.04049944877624512, train_time=0.037927865982055664
[Epoch 1][Step 104], time=0.08278226852416992, ext_time=0.03954052925109863, train_time=0.038196563720703125
[Epoch 1][Step 105], time=0.0827641487121582, ext_time=0.03953981399536133, train_time=0.038263797760009766
[Epoch 1][Step 106], time=0.08256101608276367, ext_time=0.04037880897521973, train_time=0.037265777587890625
[Epoch 1][Step 107], time=0.08277344703674316, ext_time=0.04014945030212402, train_time=0.0376439094543457
[Epoch 1][Step 108], time=0.08320426940917969, ext_time=0.03892183303833008, train_time=0.03936147689819336
[Epoch 1][Step 109], time=0.08243370056152344, ext_time=0.03961539268493652, train_time=0.03792405128479004
[Epoch 1][Step 110], time=0.08267045021057129, ext_time=0.04034566879272461, train_time=0.03734636306762695
[Epoch 1][Step 111], time=0.08353066444396973, ext_time=0.039990901947021484, train_time=0.03856945037841797
[Epoch 1][Step 112], time=0.08272480964660645, ext_time=0.039330482482910156, train_time=0.038446903228759766
[Epoch 1][Step 113], time=0.08191466331481934, ext_time=0.04004096984863281, train_time=0.0369570255279541
[Epoch 1][Step 114], time=0.08362817764282227, ext_time=0.04077410697937012, train_time=0.03780984878540039
[Epoch 1][Step 115], time=0.08217906951904297, ext_time=0.039344072341918945, train_time=0.037871360778808594
[Epoch 1][Step 116], time=0.08353328704833984, ext_time=0.03947186470031738, train_time=0.03919529914855957
[Epoch 1][Step 117], time=0.08306002616882324, ext_time=0.040036916732788086, train_time=0.03807234764099121
[Epoch 1][Step 118], time=0.08228397369384766, ext_time=0.039669036865234375, train_time=0.037650108337402344
[Epoch 1][Step 119], time=0.0831139087677002, ext_time=0.04026985168457031, train_time=0.03786301612854004
[Epoch 1][Step 120], time=0.0829007625579834, ext_time=0.03990292549133301, train_time=0.03805685043334961
[Epoch 1][Step 121], time=0.0836341381072998, ext_time=0.04070472717285156, train_time=0.03790855407714844
[Epoch 1][Step 122], time=0.08357071876525879, ext_time=0.040204763412475586, train_time=0.03840517997741699
[Epoch 1][Step 123], time=0.0833885669708252, ext_time=0.03949713706970215, train_time=0.038967132568359375
[Epoch 1][Step 124], time=0.08246088027954102, ext_time=0.038254737854003906, train_time=0.03885507583618164
[Epoch 1][Step 125], time=0.08269095420837402, ext_time=0.040827274322509766, train_time=0.03692436218261719
[Epoch 1][Step 126], time=0.08263778686523438, ext_time=0.039876699447631836, train_time=0.03785538673400879
[Epoch 1][Step 127], time=0.08396410942077637, ext_time=0.04017233848571777, train_time=0.03884577751159668
[Epoch 1][Step 128], time=0.0832676887512207, ext_time=0.03990817070007324, train_time=0.03837227821350098
[Epoch 1][Step 129], time=0.08243751525878906, ext_time=0.04008173942565918, train_time=0.037416696548461914
[Epoch 1][Step 130], time=0.08246183395385742, ext_time=0.039235591888427734, train_time=0.038234710693359375
[Epoch 1][Step 131], time=0.08218932151794434, ext_time=0.03942251205444336, train_time=0.03783154487609863
[Epoch 1][Step 132], time=0.08297204971313477, ext_time=0.03907132148742676, train_time=0.03900313377380371
[Epoch 1][Step 133], time=0.08384919166564941, ext_time=0.04100298881530762, train_time=0.03780651092529297
[Epoch 1][Step 134], time=0.0831449031829834, ext_time=0.040004730224609375, train_time=0.03814435005187988
[Epoch 1][Step 135], time=0.08395743370056152, ext_time=0.040213823318481445, train_time=0.03877687454223633
[Epoch 1][Step 136], time=0.08315134048461914, ext_time=0.03860950469970703, train_time=0.0396883487701416
[Epoch 1][Step 137], time=0.08303451538085938, ext_time=0.040018320083618164, train_time=0.03811287879943848
[Epoch 1][Step 138], time=0.08295035362243652, ext_time=0.039636850357055664, train_time=0.03831195831298828
[Epoch 1][Step 139], time=0.08293604850769043, ext_time=0.03957319259643555, train_time=0.03844118118286133
[Epoch 1][Step 140], time=0.08315277099609375, ext_time=0.039549827575683594, train_time=0.03867292404174805
[Epoch 1][Step 141], time=0.08389544486999512, ext_time=0.04082226753234863, train_time=0.038030385971069336
[Epoch 1][Step 142], time=0.08217072486877441, ext_time=0.039492130279541016, train_time=0.037772178649902344
[Epoch 1][Step 143], time=0.08243846893310547, ext_time=0.03926420211791992, train_time=0.03826308250427246
[Epoch 1][Step 144], time=0.5335564613342285, ext_time=0.040068626403808594, train_time=0.48853206634521484
[Epoch 1][Step 145], time=0.08406686782836914, ext_time=0.04048442840576172, train_time=0.03864741325378418
[Epoch 1][Step 146], time=0.08344221115112305, ext_time=0.04045295715332031, train_time=0.03804612159729004
[Epoch 1][Step 147], time=0.08306407928466797, ext_time=0.039613962173461914, train_time=0.038504838943481445
[Epoch 1][Step 148], time=0.08256936073303223, ext_time=0.039961814880371094, train_time=0.03766989707946777
[Epoch 1][Step 149], time=0.08260202407836914, ext_time=0.040402889251708984, train_time=0.037209510803222656
[Epoch 1][Step 150], time=0.08335137367248535, ext_time=0.03972935676574707, train_time=0.03864645957946777
[Epoch 1][Step 151], time=0.08285093307495117, ext_time=0.04043245315551758, train_time=0.03743886947631836
[Epoch 1][Step 152], time=0.08234715461730957, ext_time=0.03937482833862305, train_time=0.037978172302246094
[Epoch 1][Step 153], time=0.08279609680175781, ext_time=0.03978919982910156, train_time=0.03809499740600586
[Epoch 1][Step 154], time=0.08214116096496582, ext_time=0.039919376373291016, train_time=0.03730368614196777
[Epoch 1][Step 155], time=0.08262014389038086, ext_time=0.0398409366607666, train_time=0.037836313247680664
[Epoch 1][Step 156], time=0.08313846588134766, ext_time=0.04039263725280762, train_time=0.03771638870239258
[Epoch 1][Step 157], time=0.08299493789672852, ext_time=0.04041242599487305, train_time=0.037641048431396484
[Epoch 1][Step 158], time=0.0827634334564209, ext_time=0.04020524024963379, train_time=0.03759503364562988
[Epoch 1][Step 159], time=0.2702906131744385, ext_time=0.03881645202636719, train_time=0.226548433303833
[Epoch 1][Step 160], time=0.08309006690979004, ext_time=0.0394589900970459, train_time=0.0386044979095459
[Epoch 1][Step 161], time=0.0826113224029541, ext_time=0.03995561599731445, train_time=0.03771042823791504
[Epoch 1][Step 162], time=0.08354997634887695, ext_time=0.04052543640136719, train_time=0.0380556583404541
[Epoch 1][Step 163], time=0.08271169662475586, ext_time=0.04021763801574707, train_time=0.037467002868652344
[Epoch 1][Step 164], time=0.08656716346740723, ext_time=0.03937959671020508, train_time=0.04228711128234863
[Epoch 1][Step 165], time=0.08219432830810547, ext_time=0.0398252010345459, train_time=0.03737950325012207
[Epoch 1][Step 166], time=0.08208847045898438, ext_time=0.03972768783569336, train_time=0.03739452362060547
[Epoch 1][Step 167], time=0.08296465873718262, ext_time=0.04053807258605957, train_time=0.03746318817138672
[Epoch 1][Step 168], time=0.08289527893066406, ext_time=0.03995800018310547, train_time=0.03793787956237793
[Epoch 1][Step 169], time=0.08791041374206543, ext_time=0.040506601333618164, train_time=0.04228854179382324
[Epoch 1][Step 170], time=0.08427572250366211, ext_time=0.039691925048828125, train_time=0.03960061073303223
[Epoch 1][Step 171], time=0.08408713340759277, ext_time=0.039751529693603516, train_time=0.03938555717468262
[Epoch 1][Step 172], time=0.0821077823638916, ext_time=0.03879523277282715, train_time=0.03842663764953613
[Epoch 1][Step 173], time=0.08228135108947754, ext_time=0.040019989013671875, train_time=0.03732466697692871
[Epoch 1][Step 174], time=0.08226323127746582, ext_time=0.03903317451477051, train_time=0.03829169273376465
[Epoch 1][Step 175], time=0.08302021026611328, ext_time=0.04000449180603027, train_time=0.03806757926940918
[Epoch 1][Step 176], time=0.08379697799682617, ext_time=0.040669918060302734, train_time=0.038205623626708984
[Epoch 1][Step 177], time=0.08205056190490723, ext_time=0.039552927017211914, train_time=0.037529945373535156
[Epoch 1][Step 178], time=0.0820150375366211, ext_time=0.03964829444885254, train_time=0.03743791580200195
[Epoch 1][Step 179], time=0.08311867713928223, ext_time=0.040228843688964844, train_time=0.037850141525268555
[Epoch 1][Step 180], time=0.08310866355895996, ext_time=0.0402069091796875, train_time=0.0377810001373291
[Epoch 1][Step 181], time=0.0830075740814209, ext_time=0.04044032096862793, train_time=0.03757834434509277
[Epoch 1][Step 182], time=0.08229994773864746, ext_time=0.039626121520996094, train_time=0.037720441818237305
[Epoch 1][Step 183], time=0.08347868919372559, ext_time=0.0406956672668457, train_time=0.037760019302368164
[Epoch 1][Step 184], time=0.08343291282653809, ext_time=0.03988027572631836, train_time=0.0386660099029541
[Epoch 1][Step 185], time=0.08277320861816406, ext_time=0.040270328521728516, train_time=0.037546396255493164
[Epoch 1][Step 186], time=0.08320784568786621, ext_time=0.040528059005737305, train_time=0.0376734733581543
[Epoch 1][Step 187], time=0.08313345909118652, ext_time=0.040071725845336914, train_time=0.03808188438415527
[Epoch 1][Step 188], time=0.08258461952209473, ext_time=0.038877010345458984, train_time=0.038820505142211914
[Epoch 1][Step 189], time=0.08267498016357422, ext_time=0.03934478759765625, train_time=0.0383608341217041
[Epoch 1][Step 190], time=0.08337640762329102, ext_time=0.03990912437438965, train_time=0.03850579261779785
[Epoch 1][Step 191], time=0.08283567428588867, ext_time=0.04001975059509277, train_time=0.03776884078979492
[Epoch 1][Step 192], time=0.08300185203552246, ext_time=0.03967881202697754, train_time=0.038332462310791016
[Epoch 1][Step 193], time=0.08258271217346191, ext_time=0.03986191749572754, train_time=0.0377042293548584
[Epoch 1][Step 194], time=0.0825796127319336, ext_time=0.04037642478942871, train_time=0.03721332550048828
[Epoch 1][Step 195], time=0.08257937431335449, ext_time=0.040308475494384766, train_time=0.037283897399902344
[Epoch 1][Step 196], time=0.08263659477233887, ext_time=0.04040408134460449, train_time=0.03727221488952637
[Epoch 1][Step 197], time=0.08284115791320801, ext_time=0.039800167083740234, train_time=0.03811001777648926
[Epoch 1][Step 198], time=0.08253335952758789, ext_time=0.03976130485534668, train_time=0.037906646728515625
[Epoch 1][Step 199], time=0.08290624618530273, ext_time=0.0398101806640625, train_time=0.03815746307373047
[Epoch 1][Step 200], time=0.08405780792236328, ext_time=0.04079866409301758, train_time=0.038299560546875
[Epoch 1][Step 201], time=0.08349442481994629, ext_time=0.03899264335632324, train_time=0.03960895538330078
[Epoch 1][Step 202], time=0.08395099639892578, ext_time=0.04008364677429199, train_time=0.03894543647766113
[Epoch 1][Step 203], time=0.08313322067260742, ext_time=0.04041123390197754, train_time=0.037731170654296875
[Epoch 1][Step 204], time=0.08304166793823242, ext_time=0.03970789909362793, train_time=0.0384371280670166
[Epoch 1][Step 205], time=0.08304476737976074, ext_time=0.039307355880737305, train_time=0.03881216049194336
[Epoch 1][Step 206], time=0.08361601829528809, ext_time=0.039662837982177734, train_time=0.03902888298034668
[Epoch 1][Step 207], time=0.08303952217102051, ext_time=0.03979969024658203, train_time=0.03829646110534668
[Epoch 1][Step 208], time=0.08243680000305176, ext_time=0.03969979286193848, train_time=0.037795066833496094
[Epoch 1][Step 209], time=0.08368349075317383, ext_time=0.04006838798522949, train_time=0.03870892524719238
[Epoch 1][Step 210], time=0.08283376693725586, ext_time=0.0400242805480957, train_time=0.0377650260925293
[Epoch 1][Step 211], time=0.08356165885925293, ext_time=0.04042816162109375, train_time=0.03807330131530762
[Epoch 1][Step 212], time=0.08369016647338867, ext_time=0.040297746658325195, train_time=0.03836989402770996
[Epoch 1][Step 213], time=0.08336353302001953, ext_time=0.04032611846923828, train_time=0.03803586959838867
[Epoch 1][Step 214], time=0.09415817260742188, ext_time=0.039911746978759766, train_time=0.03763699531555176
[Epoch 1][Step 215], time=0.08335995674133301, ext_time=0.040906667709350586, train_time=0.037424325942993164
[Epoch 1][Step 216], time=0.08323812484741211, ext_time=0.040412187576293945, train_time=0.03783559799194336
[Epoch 1][Step 217], time=0.08299422264099121, ext_time=0.040289878845214844, train_time=0.03774428367614746
[Epoch 1][Step 218], time=0.08237957954406738, ext_time=0.04033708572387695, train_time=0.03710031509399414
[Epoch 1][Step 219], time=0.08303952217102051, ext_time=0.0403132438659668, train_time=0.03770184516906738
[Epoch 1][Step 220], time=0.08223342895507812, ext_time=0.03942275047302246, train_time=0.0379023551940918
[Epoch 1][Step 221], time=0.08231973648071289, ext_time=0.03995370864868164, train_time=0.03739285469055176
[Epoch 1][Step 222], time=0.08462285995483398, ext_time=0.03948187828063965, train_time=0.04020047187805176
[Epoch 1][Step 223], time=0.08341550827026367, ext_time=0.039346933364868164, train_time=0.039156198501586914
[Epoch 1][Step 224], time=0.08272957801818848, ext_time=0.03976607322692871, train_time=0.03804135322570801
[Epoch 1][Step 225], time=0.08266925811767578, ext_time=0.04012870788574219, train_time=0.03754782676696777
[Epoch 1][Step 226], time=0.08261895179748535, ext_time=0.04027891159057617, train_time=0.037363529205322266
[Epoch 1][Step 227], time=0.08228826522827148, ext_time=0.03934121131896973, train_time=0.03809356689453125
[Epoch 1][Step 228], time=0.08316278457641602, ext_time=0.0396876335144043, train_time=0.0385737419128418
[Epoch 1][Step 229], time=0.08276534080505371, ext_time=0.03966975212097168, train_time=0.03810238838195801
[Epoch 1][Step 230], time=0.08240032196044922, ext_time=0.03998899459838867, train_time=0.03745245933532715
[Epoch 1][Step 231], time=0.08272695541381836, ext_time=0.039693593978881836, train_time=0.03808879852294922
[Epoch 1][Step 232], time=0.08285856246948242, ext_time=0.03943014144897461, train_time=0.038450002670288086
[Epoch 1][Step 233], time=0.08273530006408691, ext_time=0.03902626037597656, train_time=0.03872799873352051
[Epoch 1][Step 234], time=0.0832061767578125, ext_time=0.04033160209655762, train_time=0.03786468505859375
[Epoch 1][Step 235], time=0.08272814750671387, ext_time=0.0399777889251709, train_time=0.03780078887939453
[Epoch 1][Step 236], time=0.08350467681884766, ext_time=0.04002046585083008, train_time=0.038480520248413086
[Epoch 1][Step 237], time=0.0836336612701416, ext_time=0.04002714157104492, train_time=0.03866720199584961
[Epoch 1][Step 238], time=0.0827631950378418, ext_time=0.03989696502685547, train_time=0.03791093826293945
[Epoch 1][Step 239], time=0.08307337760925293, ext_time=0.03989720344543457, train_time=0.03822207450866699
[Epoch 1][Step 240], time=0.08222484588623047, ext_time=0.03997325897216797, train_time=0.03730154037475586
[Epoch 1][Step 241], time=0.08357787132263184, ext_time=0.040863990783691406, train_time=0.03767514228820801
[Epoch 1][Step 242], time=0.08311128616333008, ext_time=0.04030251502990723, train_time=0.037836313247680664
[Epoch 1][Step 243], time=0.08228087425231934, ext_time=0.04014182090759277, train_time=0.03716611862182617
[Epoch 1][Step 244], time=0.08319902420043945, ext_time=0.04030656814575195, train_time=0.03793501853942871
[Epoch 1][Step 245], time=0.08221101760864258, ext_time=0.040073394775390625, train_time=0.037215471267700195
[Epoch 1][Step 246], time=0.08236122131347656, ext_time=0.039520978927612305, train_time=0.0379023551940918
[Epoch 1][Step 247], time=0.08265471458435059, ext_time=0.04034066200256348, train_time=0.03731131553649902
[Epoch 1][Step 248], time=0.08253026008605957, ext_time=0.040105342864990234, train_time=0.037427663803100586
[Epoch 1][Step 249], time=0.0838475227355957, ext_time=0.04058670997619629, train_time=0.03822946548461914
[Epoch 1], time=21.754146337509155, loss=nan
[Epoch 2][Step 0], time=0.08319354057312012, ext_time=0.0396120548248291, train_time=0.038632869720458984
[Epoch 2][Step 1], time=0.08440303802490234, ext_time=0.0410158634185791, train_time=0.03832101821899414
[Epoch 2][Step 2], time=0.0825490951538086, ext_time=0.03995347023010254, train_time=0.03758692741394043
[Epoch 2][Step 3], time=0.08259892463684082, ext_time=0.04014730453491211, train_time=0.037477731704711914
[Epoch 2][Step 4], time=0.08335471153259277, ext_time=0.04044175148010254, train_time=0.03797173500061035
[Epoch 2][Step 5], time=0.08335089683532715, ext_time=0.04033541679382324, train_time=0.03801751136779785
[Epoch 2][Step 6], time=0.08289813995361328, ext_time=0.04058504104614258, train_time=0.03740572929382324
[Epoch 2][Step 7], time=0.08495950698852539, ext_time=0.04017329216003418, train_time=0.039737701416015625
[Epoch 2][Step 8], time=0.08315443992614746, ext_time=0.0398402214050293, train_time=0.03836536407470703
[Epoch 2][Step 9], time=0.08297157287597656, ext_time=0.04029202461242676, train_time=0.03765225410461426
[Epoch 2][Step 10], time=0.08292126655578613, ext_time=0.04037737846374512, train_time=0.03756356239318848
[Epoch 2][Step 11], time=0.08425712585449219, ext_time=0.03967595100402832, train_time=0.03964352607727051
[Epoch 2][Step 12], time=0.08303356170654297, ext_time=0.04038834571838379, train_time=0.03767204284667969
[Epoch 2][Step 13], time=0.0825953483581543, ext_time=0.040122032165527344, train_time=0.03752779960632324
[Epoch 2][Step 14], time=0.0828249454498291, ext_time=0.0403597354888916, train_time=0.03743720054626465
[Epoch 2][Step 15], time=0.08393287658691406, ext_time=0.04064440727233887, train_time=0.03825879096984863
[Epoch 2][Step 16], time=0.08310580253601074, ext_time=0.03971362113952637, train_time=0.03781843185424805
[Epoch 2][Step 17], time=0.08285284042358398, ext_time=0.040282487869262695, train_time=0.03756976127624512
[Epoch 2][Step 18], time=0.08279109001159668, ext_time=0.04038667678833008, train_time=0.03741812705993652
[Epoch 2][Step 19], time=0.0830230712890625, ext_time=0.040621042251586914, train_time=0.037420034408569336
[Epoch 2][Step 20], time=0.08274102210998535, ext_time=0.039020538330078125, train_time=0.03881573677062988
[Epoch 2][Step 21], time=0.08289718627929688, ext_time=0.04054093360900879, train_time=0.03736686706542969
[Epoch 2][Step 22], time=0.08278632164001465, ext_time=0.04062628746032715, train_time=0.03721785545349121
[Epoch 2][Step 23], time=0.08278608322143555, ext_time=0.040094852447509766, train_time=0.037709712982177734
[Epoch 2][Step 24], time=0.08300375938415527, ext_time=0.0402827262878418, train_time=0.03781390190124512
[Epoch 2][Step 25], time=0.083892822265625, ext_time=0.040405988693237305, train_time=0.03852510452270508
[Epoch 2][Step 26], time=0.08308196067810059, ext_time=0.0403437614440918, train_time=0.03772926330566406
[Epoch 2][Step 27], time=0.08286690711975098, ext_time=0.039621829986572266, train_time=0.038271427154541016
[Epoch 2][Step 28], time=0.08400130271911621, ext_time=0.04098343849182129, train_time=0.03802323341369629
[Epoch 2][Step 29], time=0.08316469192504883, ext_time=0.03999662399291992, train_time=0.03820300102233887
[Epoch 2][Step 30], time=0.08334183692932129, ext_time=0.039649248123168945, train_time=0.03868889808654785
[Epoch 2][Step 31], time=0.08275032043457031, ext_time=0.039568185806274414, train_time=0.038243770599365234
[Epoch 2][Step 32], time=0.08300137519836426, ext_time=0.03922128677368164, train_time=0.03890109062194824
[Epoch 2][Step 33], time=0.08309268951416016, ext_time=0.04036974906921387, train_time=0.03777289390563965
[Epoch 2][Step 34], time=0.08238768577575684, ext_time=0.039983272552490234, train_time=0.03741621971130371
[Epoch 2][Step 35], time=0.08263254165649414, ext_time=0.040392160415649414, train_time=0.03728342056274414
[Epoch 2][Step 36], time=0.08257389068603516, ext_time=0.04036664962768555, train_time=0.037247419357299805
[Epoch 2][Step 37], time=0.08347105979919434, ext_time=0.04045844078063965, train_time=0.03799128532409668
[Epoch 2][Step 38], time=0.08269929885864258, ext_time=0.039778709411621094, train_time=0.037960052490234375
[Epoch 2][Step 39], time=0.08197593688964844, ext_time=0.03951120376586914, train_time=0.03755903244018555
[Epoch 2][Step 40], time=0.08303952217102051, ext_time=0.039834022521972656, train_time=0.03817272186279297
[Epoch 2][Step 41], time=0.08297181129455566, ext_time=0.03990030288696289, train_time=0.03808856010437012
[Epoch 2][Step 42], time=0.08339309692382812, ext_time=0.04024171829223633, train_time=0.038156747817993164
[Epoch 2][Step 43], time=0.08273100852966309, ext_time=0.03872394561767578, train_time=0.039055824279785156
[Epoch 2][Step 44], time=0.08394622802734375, ext_time=0.040938615798950195, train_time=0.038002729415893555
[Epoch 2][Step 45], time=0.08353614807128906, ext_time=0.04000067710876465, train_time=0.03855586051940918
[Epoch 2][Step 46], time=0.08229279518127441, ext_time=0.04016518592834473, train_time=0.03716707229614258
[Epoch 2][Step 47], time=0.08241081237792969, ext_time=0.03974318504333496, train_time=0.03770089149475098
[Epoch 2][Step 48], time=0.08255147933959961, ext_time=0.039955854415893555, train_time=0.03760218620300293
[Epoch 2][Step 49], time=0.08465981483459473, ext_time=0.04069995880126953, train_time=0.03896832466125488
[Epoch 2][Step 50], time=0.08382058143615723, ext_time=0.039670467376708984, train_time=0.03919196128845215
[Epoch 2][Step 51], time=0.08416056632995605, ext_time=0.04018449783325195, train_time=0.03896141052246094
[Epoch 2][Step 52], time=0.08240199089050293, ext_time=0.039694786071777344, train_time=0.03770303726196289
[Epoch 2][Step 53], time=0.08357572555541992, ext_time=0.040129661560058594, train_time=0.03796982765197754
[Epoch 2][Step 54], time=0.08284258842468262, ext_time=0.040194034576416016, train_time=0.03767848014831543
[Epoch 2][Step 55], time=0.08407783508300781, ext_time=0.04030346870422363, train_time=0.038791656494140625
[Epoch 2][Step 56], time=0.08336138725280762, ext_time=0.039872169494628906, train_time=0.03860020637512207
[Epoch 2][Step 57], time=0.08264374732971191, ext_time=0.0385286808013916, train_time=0.039232730865478516
[Epoch 2][Step 58], time=0.08411860466003418, ext_time=0.0403285026550293, train_time=0.03882288932800293
[Epoch 2][Step 59], time=0.08481097221374512, ext_time=0.03969454765319824, train_time=0.04007744789123535
[Epoch 2][Step 60], time=0.08243560791015625, ext_time=0.03979134559631348, train_time=0.03764009475708008
[Epoch 2][Step 61], time=0.08333635330200195, ext_time=0.04020261764526367, train_time=0.03814125061035156
[Epoch 2][Step 62], time=0.08347725868225098, ext_time=0.03990435600280762, train_time=0.03863978385925293
[Epoch 2][Step 63], time=0.0829627513885498, ext_time=0.037813663482666016, train_time=0.04021620750427246
[Epoch 2][Step 64], time=0.08290553092956543, ext_time=0.040199995040893555, train_time=0.037801504135131836
[Epoch 2][Step 65], time=0.08371210098266602, ext_time=0.04098963737487793, train_time=0.03769659996032715
[Epoch 2][Step 66], time=0.08384084701538086, ext_time=0.0400235652923584, train_time=0.03885984420776367
[Epoch 2][Step 67], time=0.0830385684967041, ext_time=0.04031634330749512, train_time=0.037699222564697266
[Epoch 2][Step 68], time=0.08360862731933594, ext_time=0.04063844680786133, train_time=0.037969350814819336
[Epoch 2][Step 69], time=0.08304524421691895, ext_time=0.03956270217895508, train_time=0.03855752944946289
[Epoch 2][Step 70], time=0.08436751365661621, ext_time=0.040610313415527344, train_time=0.03883028030395508
[Epoch 2][Step 71], time=0.08228492736816406, ext_time=0.039290428161621094, train_time=0.03805804252624512
[Epoch 2][Step 72], time=0.08301711082458496, ext_time=0.04032707214355469, train_time=0.03772926330566406
[Epoch 2][Step 73], time=0.08370566368103027, ext_time=0.04029726982116699, train_time=0.03842926025390625
[Epoch 2][Step 74], time=0.08284974098205566, ext_time=0.039994001388549805, train_time=0.03790760040283203
[Epoch 2][Step 75], time=0.08279633522033691, ext_time=0.04007530212402344, train_time=0.037705183029174805
[Epoch 2][Step 76], time=0.08280777931213379, ext_time=0.04030799865722656, train_time=0.03746962547302246
[Epoch 2][Step 77], time=0.08248734474182129, ext_time=0.04021644592285156, train_time=0.037297725677490234
[Epoch 2][Step 78], time=0.08294391632080078, ext_time=0.04040837287902832, train_time=0.037520408630371094
[Epoch 2][Step 79], time=0.08273005485534668, ext_time=0.0399172306060791, train_time=0.037920236587524414
[Epoch 2][Step 80], time=0.08487057685852051, ext_time=0.03934454917907715, train_time=0.04063224792480469
[Epoch 2][Step 81], time=0.08314228057861328, ext_time=0.039737701416015625, train_time=0.03848910331726074
[Epoch 2][Step 82], time=0.0825355052947998, ext_time=0.03987884521484375, train_time=0.037683963775634766
[Epoch 2][Step 83], time=0.08306026458740234, ext_time=0.0401463508605957, train_time=0.03793692588806152
[Epoch 2][Step 84], time=0.08324790000915527, ext_time=0.0401155948638916, train_time=0.03816699981689453
[Epoch 2][Step 85], time=0.08223223686218262, ext_time=0.040009260177612305, train_time=0.037267446517944336
[Epoch 2][Step 86], time=0.08294105529785156, ext_time=0.039806365966796875, train_time=0.03820991516113281
[Epoch 2][Step 87], time=0.08287334442138672, ext_time=0.039762258529663086, train_time=0.03817582130432129
[Epoch 2][Step 88], time=0.08313202857971191, ext_time=0.039160728454589844, train_time=0.0390470027923584
[Epoch 2][Step 89], time=0.08277440071105957, ext_time=0.03966856002807617, train_time=0.038101911544799805
[Epoch 2][Step 90], time=0.08235836029052734, ext_time=0.04027867317199707, train_time=0.03711438179016113
[Epoch 2][Step 91], time=0.08297324180603027, ext_time=0.040157318115234375, train_time=0.03784537315368652
[Epoch 2][Step 92], time=0.08326172828674316, ext_time=0.040358543395996094, train_time=0.037943124771118164
[Epoch 2][Step 93], time=0.08278512954711914, ext_time=0.039361000061035156, train_time=0.038466453552246094
[Epoch 2][Step 94], time=0.08267021179199219, ext_time=0.040144920349121094, train_time=0.03753972053527832
[Epoch 2][Step 95], time=0.08264398574829102, ext_time=0.03930377960205078, train_time=0.03839540481567383
[Epoch 2][Step 96], time=0.08269453048706055, ext_time=0.03986096382141113, train_time=0.037903785705566406
[Epoch 2][Step 97], time=0.08230233192443848, ext_time=0.03974294662475586, train_time=0.037560462951660156
[Epoch 2][Step 98], time=0.08257651329040527, ext_time=0.03971433639526367, train_time=0.037894248962402344
[Epoch 2][Step 99], time=0.08332633972167969, ext_time=0.039845943450927734, train_time=0.03846454620361328
[Epoch 2][Step 100], time=0.08326244354248047, ext_time=0.04055953025817871, train_time=0.037703514099121094
[Epoch 2][Step 101], time=0.08299112319946289, ext_time=0.040166378021240234, train_time=0.037859439849853516
[Epoch 2][Step 102], time=0.08381056785583496, ext_time=0.04037976264953613, train_time=0.03844904899597168
[Epoch 2][Step 103], time=0.08331131935119629, ext_time=0.04030561447143555, train_time=0.037950754165649414
[Epoch 2][Step 104], time=0.08306550979614258, ext_time=0.03988242149353027, train_time=0.03815579414367676
[Epoch 2][Step 105], time=0.08314204216003418, ext_time=0.039524078369140625, train_time=0.038604736328125
[Epoch 2][Step 106], time=0.0822749137878418, ext_time=0.04032564163208008, train_time=0.03702092170715332
[Epoch 2][Step 107], time=0.08332633972167969, ext_time=0.03981494903564453, train_time=0.038596153259277344
[Epoch 2][Step 108], time=0.08325600624084473, ext_time=0.039502620697021484, train_time=0.03879737854003906
[Epoch 2][Step 109], time=0.0823361873626709, ext_time=0.038889169692993164, train_time=0.036878108978271484
[Epoch 2][Step 110], time=0.08369970321655273, ext_time=0.04097914695739746, train_time=0.037714481353759766
[Epoch 2][Step 111], time=0.08293437957763672, ext_time=0.04029965400695801, train_time=0.03767085075378418
[Epoch 2][Step 112], time=0.0826406478881836, ext_time=0.039460182189941406, train_time=0.03819894790649414
[Epoch 2][Step 113], time=0.08267927169799805, ext_time=0.0398867130279541, train_time=0.0378720760345459
[Epoch 2][Step 114], time=0.08247876167297363, ext_time=0.040014028549194336, train_time=0.03751516342163086
[Epoch 2][Step 115], time=0.08224344253540039, ext_time=0.039405107498168945, train_time=0.037889719009399414
[Epoch 2][Step 116], time=0.08445215225219727, ext_time=0.04013967514038086, train_time=0.03937506675720215
[Epoch 2][Step 117], time=0.08262181282043457, ext_time=0.03995084762573242, train_time=0.03770899772644043
[Epoch 2][Step 118], time=0.08324790000915527, ext_time=0.03980445861816406, train_time=0.03840494155883789
[Epoch 2][Step 119], time=0.08337163925170898, ext_time=0.04055047035217285, train_time=0.03781294822692871
[Epoch 2][Step 120], time=0.08328461647033691, ext_time=0.0397191047668457, train_time=0.03863716125488281
[Epoch 2][Step 121], time=0.08332467079162598, ext_time=0.040659427642822266, train_time=0.03764605522155762
[Epoch 2][Step 122], time=0.08327865600585938, ext_time=0.0397188663482666, train_time=0.038637638092041016
[Epoch 2][Step 123], time=0.08331966400146484, ext_time=0.03974199295043945, train_time=0.03860902786254883
[Epoch 2][Step 124], time=0.08338427543640137, ext_time=0.03994417190551758, train_time=0.038504600524902344
[Epoch 2][Step 125], time=0.0824730396270752, ext_time=0.04056954383850098, train_time=0.03701305389404297
[Epoch 2][Step 126], time=0.08234214782714844, ext_time=0.039626359939575195, train_time=0.037790536880493164
[Epoch 2][Step 127], time=0.08326005935668945, ext_time=0.03964948654174805, train_time=0.038693904876708984
[Epoch 2][Step 128], time=0.08347940444946289, ext_time=0.04029703140258789, train_time=0.038169145584106445
[Epoch 2][Step 129], time=0.08245992660522461, ext_time=0.040246009826660156, train_time=0.03725171089172363
[Epoch 2][Step 130], time=0.0826561450958252, ext_time=0.03972363471984863, train_time=0.0379486083984375
[Epoch 2][Step 131], time=0.08255219459533691, ext_time=0.040039777755737305, train_time=0.037538766860961914
[Epoch 2][Step 132], time=0.08270144462585449, ext_time=0.03909039497375488, train_time=0.03873157501220703
[Epoch 2][Step 133], time=0.08298945426940918, ext_time=0.04018568992614746, train_time=0.037772178649902344
[Epoch 2][Step 134], time=0.0881204605102539, ext_time=0.039511680603027344, train_time=0.038330793380737305
[Epoch 2][Step 135], time=0.08376646041870117, ext_time=0.039894819259643555, train_time=0.03892779350280762
[Epoch 2][Step 136], time=0.0827951431274414, ext_time=0.03910636901855469, train_time=0.03879499435424805
[Epoch 2][Step 137], time=0.08314108848571777, ext_time=0.04033327102661133, train_time=0.03790283203125
[Epoch 2][Step 138], time=0.0831291675567627, ext_time=0.039927005767822266, train_time=0.038153648376464844
[Epoch 2][Step 139], time=0.0829000473022461, ext_time=0.03949689865112305, train_time=0.03848838806152344
[Epoch 2][Step 140], time=0.08247256278991699, ext_time=0.03954482078552246, train_time=0.037999868392944336
[Epoch 2][Step 141], time=0.08392143249511719, ext_time=0.04073786735534668, train_time=0.03815627098083496
[Epoch 2][Step 142], time=0.08238887786865234, ext_time=0.039981842041015625, train_time=0.037390947341918945
[Epoch 2][Step 143], time=0.0824575424194336, ext_time=0.04011821746826172, train_time=0.03738069534301758
[Epoch 2][Step 144], time=0.08276915550231934, ext_time=0.039868831634521484, train_time=0.03793501853942871
[Epoch 2][Step 145], time=0.08368062973022461, ext_time=0.04089164733886719, train_time=0.03782153129577637
[Epoch 2][Step 146], time=0.08302879333496094, ext_time=0.03928256034851074, train_time=0.0372776985168457
[Epoch 2][Step 147], time=0.08277463912963867, ext_time=0.03993034362792969, train_time=0.03788495063781738
[Epoch 2][Step 148], time=0.08303046226501465, ext_time=0.04068613052368164, train_time=0.03735971450805664
[Epoch 2][Step 149], time=0.08251523971557617, ext_time=0.03998303413391113, train_time=0.037603139877319336
[Epoch 2][Step 150], time=0.0835573673248291, ext_time=0.03935885429382324, train_time=0.039237260818481445
[Epoch 2][Step 151], time=0.0830068588256836, ext_time=0.04050803184509277, train_time=0.0374603271484375
[Epoch 2][Step 152], time=0.08280730247497559, ext_time=0.03962111473083496, train_time=0.0381922721862793
[Epoch 2][Step 153], time=0.0831902027130127, ext_time=0.03994154930114746, train_time=0.038355350494384766
[Epoch 2][Step 154], time=0.08197522163391113, ext_time=0.03996109962463379, train_time=0.03706622123718262
[Epoch 2][Step 155], time=0.08316946029663086, ext_time=0.04017782211303711, train_time=0.03802800178527832
[Epoch 2][Step 156], time=0.08294558525085449, ext_time=0.040129899978637695, train_time=0.03777027130126953
[Epoch 2][Step 157], time=0.08289504051208496, ext_time=0.04003143310546875, train_time=0.03796100616455078
[Epoch 2][Step 158], time=0.08282613754272461, ext_time=0.04009699821472168, train_time=0.03777122497558594
[Epoch 2][Step 159], time=0.0833287239074707, ext_time=0.03879952430725098, train_time=0.03961610794067383
[Epoch 2][Step 160], time=0.08324575424194336, ext_time=0.03978562355041504, train_time=0.038468122482299805
[Epoch 2][Step 161], time=0.08300518989562988, ext_time=0.04052281379699707, train_time=0.03747296333312988
[Epoch 2][Step 162], time=0.08358407020568848, ext_time=0.040331125259399414, train_time=0.038278818130493164
[Epoch 2][Step 163], time=0.0826261043548584, ext_time=0.04013776779174805, train_time=0.03751063346862793
[Epoch 2][Step 164], time=0.08272051811218262, ext_time=0.03920125961303711, train_time=0.0386202335357666
[Epoch 2][Step 165], time=0.08239364624023438, ext_time=0.03972792625427246, train_time=0.037714242935180664
[Epoch 2][Step 166], time=0.08217930793762207, ext_time=0.03972768783569336, train_time=0.03749489784240723
[Epoch 2][Step 167], time=0.0838768482208252, ext_time=0.040415287017822266, train_time=0.03846454620361328
[Epoch 2][Step 168], time=0.08301830291748047, ext_time=0.04037904739379883, train_time=0.03765368461608887
[Epoch 2][Step 169], time=0.46131134033203125, ext_time=0.040349483489990234, train_time=0.4159235954284668
[Epoch 2][Step 170], time=0.08375978469848633, ext_time=0.03964638710021973, train_time=0.0391237735748291
[Epoch 2][Step 171], time=0.08260655403137207, ext_time=0.03991246223449707, train_time=0.03771638870239258
[Epoch 2][Step 172], time=0.08367419242858887, ext_time=0.038814544677734375, train_time=0.03997540473937988
[Epoch 2][Step 173], time=0.08350014686584473, ext_time=0.040674448013305664, train_time=0.03784298896789551
[Epoch 2][Step 174], time=0.08259320259094238, ext_time=0.03947281837463379, train_time=0.03814959526062012
[Epoch 2][Step 175], time=0.08348703384399414, ext_time=0.04007291793823242, train_time=0.038459062576293945
[Epoch 2][Step 176], time=0.0836794376373291, ext_time=0.04106736183166504, train_time=0.03766489028930664
[Epoch 2][Step 177], time=0.0827336311340332, ext_time=0.039402008056640625, train_time=0.03841066360473633
[Epoch 2][Step 178], time=0.08181595802307129, ext_time=0.03977179527282715, train_time=0.03710770606994629
[Epoch 2][Step 179], time=0.08350253105163574, ext_time=0.03996443748474121, train_time=0.03855419158935547
[Epoch 2][Step 180], time=0.0828249454498291, ext_time=0.03961896896362305, train_time=0.03823494911193848
[Epoch 2][Step 181], time=0.08270382881164551, ext_time=0.04018712043762207, train_time=0.037516117095947266
[Epoch 2][Step 182], time=0.08228278160095215, ext_time=0.039113521575927734, train_time=0.038248538970947266
[Epoch 2][Step 183], time=0.08390545845031738, ext_time=0.04049563407897949, train_time=0.03846549987792969
[Epoch 2][Step 184], time=0.08271646499633789, ext_time=0.040343284606933594, train_time=0.03744220733642578
[Epoch 2][Step 185], time=0.08257722854614258, ext_time=0.040268898010253906, train_time=0.037358999252319336
[Epoch 2][Step 186], time=0.08291125297546387, ext_time=0.04008316993713379, train_time=0.03778433799743652
[Epoch 2][Step 187], time=0.08318424224853516, ext_time=0.04067564010620117, train_time=0.03749895095825195
[Epoch 2][Step 188], time=0.08415365219116211, ext_time=0.03929615020751953, train_time=0.03990983963012695
[Epoch 2][Step 189], time=0.08316302299499512, ext_time=0.03898978233337402, train_time=0.03923177719116211
[Epoch 2][Step 190], time=0.08201932907104492, ext_time=0.03914332389831543, train_time=0.03795003890991211
[Epoch 2][Step 191], time=0.08283162117004395, ext_time=0.040123939514160156, train_time=0.037682533264160156
[Epoch 2][Step 192], time=0.0830075740814209, ext_time=0.03944873809814453, train_time=0.03862285614013672
[Epoch 2][Step 193], time=0.08262443542480469, ext_time=0.03934216499328613, train_time=0.038262128829956055
[Epoch 2][Step 194], time=0.08355212211608887, ext_time=0.040218353271484375, train_time=0.038338422775268555
[Epoch 2][Step 195], time=0.08282899856567383, ext_time=0.040213584899902344, train_time=0.03760194778442383
[Epoch 2][Step 196], time=0.08248686790466309, ext_time=0.0401453971862793, train_time=0.037409305572509766
[Epoch 2][Step 197], time=0.082183837890625, ext_time=0.039762020111083984, train_time=0.037484169006347656
[Epoch 2][Step 198], time=0.08281707763671875, ext_time=0.03989863395690918, train_time=0.03804349899291992
[Epoch 2][Step 199], time=0.08289074897766113, ext_time=0.039263248443603516, train_time=0.03872537612915039
[Epoch 2][Step 200], time=0.08296489715576172, ext_time=0.040570974349975586, train_time=0.037461042404174805
[Epoch 2][Step 201], time=0.49361205101013184, ext_time=0.03959250450134277, train_time=0.44907045364379883
[Epoch 2][Step 202], time=0.08370041847229004, ext_time=0.039713382720947266, train_time=0.03903317451477051
[Epoch 2][Step 203], time=0.0825185775756836, ext_time=0.039629459381103516, train_time=0.03795671463012695
[Epoch 2][Step 204], time=0.08277750015258789, ext_time=0.03984189033508301, train_time=0.03804326057434082
[Epoch 2][Step 205], time=0.08261871337890625, ext_time=0.03920865058898926, train_time=0.03851032257080078
[Epoch 2][Step 206], time=0.08281970024108887, ext_time=0.03883767127990723, train_time=0.03911256790161133
[Epoch 2][Step 207], time=0.0834496021270752, ext_time=0.03990626335144043, train_time=0.03856968879699707
[Epoch 2][Step 208], time=0.08234643936157227, ext_time=0.03967142105102539, train_time=0.037731170654296875
[Epoch 2][Step 209], time=0.08352422714233398, ext_time=0.040140628814697266, train_time=0.03846406936645508
[Epoch 2][Step 210], time=0.08266210556030273, ext_time=0.03990530967712402, train_time=0.03777456283569336
[Epoch 2][Step 211], time=0.08437967300415039, ext_time=0.040488481521606445, train_time=0.03886151313781738
[Epoch 2][Step 212], time=0.08341503143310547, ext_time=0.04061174392700195, train_time=0.03774738311767578
[Epoch 2][Step 213], time=0.08267402648925781, ext_time=0.04007911682128906, train_time=0.03758668899536133
[Epoch 2][Step 214], time=0.08295273780822754, ext_time=0.0398707389831543, train_time=0.03811025619506836
[Epoch 2][Step 215], time=0.08285784721374512, ext_time=0.04073476791381836, train_time=0.0371556282043457
[Epoch 2][Step 216], time=0.08339524269104004, ext_time=0.04008603096008301, train_time=0.03833341598510742
[Epoch 2][Step 217], time=0.08282136917114258, ext_time=0.04046225547790527, train_time=0.037355661392211914
[Epoch 2][Step 218], time=0.08263492584228516, ext_time=0.04019665718078613, train_time=0.037552833557128906
[Epoch 2][Step 219], time=0.08347630500793457, ext_time=0.04068803787231445, train_time=0.03775477409362793
[Epoch 2][Step 220], time=0.08232283592224121, ext_time=0.03979992866516113, train_time=0.03756833076477051
[Epoch 2][Step 221], time=0.08288335800170898, ext_time=0.04020571708679199, train_time=0.037729501724243164
[Epoch 2][Step 222], time=0.08252763748168945, ext_time=0.0400090217590332, train_time=0.03750920295715332
[Epoch 2][Step 223], time=0.0825490951538086, ext_time=0.04033160209655762, train_time=0.037236690521240234
[Epoch 2][Step 224], time=0.08199405670166016, ext_time=0.039663076400756836, train_time=0.037430763244628906
[Epoch 2][Step 225], time=0.08259725570678711, ext_time=0.04013681411743164, train_time=0.03747105598449707
[Epoch 2][Step 226], time=0.08284115791320801, ext_time=0.04040813446044922, train_time=0.0374755859375
[Epoch 2][Step 227], time=0.08286762237548828, ext_time=0.03936028480529785, train_time=0.0386202335357666
[Epoch 2][Step 228], time=0.08275175094604492, ext_time=0.0403902530670166, train_time=0.037384748458862305
[Epoch 2][Step 229], time=0.08311820030212402, ext_time=0.03952336311340332, train_time=0.0386347770690918
[Epoch 2][Step 230], time=0.0828704833984375, ext_time=0.04035162925720215, train_time=0.03749537467956543
[Epoch 2][Step 231], time=0.08222270011901855, ext_time=0.039983272552490234, train_time=0.037270545959472656
[Epoch 2][Step 232], time=0.08261370658874512, ext_time=0.03895449638366699, train_time=0.038700103759765625
[Epoch 2][Step 233], time=0.0832829475402832, ext_time=0.0395359992980957, train_time=0.03875613212585449
[Epoch 2][Step 234], time=0.08331561088562012, ext_time=0.040018558502197266, train_time=0.03827691078186035
[Epoch 2][Step 235], time=0.08249568939208984, ext_time=0.03965163230895996, train_time=0.037877798080444336
[Epoch 2][Step 236], time=0.08311963081359863, ext_time=0.040206193923950195, train_time=0.03792738914489746
[Epoch 2][Step 237], time=0.08419084548950195, ext_time=0.04044198989868164, train_time=0.038799285888671875
[Epoch 2][Step 238], time=0.08228182792663574, ext_time=0.03978085517883301, train_time=0.03755784034729004
[Epoch 2][Step 239], time=0.0825035572052002, ext_time=0.03979682922363281, train_time=0.03773975372314453
[Epoch 2][Step 240], time=0.08359575271606445, ext_time=0.040399789810180664, train_time=0.038213491439819336
[Epoch 2][Step 241], time=0.08224272727966309, ext_time=0.04020571708679199, train_time=0.03708457946777344
[Epoch 2][Step 242], time=0.0827178955078125, ext_time=0.040261268615722656, train_time=0.037451744079589844
[Epoch 2][Step 243], time=0.08231496810913086, ext_time=0.040131568908691406, train_time=0.037212371826171875
[Epoch 2][Step 244], time=0.08308839797973633, ext_time=0.0403592586517334, train_time=0.037746429443359375
[Epoch 2][Step 245], time=0.08262443542480469, ext_time=0.04014778137207031, train_time=0.03751516342163086
[Epoch 2][Step 246], time=0.08291292190551758, ext_time=0.03957509994506836, train_time=0.03846383094787598
[Epoch 2][Step 247], time=0.08292198181152344, ext_time=0.0403141975402832, train_time=0.03760671615600586
[Epoch 2][Step 248], time=0.08236432075500488, ext_time=0.03944826126098633, train_time=0.03798103332519531
[Epoch 2][Step 249], time=0.08295512199401855, ext_time=0.04021859169006348, train_time=0.03772401809692383
[Epoch 2], time=21.564085006713867, loss=nan
[Epoch 3][Step 0], time=0.08288764953613281, ext_time=0.0402836799621582, train_time=0.037596702575683594
[Epoch 3][Step 1], time=0.08404684066772461, ext_time=0.04082989692687988, train_time=0.03815793991088867
[Epoch 3][Step 2], time=0.08282828330993652, ext_time=0.03943300247192383, train_time=0.03846144676208496
[Epoch 3][Step 3], time=0.08321785926818848, ext_time=0.04025125503540039, train_time=0.037995338439941406
[Epoch 3][Step 4], time=0.08330845832824707, ext_time=0.04061174392700195, train_time=0.03773331642150879
[Epoch 3][Step 5], time=0.08330965042114258, ext_time=0.04042363166809082, train_time=0.03786826133728027
[Epoch 3][Step 6], time=0.08320879936218262, ext_time=0.03958272933959961, train_time=0.038666725158691406
[Epoch 3][Step 7], time=0.08340024948120117, ext_time=0.04022860527038574, train_time=0.038202762603759766
[Epoch 3][Step 8], time=0.08271384239196777, ext_time=0.040075063705444336, train_time=0.03765869140625
[Epoch 3][Step 9], time=0.08330512046813965, ext_time=0.03983139991760254, train_time=0.03851675987243652
[Epoch 3][Step 10], time=0.08393359184265137, ext_time=0.040933847427368164, train_time=0.03800463676452637
[Epoch 3][Step 11], time=0.0835869312286377, ext_time=0.03989076614379883, train_time=0.03870749473571777
[Epoch 3][Step 12], time=0.08301472663879395, ext_time=0.040426015853881836, train_time=0.03767251968383789
[Epoch 3][Step 13], time=0.0824422836303711, ext_time=0.0403590202331543, train_time=0.03714561462402344
[Epoch 3][Step 14], time=0.08333683013916016, ext_time=0.04056143760681152, train_time=0.03773212432861328
[Epoch 3][Step 15], time=0.08352518081665039, ext_time=0.040276288986206055, train_time=0.03826332092285156
[Epoch 3][Step 16], time=0.08297610282897949, ext_time=0.039839744567871094, train_time=0.03815436363220215
[Epoch 3][Step 17], time=0.08267521858215332, ext_time=0.03997468948364258, train_time=0.03769063949584961
[Epoch 3][Step 18], time=0.08297276496887207, ext_time=0.04002237319946289, train_time=0.03802847862243652
[Epoch 3][Step 19], time=0.08363008499145508, ext_time=0.04049420356750488, train_time=0.038152456283569336
[Epoch 3][Step 20], time=0.08318710327148438, ext_time=0.039333343505859375, train_time=0.038927555084228516
[Epoch 3][Step 21], time=0.08248543739318848, ext_time=0.04018521308898926, train_time=0.03731060028076172
[Epoch 3][Step 22], time=0.08293938636779785, ext_time=0.04080986976623535, train_time=0.03716015815734863
[Epoch 3][Step 23], time=0.08305668830871582, ext_time=0.040567636489868164, train_time=0.037506818771362305
[Epoch 3][Step 24], time=0.0832521915435791, ext_time=0.04070329666137695, train_time=0.03758883476257324
[Epoch 3][Step 25], time=0.08294320106506348, ext_time=0.040218353271484375, train_time=0.03779792785644531
[Epoch 3][Step 26], time=0.08319616317749023, ext_time=0.04027223587036133, train_time=0.037871599197387695
[Epoch 3][Step 27], time=0.08252859115600586, ext_time=0.03978729248046875, train_time=0.03773832321166992
[Epoch 3][Step 28], time=0.08321261405944824, ext_time=0.04058718681335449, train_time=0.03767991065979004
[Epoch 3][Step 29], time=0.08318614959716797, ext_time=0.04025411605834961, train_time=0.03790855407714844
[Epoch 3][Step 30], time=0.08254718780517578, ext_time=0.03982353210449219, train_time=0.03770852088928223
[Epoch 3][Step 31], time=0.08246159553527832, ext_time=0.03962874412536621, train_time=0.03790283203125
[Epoch 3][Step 32], time=0.08324289321899414, ext_time=0.039620161056518555, train_time=0.03869915008544922
[Epoch 3][Step 33], time=0.08267688751220703, ext_time=0.04039263725280762, train_time=0.03734755516052246
[Epoch 3][Step 34], time=0.0821535587310791, ext_time=0.03992605209350586, train_time=0.037306785583496094
[Epoch 3][Step 35], time=0.08271908760070801, ext_time=0.040193796157836914, train_time=0.03761696815490723
[Epoch 3][Step 36], time=0.08333230018615723, ext_time=0.04062604904174805, train_time=0.03752398490905762
[Epoch 3][Step 37], time=0.08312511444091797, ext_time=0.0404205322265625, train_time=0.03766775131225586
[Epoch 3][Step 38], time=0.08251404762268066, ext_time=0.039635419845581055, train_time=0.037964582443237305
[Epoch 3][Step 39], time=0.08268618583679199, ext_time=0.0393831729888916, train_time=0.0383758544921875
[Epoch 3][Step 40], time=0.08327245712280273, ext_time=0.03970003128051758, train_time=0.038537025451660156
[Epoch 3][Step 41], time=0.08325004577636719, ext_time=0.04017233848571777, train_time=0.037999868392944336
[Epoch 3][Step 42], time=0.08401656150817871, ext_time=0.040099382400512695, train_time=0.03889942169189453
[Epoch 3][Step 43], time=0.08213376998901367, ext_time=0.03954458236694336, train_time=0.037644147872924805
[Epoch 3][Step 44], time=0.08416962623596191, ext_time=0.0409243106842041, train_time=0.03824591636657715
[Epoch 3][Step 45], time=0.08375883102416992, ext_time=0.03826093673706055, train_time=0.04051494598388672
[Epoch 3][Step 46], time=0.08279824256896973, ext_time=0.040067195892333984, train_time=0.037761688232421875
[Epoch 3][Step 47], time=0.08973073959350586, ext_time=0.03958487510681152, train_time=0.04520392417907715
[Epoch 3][Step 48], time=0.08287358283996582, ext_time=0.0399622917175293, train_time=0.037897586822509766
[Epoch 3][Step 49], time=0.08391165733337402, ext_time=0.04001665115356445, train_time=0.03896141052246094
[Epoch 3][Step 50], time=0.0834040641784668, ext_time=0.03919029235839844, train_time=0.03924989700317383
[Epoch 3][Step 51], time=0.08416128158569336, ext_time=0.039502859115600586, train_time=0.03969907760620117
[Epoch 3][Step 52], time=0.08257579803466797, ext_time=0.039788007736206055, train_time=0.03782510757446289
[Epoch 3][Step 53], time=0.08238482475280762, ext_time=0.03991055488586426, train_time=0.037522077560424805
[Epoch 3][Step 54], time=0.0917510986328125, ext_time=0.03937053680419922, train_time=0.040848493576049805
[Epoch 3][Step 55], time=0.08263683319091797, ext_time=0.040377140045166016, train_time=0.03728365898132324
[Epoch 3][Step 56], time=0.08248281478881836, ext_time=0.03989458084106445, train_time=0.03769493103027344
[Epoch 3][Step 57], time=0.08221101760864258, ext_time=0.039501190185546875, train_time=0.03783583641052246
[Epoch 3][Step 58], time=0.08385920524597168, ext_time=0.040593862533569336, train_time=0.03826308250427246
[Epoch 3][Step 59], time=0.08291482925415039, ext_time=0.03946208953857422, train_time=0.038460731506347656
[Epoch 3][Step 60], time=0.0825948715209961, ext_time=0.039928436279296875, train_time=0.03766632080078125
[Epoch 3][Step 61], time=0.08300232887268066, ext_time=0.04025459289550781, train_time=0.03777956962585449
[Epoch 3][Step 62], time=0.08256411552429199, ext_time=0.03969931602478027, train_time=0.03792977333068848
[Epoch 3][Step 63], time=0.08284378051757812, ext_time=0.03955507278442383, train_time=0.03838372230529785
[Epoch 3][Step 64], time=0.0827939510345459, ext_time=0.039966583251953125, train_time=0.03791451454162598
[Epoch 3][Step 65], time=0.0842893123626709, ext_time=0.039727210998535156, train_time=0.03956174850463867
[Epoch 3][Step 66], time=0.08294868469238281, ext_time=0.040300846099853516, train_time=0.037686824798583984
[Epoch 3][Step 67], time=0.08286881446838379, ext_time=0.04007124900817871, train_time=0.03777813911437988
[Epoch 3][Step 68], time=0.08274698257446289, ext_time=0.03998279571533203, train_time=0.03781390190124512
[Epoch 3][Step 69], time=0.08244657516479492, ext_time=0.039946794509887695, train_time=0.03752899169921875
[Epoch 3][Step 70], time=0.08395028114318848, ext_time=0.040617942810058594, train_time=0.03840756416320801
[Epoch 3][Step 71], time=0.08216524124145508, ext_time=0.03920865058898926, train_time=0.03799891471862793
[Epoch 3][Step 72], time=0.08338546752929688, ext_time=0.04078054428100586, train_time=0.03762364387512207
[Epoch 3][Step 73], time=0.08297038078308105, ext_time=0.03993678092956543, train_time=0.038042545318603516
[Epoch 3][Step 74], time=0.08366990089416504, ext_time=0.04034876823425293, train_time=0.038336753845214844
[Epoch 3][Step 75], time=0.08201432228088379, ext_time=0.03962254524230957, train_time=0.03741765022277832
[Epoch 3][Step 76], time=0.08336734771728516, ext_time=0.04063081741333008, train_time=0.03772711753845215
[Epoch 3][Step 77], time=0.08335995674133301, ext_time=0.0406193733215332, train_time=0.03777575492858887
[Epoch 3][Step 78], time=0.08370184898376465, ext_time=0.040463924407958984, train_time=0.03821921348571777
[Epoch 3][Step 79], time=0.08240270614624023, ext_time=0.03933000564575195, train_time=0.038210153579711914
[Epoch 3][Step 80], time=0.08258461952209473, ext_time=0.039444684982299805, train_time=0.03824186325073242
[Epoch 3][Step 81], time=0.08267331123352051, ext_time=0.039356231689453125, train_time=0.03843379020690918
[Epoch 3][Step 82], time=0.08244657516479492, ext_time=0.03979992866516113, train_time=0.03763532638549805
[Epoch 3][Step 83], time=0.08350872993469238, ext_time=0.04052281379699707, train_time=0.03794503211975098
[Epoch 3][Step 84], time=0.0825655460357666, ext_time=0.04023313522338867, train_time=0.03739500045776367
[Epoch 3][Step 85], time=0.08336114883422852, ext_time=0.0402827262878418, train_time=0.038149118423461914
[Epoch 3][Step 86], time=0.08262777328491211, ext_time=0.03961324691772461, train_time=0.038056135177612305
[Epoch 3][Step 87], time=0.08363866806030273, ext_time=0.03981757164001465, train_time=0.03887605667114258
[Epoch 3][Step 88], time=0.08254837989807129, ext_time=0.03979229927062988, train_time=0.03785538673400879
[Epoch 3][Step 89], time=0.08318328857421875, ext_time=0.03941631317138672, train_time=0.038785457611083984
[Epoch 3][Step 90], time=0.0826566219329834, ext_time=0.040328025817871094, train_time=0.03734445571899414
[Epoch 3][Step 91], time=0.08285880088806152, ext_time=0.040262699127197266, train_time=0.0375971794128418
[Epoch 3][Step 92], time=0.08397555351257324, ext_time=0.03964710235595703, train_time=0.03941535949707031
[Epoch 3][Step 93], time=0.08294129371643066, ext_time=0.03973817825317383, train_time=0.03819561004638672
[Epoch 3][Step 94], time=0.08231425285339355, ext_time=0.03990578651428223, train_time=0.03746986389160156
[Epoch 3][Step 95], time=0.08267378807067871, ext_time=0.03941035270690918, train_time=0.038278818130493164
[Epoch 3][Step 96], time=0.08305239677429199, ext_time=0.039927005767822266, train_time=0.03813338279724121
[Epoch 3][Step 97], time=0.0828862190246582, ext_time=0.04009389877319336, train_time=0.03774690628051758
[Epoch 3][Step 98], time=0.08247804641723633, ext_time=0.04012155532836914, train_time=0.0373845100402832
[Epoch 3][Step 99], time=0.08330821990966797, ext_time=0.03988289833068848, train_time=0.03845405578613281
[Epoch 3][Step 100], time=0.08286881446838379, ext_time=0.0400998592376709, train_time=0.037811279296875
[Epoch 3][Step 101], time=0.0828697681427002, ext_time=0.04004359245300293, train_time=0.03786277770996094
[Epoch 3][Step 102], time=0.0835726261138916, ext_time=0.04076361656188965, train_time=0.03777337074279785
[Epoch 3][Step 103], time=0.08323502540588379, ext_time=0.040349721908569336, train_time=0.03786444664001465
[Epoch 3][Step 104], time=0.08321571350097656, ext_time=0.039888858795166016, train_time=0.03823685646057129
[Epoch 3][Step 105], time=0.08347535133361816, ext_time=0.039643287658691406, train_time=0.03888130187988281
[Epoch 3][Step 106], time=0.08301043510437012, ext_time=0.040154218673706055, train_time=0.03793001174926758
[Epoch 3][Step 107], time=0.08278965950012207, ext_time=0.03992915153503418, train_time=0.03791642189025879
[Epoch 3][Step 108], time=0.08408236503601074, ext_time=0.03938865661621094, train_time=0.03975820541381836
[Epoch 3][Step 109], time=0.08256793022155762, ext_time=0.03952908515930176, train_time=0.03810572624206543
[Epoch 3][Step 110], time=0.08278751373291016, ext_time=0.0406641960144043, train_time=0.03715062141418457
[Epoch 3][Step 111], time=0.08306241035461426, ext_time=0.040256500244140625, train_time=0.03783607482910156
[Epoch 3][Step 112], time=0.0831139087677002, ext_time=0.03959918022155762, train_time=0.03854489326477051
[Epoch 3][Step 113], time=0.08284544944763184, ext_time=0.039984941482543945, train_time=0.0379638671875
[Epoch 3][Step 114], time=0.0829629898071289, ext_time=0.04036664962768555, train_time=0.03759336471557617
[Epoch 3][Step 115], time=0.08239102363586426, ext_time=0.03895711898803711, train_time=0.03854227066040039
[Epoch 3][Step 116], time=0.08340334892272949, ext_time=0.0392453670501709, train_time=0.03927183151245117
[Epoch 3][Step 117], time=0.08271646499633789, ext_time=0.04007387161254883, train_time=0.03768515586853027
[Epoch 3][Step 118], time=0.08267545700073242, ext_time=0.039990901947021484, train_time=0.03765153884887695
[Epoch 3][Step 119], time=0.08340883255004883, ext_time=0.040476083755493164, train_time=0.037943124771118164
[Epoch 3][Step 120], time=0.08309698104858398, ext_time=0.04024982452392578, train_time=0.037842750549316406
[Epoch 3][Step 121], time=0.0840601921081543, ext_time=0.040918827056884766, train_time=0.03811216354370117
[Epoch 3][Step 122], time=0.08349943161010742, ext_time=0.03980898857116699, train_time=0.0387578010559082
[Epoch 3][Step 123], time=0.08303356170654297, ext_time=0.03997063636779785, train_time=0.0381016731262207
[Epoch 3][Step 124], time=0.08298993110656738, ext_time=0.03965425491333008, train_time=0.03838324546813965
[Epoch 3][Step 125], time=0.08285164833068848, ext_time=0.040685415267944336, train_time=0.03713703155517578
[Epoch 3][Step 126], time=0.08257341384887695, ext_time=0.040000200271606445, train_time=0.0376429557800293
[Epoch 3][Step 127], time=0.08403730392456055, ext_time=0.03908371925354004, train_time=0.04005765914916992
[Epoch 3][Step 128], time=0.08326530456542969, ext_time=0.04006528854370117, train_time=0.038213491439819336
[Epoch 3][Step 129], time=0.08223080635070801, ext_time=0.03994393348693848, train_time=0.037253618240356445
[Epoch 3][Step 130], time=0.08288908004760742, ext_time=0.03996086120605469, train_time=0.037899017333984375
[Epoch 3][Step 131], time=0.08260774612426758, ext_time=0.03976631164550781, train_time=0.03786778450012207
[Epoch 3][Step 132], time=0.08334493637084961, ext_time=0.0394742488861084, train_time=0.03896021842956543
[Epoch 3][Step 133], time=0.08241057395935059, ext_time=0.039806365966796875, train_time=0.037647247314453125
[Epoch 3][Step 134], time=0.08481764793395996, ext_time=0.0401153564453125, train_time=0.039717674255371094
[Epoch 3][Step 135], time=0.08307743072509766, ext_time=0.03952479362487793, train_time=0.03864598274230957
[Epoch 3][Step 136], time=0.08292865753173828, ext_time=0.03892111778259277, train_time=0.03913259506225586
[Epoch 3][Step 137], time=0.08347487449645996, ext_time=0.040270328521728516, train_time=0.03826165199279785
[Epoch 3][Step 138], time=0.08377408981323242, ext_time=0.03922224044799805, train_time=0.039597511291503906
[Epoch 3][Step 139], time=0.08236289024353027, ext_time=0.03925466537475586, train_time=0.03818368911743164
[Epoch 3][Step 140], time=0.0829620361328125, ext_time=0.03931784629821777, train_time=0.038709163665771484
[Epoch 3][Step 141], time=0.08377790451049805, ext_time=0.04062294960021973, train_time=0.03813886642456055
[Epoch 3][Step 142], time=0.08326530456542969, ext_time=0.03985857963562012, train_time=0.03846621513366699
[Epoch 3][Step 143], time=0.08270406723022461, ext_time=0.04036092758178711, train_time=0.03739213943481445
[Epoch 3][Step 144], time=0.08229351043701172, ext_time=0.03974342346191406, train_time=0.03757977485656738
[Epoch 3][Step 145], time=0.0834054946899414, ext_time=0.041027069091796875, train_time=0.03739619255065918
[Epoch 3][Step 146], time=0.0828256607055664, ext_time=0.03993391990661621, train_time=0.03795981407165527
[Epoch 3][Step 147], time=0.08348870277404785, ext_time=0.04000568389892578, train_time=0.03849458694458008
[Epoch 3][Step 148], time=0.08290505409240723, ext_time=0.03998589515686035, train_time=0.03799581527709961
[Epoch 3][Step 149], time=0.08266878128051758, ext_time=0.04060101509094238, train_time=0.03712272644042969
[Epoch 3][Step 150], time=0.08299732208251953, ext_time=0.03994417190551758, train_time=0.03806757926940918
[Epoch 3][Step 151], time=0.08319401741027832, ext_time=0.04082942008972168, train_time=0.0373842716217041
[Epoch 3][Step 152], time=0.08299088478088379, ext_time=0.03992819786071777, train_time=0.038071393966674805
[Epoch 3][Step 153], time=0.0829460620880127, ext_time=0.03937077522277832, train_time=0.03872227668762207
[Epoch 3][Step 154], time=0.08223986625671387, ext_time=0.03945565223693848, train_time=0.03789997100830078
[Epoch 3][Step 155], time=0.08319330215454102, ext_time=0.039899349212646484, train_time=0.03834342956542969
[Epoch 3][Step 156], time=0.08317303657531738, ext_time=0.0406031608581543, train_time=0.03756594657897949
[Epoch 3][Step 157], time=0.08302927017211914, ext_time=0.04059314727783203, train_time=0.037464141845703125
[Epoch 3][Step 158], time=0.08294343948364258, ext_time=0.03971385955810547, train_time=0.03834724426269531
[Epoch 3][Step 159], time=0.08327436447143555, ext_time=0.038845062255859375, train_time=0.03949475288391113
[Epoch 3][Step 160], time=0.08280801773071289, ext_time=0.04010319709777832, train_time=0.03768348693847656
[Epoch 3][Step 161], time=0.08287763595581055, ext_time=0.04033994674682617, train_time=0.037554025650024414
[Epoch 3][Step 162], time=0.08347225189208984, ext_time=0.040316104888916016, train_time=0.03820013999938965
[Epoch 3][Step 163], time=0.08312106132507324, ext_time=0.04018211364746094, train_time=0.03800010681152344
[Epoch 3][Step 164], time=0.08307218551635742, ext_time=0.038865089416503906, train_time=0.039311885833740234
[Epoch 3][Step 165], time=0.08252453804016113, ext_time=0.0398709774017334, train_time=0.03765726089477539
[Epoch 3][Step 166], time=0.08265209197998047, ext_time=0.04013705253601074, train_time=0.037499427795410156
[Epoch 3][Step 167], time=0.08307051658630371, ext_time=0.040590524673461914, train_time=0.03744959831237793
[Epoch 3][Step 168], time=0.08298754692077637, ext_time=0.04058527946472168, train_time=0.03739476203918457
[Epoch 3][Step 169], time=0.08304476737976074, ext_time=0.03981423377990723, train_time=0.03819537162780762
[Epoch 3][Step 170], time=0.08394265174865723, ext_time=0.03937482833862305, train_time=0.03959226608276367
[Epoch 3][Step 171], time=0.08403468132019043, ext_time=0.04078960418701172, train_time=0.03820633888244629
[Epoch 3][Step 172], time=0.08254194259643555, ext_time=0.03917813301086426, train_time=0.03839111328125
[Epoch 3][Step 173], time=0.08308863639831543, ext_time=0.03992509841918945, train_time=0.038236141204833984
[Epoch 3][Step 174], time=0.08329510688781738, ext_time=0.039678335189819336, train_time=0.038646697998046875
[Epoch 3][Step 175], time=0.08340787887573242, ext_time=0.03933572769165039, train_time=0.03914237022399902
[Epoch 3][Step 176], time=0.08341217041015625, ext_time=0.04114127159118652, train_time=0.03724956512451172
[Epoch 3][Step 177], time=0.08296322822570801, ext_time=0.03998303413391113, train_time=0.03800821304321289
[Epoch 3][Step 178], time=0.08181190490722656, ext_time=0.039884090423583984, train_time=0.03700137138366699
[Epoch 3][Step 179], time=0.08331608772277832, ext_time=0.040335893630981445, train_time=0.037944793701171875
[Epoch 3][Step 180], time=0.08291864395141602, ext_time=0.03993368148803711, train_time=0.03795957565307617
[Epoch 3][Step 181], time=0.08280825614929199, ext_time=0.04029512405395508, train_time=0.03752398490905762
[Epoch 3][Step 182], time=0.08224153518676758, ext_time=0.039592742919921875, train_time=0.037676334381103516
[Epoch 3][Step 183], time=0.08283114433288574, ext_time=0.040160417556762695, train_time=0.03769540786743164
[Epoch 3][Step 184], time=0.08290362358093262, ext_time=0.04038286209106445, train_time=0.037549495697021484
[Epoch 3][Step 185], time=0.08355975151062012, ext_time=0.04028034210205078, train_time=0.03747367858886719
[Epoch 3][Step 186], time=0.08309078216552734, ext_time=0.03998208045959473, train_time=0.03814101219177246
[Epoch 3][Step 187], time=0.08259201049804688, ext_time=0.03991556167602539, train_time=0.037758827209472656
[Epoch 3][Step 188], time=0.08312582969665527, ext_time=0.039489030838012695, train_time=0.0386960506439209
[Epoch 3][Step 189], time=0.08316302299499512, ext_time=0.03948855400085449, train_time=0.03866934776306152
[Epoch 3][Step 190], time=0.08297848701477051, ext_time=0.03954482078552246, train_time=0.03844571113586426
[Epoch 3][Step 191], time=0.08297061920166016, ext_time=0.04026675224304199, train_time=0.03769373893737793
[Epoch 3][Step 192], time=0.08315658569335938, ext_time=0.038860321044921875, train_time=0.0393977165222168
[Epoch 3][Step 193], time=0.08215856552124023, ext_time=0.0392608642578125, train_time=0.03794980049133301
[Epoch 3][Step 194], time=0.08645844459533691, ext_time=0.040157318115234375, train_time=0.041315317153930664
[Epoch 3][Step 195], time=0.08250093460083008, ext_time=0.04004406929016113, train_time=0.03743267059326172
[Epoch 3][Step 196], time=0.08321475982666016, ext_time=0.0407252311706543, train_time=0.03754067420959473
[Epoch 3][Step 197], time=0.0826425552368164, ext_time=0.040316104888916016, train_time=0.037378549575805664
[Epoch 3][Step 198], time=0.08306026458740234, ext_time=0.040255069732666016, train_time=0.03789973258972168
[Epoch 3][Step 199], time=0.08331990242004395, ext_time=0.03989386558532715, train_time=0.03846311569213867
[Epoch 3][Step 200], time=0.08437919616699219, ext_time=0.041188716888427734, train_time=0.03823661804199219
[Epoch 3][Step 201], time=0.08349418640136719, ext_time=0.03939557075500488, train_time=0.039173126220703125
[Epoch 3][Step 202], time=0.08347749710083008, ext_time=0.04027819633483887, train_time=0.03827309608459473
[Epoch 3][Step 203], time=0.08319997787475586, ext_time=0.04017376899719238, train_time=0.03807711601257324
[Epoch 3][Step 204], time=0.08287620544433594, ext_time=0.04038548469543457, train_time=0.03749513626098633
[Epoch 3][Step 205], time=0.08334565162658691, ext_time=0.0403134822845459, train_time=0.038034677505493164
[Epoch 3][Step 206], time=0.08275651931762695, ext_time=0.039507150650024414, train_time=0.03830289840698242
[Epoch 3][Step 207], time=0.08344078063964844, ext_time=0.03995060920715332, train_time=0.0385136604309082
[Epoch 3][Step 208], time=0.08270502090454102, ext_time=0.03913760185241699, train_time=0.03749966621398926
[Epoch 3][Step 209], time=0.08344054222106934, ext_time=0.03962230682373047, train_time=0.03894376754760742
[Epoch 3][Step 210], time=0.08290791511535645, ext_time=0.03974151611328125, train_time=0.038155555725097656
[Epoch 3][Step 211], time=0.08362197875976562, ext_time=0.0398404598236084, train_time=0.038782596588134766
[Epoch 3][Step 212], time=0.08358955383300781, ext_time=0.04012346267700195, train_time=0.0384831428527832
[Epoch 3][Step 213], time=0.08299970626831055, ext_time=0.04051065444946289, train_time=0.037470340728759766
[Epoch 3][Step 214], time=0.08241605758666992, ext_time=0.03990507125854492, train_time=0.03753519058227539
[Epoch 3][Step 215], time=0.08260965347290039, ext_time=0.04041862487792969, train_time=0.03718852996826172
[Epoch 3][Step 216], time=0.08535385131835938, ext_time=0.04030466079711914, train_time=0.040068864822387695
[Epoch 3][Step 217], time=0.0844869613647461, ext_time=0.041147470474243164, train_time=0.03829813003540039
[Epoch 3][Step 218], time=0.08252930641174316, ext_time=0.04009509086608887, train_time=0.03744316101074219
[Epoch 3][Step 219], time=0.08306050300598145, ext_time=0.04019474983215332, train_time=0.037805795669555664
[Epoch 3][Step 220], time=0.08300375938415527, ext_time=0.039697885513305664, train_time=0.0383760929107666
[Epoch 3][Step 221], time=0.08225560188293457, ext_time=0.039525747299194336, train_time=0.037819862365722656
[Epoch 3][Step 222], time=0.08295297622680664, ext_time=0.03993535041809082, train_time=0.0379939079284668
[Epoch 3][Step 223], time=0.08305501937866211, ext_time=0.03952479362487793, train_time=0.03859686851501465
[Epoch 3][Step 224], time=0.08731818199157715, ext_time=0.039577484130859375, train_time=0.03784441947937012
[Epoch 3][Step 225], time=0.08437204360961914, ext_time=0.040350914001464844, train_time=0.03901553153991699
[Epoch 3][Step 226], time=0.08401751518249512, ext_time=0.04012036323547363, train_time=0.03895378112792969
[Epoch 3][Step 227], time=0.08229207992553711, ext_time=0.03970599174499512, train_time=0.03764224052429199
[Epoch 3][Step 228], time=0.08202314376831055, ext_time=0.03992152214050293, train_time=0.037162065505981445
[Epoch 3][Step 229], time=0.09039068222045898, ext_time=0.0393521785736084, train_time=0.04604482650756836
[Epoch 3][Step 230], time=0.0829768180847168, ext_time=0.04043388366699219, train_time=0.037473201751708984
[Epoch 3][Step 231], time=0.08257699012756348, ext_time=0.04032731056213379, train_time=0.03731060028076172
[Epoch 3][Step 232], time=0.08310985565185547, ext_time=0.039391517639160156, train_time=0.03872275352478027
[Epoch 3][Step 233], time=0.08286285400390625, ext_time=0.03905677795410156, train_time=0.038814544677734375
[Epoch 3][Step 234], time=0.08320736885070801, ext_time=0.04016613960266113, train_time=0.03804731369018555
[Epoch 3][Step 235], time=0.0827631950378418, ext_time=0.03995776176452637, train_time=0.03783988952636719
[Epoch 3][Step 236], time=0.08347558975219727, ext_time=0.04040050506591797, train_time=0.038062334060668945
[Epoch 3][Step 237], time=0.08408999443054199, ext_time=0.040404319763183594, train_time=0.03872942924499512
[Epoch 3][Step 238], time=0.08286356925964355, ext_time=0.0389864444732666, train_time=0.03899741172790527
[Epoch 3][Step 239], time=0.08249974250793457, ext_time=0.040160179138183594, train_time=0.037360429763793945
[Epoch 3][Step 240], time=0.08202672004699707, ext_time=0.03969120979309082, train_time=0.037444114685058594
[Epoch 3][Step 241], time=0.08259248733520508, ext_time=0.04034113883972168, train_time=0.03727412223815918
[Epoch 3][Step 242], time=0.08290767669677734, ext_time=0.03985786437988281, train_time=0.03811073303222656
[Epoch 3][Step 243], time=0.08248043060302734, ext_time=0.04009437561035156, train_time=0.03744816780090332
[Epoch 3][Step 244], time=0.08275389671325684, ext_time=0.04029488563537598, train_time=0.037485361099243164
[Epoch 3][Step 245], time=0.08207392692565918, ext_time=0.039736270904541016, train_time=0.037378787994384766
[Epoch 3][Step 246], time=0.08260416984558105, ext_time=0.039257049560546875, train_time=0.038465023040771484
[Epoch 3][Step 247], time=0.08463168144226074, ext_time=0.040348052978515625, train_time=0.03928089141845703
[Epoch 3][Step 248], time=0.08332252502441406, ext_time=0.03973674774169922, train_time=0.03862309455871582
[Epoch 3][Step 249], time=0.08311939239501953, ext_time=0.04020857810974121, train_time=0.03788185119628906
[Epoch 3], time=20.8082492351532, loss=nan
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 1         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  127134 KB |    8118 MB |   13002 GB |   13002 GB |
|       from large pool |  122887 KB |    8114 MB |   12989 GB |   12989 GB |
|       from small pool |    4246 KB |       5 MB |      13 GB |      13 GB |
|---------------------------------------------------------------------------|
| Active memory         |  127134 KB |    8118 MB |   13002 GB |   13002 GB |
|       from large pool |  122887 KB |    8114 MB |   12989 GB |   12989 GB |
|       from small pool |    4246 KB |       5 MB |      13 GB |      13 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   19864 MB |   21984 MB |   38576 MB |   18712 MB |
|       from large pool |   19856 MB |   21976 MB |   38566 MB |   18710 MB |
|       from small pool |       8 MB |       8 MB |      10 MB |       2 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |    3191 MB |    7801 MB |   11661 GB |   11658 GB |
|       from large pool |    3189 MB |    7799 MB |   11646 GB |   11643 GB |
|       from small pool |       1 MB |       4 MB |      15 GB |      15 GB |
|---------------------------------------------------------------------------|
| Allocations           |      57    |      94    |  303291    |  303234    |
|       from large pool |      24    |      51    |  139017    |  138993    |
|       from small pool |      33    |      46    |  164274    |  164241    |
|---------------------------------------------------------------------------|
| Active allocs         |      57    |      94    |  303291    |  303234    |
|       from large pool |      24    |      51    |  139017    |  138993    |
|       from small pool |      33    |      46    |  164274    |  164241    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      20    |      20    |      25    |       5    |
|       from large pool |      16    |      16    |      20    |       4    |
|       from small pool |       4    |       4    |       5    |       1    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      32    |      41    |  114508    |  114476    |
|       from large pool |      17    |      26    |   73348    |   73331    |
|       from small pool |      15    |      22    |   41160    |   41145    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[TRAIN_TIME] train time is 88.787698 seconds
[EPOCH_TIME] 22.196925 seconds, maybe large due to not enough epoch skipped.
    [Step(average) Profiler Level 1 E3 S1999]
        L1  sample           0.004984 | send           0.000000
        L1  recv             0.000000 | copy           0.039689 | convert time 0.000000 | train  0.040779
        L1  feature nbytes    2.23 GB | label nbytes 0.00 Bytes
        L1  id nbytes      0.00 Bytes | graph nbytes 0.00 Bytes
        L1  miss nbytes    0.00 Bytes | remote nbytes 0.00 Bytes
        L1  num nodes               0 | num samples           0
        L1  seq duration     0.000000 | refresh duration   0.000000
    [Step(average) Profiler Level 2 E3 S1999]
        L2  shuffle     0.000000 | core sample  0.000000 | id remap        0.000000
        L2  graph copy  0.000000 | id copy      0.000000 | cache feat copy 0.039689
        L2  last layer sample time 0.000000 | size 0.000000
    [Step(average) Profiler Level 3 E3 S1999]
        L3  khop sample coo  0.000000 | khop sort coo      0.000000 | khop count edge     0.000000 | khop compact edge 0.000000
        L3  walk sample coo  0.000000 | walk topk total    0.000000 | walk topk step1     0.000000 | walk topk step2   0.000000
        L3  walk topk step3  0.000000 | walk topk step4    0.000000 | walk topk step5     0.000000
        L3  walk topk step6  0.000000 | walk topk step7    0.000000
        L3  remap unique     0.000000 | remap populate     0.000000 | remap mapnode       0.000000 | remap mapedge     0.000000
        L3  cache get_index  0.000502 | cache copy_index   0.000000 | cache extract_miss  0.000000
        L3  cache copy_miss  0.000000 | cache combine_miss 0.000000 | cache combine cache 0.039158 | cache combine remote 0.000000
        L3  label extract  0.000000
    [Profiler Level Percentiles E3 S1999]
        p50.00_tail_logl2featcopy=0.039727
        p90.00_tail_logl2featcopy=0.040380
        p95.00_tail_logl2featcopy=0.040547
        p99.00_tail_logl2featcopy=0.040918
        p99.90_tail_logl2featcopy=0.056416
[CUDA] cuda: usage: 75.03 GB
worker 2 running with pid=61411
loading train edge idx from disk
loading train edge idx from disk done
tensor([ 367470406, 3158702471, 3196913887,  311268946, 2622541626, 2707306334,
        2288750783,  341639546, 2394912536, 3266219078,  474737188, 1665128055,
        3225579545,  584996459,  307810634,  726851972, 1000854521, 1061370191,
         371057554,  526478766,  273325093, 1382980281, 1363464091,  971316959,
        1643305663, 1559556869,  792051811, 2593715952, 2627476216,  642711792,
        1279512108,  281028249, 2848334841, 1142277951, 1624797255, 1682408139,
         288375990,  530555421, 1190696744, 1515340461,  396873136, 3079813016,
         574876927,   31156367,  607610239, 1664434120,  774080817, 2850247945,
         655998496,  888602410,  350570870,  624008623,   69778231,  638128676,
        1443388341, 1479712286, 2858804367,  550628163,  198023098, 2583590303,
        2518492873,    2593795, 2722269746,  659106604, 1369497066,  235303384,
         645516367, 3053389785, 3376243999,  792250187, 1401047469, 1545651011,
        1827797263, 1275030316, 2075895474, 2919804301, 2493902937,  112768749,
          11701078,  500365351,  404737965,  786261376,  934911988,  757583227,
        1135493038, 3162165660, 1144120843, 2861906075,      93256, 1866677628,
         103141175, 3295574170, 1840253021,  747507530,  196097433, 3025516425,
         133597469,  755176081, 2348166713,   80549681])
Rank=2, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.008889, per step: 0.000036
presamping
presamping takes 17.707096099853516
worker 1 running with pid=61410
loading train edge idx from disk
loading train edge idx from disk done
tensor([ 367470406, 3158702471, 3196913887,  311268946, 2622541626, 2707306334,
        2288750783,  341639546, 2394912536, 3266219078,  474737188, 1665128055,
        3225579545,  584996459,  307810634,  726851972, 1000854521, 1061370191,
         371057554,  526478766,  273325093, 1382980281, 1363464091,  971316959,
        1643305663, 1559556869,  792051811, 2593715952, 2627476216,  642711792,
        1279512108,  281028249, 2848334841, 1142277951, 1624797255, 1682408139,
         288375990,  530555421, 1190696744, 1515340461,  396873136, 3079813016,
         574876927,   31156367,  607610239, 1664434120,  774080817, 2850247945,
         655998496,  888602410,  350570870,  624008623,   69778231,  638128676,
        1443388341, 1479712286, 2858804367,  550628163,  198023098, 2583590303,
        2518492873,    2593795, 2722269746,  659106604, 1369497066,  235303384,
         645516367, 3053389785, 3376243999,  792250187, 1401047469, 1545651011,
        1827797263, 1275030316, 2075895474, 2919804301, 2493902937,  112768749,
          11701078,  500365351,  404737965,  786261376,  934911988,  757583227,
        1135493038, 3162165660, 1144120843, 2861906075,      93256, 1866677628,
         103141175, 3295574170, 1840253021,  747507530,  196097433, 3025516425,
         133597469,  755176081, 2348166713,   80549681])
Rank=1, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.009495, per step: 0.000038
presamping
presamping takes 17.001022577285767
worker 6 running with pid=61419
loading train edge idx from disk
loading train edge idx from disk done
tensor([ 367470406, 3158702471, 3196913887,  311268946, 2622541626, 2707306334,
        2288750783,  341639546, 2394912536, 3266219078,  474737188, 1665128055,
        3225579545,  584996459,  307810634,  726851972, 1000854521, 1061370191,
         371057554,  526478766,  273325093, 1382980281, 1363464091,  971316959,
        1643305663, 1559556869,  792051811, 2593715952, 2627476216,  642711792,
        1279512108,  281028249, 2848334841, 1142277951, 1624797255, 1682408139,
         288375990,  530555421, 1190696744, 1515340461,  396873136, 3079813016,
         574876927,   31156367,  607610239, 1664434120,  774080817, 2850247945,
         655998496,  888602410,  350570870,  624008623,   69778231,  638128676,
        1443388341, 1479712286, 2858804367,  550628163,  198023098, 2583590303,
        2518492873,    2593795, 2722269746,  659106604, 1369497066,  235303384,
         645516367, 3053389785, 3376243999,  792250187, 1401047469, 1545651011,
        1827797263, 1275030316, 2075895474, 2919804301, 2493902937,  112768749,
          11701078,  500365351,  404737965,  786261376,  934911988,  757583227,
        1135493038, 3162165660, 1144120843, 2861906075,      93256, 1866677628,
         103141175, 3295574170, 1840253021,  747507530,  196097433, 3025516425,
         133597469,  755176081, 2348166713,   80549681])
Rank=6, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.010816, per step: 0.000043
presamping
presamping takes 17.873610973358154
[EPOCH_TIME] 21.186405 seconds
worker 3 running with pid=61413
loading train edge idx from disk
loading train edge idx from disk done
tensor([ 367470406, 3158702471, 3196913887,  311268946, 2622541626, 2707306334,
        2288750783,  341639546, 2394912536, 3266219078,  474737188, 1665128055,
        3225579545,  584996459,  307810634,  726851972, 1000854521, 1061370191,
         371057554,  526478766,  273325093, 1382980281, 1363464091,  971316959,
        1643305663, 1559556869,  792051811, 2593715952, 2627476216,  642711792,
        1279512108,  281028249, 2848334841, 1142277951, 1624797255, 1682408139,
         288375990,  530555421, 1190696744, 1515340461,  396873136, 3079813016,
         574876927,   31156367,  607610239, 1664434120,  774080817, 2850247945,
         655998496,  888602410,  350570870,  624008623,   69778231,  638128676,
        1443388341, 1479712286, 2858804367,  550628163,  198023098, 2583590303,
        2518492873,    2593795, 2722269746,  659106604, 1369497066,  235303384,
         645516367, 3053389785, 3376243999,  792250187, 1401047469, 1545651011,
        1827797263, 1275030316, 2075895474, 2919804301, 2493902937,  112768749,
          11701078,  500365351,  404737965,  786261376,  934911988,  757583227,
        1135493038, 3162165660, 1144120843, 2861906075,      93256, 1866677628,
         103141175, 3295574170, 1840253021,  747507530,  196097433, 3025516425,
         133597469,  755176081, 2348166713,   80549681])
Rank=3, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.008962, per step: 0.000036
presamping
presamping takes 18.972140550613403
worker 7 running with pid=61421
loading train edge idx from disk
loading train edge idx from disk done
tensor([ 367470406, 3158702471, 3196913887,  311268946, 2622541626, 2707306334,
        2288750783,  341639546, 2394912536, 3266219078,  474737188, 1665128055,
        3225579545,  584996459,  307810634,  726851972, 1000854521, 1061370191,
         371057554,  526478766,  273325093, 1382980281, 1363464091,  971316959,
        1643305663, 1559556869,  792051811, 2593715952, 2627476216,  642711792,
        1279512108,  281028249, 2848334841, 1142277951, 1624797255, 1682408139,
         288375990,  530555421, 1190696744, 1515340461,  396873136, 3079813016,
         574876927,   31156367,  607610239, 1664434120,  774080817, 2850247945,
         655998496,  888602410,  350570870,  624008623,   69778231,  638128676,
        1443388341, 1479712286, 2858804367,  550628163,  198023098, 2583590303,
        2518492873,    2593795, 2722269746,  659106604, 1369497066,  235303384,
         645516367, 3053389785, 3376243999,  792250187, 1401047469, 1545651011,
        1827797263, 1275030316, 2075895474, 2919804301, 2493902937,  112768749,
          11701078,  500365351,  404737965,  786261376,  934911988,  757583227,
        1135493038, 3162165660, 1144120843, 2861906075,      93256, 1866677628,
         103141175, 3295574170, 1840253021,  747507530,  196097433, 3025516425,
         133597469,  755176081, 2348166713,   80549681])
Rank=7, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.009086, per step: 0.000036
presamping
presamping takes 16.90799570083618
worker 4 running with pid=61415
loading train edge idx from disk
loading train edge idx from disk done
tensor([ 367470406, 3158702471, 3196913887,  311268946, 2622541626, 2707306334,
        2288750783,  341639546, 2394912536, 3266219078,  474737188, 1665128055,
        3225579545,  584996459,  307810634,  726851972, 1000854521, 1061370191,
         371057554,  526478766,  273325093, 1382980281, 1363464091,  971316959,
        1643305663, 1559556869,  792051811, 2593715952, 2627476216,  642711792,
        1279512108,  281028249, 2848334841, 1142277951, 1624797255, 1682408139,
         288375990,  530555421, 1190696744, 1515340461,  396873136, 3079813016,
         574876927,   31156367,  607610239, 1664434120,  774080817, 2850247945,
         655998496,  888602410,  350570870,  624008623,   69778231,  638128676,
        1443388341, 1479712286, 2858804367,  550628163,  198023098, 2583590303,
        2518492873,    2593795, 2722269746,  659106604, 1369497066,  235303384,
         645516367, 3053389785, 3376243999,  792250187, 1401047469, 1545651011,
        1827797263, 1275030316, 2075895474, 2919804301, 2493902937,  112768749,
          11701078,  500365351,  404737965,  786261376,  934911988,  757583227,
        1135493038, 3162165660, 1144120843, 2861906075,      93256, 1866677628,
         103141175, 3295574170, 1840253021,  747507530,  196097433, 3025516425,
         133597469,  755176081, 2348166713,   80549681])
Rank=4, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.010657, per step: 0.000043
presamping
presamping takes 18.844656229019165
worker 5 running with pid=61417
loading train edge idx from disk
loading train edge idx from disk done
tensor([ 367470406, 3158702471, 3196913887,  311268946, 2622541626, 2707306334,
        2288750783,  341639546, 2394912536, 3266219078,  474737188, 1665128055,
        3225579545,  584996459,  307810634,  726851972, 1000854521, 1061370191,
         371057554,  526478766,  273325093, 1382980281, 1363464091,  971316959,
        1643305663, 1559556869,  792051811, 2593715952, 2627476216,  642711792,
        1279512108,  281028249, 2848334841, 1142277951, 1624797255, 1682408139,
         288375990,  530555421, 1190696744, 1515340461,  396873136, 3079813016,
         574876927,   31156367,  607610239, 1664434120,  774080817, 2850247945,
         655998496,  888602410,  350570870,  624008623,   69778231,  638128676,
        1443388341, 1479712286, 2858804367,  550628163,  198023098, 2583590303,
        2518492873,    2593795, 2722269746,  659106604, 1369497066,  235303384,
         645516367, 3053389785, 3376243999,  792250187, 1401047469, 1545651011,
        1827797263, 1275030316, 2075895474, 2919804301, 2493902937,  112768749,
          11701078,  500365351,  404737965,  786261376,  934911988,  757583227,
        1135493038, 3162165660, 1144120843, 2861906075,      93256, 1866677628,
         103141175, 3295574170, 1840253021,  747507530,  196097433, 3025516425,
         133597469,  755176081, 2348166713,   80549681])
Rank=5, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.009079, per step: 0.000036
presamping
presamping takes 17.957698345184326

