succeed=True
[CUDA] cuda: usage: 6.39 GB
0 :  {link #0 : 1}, {link #1 : 2}, {link #2 : 3}, {link #3 : 4}, {link #4 : 5}, {link #5 : 6}, {link #6 : 7},
1 :  {link #0 : 2}, {link #1 : 3}, {link #2 : 4}, {link #3 : 5}, {link #4 : 6}, {link #5 : 7}, {link #6 : 0},
2 :  {link #0 : 3}, {link #1 : 4}, {link #2 : 5}, {link #3 : 6}, {link #4 : 7}, {link #5 : 0}, {link #6 : 1},
3 :  {link #0 : 4}, {link #1 : 5}, {link #2 : 6}, {link #3 : 7}, {link #4 : 0}, {link #5 : 1}, {link #6 : 2},
4 :  {link #0 : 5}, {link #1 : 6}, {link #2 : 7}, {link #3 : 0}, {link #4 : 1}, {link #5 : 2}, {link #6 : 3},
5 :  {link #0 : 6}, {link #1 : 7}, {link #2 : 0}, {link #3 : 1}, {link #4 : 2}, {link #5 : 3}, {link #6 : 4},
6 :  {link #0 : 7}, {link #1 : 0}, {link #2 : 1}, {link #3 : 2}, {link #4 : 3}, {link #5 : 4}, {link #6 : 5},
7 :  {link #0 : 0}, {link #1 : 1}, {link #2 : 2}, {link #3 : 3}, {link #4 : 4}, {link #5 : 5}, {link #6 : 6},
0 : local 108, cpu 0 {link #0 : g1 0}, {link #1 : g2 0}, {link #2 : g3 0}, {link #3 : g4 0}, {link #4 : g5 0}, {link #5 : g6 0}, {link #6 : g7 0},
1 : local 108, cpu 0 {link #0 : g2 0}, {link #1 : g3 0}, {link #2 : g4 0}, {link #3 : g5 0}, {link #4 : g6 0}, {link #5 : g7 0}, {link #6 : g0 0},
2 : local 108, cpu 0 {link #0 : g3 0}, {link #1 : g4 0}, {link #2 : g5 0}, {link #3 : g6 0}, {link #4 : g7 0}, {link #5 : g0 0}, {link #6 : g1 0},
3 : local 108, cpu 0 {link #0 : g4 0}, {link #1 : g5 0}, {link #2 : g6 0}, {link #3 : g7 0}, {link #4 : g0 0}, {link #5 : g1 0}, {link #6 : g2 0},
4 : local 108, cpu 0 {link #0 : g5 0}, {link #1 : g6 0}, {link #2 : g7 0}, {link #3 : g0 0}, {link #4 : g1 0}, {link #5 : g2 0}, {link #6 : g3 0},
5 : local 108, cpu 0 {link #0 : g6 0}, {link #1 : g7 0}, {link #2 : g0 0}, {link #3 : g1 0}, {link #4 : g2 0}, {link #5 : g3 0}, {link #6 : g4 0},
6 : local 108, cpu 0 {link #0 : g7 0}, {link #1 : g0 0}, {link #2 : g1 0}, {link #3 : g2 0}, {link #4 : g3 0}, {link #5 : g4 0}, {link #6 : g5 0},
7 : local 108, cpu 0 {link #0 : g0 0}, {link #1 : g1 0}, {link #2 : g2 0}, {link #3 : g3 0}, {link #4 : g4 0}, {link #5 : g5 0}, {link #6 : g6 0},
0 :  {link #0 : 1}, {link #1 : 2}, {link #2 : 3}, {link #3 : 4}, {link #4 : 5}, {link #5 : 6}, {link #6 : 7},
1 :  {link #0 : 2}, {link #1 : 3}, {link #2 : 4}, {link #3 : 5}, {link #4 : 6}, {link #5 : 7}, {link #6 : 0},
2 :  {link #0 : 3}, {link #1 : 4}, {link #2 : 5}, {link #3 : 6}, {link #4 : 7}, {link #5 : 0}, {link #6 : 1},
3 :  {link #0 : 4}, {link #1 : 5}, {link #2 : 6}, {link #3 : 7}, {link #4 : 0}, {link #5 : 1}, {link #6 : 2},
4 :  {link #0 : 5}, {link #1 : 6}, {link #2 : 7}, {link #3 : 0}, {link #4 : 1}, {link #5 : 2}, {link #6 : 3},
5 :  {link #0 : 6}, {link #1 : 7}, {link #2 : 0}, {link #3 : 1}, {link #4 : 2}, {link #5 : 3}, {link #6 : 4},
6 :  {link #0 : 7}, {link #1 : 0}, {link #2 : 1}, {link #3 : 2}, {link #4 : 3}, {link #5 : 4}, {link #6 : 5},
7 :  {link #0 : 0}, {link #1 : 1}, {link #2 : 2}, {link #3 : 3}, {link #4 : 4}, {link #5 : 5}, {link #6 : 6},
0 : local 108, cpu 0 {link #0 : g1 0}, {link #1 : g2 0}, {link #2 : g3 0}, {link #3 : g4 0}, {link #4 : g5 0}, {link #5 : g6 0}, {link #6 : g7 0},
1 : local 108, cpu 0 {link #0 : g2 0}, {link #1 : g3 0}, {link #2 : g4 0}, {link #3 : g5 0}, {link #4 : g6 0}, {link #5 : g7 0}, {link #6 : g0 0},
2 : local 108, cpu 0 {link #0 : g3 0}, {link #1 : g4 0}, {link #2 : g5 0}, {link #3 : g6 0}, {link #4 : g7 0}, {link #5 : g0 0}, {link #6 : g1 0},
3 : local 108, cpu 0 {link #0 : g4 0}, {link #1 : g5 0}, {link #2 : g6 0}, {link #3 : g7 0}, {link #4 : g0 0}, {link #5 : g1 0}, {link #6 : g2 0},
4 : local 108, cpu 0 {link #0 : g5 0}, {link #1 : g6 0}, {link #2 : g7 0}, {link #3 : g0 0}, {link #4 : g1 0}, {link #5 : g2 0}, {link #6 : g3 0},
5 : local 108, cpu 0 {link #0 : g6 0}, {link #1 : g7 0}, {link #2 : g0 0}, {link #3 : g1 0}, {link #4 : g2 0}, {link #5 : g3 0}, {link #6 : g4 0},
6 : local 108, cpu 0 {link #0 : g7 0}, {link #1 : g0 0}, {link #2 : g1 0}, {link #3 : g2 0}, {link #4 : g3 0}, {link #5 : g4 0}, {link #6 : g5 0},
7 : local 108, cpu 0 {link #0 : g0 0}, {link #1 : g1 0}, {link #2 : g2 0}, {link #3 : g3 0}, {link #4 : g4 0}, {link #5 : g5 0}, {link #6 : g6 0},
0 :  {link #0 : 1}, {link #1 : 2}, {link #2 : 3}, {link #3 : 4}, {link #4 : 5}, {link #5 : 6}, {link #6 : 7},
1 :  {link #0 : 2}, {link #1 : 3}, {link #2 : 4}, {link #3 : 5}, {link #4 : 6}, {link #5 : 7}, {link #6 : 0},
2 :  {link #0 : 3}, {link #1 : 4}, {link #2 : 5}, {link #3 : 6}, {link #4 : 7}, {link #5 : 0}, {link #6 : 1},
3 :  {link #0 : 4}, {link #1 : 5}, {link #2 : 6}, {link #3 : 7}, {link #4 : 0}, {link #5 : 1}, {link #6 : 2},
4 :  {link #0 : 5}, {link #1 : 6}, {link #2 : 7}, {link #3 : 0}, {link #4 : 1}, {link #5 : 2}, {link #6 : 3},
5 :  {link #0 : 6}, {link #1 : 7}, {link #2 : 0}, {link #3 : 1}, {link #4 : 2}, {link #5 : 3}, {link #6 : 4},
6 :  {link #0 : 7}, {link #1 : 0}, {link #2 : 1}, {link #3 : 2}, {link #4 : 3}, {link #5 : 4}, {link #6 : 5},
7 :  {link #0 : 0}, {link #1 : 1}, {link #2 : 2}, {link #3 : 3}, {link #4 : 4}, {link #5 : 5}, {link #6 : 6},
0 :  {link #0 : 1}, {link #1 : 2}, {link #2 : 3}, {link #3 : 4}, {link #4 : 5}, {link #5 : 6}, {link #6 : 7},
1 :  {link #0 : 2}, {link #1 : 3}, {link #2 : 4}, {link #3 : 5}, {link #4 : 6}, {link #5 : 7}, {link #6 : 0},
2 :  {link #0 : 3}, {link #1 : 4}, {link #2 : 5}, {link #3 : 6}, {link #4 : 7}, {link #5 : 0}, {link #6 : 1},
3 :  {link #0 : 4}, {link #1 : 5}, {link #2 : 6}, {link #3 : 7}, {link #4 : 0}, {link #5 : 1}, {link #6 : 2},
4 :  {link #0 : 5}, {link #1 : 6}, {link #2 : 7}, {link #3 : 0}, {link #4 : 1}, {link #5 : 2}, {link #6 : 3},
5 :  {link #0 : 6}, {link #1 : 7}, {link #2 : 0}, {link #3 : 1}, {link #4 : 2}, {link #5 : 3}, {link #6 : 4},
6 :  {link #0 : 7}, {link #1 : 0}, {link #2 : 1}, {link #3 : 2}, {link #4 : 3}, {link #5 : 4}, {link #6 : 5},
7 :  {link #0 : 0}, {link #1 : 1}, {link #2 : 2}, {link #3 : 3}, {link #4 : 4}, {link #5 : 5}, {link #6 : 6},
0 : local 108, cpu 0 {link #0 : g1 0}, {link #1 : g2 0}, {link #2 : g3 0}, {link #3 : g4 0}, {link #4 : g5 0}, {link #5 : g6 0}, {link #6 : g7 0},
1 : local 108, cpu 0 {link #0 : g2 0}, {link #1 : g3 0}, {link #2 : g4 0}, {link #3 : g5 0}, {link #4 : g6 0}, {link #5 : g7 0}, {link #6 : g0 0},
2 : local 108, cpu 0 {link #0 : g3 0}, {link #1 : g4 0}, {link #2 : g5 0}, {link #3 : g6 0}, {link #4 : g7 0}, {link #5 : g0 0}, {link #6 : g1 0},
3 : local 108, cpu 0 {link #0 : g4 0}, {link #1 : g5 0}, {link #2 : g6 0}, {link #3 : g7 0}, {link #4 : g0 0}, {link #5 : g1 0}, {link #6 : g2 0},
4 : local 108, cpu 0 {link #0 : g5 0}, {link #1 : g6 0}, {link #2 : g7 0}, {link #3 : g0 0}, {link #4 : g1 0}, {link #5 : g2 0}, {link #6 : g3 0},
5 : local 108, cpu 0 {link #0 : g6 0}, {link #1 : g7 0}, {link #2 : g0 0}, {link #3 : g1 0}, {link #4 : g2 0}, {link #5 : g3 0}, {link #6 : g4 0},
6 : local 108, cpu 0 {link #0 : g7 0}, {link #1 : g0 0}, {link #2 : g1 0}, {link #3 : g2 0}, {link #4 : g3 0}, {link #5 : g4 0}, {link #6 : g5 0},
7 : local 108, cpu 0 {link #0 : g0 0}, {link #1 : g1 0}, {link #2 : g2 0}, {link #3 : g3 0}, {link #4 : g4 0}, {link #5 : g5 0}, {link #6 : g6 0},
0 : local 108, cpu 0 {link #0 : g1 0}, {link #1 : g2 0}, {link #2 : g3 0}, {link #3 : g4 0}, {link #4 : g5 0}, {link #5 : g6 0}, {link #6 : g7 0},
1 : local 108, cpu 0 {link #0 : g2 0}, {link #1 : g3 0}, {link #2 : g4 0}, {link #3 : g5 0}, {link #4 : g6 0}, {link #5 : g7 0}, {link #6 : g0 0},
2 : local 108, cpu 0 {link #0 : g3 0}, {link #1 : g4 0}, {link #2 : g5 0}, {link #3 : g6 0}, {link #4 : g7 0}, {link #5 : g0 0}, {link #6 : g1 0},
3 : local 108, cpu 0 {link #0 : g4 0}, {link #1 : g5 0}, {link #2 : g6 0}, {link #3 : g7 0}, {link #4 : g0 0}, {link #5 : g1 0}, {link #6 : g2 0},
4 : local 108, cpu 0 {link #0 : g5 0}, {link #1 : g6 0}, {link #2 : g7 0}, {link #3 : g0 0}, {link #4 : g1 0}, {link #5 : g2 0}, {link #6 : g3 0},
5 : local 108, cpu 0 {link #0 : g6 0}, {link #1 : g7 0}, {link #2 : g0 0}, {link #3 : g1 0}, {link #4 : g2 0}, {link #5 : g3 0}, {link #6 : g4 0},
6 : local 108, cpu 0 {link #0 : g7 0}, {link #1 : g0 0}, {link #2 : g1 0}, {link #3 : g2 0}, {link #4 : g3 0}, {link #5 : g4 0}, {link #6 : g5 0},
7 : local 108, cpu 0 {link #0 : g0 0}, {link #1 : g1 0}, {link #2 : g2 0}, {link #3 : g3 0}, {link #4 : g4 0}, {link #5 : g5 0}, {link #6 : g6 0},
0 :  {link #0 : 1}, {link #1 : 2}, {link #2 : 3}, {link #3 : 4}, {link #4 : 5}, {link #5 : 6}, {link #6 : 7},
1 :  {link #0 : 2}, {link #1 : 3}, {link #2 : 4}, {link #3 : 5}, {link #4 : 6}, {link #5 : 7}, {link #6 : 0},
2 :  {link #0 : 3}, {link #1 : 4}, {link #2 : 5}, {link #3 : 6}, {link #4 : 7}, {link #5 : 0}, {link #6 : 1},
3 :  {link #0 : 4}, {link #1 : 5}, {link #2 : 6}, {link #3 : 7}, {link #4 : 0}, {link #5 : 1}, {link #6 : 2},
4 :  {link #0 : 5}, {link #1 : 6}, {link #2 : 7}, {link #3 : 0}, {link #4 : 1}, {link #5 : 2}, {link #6 : 3},
5 :  {link #0 : 6}, {link #1 : 7}, {link #2 : 0}, {link #3 : 1}, {link #4 : 2}, {link #5 : 3}, {link #6 : 4},
6 :  {link #0 : 7}, {link #1 : 0}, {link #2 : 1}, {link #3 : 2}, {link #4 : 3}, {link #5 : 4}, {link #6 : 5},
7 :  {link #0 : 0}, {link #1 : 1}, {link #2 : 2}, {link #3 : 3}, {link #4 : 4}, {link #5 : 5}, {link #6 : 6},
0 : local 108, cpu 0 {link #0 : g1 0}, {link #1 : g2 0}, {link #2 : g3 0}, {link #3 : g4 0}, {link #4 : g5 0}, {link #5 : g6 0}, {link #6 : g7 0},
1 : local 108, cpu 0 {link #0 : g2 0}, {link #1 : g3 0}, {link #2 : g4 0}, {link #3 : g5 0}, {link #4 : g6 0}, {link #5 : g7 0}, {link #6 : g0 0},
2 : local 108, cpu 0 {link #0 : g3 0}, {link #1 : g4 0}, {link #2 : g5 0}, {link #3 : g6 0}, {link #4 : g7 0}, {link #5 : g0 0}, {link #6 : g1 0},
3 : local 108, cpu 0 {link #0 : g4 0}, {link #1 : g5 0}, {link #2 : g6 0}, {link #3 : g7 0}, {link #4 : g0 0}, {link #5 : g1 0}, {link #6 : g2 0},
4 : local 108, cpu 0 {link #0 : g5 0}, {link #1 : g6 0}, {link #2 : g7 0}, {link #3 : g0 0}, {link #4 : g1 0}, {link #5 : g2 0}, {link #6 : g3 0},
5 : local 108, cpu 0 {link #0 : g6 0}, {link #1 : g7 0}, {link #2 : g0 0}, {link #3 : g1 0}, {link #4 : g2 0}, {link #5 : g3 0}, {link #6 : g4 0},
6 : local 108, cpu 0 {link #0 : g7 0}, {link #1 : g0 0}, {link #2 : g1 0}, {link #3 : g2 0}, {link #4 : g3 0}, {link #5 : g4 0}, {link #6 : g5 0},
7 : local 108, cpu 0 {link #0 : g0 0}, {link #1 : g1 0}, {link #2 : g2 0}, {link #3 : g3 0}, {link #4 : g4 0}, {link #5 : g5 0}, {link #6 : g6 0},
0 :  {link #0 : 1}, {link #1 : 2}, {link #2 : 3}, {link #3 : 4}, {link #4 : 5}, {link #5 : 6}, {link #6 : 7},
1 :  {link #0 : 2}, {link #1 : 3}, {link #2 : 4}, {link #3 : 5}, {link #4 : 6}, {link #5 : 7}, {link #6 : 0},
2 :  {link #0 : 3}, {link #1 : 4}, {link #2 : 5}, {link #3 : 6}, {link #4 : 7}, {link #5 : 0}, {link #6 : 1},
3 :  {link #0 : 4}, {link #1 : 5}, {link #2 : 6}, {link #3 : 7}, {link #4 : 0}, {link #5 : 1}, {link #6 : 2},
4 :  {link #0 : 5}, {link #1 : 6}, {link #2 : 7}, {link #3 : 0}, {link #4 : 1}, {link #5 : 2}, {link #6 : 3},
5 :  {link #0 : 6}, {link #1 : 7}, {link #2 : 0}, {link #3 : 1}, {link #4 : 2}, {link #5 : 3}, {link #6 : 4},
6 :  {link #0 : 7}, {link #1 : 0}, {link #2 : 1}, {link #3 : 2}, {link #4 : 3}, {link #5 : 4}, {link #6 : 5},
7 :  {link #0 : 0}, {link #1 : 1}, {link #2 : 2}, {link #3 : 3}, {link #4 : 4}, {link #5 : 5}, {link #6 : 6},
0 : local 108, cpu 0 {link #0 : g1 0}, {link #1 : g2 0}, {link #2 : g3 0}, {link #3 : g4 0}, {link #4 : g5 0}, {link #5 : g6 0}, {link #6 : g7 0},
1 : local 108, cpu 0 {link #0 : g2 0}, {link #1 : g3 0}, {link #2 : g4 0}, {link #3 : g5 0}, {link #4 : g6 0}, {link #5 : g7 0}, {link #6 : g0 0},
2 : local 108, cpu 0 {link #0 : g3 0}, {link #1 : g4 0}, {link #2 : g5 0}, {link #3 : g6 0}, {link #4 : g7 0}, {link #5 : g0 0}, {link #6 : g1 0},
3 : local 108, cpu 0 {link #0 : g4 0}, {link #1 : g5 0}, {link #2 : g6 0}, {link #3 : g7 0}, {link #4 : g0 0}, {link #5 : g1 0}, {link #6 : g2 0},
4 : local 108, cpu 0 {link #0 : g5 0}, {link #1 : g6 0}, {link #2 : g7 0}, {link #3 : g0 0}, {link #4 : g1 0}, {link #5 : g2 0}, {link #6 : g3 0},
5 : local 108, cpu 0 {link #0 : g6 0}, {link #1 : g7 0}, {link #2 : g0 0}, {link #3 : g1 0}, {link #4 : g2 0}, {link #5 : g3 0}, {link #6 : g4 0},
6 : local 108, cpu 0 {link #0 : g7 0}, {link #1 : g0 0}, {link #2 : g1 0}, {link #3 : g2 0}, {link #4 : g3 0}, {link #5 : g4 0}, {link #6 : g5 0},
7 : local 108, cpu 0 {link #0 : g0 0}, {link #1 : g1 0}, {link #2 : g2 0}, {link #3 : g3 0}, {link #4 : g4 0}, {link #5 : g5 0}, {link #6 : g6 0},
0 :  {link #0 : 1}, {link #1 : 2}, {link #2 : 3}, {link #3 : 4}, {link #4 : 5}, {link #5 : 6}, {link #6 : 7},
1 :  {link #0 : 2}, {link #1 : 3}, {link #2 : 4}, {link #3 : 5}, {link #4 : 6}, {link #5 : 7}, {link #6 : 0},
2 :  {link #0 : 3}, {link #1 : 4}, {link #2 : 5}, {link #3 : 6}, {link #4 : 7}, {link #5 : 0}, {link #6 : 1},
3 :  {link #0 : 4}, {link #1 : 5}, {link #2 : 6}, {link #3 : 7}, {link #4 : 0}, {link #5 : 1}, {link #6 : 2},
4 :  {link #0 : 5}, {link #1 : 6}, {link #2 : 7}, {link #3 : 0}, {link #4 : 1}, {link #5 : 2}, {link #6 : 3},
5 :  {link #0 : 6}, {link #1 : 7}, {link #2 : 0}, {link #3 : 1}, {link #4 : 2}, {link #5 : 3}, {link #6 : 4},
6 :  {link #0 : 7}, {link #1 : 0}, {link #2 : 1}, {link #3 : 2}, {link #4 : 3}, {link #5 : 4}, {link #6 : 5},
7 :  {link #0 : 0}, {link #1 : 1}, {link #2 : 2}, {link #3 : 3}, {link #4 : 4}, {link #5 : 5}, {link #6 : 6},
0 : local 108, cpu 0 {link #0 : g1 0}, {link #1 : g2 0}, {link #2 : g3 0}, {link #3 : g4 0}, {link #4 : g5 0}, {link #5 : g6 0}, {link #6 : g7 0},
1 : local 108, cpu 0 {link #0 : g2 0}, {link #1 : g3 0}, {link #2 : g4 0}, {link #3 : g5 0}, {link #4 : g6 0}, {link #5 : g7 0}, {link #6 : g0 0},
2 : local 108, cpu 0 {link #0 : g3 0}, {link #1 : g4 0}, {link #2 : g5 0}, {link #3 : g6 0}, {link #4 : g7 0}, {link #5 : g0 0}, {link #6 : g1 0},
3 : local 108, cpu 0 {link #0 : g4 0}, {link #1 : g5 0}, {link #2 : g6 0}, {link #3 : g7 0}, {link #4 : g0 0}, {link #5 : g1 0}, {link #6 : g2 0},
4 : local 108, cpu 0 {link #0 : g5 0}, {link #1 : g6 0}, {link #2 : g7 0}, {link #3 : g0 0}, {link #4 : g1 0}, {link #5 : g2 0}, {link #6 : g3 0},
5 : local 108, cpu 0 {link #0 : g6 0}, {link #1 : g7 0}, {link #2 : g0 0}, {link #3 : g1 0}, {link #4 : g2 0}, {link #5 : g3 0}, {link #6 : g4 0},
6 : local 108, cpu 0 {link #0 : g7 0}, {link #1 : g0 0}, {link #2 : g1 0}, {link #3 : g2 0}, {link #4 : g3 0}, {link #5 : g4 0}, {link #6 : g5 0},
7 : local 108, cpu 0 {link #0 : g0 0}, {link #1 : g1 0}, {link #2 : g2 0}, {link #3 : g3 0}, {link #4 : g4 0}, {link #5 : g5 0}, {link #6 : g6 0},
0 :  {link #0 : 1}, {link #1 : 2}, {link #2 : 3}, {link #3 : 4}, {link #4 : 5}, {link #5 : 6}, {link #6 : 7},
1 :  {link #0 : 2}, {link #1 : 3}, {link #2 : 4}, {link #3 : 5}, {link #4 : 6}, {link #5 : 7}, {link #6 : 0},
2 :  {link #0 : 3}, {link #1 : 4}, {link #2 : 5}, {link #3 : 6}, {link #4 : 7}, {link #5 : 0}, {link #6 : 1},
3 :  {link #0 : 4}, {link #1 : 5}, {link #2 : 6}, {link #3 : 7}, {link #4 : 0}, {link #5 : 1}, {link #6 : 2},
4 :  {link #0 : 5}, {link #1 : 6}, {link #2 : 7}, {link #3 : 0}, {link #4 : 1}, {link #5 : 2}, {link #6 : 3},
5 :  {link #0 : 6}, {link #1 : 7}, {link #2 : 0}, {link #3 : 1}, {link #4 : 2}, {link #5 : 3}, {link #6 : 4},
6 :  {link #0 : 7}, {link #1 : 0}, {link #2 : 1}, {link #3 : 2}, {link #4 : 3}, {link #5 : 4}, {link #6 : 5},
7 :  {link #0 : 0}, {link #1 : 1}, {link #2 : 2}, {link #3 : 3}, {link #4 : 4}, {link #5 : 5}, {link #6 : 6},
0 : local 108, cpu 0 {link #0 : g1 0}, {link #1 : g2 0}, {link #2 : g3 0}, {link #3 : g4 0}, {link #4 : g5 0}, {link #5 : g6 0}, {link #6 : g7 0},
1 : local 108, cpu 0 {link #0 : g2 0}, {link #1 : g3 0}, {link #2 : g4 0}, {link #3 : g5 0}, {link #4 : g6 0}, {link #5 : g7 0}, {link #6 : g0 0},
2 : local 108, cpu 0 {link #0 : g3 0}, {link #1 : g4 0}, {link #2 : g5 0}, {link #3 : g6 0}, {link #4 : g7 0}, {link #5 : g0 0}, {link #6 : g1 0},
3 : local 108, cpu 0 {link #0 : g4 0}, {link #1 : g5 0}, {link #2 : g6 0}, {link #3 : g7 0}, {link #4 : g0 0}, {link #5 : g1 0}, {link #6 : g2 0},
4 : local 108, cpu 0 {link #0 : g5 0}, {link #1 : g6 0}, {link #2 : g7 0}, {link #3 : g0 0}, {link #4 : g1 0}, {link #5 : g2 0}, {link #6 : g3 0},
5 : local 108, cpu 0 {link #0 : g6 0}, {link #1 : g7 0}, {link #2 : g0 0}, {link #3 : g1 0}, {link #4 : g2 0}, {link #5 : g3 0}, {link #6 : g4 0},
6 : local 108, cpu 0 {link #0 : g7 0}, {link #1 : g0 0}, {link #2 : g1 0}, {link #3 : g2 0}, {link #4 : g3 0}, {link #5 : g4 0}, {link #6 : g5 0},
7 : local 108, cpu 0 {link #0 : g0 0}, {link #1 : g1 0}, {link #2 : g2 0}, {link #3 : g3 0}, {link #4 : g4 0}, {link #5 : g5 0}, {link #6 : g6 0},
test_result:init:cache_nbytes=56862697472
test_result:init:cache_nbytes=56862697472
test_result:init:cache_nbytes=56862697472
test_result:init:cache_nbytes=56862697472
test_result:init:cache_nbytes=56862697472
test_result:init:cache_nbytes=56862697472
test_result:init:cache_nbytes=56862697472
test_result:init:cache_nbytes=56862697472
config:eval_tsp="2023-08-06 19:07:43"
config:num_worker=8
config:num_intra_size=8
config:root_dir=/datasets_gnn/wholegraph
config:graph_name=ogbn-papers100M
config:epochs=4
config:batchsize=8000
config:skip_epoch=2
config:local_step=125
config:presc_epoch=2
config:neighbors=15,10,5
config:hiddensize=256
config:num_layer=3
config:model=gcn
config:framework=dgl
config:dataloaderworkers=0
config:dropout=0.5
config:weight_decay=0.0005
config:lr=0.003
config:use_nccl=False
config:use_amp=False
config:use_collcache=True
config:cache_percentage=1.0
config:cache_policy=rep
config:omp_thread_num=56
config:unsupervised=False
config:classnum=172
config:global_barrier=<multiprocessing.synchronize.Barrier object at 0x7f635abf2970>
config:worker_id=0
creating_intra_node_communicator root=0, local_size=8, world_size=8
Rank=0, Graph loaded.
!!!!Train_dataloader(with 18 items) enumerate latency: 0.4904003143310547
torch.Size([8000]) torch.Size([8000, 1])
torch.Size([8400]) torch.Size([8400, 1])
!!!!Train_data_list(with 18 items) enumerate latency: 2.6226043701171875e-06, transfer latency: 0.45162224769592285
epoch=4 total_steps=72
presamping
presamping takes 2.0327351093292236
start training...
[Epoch 0][Step 0], time=1.8363893032073975, ext_time=0.010532379150390625, train_time=1.8154728412628174
[Epoch 0][Step 1], time=0.043365478515625, ext_time=0.0013778209686279297, train_time=0.029018878936767578
[Epoch 0][Step 2], time=0.03924155235290527, ext_time=0.0013246536254882812, train_time=0.029091596603393555
[Epoch 0][Step 3], time=0.04024863243103027, ext_time=0.0013089179992675781, train_time=0.030266761779785156
[Epoch 0][Step 4], time=0.038208723068237305, ext_time=0.00130462646484375, train_time=0.02814960479736328
[Epoch 0][Step 5], time=0.03751111030578613, ext_time=0.0013241767883300781, train_time=0.027396678924560547
[Epoch 0][Step 6], time=0.03721189498901367, ext_time=0.0013222694396972656, train_time=0.02716541290283203
[Epoch 0][Step 7], time=0.0360260009765625, ext_time=0.0013391971588134766, train_time=0.0258026123046875
[Epoch 0][Step 8], time=0.036008596420288086, ext_time=0.0013322830200195312, train_time=0.025855302810668945
[Epoch 0][Step 9], time=0.03598618507385254, ext_time=0.0013272762298583984, train_time=0.02586841583251953
[Epoch 0][Step 10], time=0.03594660758972168, ext_time=0.0013179779052734375, train_time=0.025901079177856445
[Epoch 0][Step 11], time=0.035941123962402344, ext_time=0.0013401508331298828, train_time=0.025725603103637695
[Epoch 0][Step 12], time=0.03686928749084473, ext_time=0.001329660415649414, train_time=0.026693105697631836
[Epoch 0][Step 13], time=0.036791086196899414, ext_time=0.0013201236724853516, train_time=0.026695728302001953
[Epoch 0][Step 14], time=0.03604745864868164, ext_time=0.0013208389282226562, train_time=0.02597332000732422
[Epoch 0][Step 15], time=0.03588128089904785, ext_time=0.0013308525085449219, train_time=0.025759220123291016
[Epoch 0][Step 16], time=0.035841941833496094, ext_time=0.0013310909271240234, train_time=0.025687456130981445
[Epoch 0][Step 17], time=0.03602123260498047, ext_time=0.0013322830200195312, train_time=0.025862932205200195
[Epoch 0], time=2.4708709716796875, loss=3.253890037536621
[Epoch 1][Step 0], time=0.039206504821777344, ext_time=0.0013568401336669922, train_time=0.028760910034179688
[Epoch 1][Step 1], time=0.035930633544921875, ext_time=0.0013647079467773438, train_time=0.025793075561523438
[Epoch 1][Step 2], time=0.0359954833984375, ext_time=0.0013251304626464844, train_time=0.0258638858795166
[Epoch 1][Step 3], time=0.0359499454498291, ext_time=0.0012984275817871094, train_time=0.02599334716796875
[Epoch 1][Step 4], time=0.03576779365539551, ext_time=0.0013077259063720703, train_time=0.025723934173583984
[Epoch 1][Step 5], time=0.03589677810668945, ext_time=0.0013217926025390625, train_time=0.025794029235839844
[Epoch 1][Step 6], time=0.03617143630981445, ext_time=0.0013167858123779297, train_time=0.026125192642211914
[Epoch 1][Step 7], time=0.03594470024108887, ext_time=0.0013363361358642578, train_time=0.025729894638061523
[Epoch 1][Step 8], time=0.03599262237548828, ext_time=0.0013346672058105469, train_time=0.0258486270904541
[Epoch 1][Step 9], time=0.035910844802856445, ext_time=0.0013270378112792969, train_time=0.025792360305786133
[Epoch 1][Step 10], time=0.03602027893066406, ext_time=0.001317739486694336, train_time=0.02598881721496582
[Epoch 1][Step 11], time=0.03584551811218262, ext_time=0.0014524459838867188, train_time=0.025541067123413086
[Epoch 1][Step 12], time=0.03598523139953613, ext_time=0.0013327598571777344, train_time=0.025818586349487305
[Epoch 1][Step 13], time=0.035997629165649414, ext_time=0.001317739486694336, train_time=0.025895357131958008
[Epoch 1][Step 14], time=0.03609800338745117, ext_time=0.0013213157653808594, train_time=0.026024818420410156
[Epoch 1][Step 15], time=0.03578019142150879, ext_time=0.0013349056243896484, train_time=0.025640487670898438
[Epoch 1][Step 16], time=0.035901546478271484, ext_time=0.0013315677642822266, train_time=0.02572488784790039
[Epoch 1][Step 17], time=0.03586912155151367, ext_time=0.0013349056243896484, train_time=0.025698184967041016
[Epoch 1], time=0.6513910293579102, loss=2.4726550579071045
[Epoch 2][Step 0], time=0.03936409950256348, ext_time=0.0013592243194580078, train_time=0.028899192810058594
[Epoch 2][Step 1], time=0.03584408760070801, ext_time=0.001331329345703125, train_time=0.025624990463256836
[Epoch 2][Step 2], time=0.03603100776672363, ext_time=0.0013225078582763672, train_time=0.025898456573486328
[Epoch 2][Step 3], time=0.03595924377441406, ext_time=0.001302480697631836, train_time=0.025979995727539062
[Epoch 2][Step 4], time=0.03582453727722168, ext_time=0.0013155937194824219, train_time=0.025751590728759766
[Epoch 2][Step 5], time=0.03599905967712402, ext_time=0.001325368881225586, train_time=0.025833845138549805
[Epoch 2][Step 6], time=0.036115169525146484, ext_time=0.001321554183959961, train_time=0.0260617733001709
[Epoch 2][Step 7], time=0.03593611717224121, ext_time=0.0013375282287597656, train_time=0.025725126266479492
[Epoch 2][Step 8], time=0.03591585159301758, ext_time=0.0013275146484375, train_time=0.02575850486755371
[Epoch 2][Step 9], time=0.03594160079956055, ext_time=0.0013227462768554688, train_time=0.025847434997558594
[Epoch 2][Step 10], time=0.03626370429992676, ext_time=0.0013148784637451172, train_time=0.026232481002807617
[Epoch 2][Step 11], time=0.0352175235748291, ext_time=0.001346588134765625, train_time=0.024903535842895508
[Epoch 2][Step 12], time=0.036370277404785156, ext_time=0.0013318061828613281, train_time=0.02619147300720215
[Epoch 2][Step 13], time=0.03602266311645508, ext_time=0.0013170242309570312, train_time=0.025916337966918945
[Epoch 2][Step 14], time=0.03604269027709961, ext_time=0.001329660415649414, train_time=0.02596569061279297
[Epoch 2][Step 15], time=0.0358586311340332, ext_time=0.0013306140899658203, train_time=0.02574324607849121
[Epoch 2][Step 16], time=0.035895347595214844, ext_time=0.0013310909271240234, train_time=0.0257415771484375
[Epoch 2][Step 17], time=0.03591442108154297, ext_time=0.0013337135314941406, train_time=0.025748252868652344
[Epoch 2], time=0.6520323753356934, loss=2.1232826709747314
[Epoch 3][Step 0], time=0.03805279731750488, ext_time=0.0013573169708251953, train_time=0.02758169174194336
[Epoch 3][Step 1], time=0.03600502014160156, ext_time=0.0013680458068847656, train_time=0.025830745697021484
[Epoch 3][Step 2], time=0.03605079650878906, ext_time=0.0013222694396972656, train_time=0.025899410247802734
[Epoch 3][Step 3], time=0.035941362380981445, ext_time=0.001302480697631836, train_time=0.02595353126525879
[Epoch 3][Step 4], time=0.03583836555480957, ext_time=0.001314401626586914, train_time=0.025770187377929688
[Epoch 3][Step 5], time=0.03590250015258789, ext_time=0.0013203620910644531, train_time=0.02582836151123047
[Epoch 3][Step 6], time=0.03605985641479492, ext_time=0.0013184547424316406, train_time=0.025296688079833984
[Epoch 3][Step 7], time=0.03592061996459961, ext_time=0.0013375282287597656, train_time=0.025714874267578125
    [Step(average) Profiler Level 1 E3 S143]
        L1  sample           0.010250 | send           0.000000
        L1  recv             0.000000 | copy           0.001433 | convert time 0.000000 | train  0.024448
        L1  feature nbytes    1.10 GB | label nbytes 0.00 Bytes
        L1  id nbytes      0.00 Bytes | graph nbytes 0.00 Bytes
        L1  miss nbytes    0.00 Bytes | remote nbytes 0.00 Bytes
        L1  num nodes               0 | num samples           0
        L1  seq duration     0.000000 | refresh duration   0.000000
    [Step(average) Profiler Level 2 E3 S143]
        L2  shuffle     0.000000 | core sample  0.000000 | id remap        0.000000
        L2  graph copy  0.000000 | id copy      0.000000 | cache feat copy 0.001433
        L2  last layer sample time 0.000000 | size 0.000000
    [Step(average) Profiler Level 3 E3 S143]
        L3  khop sample coo  0.000000 | khop sort coo      0.000000 | khop count edge     0.000000 | khop compact edge 0.000000
        L3  walk sample coo  0.000000 | walk topk total    0.000000 | walk topk step1     0.000000 | walk topk step2   0.000000
        L3  walk topk step3  0.000000 | walk topk step4    0.000000 | walk topk step5     0.000000
        L3  walk topk step6  0.000000 | walk topk step7    0.000000
        L3  remap unique     0.000000 | remap populate     0.000000 | remap mapnode       0.000000 | remap mapedge     0.000000
        L3  cache get_index  0.000000 | cache copy_index   0.000000 | cache extract_miss  0.000000
        L3  cache copy_miss  0.000000 | cache combine_miss 0.000000 | cache combine cache 0.001407 | cache combine remote 0.000000
        L3  label extract  0.000000
    [Profiler Level Percentiles E3 S143]
        p50.00_tail_logl2featcopy=0.001435
        p90.00_tail_logl2featcopy=0.001567
        p95.00_tail_logl2featcopy=0.001583
        p99.00_tail_logl2featcopy=0.009010
        p99.90_tail_logl2featcopy=0.010532
[CUDA] cuda: usage: 65.76 GB
Rank=5, Graph loaded.
!!!!Train_dataloader(with 18 items) enumerate latency: 0.48812317848205566
torch.Size([8000]) torch.Size([8000, 1])
torch.Size([8400]) torch.Size([8400, 1])
!!!!Train_data_list(with 18 items) enumerate latency: 4.5299530029296875e-06, transfer latency: 0.46654200553894043
presamping
presamping takes 2.227153778076172
Rank=1, Graph loaded.
!!!!Train_dataloader(with 18 items) enumerate latency: 0.49176883697509766
torch.Size([8000]) torch.Size([8000, 1])
torch.Size([8400]) torch.Size([8400, 1])
!!!!Train_data_list(with 18 items) enumerate latency: 3.0994415283203125e-06, transfer latency: 0.4693174362182617
presamping
presamping takes 1.9249622821807861
Rank=7, Graph loaded.
!!!!Train_dataloader(with 18 items) enumerate latency: 0.48769044876098633
torch.Size([8000]) torch.Size([8000, 1])
torch.Size([8400]) torch.Size([8400, 1])
!!!!Train_data_list(with 18 items) enumerate latency: 3.814697265625e-06, transfer latency: 0.4662652015686035
presamping
presamping takes 1.701768398284912
Rank=3, Graph loaded.
!!!!Train_dataloader(with 18 items) enumerate latency: 0.4940159320831299
torch.Size([8000]) torch.Size([8000, 1])
torch.Size([8400]) torch.Size([8400, 1])
!!!!Train_data_list(with 18 items) enumerate latency: 4.5299530029296875e-06, transfer latency: 0.47102904319763184
presamping
presamping takes 2.2644264698028564
Rank=6, Graph loaded.
!!!!Train_dataloader(with 18 items) enumerate latency: 0.4831821918487549
torch.Size([8000]) torch.Size([8000, 1])
torch.Size([8400]) torch.Size([8400, 1])
!!!!Train_data_list(with 18 items) enumerate latency: 3.814697265625e-06, transfer latency: 0.46393346786499023
presamping
presamping takes 2.0380873680114746
[Epoch 3][Step 8], time=0.03598618507385254, ext_time=0.0013320446014404297, train_time=0.025848865509033203
[Epoch 3][Step 9], time=0.03575301170349121, ext_time=0.001322031021118164, train_time=0.025653600692749023
[Epoch 3][Step 10], time=0.03599834442138672, ext_time=0.0013155937194824219, train_time=0.025968074798583984
[Epoch 3][Step 11], time=0.035921573638916016, ext_time=0.0013422966003417969, train_time=0.025714397430419922
[Epoch 3][Step 12], time=0.036026954650878906, ext_time=0.0013251304626464844, train_time=0.02586841583251953
[Epoch 3][Step 13], time=0.03610038757324219, ext_time=0.0013201236724853516, train_time=0.02599930763244629
[Epoch 3][Step 14], time=0.036081790924072266, ext_time=0.0013251304626464844, train_time=0.025951623916625977
[Epoch 3][Step 15], time=0.035858154296875, ext_time=0.00133514404296875, train_time=0.02573990821838379
[Epoch 3][Step 16], time=0.03581833839416504, ext_time=0.0013341903686523438, train_time=0.025652408599853516
[Epoch 3][Step 17], time=0.03587508201599121, ext_time=0.0013337135314941406, train_time=0.025715112686157227
[Epoch 3], time=0.6503939628601074, loss=1.972025990486145
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  156766 KB |    2764 MB |  735511 MB |  735358 MB |
|       from large pool |  150100 KB |    2757 MB |  733533 MB |  733386 MB |
|       from small pool |    6665 KB |      11 MB |    1978 MB |    1971 MB |
|---------------------------------------------------------------------------|
| Active memory         |  156766 KB |    2764 MB |  735511 MB |  735358 MB |
|       from large pool |  150100 KB |    2757 MB |  733533 MB |  733386 MB |
|       from small pool |    6665 KB |      11 MB |    1978 MB |    1971 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    5232 MB |    5232 MB |    5232 MB |       0 B  |
|       from large pool |    5216 MB |    5216 MB |    5216 MB |       0 B  |
|       from small pool |      16 MB |      16 MB |      16 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1180 MB |    2703 MB |  341483 MB |  340302 MB |
|       from large pool |    1175 MB |    2698 MB |  339404 MB |  338229 MB |
|       from small pool |       5 MB |       8 MB |    2078 MB |    2073 MB |
|---------------------------------------------------------------------------|
| Allocations           |      62    |      88    |   18756    |   18694    |
|       from large pool |      21    |      41    |    9216    |    9195    |
|       from small pool |      41    |      49    |    9540    |    9499    |
|---------------------------------------------------------------------------|
| Active allocs         |      62    |      88    |   18756    |   18694    |
|       from large pool |      21    |      41    |    9216    |    9195    |
|       from small pool |      41    |      49    |    9540    |    9499    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      29    |      29    |      29    |       0    |
|       from large pool |      21    |      21    |      21    |       0    |
|       from small pool |       8    |       8    |       8    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      31    |      42    |    7572    |    7541    |
|       from large pool |      15    |      23    |    5427    |    5412    |
|       from small pool |      16    |      23    |    2145    |    2129    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[TRAIN_TIME] train time is 4.425642 seconds
[EPOCH_TIME] 1.106411 seconds, maybe large due to not enough epoch skipped.
[EPOCH_TIME] 0.651376 seconds
Rank=4, Graph loaded.
!!!!Train_dataloader(with 18 items) enumerate latency: 0.48984313011169434
torch.Size([8000]) torch.Size([8000, 1])
torch.Size([8400]) torch.Size([8400, 1])
!!!!Train_data_list(with 18 items) enumerate latency: 4.291534423828125e-06, transfer latency: 0.4713935852050781
presamping
presamping takes 2.165343999862671
Rank=2, Graph loaded.
!!!!Train_dataloader(with 18 items) enumerate latency: 0.4837329387664795
torch.Size([8000]) torch.Size([8000, 1])
torch.Size([8400]) torch.Size([8400, 1])
!!!!Train_data_list(with 18 items) enumerate latency: 5.0067901611328125e-06, transfer latency: 0.4742565155029297
presamping
presamping takes 1.9035718441009521

