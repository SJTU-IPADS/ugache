succeed=True
[CUDA] cuda: usage: 6.91 GB
0 :  {link #0 : 1}, {link #1 : 2}, {link #2 : 3}, {link #3 : 4}, {link #4 : 5}, {link #5 : 6}, {link #6 : 7},
1 :  {link #0 : 2}, {link #1 : 3}, {link #2 : 4}, {link #3 : 5}, {link #4 : 6}, {link #5 : 7}, {link #6 : 0},
2 :  {link #0 : 3}, {link #1 : 4}, {link #2 : 5}, {link #3 : 6}, {link #4 : 7}, {link #5 : 0}, {link #6 : 1},
3 :  {link #0 : 4}, {link #1 : 5}, {link #2 : 6}, {link #3 : 7}, {link #4 : 0}, {link #5 : 1}, {link #6 : 2},
4 :  {link #0 : 5}, {link #1 : 6}, {link #2 : 7}, {link #3 : 0}, {link #4 : 1}, {link #5 : 2}, {link #6 : 3},
5 :  {link #0 : 6}, {link #1 : 7}, {link #2 : 0}, {link #3 : 1}, {link #4 : 2}, {link #5 : 3}, {link #6 : 4},
6 :  {link #0 : 7}, {link #1 : 0}, {link #2 : 1}, {link #3 : 2}, {link #4 : 3}, {link #5 : 4}, {link #6 : 5},
7 :  {link #0 : 0}, {link #1 : 1}, {link #2 : 2}, {link #3 : 3}, {link #4 : 4}, {link #5 : 5}, {link #6 : 6},
0 : local 98, cpu 10 {link #0 : g1 8}, {link #1 : g2 8}, {link #2 : g3 8}, {link #3 : g4 8}, {link #4 : g5 8}, {link #5 : g6 8}, {link #6 : g7 8},
1 : local 98, cpu 10 {link #0 : g2 8}, {link #1 : g3 8}, {link #2 : g4 8}, {link #3 : g5 8}, {link #4 : g6 8}, {link #5 : g7 8}, {link #6 : g0 8},
2 : local 98, cpu 10 {link #0 : g3 8}, {link #1 : g4 8}, {link #2 : g5 8}, {link #3 : g6 8}, {link #4 : g7 8}, {link #5 : g0 8}, {link #6 : g1 8},
3 : local 98, cpu 10 {link #0 : g4 8}, {link #1 : g5 8}, {link #2 : g6 8}, {link #3 : g7 8}, {link #4 : g0 8}, {link #5 : g1 8}, {link #6 : g2 8},
4 : local 98, cpu 10 {link #0 : g5 8}, {link #1 : g6 8}, {link #2 : g7 8}, {link #3 : g0 8}, {link #4 : g1 8}, {link #5 : g2 8}, {link #6 : g3 8},
5 : local 98, cpu 10 {link #0 : g6 8}, {link #1 : g7 8}, {link #2 : g0 8}, {link #3 : g1 8}, {link #4 : g2 8}, {link #5 : g3 8}, {link #6 : g4 8},
6 : local 98, cpu 10 {link #0 : g7 8}, {link #1 : g0 8}, {link #2 : g1 8}, {link #3 : g2 8}, {link #4 : g3 8}, {link #5 : g4 8}, {link #6 : g5 8},
7 : local 98, cpu 10 {link #0 : g0 8}, {link #1 : g1 8}, {link #2 : g2 8}, {link #3 : g3 8}, {link #4 : g4 8}, {link #5 : g5 8}, {link #6 : g6 8},
0 :  {link #0 : 1}, {link #1 : 2}, {link #2 : 3}, {link #3 : 4}, {link #4 : 5}, {link #5 : 6}, {link #6 : 7},
1 :  {link #0 : 2}, {link #1 : 3}, {link #2 : 4}, {link #3 : 5}, {link #4 : 6}, {link #5 : 7}, {link #6 : 0},
2 :  {link #0 : 3}, {link #1 : 4}, {link #2 : 5}, {link #3 : 6}, {link #4 : 7}, {link #5 : 0}, {link #6 : 1},
3 :  {link #0 : 4}, {link #1 : 5}, {link #2 : 6}, {link #3 : 7}, {link #4 : 0}, {link #5 : 1}, {link #6 : 2},
4 :  {link #0 : 5}, {link #1 : 6}, {link #2 : 7}, {link #3 : 0}, {link #4 : 1}, {link #5 : 2}, {link #6 : 3},
5 :  {link #0 : 6}, {link #1 : 7}, {link #2 : 0}, {link #3 : 1}, {link #4 : 2}, {link #5 : 3}, {link #6 : 4},
6 :  {link #0 : 7}, {link #1 : 0}, {link #2 : 1}, {link #3 : 2}, {link #4 : 3}, {link #5 : 4}, {link #6 : 5},
7 :  {link #0 : 0}, {link #1 : 1}, {link #2 : 2}, {link #3 : 3}, {link #4 : 4}, {link #5 : 5}, {link #6 : 6},
0 : local 98, cpu 10 {link #0 : g1 8}, {link #1 : g2 8}, {link #2 : g3 8}, {link #3 : g4 8}, {link #4 : g5 8}, {link #5 : g6 8}, {link #6 : g7 8},
1 : local 98, cpu 10 {link #0 : g2 8}, {link #1 : g3 8}, {link #2 : g4 8}, {link #3 : g5 8}, {link #4 : g6 8}, {link #5 : g7 8}, {link #6 : g0 8},
2 : local 98, cpu 10 {link #0 : g3 8}, {link #1 : g4 8}, {link #2 : g5 8}, {link #3 : g6 8}, {link #4 : g7 8}, {link #5 : g0 8}, {link #6 : g1 8},
3 : local 98, cpu 10 {link #0 : g4 8}, {link #1 : g5 8}, {link #2 : g6 8}, {link #3 : g7 8}, {link #4 : g0 8}, {link #5 : g1 8}, {link #6 : g2 8},
4 : local 98, cpu 10 {link #0 : g5 8}, {link #1 : g6 8}, {link #2 : g7 8}, {link #3 : g0 8}, {link #4 : g1 8}, {link #5 : g2 8}, {link #6 : g3 8},
5 : local 98, cpu 10 {link #0 : g6 8}, {link #1 : g7 8}, {link #2 : g0 8}, {link #3 : g1 8}, {link #4 : g2 8}, {link #5 : g3 8}, {link #6 : g4 8},
6 : local 98, cpu 10 {link #0 : g7 8}, {link #1 : g0 8}, {link #2 : g1 8}, {link #3 : g2 8}, {link #4 : g3 8}, {link #5 : g4 8}, {link #6 : g5 8},
7 : local 98, cpu 10 {link #0 : g0 8}, {link #1 : g1 8}, {link #2 : g2 8}, {link #3 : g3 8}, {link #4 : g4 8}, {link #5 : g5 8}, {link #6 : g6 8},
0 :  {link #0 : 1}, {link #1 : 2}, {link #2 : 3}, {link #3 : 4}, {link #4 : 5}, {link #5 : 6}, {link #6 : 7},
1 :  {link #0 : 2}, {link #1 : 3}, {link #2 : 4}, {link #3 : 5}, {link #4 : 6}, {link #5 : 7}, {link #6 : 0},
2 :  {link #0 : 3}, {link #1 : 4}, {link #2 : 5}, {link #3 : 6}, {link #4 : 7}, {link #5 : 0}, {link #6 : 1},
3 :  {link #0 : 4}, {link #1 : 5}, {link #2 : 6}, {link #3 : 7}, {link #4 : 0}, {link #5 : 1}, {link #6 : 2},
4 :  {link #0 : 5}, {link #1 : 6}, {link #2 : 7}, {link #3 : 0}, {link #4 : 1}, {link #5 : 2}, {link #6 : 3},
5 :  {link #0 : 6}, {link #1 : 7}, {link #2 : 0}, {link #3 : 1}, {link #4 : 2}, {link #5 : 3}, {link #6 : 4},
6 :  {link #0 : 7}, {link #1 : 0}, {link #2 : 1}, {link #3 : 2}, {link #4 : 3}, {link #5 : 4}, {link #6 : 5},
7 :  {link #0 : 0}, {link #1 : 1}, {link #2 : 2}, {link #3 : 3}, {link #4 : 4}, {link #5 : 5}, {link #6 : 6},
0 :  {link #0 : 1}, {link #1 : 2}, {link #2 : 3}, {link #3 : 4}, {link #4 : 5}, {link #5 : 6}, {link #6 : 7},
1 :  {link #0 : 2}, {link #1 : 3}, {link #2 : 4}, {link #3 : 5}, {link #4 : 6}, {link #5 : 7}, {link #6 : 0},
2 :  {link #0 : 3}, {link #1 : 4}, {link #2 : 5}, {link #3 : 6}, {link #4 : 7}, {link #5 : 0}, {link #6 : 1},
3 :  {link #0 : 4}, {link #1 : 5}, {link #2 : 6}, {link #3 : 7}, {link #4 : 0}, {link #5 : 1}, {link #6 : 2},
4 :  {link #0 : 5}, {link #1 : 6}, {link #2 : 7}, {link #3 : 0}, {link #4 : 1}, {link #5 : 2}, {link #6 : 3},
5 :  {link #0 : 6}, {link #1 : 7}, {link #2 : 0}, {link #3 : 1}, {link #4 : 2}, {link #5 : 3}, {link #6 : 4},
6 :  {link #0 : 7}, {link #1 : 0}, {link #2 : 1}, {link #3 : 2}, {link #4 : 3}, {link #5 : 4}, {link #6 : 5},
7 :  {link #0 : 0}, {link #1 : 1}, {link #2 : 2}, {link #3 : 3}, {link #4 : 4}, {link #5 : 5}, {link #6 : 6},
0 : local 98, cpu 10 {link #0 : g1 8}, {link #1 : g2 8}, {link #2 : g3 8}, {link #3 : g4 8}, {link #4 : g5 8}, {link #5 : g6 8}, {link #6 : g7 8},
1 : local 98, cpu 10 {link #0 : g2 8}, {link #1 : g3 8}, {link #2 : g4 8}, {link #3 : g5 8}, {link #4 : g6 8}, {link #5 : g7 8}, {link #6 : g0 8},
2 : local 98, cpu 10 {link #0 : g3 8}, {link #1 : g4 8}, {link #2 : g5 8}, {link #3 : g6 8}, {link #4 : g7 8}, {link #5 : g0 8}, {link #6 : g1 8},
3 : local 98, cpu 10 {link #0 : g4 8}, {link #1 : g5 8}, {link #2 : g6 8}, {link #3 : g7 8}, {link #4 : g0 8}, {link #5 : g1 8}, {link #6 : g2 8},
4 : local 98, cpu 10 {link #0 : g5 8}, {link #1 : g6 8}, {link #2 : g7 8}, {link #3 : g0 8}, {link #4 : g1 8}, {link #5 : g2 8}, {link #6 : g3 8},
5 : local 98, cpu 10 {link #0 : g6 8}, {link #1 : g7 8}, {link #2 : g0 8}, {link #3 : g1 8}, {link #4 : g2 8}, {link #5 : g3 8}, {link #6 : g4 8},
6 : local 98, cpu 10 {link #0 : g7 8}, {link #1 : g0 8}, {link #2 : g1 8}, {link #3 : g2 8}, {link #4 : g3 8}, {link #5 : g4 8}, {link #6 : g5 8},
7 : local 98, cpu 10 {link #0 : g0 8}, {link #1 : g1 8}, {link #2 : g2 8}, {link #3 : g3 8}, {link #4 : g4 8}, {link #5 : g5 8}, {link #6 : g6 8},
0 :  {link #0 : 1}, {link #1 : 2}, {link #2 : 3}, {link #3 : 4}, {link #4 : 5}, {link #5 : 6}, {link #6 : 7},
1 :  {link #0 : 2}, {link #1 : 3}, {link #2 : 4}, {link #3 : 5}, {link #4 : 6}, {link #5 : 7}, {link #6 : 0},
2 :  {link #0 : 3}, {link #1 : 4}, {link #2 : 5}, {link #3 : 6}, {link #4 : 7}, {link #5 : 0}, {link #6 : 1},
3 :  {link #0 : 4}, {link #1 : 5}, {link #2 : 6}, {link #3 : 7}, {link #4 : 0}, {link #5 : 1}, {link #6 : 2},
4 :  {link #0 : 5}, {link #1 : 6}, {link #2 : 7}, {link #3 : 0}, {link #4 : 1}, {link #5 : 2}, {link #6 : 3},
5 :  {link #0 : 6}, {link #1 : 7}, {link #2 : 0}, {link #3 : 1}, {link #4 : 2}, {link #5 : 3}, {link #6 : 4},
6 :  {link #0 : 7}, {link #1 : 0}, {link #2 : 1}, {link #3 : 2}, {link #4 : 3}, {link #5 : 4}, {link #6 : 5},
7 :  {link #0 : 0}, {link #1 : 1}, {link #2 : 2}, {link #3 : 3}, {link #4 : 4}, {link #5 : 5}, {link #6 : 6},
0 : local 98, cpu 10 {link #0 : g1 8}, {link #1 : g2 8}, {link #2 : g3 8}, {link #3 : g4 8}, {link #4 : g5 8}, {link #5 : g6 8}, {link #6 : g7 8},
1 : local 98, cpu 10 {link #0 : g2 8}, {link #1 : g3 8}, {link #2 : g4 8}, {link #3 : g5 8}, {link #4 : g6 8}, {link #5 : g7 8}, {link #6 : g0 8},
2 : local 98, cpu 10 {link #0 : g3 8}, {link #1 : g4 8}, {link #2 : g5 8}, {link #3 : g6 8}, {link #4 : g7 8}, {link #5 : g0 8}, {link #6 : g1 8},
3 : local 98, cpu 10 {link #0 : g4 8}, {link #1 : g5 8}, {link #2 : g6 8}, {link #3 : g7 8}, {link #4 : g0 8}, {link #5 : g1 8}, {link #6 : g2 8},
4 : local 98, cpu 10 {link #0 : g5 8}, {link #1 : g6 8}, {link #2 : g7 8}, {link #3 : g0 8}, {link #4 : g1 8}, {link #5 : g2 8}, {link #6 : g3 8},
5 : local 98, cpu 10 {link #0 : g6 8}, {link #1 : g7 8}, {link #2 : g0 8}, {link #3 : g1 8}, {link #4 : g2 8}, {link #5 : g3 8}, {link #6 : g4 8},
6 : local 98, cpu 10 {link #0 : g7 8}, {link #1 : g0 8}, {link #2 : g1 8}, {link #3 : g2 8}, {link #4 : g3 8}, {link #5 : g4 8}, {link #6 : g5 8},
7 : local 98, cpu 10 {link #0 : g0 8}, {link #1 : g1 8}, {link #2 : g2 8}, {link #3 : g3 8}, {link #4 : g4 8}, {link #5 : g5 8}, {link #6 : g6 8},
0 : local 98, cpu 10 {link #0 : g1 8}, {link #1 : g2 8}, {link #2 : g3 8}, {link #3 : g4 8}, {link #4 : g5 8}, {link #5 : g6 8}, {link #6 : g7 8},
1 : local 98, cpu 10 {link #0 : g2 8}, {link #1 : g3 8}, {link #2 : g4 8}, {link #3 : g5 8}, {link #4 : g6 8}, {link #5 : g7 8}, {link #6 : g0 8},
2 : local 98, cpu 10 {link #0 : g3 8}, {link #1 : g4 8}, {link #2 : g5 8}, {link #3 : g6 8}, {link #4 : g7 8}, {link #5 : g0 8}, {link #6 : g1 8},
3 : local 98, cpu 10 {link #0 : g4 8}, {link #1 : g5 8}, {link #2 : g6 8}, {link #3 : g7 8}, {link #4 : g0 8}, {link #5 : g1 8}, {link #6 : g2 8},
4 : local 98, cpu 10 {link #0 : g5 8}, {link #1 : g6 8}, {link #2 : g7 8}, {link #3 : g0 8}, {link #4 : g1 8}, {link #5 : g2 8}, {link #6 : g3 8},
5 : local 98, cpu 10 {link #0 : g6 8}, {link #1 : g7 8}, {link #2 : g0 8}, {link #3 : g1 8}, {link #4 : g2 8}, {link #5 : g3 8}, {link #6 : g4 8},
6 : local 98, cpu 10 {link #0 : g7 8}, {link #1 : g0 8}, {link #2 : g1 8}, {link #3 : g2 8}, {link #4 : g3 8}, {link #5 : g4 8}, {link #6 : g5 8},
7 : local 98, cpu 10 {link #0 : g0 8}, {link #1 : g1 8}, {link #2 : g2 8}, {link #3 : g3 8}, {link #4 : g4 8}, {link #5 : g5 8}, {link #6 : g6 8},
0 :  {link #0 : 1}, {link #1 : 2}, {link #2 : 3}, {link #3 : 4}, {link #4 : 5}, {link #5 : 6}, {link #6 : 7},
1 :  {link #0 : 2}, {link #1 : 3}, {link #2 : 4}, {link #3 : 5}, {link #4 : 6}, {link #5 : 7}, {link #6 : 0},
2 :  {link #0 : 3}, {link #1 : 4}, {link #2 : 5}, {link #3 : 6}, {link #4 : 7}, {link #5 : 0}, {link #6 : 1},
3 :  {link #0 : 4}, {link #1 : 5}, {link #2 : 6}, {link #3 : 7}, {link #4 : 0}, {link #5 : 1}, {link #6 : 2},
4 :  {link #0 : 5}, {link #1 : 6}, {link #2 : 7}, {link #3 : 0}, {link #4 : 1}, {link #5 : 2}, {link #6 : 3},
5 :  {link #0 : 6}, {link #1 : 7}, {link #2 : 0}, {link #3 : 1}, {link #4 : 2}, {link #5 : 3}, {link #6 : 4},
6 :  {link #0 : 7}, {link #1 : 0}, {link #2 : 1}, {link #3 : 2}, {link #4 : 3}, {link #5 : 4}, {link #6 : 5},
7 :  {link #0 : 0}, {link #1 : 1}, {link #2 : 2}, {link #3 : 3}, {link #4 : 4}, {link #5 : 5}, {link #6 : 6},
0 : local 98, cpu 10 {link #0 : g1 8}, {link #1 : g2 8}, {link #2 : g3 8}, {link #3 : g4 8}, {link #4 : g5 8}, {link #5 : g6 8}, {link #6 : g7 8},
1 : local 98, cpu 10 {link #0 : g2 8}, {link #1 : g3 8}, {link #2 : g4 8}, {link #3 : g5 8}, {link #4 : g6 8}, {link #5 : g7 8}, {link #6 : g0 8},
2 : local 98, cpu 10 {link #0 : g3 8}, {link #1 : g4 8}, {link #2 : g5 8}, {link #3 : g6 8}, {link #4 : g7 8}, {link #5 : g0 8}, {link #6 : g1 8},
3 : local 98, cpu 10 {link #0 : g4 8}, {link #1 : g5 8}, {link #2 : g6 8}, {link #3 : g7 8}, {link #4 : g0 8}, {link #5 : g1 8}, {link #6 : g2 8},
4 : local 98, cpu 10 {link #0 : g5 8}, {link #1 : g6 8}, {link #2 : g7 8}, {link #3 : g0 8}, {link #4 : g1 8}, {link #5 : g2 8}, {link #6 : g3 8},
5 : local 98, cpu 10 {link #0 : g6 8}, {link #1 : g7 8}, {link #2 : g0 8}, {link #3 : g1 8}, {link #4 : g2 8}, {link #5 : g3 8}, {link #6 : g4 8},
6 : local 98, cpu 10 {link #0 : g7 8}, {link #1 : g0 8}, {link #2 : g1 8}, {link #3 : g2 8}, {link #4 : g3 8}, {link #5 : g4 8}, {link #6 : g5 8},
7 : local 98, cpu 10 {link #0 : g0 8}, {link #1 : g1 8}, {link #2 : g2 8}, {link #3 : g3 8}, {link #4 : g4 8}, {link #5 : g5 8}, {link #6 : g6 8},
0 :  {link #0 : 1}, {link #1 : 2}, {link #2 : 3}, {link #3 : 4}, {link #4 : 5}, {link #5 : 6}, {link #6 : 7},
1 :  {link #0 : 2}, {link #1 : 3}, {link #2 : 4}, {link #3 : 5}, {link #4 : 6}, {link #5 : 7}, {link #6 : 0},
2 :  {link #0 : 3}, {link #1 : 4}, {link #2 : 5}, {link #3 : 6}, {link #4 : 7}, {link #5 : 0}, {link #6 : 1},
3 :  {link #0 : 4}, {link #1 : 5}, {link #2 : 6}, {link #3 : 7}, {link #4 : 0}, {link #5 : 1}, {link #6 : 2},
4 :  {link #0 : 5}, {link #1 : 6}, {link #2 : 7}, {link #3 : 0}, {link #4 : 1}, {link #5 : 2}, {link #6 : 3},
5 :  {link #0 : 6}, {link #1 : 7}, {link #2 : 0}, {link #3 : 1}, {link #4 : 2}, {link #5 : 3}, {link #6 : 4},
6 :  {link #0 : 7}, {link #1 : 0}, {link #2 : 1}, {link #3 : 2}, {link #4 : 3}, {link #5 : 4}, {link #6 : 5},
7 :  {link #0 : 0}, {link #1 : 1}, {link #2 : 2}, {link #3 : 3}, {link #4 : 4}, {link #5 : 5}, {link #6 : 6},
0 : local 98, cpu 10 {link #0 : g1 8}, {link #1 : g2 8}, {link #2 : g3 8}, {link #3 : g4 8}, {link #4 : g5 8}, {link #5 : g6 8}, {link #6 : g7 8},
1 : local 98, cpu 10 {link #0 : g2 8}, {link #1 : g3 8}, {link #2 : g4 8}, {link #3 : g5 8}, {link #4 : g6 8}, {link #5 : g7 8}, {link #6 : g0 8},
2 : local 98, cpu 10 {link #0 : g3 8}, {link #1 : g4 8}, {link #2 : g5 8}, {link #3 : g6 8}, {link #4 : g7 8}, {link #5 : g0 8}, {link #6 : g1 8},
3 : local 98, cpu 10 {link #0 : g4 8}, {link #1 : g5 8}, {link #2 : g6 8}, {link #3 : g7 8}, {link #4 : g0 8}, {link #5 : g1 8}, {link #6 : g2 8},
4 : local 98, cpu 10 {link #0 : g5 8}, {link #1 : g6 8}, {link #2 : g7 8}, {link #3 : g0 8}, {link #4 : g1 8}, {link #5 : g2 8}, {link #6 : g3 8},
5 : local 98, cpu 10 {link #0 : g6 8}, {link #1 : g7 8}, {link #2 : g0 8}, {link #3 : g1 8}, {link #4 : g2 8}, {link #5 : g3 8}, {link #6 : g4 8},
6 : local 98, cpu 10 {link #0 : g7 8}, {link #1 : g0 8}, {link #2 : g1 8}, {link #3 : g2 8}, {link #4 : g3 8}, {link #5 : g4 8}, {link #6 : g5 8},
7 : local 98, cpu 10 {link #0 : g0 8}, {link #1 : g1 8}, {link #2 : g2 8}, {link #3 : g3 8}, {link #4 : g4 8}, {link #5 : g5 8}, {link #6 : g6 8},
0 :  {link #0 : 1}, {link #1 : 2}, {link #2 : 3}, {link #3 : 4}, {link #4 : 5}, {link #5 : 6}, {link #6 : 7},
1 :  {link #0 : 2}, {link #1 : 3}, {link #2 : 4}, {link #3 : 5}, {link #4 : 6}, {link #5 : 7}, {link #6 : 0},
2 :  {link #0 : 3}, {link #1 : 4}, {link #2 : 5}, {link #3 : 6}, {link #4 : 7}, {link #5 : 0}, {link #6 : 1},
3 :  {link #0 : 4}, {link #1 : 5}, {link #2 : 6}, {link #3 : 7}, {link #4 : 0}, {link #5 : 1}, {link #6 : 2},
4 :  {link #0 : 5}, {link #1 : 6}, {link #2 : 7}, {link #3 : 0}, {link #4 : 1}, {link #5 : 2}, {link #6 : 3},
5 :  {link #0 : 6}, {link #1 : 7}, {link #2 : 0}, {link #3 : 1}, {link #4 : 2}, {link #5 : 3}, {link #6 : 4},
6 :  {link #0 : 7}, {link #1 : 0}, {link #2 : 1}, {link #3 : 2}, {link #4 : 3}, {link #5 : 4}, {link #6 : 5},
7 :  {link #0 : 0}, {link #1 : 1}, {link #2 : 2}, {link #3 : 3}, {link #4 : 4}, {link #5 : 5}, {link #6 : 6},
0 : local 98, cpu 10 {link #0 : g1 8}, {link #1 : g2 8}, {link #2 : g3 8}, {link #3 : g4 8}, {link #4 : g5 8}, {link #5 : g6 8}, {link #6 : g7 8},
1 : local 98, cpu 10 {link #0 : g2 8}, {link #1 : g3 8}, {link #2 : g4 8}, {link #3 : g5 8}, {link #4 : g6 8}, {link #5 : g7 8}, {link #6 : g0 8},
2 : local 98, cpu 10 {link #0 : g3 8}, {link #1 : g4 8}, {link #2 : g5 8}, {link #3 : g6 8}, {link #4 : g7 8}, {link #5 : g0 8}, {link #6 : g1 8},
3 : local 98, cpu 10 {link #0 : g4 8}, {link #1 : g5 8}, {link #2 : g6 8}, {link #3 : g7 8}, {link #4 : g0 8}, {link #5 : g1 8}, {link #6 : g2 8},
4 : local 98, cpu 10 {link #0 : g5 8}, {link #1 : g6 8}, {link #2 : g7 8}, {link #3 : g0 8}, {link #4 : g1 8}, {link #5 : g2 8}, {link #6 : g3 8},
5 : local 98, cpu 10 {link #0 : g6 8}, {link #1 : g7 8}, {link #2 : g0 8}, {link #3 : g1 8}, {link #4 : g2 8}, {link #5 : g3 8}, {link #6 : g4 8},
6 : local 98, cpu 10 {link #0 : g7 8}, {link #1 : g0 8}, {link #2 : g1 8}, {link #3 : g2 8}, {link #4 : g3 8}, {link #5 : g4 8}, {link #6 : g5 8},
7 : local 98, cpu 10 {link #0 : g0 8}, {link #1 : g1 8}, {link #2 : g2 8}, {link #3 : g3 8}, {link #4 : g4 8}, {link #5 : g5 8}, {link #6 : g6 8},
test_result:init:cache_nbytes=56862697472
test_result:init:cache_nbytes=56862697472
test_result:init:cache_nbytes=56862697472
test_result:init:cache_nbytes=56862697472
test_result:init:cache_nbytes=56862697472
test_result:init:cache_nbytes=56862697472
test_result:init:cache_nbytes=56862697472
test_result:init:cache_nbytes=56862697472
worker 0 running with pid=15559
config:eval_tsp="2023-08-06 09:28:48"
config:num_worker=8
config:num_intra_size=8
config:root_dir=/datasets_gnn/wholegraph
config:graph_name=ogbn-papers100M
config:epochs=4
config:batchsize=4000
config:skip_epoch=2
config:local_step=125
config:presc_epoch=2
config:neighbors=15,10,5
config:hiddensize=256
config:num_layer=3
config:model=gcn
config:framework=dgl
config:dataloaderworkers=0
config:dropout=0.5
config:weight_decay=0.0005
config:lr=0.003
config:use_nccl=False
config:use_amp=False
config:use_collcache=True
config:cache_percentage=1.0
config:cache_policy=coll_cache_asymm_link
config:omp_thread_num=56
config:unsupervised=True
config:classnum=172
config:global_barrier=<multiprocessing.synchronize.Barrier object at 0x7f354ec4e8b0>
config:worker_id=0
creating_intra_node_communicator root=0, local_size=8, world_size=8
loading train edge idx from disk
loading train edge idx from disk done
tensor([ 367470406, 3158702471, 3196913887,  534369026, 2622541626, 2707306334,
        2288750783,  341639546, 2394912536,   34847343,  697837268, 1665128055,
        3225579545,  808096539,  530910714,  726851972, 1000854521, 1061370191,
         594157634,  526478766,  496425173, 1382980281, 1363464091,  971316959,
        1643305663, 1559556869,  792051811, 2593715952, 2627476216,  865811872,
        1279512108,  281028249, 2848334841, 1142277951, 1624797255, 1682408139,
         511476070,  753655501, 1190696744, 1515340461,  396873136, 3079813016,
         574876927,   31156367,  830710319, 1664434120,  774080817, 2850247945,
         655998496,  888602410,  350570870,  847108703,   69778231,  638128676,
        1443388341, 1479712286, 2858804367,  550628163,  198023098, 2583590303,
        2518492873,    2593795, 2722269746,  659106604, 1369497066,  458403464,
         645516367, 3053389785,  144872323,  792250187, 1401047469, 1545651011,
        1827797263, 1275030316, 2075895474, 2919804301, 2493902937,  112768749,
          11701078,  723465431,  404737965,  786261376,  934911988,  757583227,
        1135493038, 3162165660, 1144120843, 2861906075,  223193336, 1866677628,
         326241255,   64202517, 1840253021,  970607610,  419197513, 3025516425,
         133597469,  978276161, 2348166713,  303649761])
Rank=0, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.005692, per step: 0.000046
epoch=4 total_steps=500
presamping
presamping takes 32.43220353126526
start training...
[Epoch 0][Step 0], time=2.0403659343719482, ext_time=0.02732062339782715, train_time=1.9901740550994873
[Epoch 0][Step 1], time=0.0938410758972168, ext_time=0.004195213317871094, train_time=0.055611371994018555
[Epoch 0][Step 2], time=0.07652068138122559, ext_time=0.004150390625, train_time=0.051154375076293945
[Epoch 0][Step 3], time=0.07271313667297363, ext_time=0.00408625602722168, train_time=0.0473475456237793
[Epoch 0][Step 4], time=0.0776212215423584, ext_time=0.004113674163818359, train_time=0.05210566520690918
[Epoch 0][Step 5], time=0.36220264434814453, ext_time=0.004091739654541016, train_time=0.3368074893951416
[Epoch 0][Step 6], time=0.07077217102050781, ext_time=0.0041162967681884766, train_time=0.04530763626098633
[Epoch 0][Step 7], time=0.06982254981994629, ext_time=0.004095554351806641, train_time=0.04439091682434082
[Epoch 0][Step 8], time=0.07451033592224121, ext_time=0.004094362258911133, train_time=0.049097299575805664
[Epoch 0][Step 9], time=0.07366538047790527, ext_time=0.004098653793334961, train_time=0.04827761650085449
[Epoch 0][Step 10], time=0.0709085464477539, ext_time=0.0041158199310302734, train_time=0.04533720016479492
[Epoch 0][Step 11], time=0.06886458396911621, ext_time=0.004144430160522461, train_time=0.04334688186645508
[Epoch 0][Step 12], time=0.06892538070678711, ext_time=0.004096508026123047, train_time=0.04346752166748047
[Epoch 0][Step 13], time=0.36463499069213867, ext_time=0.004098653793334961, train_time=0.33921170234680176
[Epoch 0][Step 14], time=0.31887030601501465, ext_time=0.004088640213012695, train_time=0.29358339309692383
[Epoch 0][Step 15], time=0.0700235366821289, ext_time=0.004088401794433594, train_time=0.044635772705078125
[Epoch 0][Step 16], time=0.06964349746704102, ext_time=0.004105567932128906, train_time=0.04417991638183594
[Epoch 0][Step 17], time=0.07028579711914062, ext_time=0.004099369049072266, train_time=0.04483985900878906
[Epoch 0][Step 18], time=0.06886935234069824, ext_time=0.0041162967681884766, train_time=0.043332576751708984
[Epoch 0][Step 19], time=0.06865501403808594, ext_time=0.0041196346282958984, train_time=0.04315757751464844
[Epoch 0][Step 20], time=0.06891441345214844, ext_time=0.0041065216064453125, train_time=0.04343748092651367
[Epoch 0][Step 21], time=0.4295470714569092, ext_time=0.004082441329956055, train_time=0.4041612148284912
[Epoch 0][Step 22], time=0.07033371925354004, ext_time=0.004080772399902344, train_time=0.04503607749938965
[Epoch 0][Step 23], time=0.06963229179382324, ext_time=0.004095792770385742, train_time=0.044165611267089844
[Epoch 0][Step 24], time=0.07028317451477051, ext_time=0.004103422164916992, train_time=0.0448300838470459
[Epoch 0][Step 25], time=0.06902027130126953, ext_time=0.004109621047973633, train_time=0.043538808822631836
[Epoch 0][Step 26], time=0.06880760192871094, ext_time=0.004099130630493164, train_time=0.04333949089050293
[Epoch 0][Step 27], time=0.06910228729248047, ext_time=0.004080057144165039, train_time=0.043700218200683594
[Epoch 0][Step 28], time=0.06911039352416992, ext_time=0.0041086673736572266, train_time=0.04359292984008789
[Epoch 0][Step 29], time=0.06905388832092285, ext_time=0.004083871841430664, train_time=0.04366755485534668
[Epoch 0][Step 30], time=0.0746922492980957, ext_time=0.004108428955078125, train_time=0.04330611228942871
[Epoch 0][Step 31], time=0.06900429725646973, ext_time=0.004109621047973633, train_time=0.043495893478393555
[Epoch 0][Step 32], time=0.0725548267364502, ext_time=0.004105567932128906, train_time=0.04705977439880371
[Epoch 0][Step 33], time=0.06888747215270996, ext_time=0.00409245491027832, train_time=0.04349088668823242
[Epoch 0][Step 34], time=0.30684614181518555, ext_time=0.004128932952880859, train_time=0.28119587898254395
[Epoch 0][Step 35], time=0.06951022148132324, ext_time=0.004242420196533203, train_time=0.0436093807220459
[Epoch 0][Step 36], time=0.06940960884094238, ext_time=0.004106283187866211, train_time=0.043903350830078125
[Epoch 0][Step 37], time=0.0688481330871582, ext_time=0.004094600677490234, train_time=0.04333019256591797
[Epoch 0][Step 38], time=0.06901693344116211, ext_time=0.004110097885131836, train_time=0.0434718132019043
[Epoch 0][Step 39], time=0.06918168067932129, ext_time=0.004131317138671875, train_time=0.04378008842468262
[Epoch 0][Step 40], time=0.07347512245178223, ext_time=0.004117488861083984, train_time=0.04794716835021973
[Epoch 0][Step 41], time=0.06884098052978516, ext_time=0.004152059555053711, train_time=0.043322086334228516
[Epoch 0][Step 42], time=0.0686640739440918, ext_time=0.004069805145263672, train_time=0.04339098930358887
[Epoch 0][Step 43], time=0.07292008399963379, ext_time=0.004102468490600586, train_time=0.047518014907836914
[Epoch 0][Step 44], time=0.06907916069030762, ext_time=0.004079103469848633, train_time=0.04374527931213379
[Epoch 0][Step 45], time=0.06878995895385742, ext_time=0.004100799560546875, train_time=0.0434114933013916
[Epoch 0][Step 46], time=0.06914520263671875, ext_time=0.004105567932128906, train_time=0.043663978576660156
[Epoch 0][Step 47], time=0.06900167465209961, ext_time=0.004122257232666016, train_time=0.04340624809265137
[Epoch 0][Step 48], time=0.07231736183166504, ext_time=0.004094839096069336, train_time=0.046875715255737305
[Epoch 0][Step 49], time=0.06902480125427246, ext_time=0.004127025604248047, train_time=0.043492794036865234
[Epoch 0][Step 50], time=0.06903338432312012, ext_time=0.0041103363037109375, train_time=0.04352569580078125
[Epoch 0][Step 51], time=0.06902050971984863, ext_time=0.004098653793334961, train_time=0.043599605560302734
[Epoch 0][Step 52], time=0.07008719444274902, ext_time=0.004105806350708008, train_time=0.044666290283203125
[Epoch 0][Step 53], time=0.06914925575256348, ext_time=0.004080533981323242, train_time=0.043848276138305664
[Epoch 0][Step 54], time=0.06883025169372559, ext_time=0.004119396209716797, train_time=0.04334306716918945
[Epoch 0][Step 55], time=0.06870293617248535, ext_time=0.004098176956176758, train_time=0.04323911666870117
[Epoch 0][Step 56], time=0.07055854797363281, ext_time=0.004094362258911133, train_time=0.045166730880737305
[Epoch 0][Step 57], time=0.06890463829040527, ext_time=0.0040891170501708984, train_time=0.04349946975708008
[Epoch 0][Step 58], time=0.06943821907043457, ext_time=0.004090070724487305, train_time=0.04400444030761719
[Epoch 0][Step 59], time=0.06902480125427246, ext_time=0.004080772399902344, train_time=0.04368019104003906
[Epoch 0][Step 60], time=0.06881523132324219, ext_time=0.004103899002075195, train_time=0.04331517219543457
[Epoch 0][Step 61], time=0.06902408599853516, ext_time=0.004069089889526367, train_time=0.043671607971191406
[Epoch 0][Step 62], time=0.06898307800292969, ext_time=0.004098176956176758, train_time=0.043479204177856445
[Epoch 0][Step 63], time=0.06888818740844727, ext_time=0.004080533981323242, train_time=0.043541908264160156
[Epoch 0][Step 64], time=0.06909537315368652, ext_time=0.00410151481628418, train_time=0.04359292984008789
[Epoch 0][Step 65], time=0.06905126571655273, ext_time=0.004107236862182617, train_time=0.04356265068054199
[Epoch 0][Step 66], time=0.06875276565551758, ext_time=0.004106044769287109, train_time=0.04325723648071289
[Epoch 0][Step 67], time=0.06888580322265625, ext_time=0.004099130630493164, train_time=0.043390750885009766
[Epoch 0][Step 68], time=0.06879591941833496, ext_time=0.004099607467651367, train_time=0.04337000846862793
[Epoch 0][Step 69], time=0.06900691986083984, ext_time=0.004100322723388672, train_time=0.043512821197509766
[Epoch 0][Step 70], time=0.06906700134277344, ext_time=0.0040798187255859375, train_time=0.04372978210449219
[Epoch 0][Step 71], time=0.06881141662597656, ext_time=0.0040895938873291016, train_time=0.04345369338989258
[Epoch 0][Step 72], time=0.07610487937927246, ext_time=0.004100322723388672, train_time=0.043436527252197266
[Epoch 0][Step 73], time=0.06892228126525879, ext_time=0.004096031188964844, train_time=0.04344534873962402
[Epoch 0][Step 74], time=0.06894516944885254, ext_time=0.004117488861083984, train_time=0.043396711349487305
[Epoch 0][Step 75], time=0.06866908073425293, ext_time=0.004085540771484375, train_time=0.04327821731567383
[Epoch 0][Step 76], time=0.06891322135925293, ext_time=0.00409388542175293, train_time=0.04350399971008301
[Epoch 0][Step 77], time=0.07135176658630371, ext_time=0.004117488861083984, train_time=0.045770883560180664
[Epoch 0][Step 78], time=0.0689387321472168, ext_time=0.004116535186767578, train_time=0.04340791702270508
[Epoch 0][Step 79], time=0.06918859481811523, ext_time=0.004097938537597656, train_time=0.043698787689208984
[Epoch 0][Step 80], time=0.06879472732543945, ext_time=0.004108905792236328, train_time=0.04330015182495117
[Epoch 0][Step 81], time=0.06905007362365723, ext_time=0.004118680953979492, train_time=0.04345273971557617
[Epoch 0][Step 82], time=0.06886816024780273, ext_time=0.0041162967681884766, train_time=0.04331636428833008
[Epoch 0][Step 83], time=0.06919336318969727, ext_time=0.0040967464447021484, train_time=0.04371976852416992
[Epoch 0][Step 84], time=0.06900215148925781, ext_time=0.00409245491027832, train_time=0.04360675811767578
[Epoch 0][Step 85], time=0.06902480125427246, ext_time=0.004098653793334961, train_time=0.043614864349365234
[Epoch 0][Step 86], time=0.06905436515808105, ext_time=0.004117727279663086, train_time=0.04350161552429199
[Epoch 0][Step 87], time=0.0690150260925293, ext_time=0.004119157791137695, train_time=0.043428897857666016
[Epoch 0][Step 88], time=0.06984901428222656, ext_time=0.004086971282958984, train_time=0.04444408416748047
[Epoch 0][Step 89], time=0.06892800331115723, ext_time=0.004104137420654297, train_time=0.04349684715270996
[Epoch 0][Step 90], time=0.06870150566101074, ext_time=0.004103899002075195, train_time=0.043218374252319336
[Epoch 0][Step 91], time=0.06905770301818848, ext_time=0.0041046142578125, train_time=0.04355168342590332
[Epoch 0][Step 92], time=0.3812994956970215, ext_time=0.004141569137573242, train_time=0.35565972328186035
[Epoch 0][Step 93], time=0.06902885437011719, ext_time=0.00414586067199707, train_time=0.04354214668273926
[Epoch 0][Step 94], time=0.06943297386169434, ext_time=0.00409245491027832, train_time=0.04392886161804199
[Epoch 0][Step 95], time=0.06865096092224121, ext_time=0.004090785980224609, train_time=0.04323530197143555
[Epoch 0][Step 96], time=0.06896233558654785, ext_time=0.004080772399902344, train_time=0.04356741905212402
[Epoch 0][Step 97], time=0.06889772415161133, ext_time=0.004080533981323242, train_time=0.04354381561279297
[Epoch 0][Step 98], time=0.06904458999633789, ext_time=0.004102945327758789, train_time=0.04353928565979004
[Epoch 0][Step 99], time=0.06911969184875488, ext_time=0.0040929317474365234, train_time=0.04364800453186035
[Epoch 0][Step 100], time=0.06937766075134277, ext_time=0.0041010379791259766, train_time=0.043901681900024414
[Epoch 0][Step 101], time=0.06970667839050293, ext_time=0.00410008430480957, train_time=0.0442204475402832
[Epoch 0][Step 102], time=0.06913495063781738, ext_time=0.0041408538818359375, train_time=0.0437014102935791
[Epoch 0][Step 103], time=0.06920099258422852, ext_time=0.0040967464447021484, train_time=0.043735504150390625
[Epoch 0][Step 104], time=0.06897807121276855, ext_time=0.004090070724487305, train_time=0.04356861114501953
[Epoch 0][Step 105], time=0.06881403923034668, ext_time=0.00408625602722168, train_time=0.04338407516479492
[Epoch 0][Step 106], time=0.06900644302368164, ext_time=0.004106044769287109, train_time=0.043550729751586914
[Epoch 0][Step 107], time=0.0697166919708252, ext_time=0.0041065216064453125, train_time=0.04422760009765625
[Epoch 0][Step 108], time=0.06881427764892578, ext_time=0.004093647003173828, train_time=0.04340338706970215
[Epoch 0][Step 109], time=0.0688786506652832, ext_time=0.004109621047973633, train_time=0.0433809757232666
[Epoch 0][Step 110], time=0.06886839866638184, ext_time=0.004147052764892578, train_time=0.04339909553527832
[Epoch 0][Step 111], time=0.06893229484558105, ext_time=0.004071474075317383, train_time=0.043611764907836914
[Epoch 0][Step 112], time=0.06891894340515137, ext_time=0.004109859466552734, train_time=0.043349266052246094
[Epoch 0][Step 113], time=0.06893634796142578, ext_time=0.004082202911376953, train_time=0.04357004165649414
[Epoch 0][Step 114], time=0.07618331909179688, ext_time=0.004117727279663086, train_time=0.04373764991760254
[Epoch 0][Step 115], time=0.0701909065246582, ext_time=0.004173994064331055, train_time=0.044522762298583984
[Epoch 0][Step 116], time=0.0688014030456543, ext_time=0.004145383834838867, train_time=0.043274879455566406
[Epoch 0][Step 117], time=0.0687568187713623, ext_time=0.00410771369934082, train_time=0.04323387145996094
[Epoch 0][Step 118], time=0.06917858123779297, ext_time=0.0041158199310302734, train_time=0.04372119903564453
[Epoch 0][Step 119], time=0.06918096542358398, ext_time=0.0041027069091796875, train_time=0.04366111755371094
[Epoch 0][Step 120], time=0.06894326210021973, ext_time=0.0040895938873291016, train_time=0.04346919059753418
[Epoch 0][Step 121], time=0.06893253326416016, ext_time=0.004094362258911133, train_time=0.04351210594177246
[Epoch 0][Step 122], time=0.06902956962585449, ext_time=0.0041010379791259766, train_time=0.0435636043548584
[Epoch 0][Step 123], time=0.06911969184875488, ext_time=0.004106760025024414, train_time=0.04359793663024902
[Epoch 0][Step 124], time=0.35964512825012207, ext_time=0.00410151481628418, train_time=0.33416748046875
[Epoch 0], time=12.75079083442688, loss=0.4625474512577057
[Epoch 1][Step 0], time=0.3388655185699463, ext_time=0.004124164581298828, train_time=0.3132815361022949
[Epoch 1][Step 1], time=0.06918740272521973, ext_time=0.004125118255615234, train_time=0.04356074333190918
[Epoch 1][Step 2], time=0.06868910789489746, ext_time=0.004075050354003906, train_time=0.043303489685058594
[Epoch 1][Step 3], time=0.06893658638000488, ext_time=0.004105091094970703, train_time=0.0434422492980957
[Epoch 1][Step 4], time=0.06877994537353516, ext_time=0.004099130630493164, train_time=0.04335498809814453
[Epoch 1][Step 5], time=0.06873559951782227, ext_time=0.004089832305908203, train_time=0.04332089424133301
[Epoch 1][Step 6], time=0.06895065307617188, ext_time=0.00409698486328125, train_time=0.04346418380737305
[Epoch 1][Step 7], time=0.06995916366577148, ext_time=0.005029916763305664, train_time=0.0435488224029541
[Epoch 1][Step 8], time=0.06907105445861816, ext_time=0.004114627838134766, train_time=0.04359173774719238
[Epoch 1][Step 9], time=0.06869292259216309, ext_time=0.004105567932128906, train_time=0.04319286346435547
[Epoch 1][Step 10], time=0.06911134719848633, ext_time=0.004118204116821289, train_time=0.0435175895690918
[Epoch 1][Step 11], time=0.06887245178222656, ext_time=0.004087209701538086, train_time=0.04345846176147461
[Epoch 1][Step 12], time=0.06913399696350098, ext_time=0.004110574722290039, train_time=0.04360532760620117
[Epoch 1][Step 13], time=0.06901073455810547, ext_time=0.004082918167114258, train_time=0.04363083839416504
[Epoch 1][Step 14], time=0.06907033920288086, ext_time=0.004088878631591797, train_time=0.04364132881164551
[Epoch 1][Step 15], time=0.06870698928833008, ext_time=0.0040814876556396484, train_time=0.04332375526428223
[Epoch 1][Step 16], time=0.06910419464111328, ext_time=0.0040819644927978516, train_time=0.04374122619628906
[Epoch 1][Step 17], time=0.06894493103027344, ext_time=0.0041120052337646484, train_time=0.04337787628173828
[Epoch 1][Step 18], time=0.06878447532653809, ext_time=0.004094839096069336, train_time=0.04335212707519531
[Epoch 1][Step 19], time=0.06882452964782715, ext_time=0.004099130630493164, train_time=0.04333686828613281
[Epoch 1][Step 20], time=0.06910037994384766, ext_time=0.004110097885131836, train_time=0.043581485748291016
[Epoch 1][Step 21], time=0.06906938552856445, ext_time=0.004105329513549805, train_time=0.043607234954833984
[Epoch 1][Step 22], time=0.06884264945983887, ext_time=0.004095792770385742, train_time=0.04340839385986328
[Epoch 1][Step 23], time=0.06949067115783691, ext_time=0.0040967464447021484, train_time=0.044031620025634766
[Epoch 1][Step 24], time=0.06940007209777832, ext_time=0.0041196346282958984, train_time=0.04382061958312988
[Epoch 1][Step 25], time=0.06898212432861328, ext_time=0.00411224365234375, train_time=0.04346108436584473
[Epoch 1][Step 26], time=0.06910467147827148, ext_time=0.0041043758392333984, train_time=0.04356694221496582
[Epoch 1][Step 27], time=0.0689995288848877, ext_time=0.0041217803955078125, train_time=0.04346799850463867
[Epoch 1][Step 28], time=0.06888484954833984, ext_time=0.004118442535400391, train_time=0.04330611228942871
[Epoch 1][Step 29], time=0.06892108917236328, ext_time=0.004092693328857422, train_time=0.04351663589477539
[Epoch 1][Step 30], time=0.06893229484558105, ext_time=0.004114866256713867, train_time=0.043349504470825195
[Epoch 1][Step 31], time=0.07614445686340332, ext_time=0.0041158199310302734, train_time=0.04343867301940918
[Epoch 1][Step 32], time=0.06886506080627441, ext_time=0.004114627838134766, train_time=0.04337763786315918
[Epoch 1][Step 33], time=0.06876301765441895, ext_time=0.004076480865478516, train_time=0.043460845947265625
[Epoch 1][Step 34], time=0.06889915466308594, ext_time=0.004095554351806641, train_time=0.043431758880615234
[Epoch 1][Step 35], time=0.06902122497558594, ext_time=0.004103422164916992, train_time=0.04356741905212402
[Epoch 1][Step 36], time=0.06904959678649902, ext_time=0.004119396209716797, train_time=0.04338717460632324
[Epoch 1][Step 37], time=0.06886649131774902, ext_time=0.004098653793334961, train_time=0.04339265823364258
[Epoch 1][Step 38], time=0.06878042221069336, ext_time=0.004107236862182617, train_time=0.04326462745666504
[Epoch 1][Step 39], time=0.06909322738647461, ext_time=0.004095792770385742, train_time=0.04360771179199219
[Epoch 1][Step 40], time=0.06908798217773438, ext_time=0.004129171371459961, train_time=0.043480873107910156
[Epoch 1][Step 41], time=0.0689091682434082, ext_time=0.004120349884033203, train_time=0.0433351993560791
[Epoch 1][Step 42], time=0.06876611709594727, ext_time=0.004091501235961914, train_time=0.043260812759399414
[Epoch 1][Step 43], time=0.06896257400512695, ext_time=0.0040819644927978516, train_time=0.04356575012207031
[Epoch 1][Step 44], time=0.06900191307067871, ext_time=0.004097938537597656, train_time=0.043530941009521484
[Epoch 1][Step 45], time=0.06878089904785156, ext_time=0.004108905792236328, train_time=0.043279409408569336
[Epoch 1][Step 46], time=0.07325315475463867, ext_time=0.0041005611419677734, train_time=0.0477907657623291
[Epoch 1][Step 47], time=0.06900453567504883, ext_time=0.004117488861083984, train_time=0.04340863227844238
[Epoch 1][Step 48], time=0.06900548934936523, ext_time=0.004119157791137695, train_time=0.0434415340423584
[Epoch 1][Step 49], time=0.06885957717895508, ext_time=0.0041081905364990234, train_time=0.04335761070251465
[Epoch 1][Step 50], time=0.0691537857055664, ext_time=0.004106283187866211, train_time=0.04360055923461914
[Epoch 1][Step 51], time=0.06915974617004395, ext_time=0.00409698486328125, train_time=0.043752431869506836
[Epoch 1][Step 52], time=0.06870055198669434, ext_time=0.00410008430480957, train_time=0.04323601722717285
[Epoch 1][Step 53], time=0.07361507415771484, ext_time=0.004101276397705078, train_time=0.04819965362548828
[Epoch 1][Step 54], time=0.06892848014831543, ext_time=0.004111051559448242, train_time=0.043410301208496094
[Epoch 1][Step 55], time=0.06974101066589355, ext_time=0.004110574722290039, train_time=0.04415464401245117
[Epoch 1][Step 56], time=0.06880855560302734, ext_time=0.004067420959472656, train_time=0.04349493980407715
[Epoch 1][Step 57], time=0.07103896141052246, ext_time=0.004085540771484375, train_time=0.04564189910888672
[Epoch 1][Step 58], time=0.06863808631896973, ext_time=0.004111766815185547, train_time=0.04321742057800293
[Epoch 1][Step 59], time=0.06874275207519531, ext_time=0.004090070724487305, train_time=0.04335904121398926
[Epoch 1][Step 60], time=0.06876134872436523, ext_time=0.004086494445800781, train_time=0.04337334632873535
[Epoch 1][Step 61], time=0.0689089298248291, ext_time=0.004096508026123047, train_time=0.04345560073852539
[Epoch 1][Step 62], time=0.06920790672302246, ext_time=0.0040988922119140625, train_time=0.04373908042907715
[Epoch 1][Step 63], time=0.06879186630249023, ext_time=0.004089832305908203, train_time=0.04341626167297363
[Epoch 1][Step 64], time=0.06894969940185547, ext_time=0.004107236862182617, train_time=0.04343914985656738
[Epoch 1][Step 65], time=0.06925582885742188, ext_time=0.004100322723388672, train_time=0.04379105567932129
[Epoch 1][Step 66], time=0.06898140907287598, ext_time=0.0041086673736572266, train_time=0.04351210594177246
[Epoch 1][Step 67], time=0.06911945343017578, ext_time=0.0041162967681884766, train_time=0.04348921775817871
[Epoch 1][Step 68], time=0.06886816024780273, ext_time=0.0040929317474365234, train_time=0.04353642463684082
[Epoch 1][Step 69], time=0.0687720775604248, ext_time=0.004100322723388672, train_time=0.04330778121948242
[Epoch 1][Step 70], time=0.0692741870880127, ext_time=0.004095554351806641, train_time=0.043929100036621094
[Epoch 1][Step 71], time=0.06900954246520996, ext_time=0.004110813140869141, train_time=0.04354429244995117
[Epoch 1][Step 72], time=0.06894421577453613, ext_time=0.004101276397705078, train_time=0.04345893859863281
[Epoch 1][Step 73], time=0.07620072364807129, ext_time=0.004112958908081055, train_time=0.04342460632324219
[Epoch 1][Step 74], time=0.06875824928283691, ext_time=0.004095792770385742, train_time=0.04330778121948242
[Epoch 1][Step 75], time=0.07001996040344238, ext_time=0.004084110260009766, train_time=0.04464411735534668
[Epoch 1][Step 76], time=0.06894469261169434, ext_time=0.004102230072021484, train_time=0.04351806640625
[Epoch 1][Step 77], time=0.06911444664001465, ext_time=0.004117250442504883, train_time=0.043488502502441406
[Epoch 1][Step 78], time=0.06879472732543945, ext_time=0.004100799560546875, train_time=0.043326616287231445
[Epoch 1][Step 79], time=0.06905055046081543, ext_time=0.004102230072021484, train_time=0.043605804443359375
[Epoch 1][Step 80], time=0.06896662712097168, ext_time=0.004084587097167969, train_time=0.043590545654296875
[Epoch 1][Step 81], time=0.06881427764892578, ext_time=0.004101753234863281, train_time=0.043253421783447266
[Epoch 1][Step 82], time=0.27176833152770996, ext_time=0.0041277408599853516, train_time=0.24610686302185059
[Epoch 1][Step 83], time=0.07019519805908203, ext_time=0.004228353500366211, train_time=0.044487953186035156
[Epoch 1][Step 84], time=0.06916117668151855, ext_time=0.0040760040283203125, train_time=0.04381084442138672
[Epoch 1][Step 85], time=0.3834199905395508, ext_time=0.004149675369262695, train_time=0.35794854164123535
[Epoch 1][Step 86], time=0.07007694244384766, ext_time=0.0041046142578125, train_time=0.04456663131713867
[Epoch 1][Step 87], time=0.0697331428527832, ext_time=0.004105567932128906, train_time=0.044194936752319336
[Epoch 1][Step 88], time=0.06910538673400879, ext_time=0.0041179656982421875, train_time=0.04356813430786133
[Epoch 1][Step 89], time=0.06959152221679688, ext_time=0.0041027069091796875, train_time=0.044146060943603516
[Epoch 1][Step 90], time=0.0690314769744873, ext_time=0.004082918167114258, train_time=0.043657779693603516
[Epoch 1][Step 91], time=0.06922578811645508, ext_time=0.00411534309387207, train_time=0.043670654296875
[Epoch 1][Step 92], time=0.06900835037231445, ext_time=0.004149675369262695, train_time=0.043494224548339844
[Epoch 1][Step 93], time=0.06882119178771973, ext_time=0.0041048526763916016, train_time=0.043309926986694336
[Epoch 1][Step 94], time=0.06874251365661621, ext_time=0.004090785980224609, train_time=0.04334688186645508
[Epoch 1][Step 95], time=0.06877374649047852, ext_time=0.004088401794433594, train_time=0.043378353118896484
[Epoch 1][Step 96], time=0.06988096237182617, ext_time=0.004105091094970703, train_time=0.04440498352050781
[Epoch 1][Step 97], time=0.0691680908203125, ext_time=0.004087209701538086, train_time=0.043770790100097656
[Epoch 1][Step 98], time=0.06894063949584961, ext_time=0.004108905792236328, train_time=0.043379783630371094
[Epoch 1][Step 99], time=0.06905817985534668, ext_time=0.0041086673736572266, train_time=0.04354739189147949
[Epoch 1][Step 100], time=0.06892013549804688, ext_time=0.0041027069091796875, train_time=0.043322086334228516
[Epoch 1][Step 101], time=0.0686955451965332, ext_time=0.00408935546875, train_time=0.04321622848510742
[Epoch 1][Step 102], time=0.06877613067626953, ext_time=0.004095792770385742, train_time=0.04336977005004883
[Epoch 1][Step 103], time=0.0688314437866211, ext_time=0.004097938537597656, train_time=0.04331660270690918
[Epoch 1][Step 104], time=0.06906962394714355, ext_time=0.004091739654541016, train_time=0.0431821346282959
[Epoch 1][Step 105], time=0.06923222541809082, ext_time=0.0041048526763916016, train_time=0.043772220611572266
[Epoch 1][Step 106], time=0.07209610939025879, ext_time=0.004101753234863281, train_time=0.04668068885803223
[Epoch 1][Step 107], time=0.06916141510009766, ext_time=0.0041348934173583984, train_time=0.0437469482421875
[Epoch 1][Step 108], time=0.06885051727294922, ext_time=0.0040853023529052734, train_time=0.04346632957458496
[Epoch 1][Step 109], time=0.06873917579650879, ext_time=0.004097461700439453, train_time=0.043277740478515625
[Epoch 1][Step 110], time=0.07092428207397461, ext_time=0.004079341888427734, train_time=0.04561305046081543
[Epoch 1][Step 111], time=0.06908202171325684, ext_time=0.00408625602722168, train_time=0.0436856746673584
[Epoch 1][Step 112], time=0.06880521774291992, ext_time=0.004118680953979492, train_time=0.043305158615112305
[Epoch 1][Step 113], time=0.06917405128479004, ext_time=0.004193305969238281, train_time=0.04364132881164551
[Epoch 1][Step 114], time=0.06894516944885254, ext_time=0.004108428955078125, train_time=0.04343461990356445
[Epoch 1][Step 115], time=0.07670950889587402, ext_time=0.004109859466552734, train_time=0.044449567794799805
[Epoch 1][Step 116], time=0.06894731521606445, ext_time=0.004113674163818359, train_time=0.04338383674621582
[Epoch 1][Step 117], time=0.06885242462158203, ext_time=0.004160165786743164, train_time=0.043302059173583984
[Epoch 1][Step 118], time=0.06892848014831543, ext_time=0.004091978073120117, train_time=0.04349780082702637
[Epoch 1][Step 119], time=0.0690913200378418, ext_time=0.004113197326660156, train_time=0.043512582778930664
[Epoch 1][Step 120], time=0.06912755966186523, ext_time=0.0040781497955322266, train_time=0.04374122619628906
[Epoch 1][Step 121], time=0.06890034675598145, ext_time=0.004098653793334961, train_time=0.0433807373046875
[Epoch 1][Step 122], time=0.06909942626953125, ext_time=0.004080295562744141, train_time=0.0437314510345459
[Epoch 1][Step 123], time=0.06900715827941895, ext_time=0.0040819644927978516, train_time=0.04363656044006348
[Epoch 1][Step 124], time=0.06888008117675781, ext_time=0.004086971282958984, train_time=0.04344773292541504
[Epoch 1], time=9.459718227386475, loss=0.43627670407295227
[Epoch 2][Step 0], time=0.28080201148986816, ext_time=0.00410008430480957, train_time=0.25528955459594727
[Epoch 2][Step 1], time=0.06923294067382812, ext_time=0.0041141510009765625, train_time=0.0436701774597168
[Epoch 2][Step 2], time=0.06918549537658691, ext_time=0.004102230072021484, train_time=0.04374384880065918
[Epoch 2][Step 3], time=0.06883096694946289, ext_time=0.0040929317474365234, train_time=0.04341626167297363
[Epoch 2][Step 4], time=0.06902742385864258, ext_time=0.004096269607543945, train_time=0.043498992919921875
[Epoch 2][Step 5], time=0.0688931941986084, ext_time=0.004086971282958984, train_time=0.04350447654724121
[Epoch 2][Step 6], time=0.06918978691101074, ext_time=0.004101991653442383, train_time=0.04366445541381836
[Epoch 2][Step 7], time=0.06871175765991211, ext_time=0.004113912582397461, train_time=0.043313026428222656
[Epoch 2][Step 8], time=0.06894969940185547, ext_time=0.004099369049072266, train_time=0.043493032455444336
[Epoch 2][Step 9], time=0.06867480278015137, ext_time=0.0041010379791259766, train_time=0.04318571090698242
[Epoch 2][Step 10], time=0.06886696815490723, ext_time=0.004110097885131836, train_time=0.04333686828613281
[Epoch 2][Step 11], time=0.06892800331115723, ext_time=0.0040988922119140625, train_time=0.04347491264343262
[Epoch 2][Step 12], time=0.06991696357727051, ext_time=0.004106044769287109, train_time=0.04332280158996582
[Epoch 2][Step 13], time=0.06891512870788574, ext_time=0.0041081905364990234, train_time=0.043431758880615234
[Epoch 2][Step 14], time=0.06902742385864258, ext_time=0.004101276397705078, train_time=0.04357576370239258
[Epoch 2][Step 15], time=0.06920528411865234, ext_time=0.004088878631591797, train_time=0.043843746185302734
[Epoch 2][Step 16], time=0.06908273696899414, ext_time=0.00408935546875, train_time=0.043665170669555664
[Epoch 2][Step 17], time=0.06871628761291504, ext_time=0.0040891170501708984, train_time=0.043328285217285156
[Epoch 2][Step 18], time=0.06876969337463379, ext_time=0.004098415374755859, train_time=0.04331851005554199
[Epoch 2][Step 19], time=0.06892037391662598, ext_time=0.004098653793334961, train_time=0.04348182678222656
[Epoch 2][Step 20], time=0.06892132759094238, ext_time=0.0041086673736572266, train_time=0.0433652400970459
[Epoch 2][Step 21], time=0.06893372535705566, ext_time=0.004086017608642578, train_time=0.043537139892578125
[Epoch 2][Step 22], time=0.06912994384765625, ext_time=0.004079103469848633, train_time=0.04372715950012207
[Epoch 2][Step 23], time=0.06911301612854004, ext_time=0.004109859466552734, train_time=0.04358243942260742
[Epoch 2][Step 24], time=0.06889462471008301, ext_time=0.004106283187866211, train_time=0.04341387748718262
[Epoch 2][Step 25], time=0.06923031806945801, ext_time=0.004101753234863281, train_time=0.043715715408325195
[Epoch 2][Step 26], time=0.06905865669250488, ext_time=0.0041010379791259766, train_time=0.04358267784118652
[Epoch 2][Step 27], time=0.0688791275024414, ext_time=0.004112720489501953, train_time=0.04340815544128418
[Epoch 2][Step 28], time=0.06854557991027832, ext_time=0.00408935546875, train_time=0.04323172569274902
[Epoch 2][Step 29], time=0.07100248336791992, ext_time=0.0040836334228515625, train_time=0.04565691947937012
[Epoch 2][Step 30], time=0.0690910816192627, ext_time=0.004103422164916992, train_time=0.04363059997558594
[Epoch 2][Step 31], time=0.06904745101928711, ext_time=0.004103660583496094, train_time=0.04358935356140137
[Epoch 2][Step 32], time=0.07601499557495117, ext_time=0.004115581512451172, train_time=0.043463706970214844
[Epoch 2][Step 33], time=0.06912875175476074, ext_time=0.004090547561645508, train_time=0.04373574256896973
[Epoch 2][Step 34], time=0.0687100887298584, ext_time=0.004095792770385742, train_time=0.04324531555175781
[Epoch 2][Step 35], time=0.06919002532958984, ext_time=0.004102468490600586, train_time=0.04376363754272461
[Epoch 2][Step 36], time=0.06905221939086914, ext_time=0.0041158199310302734, train_time=0.04348349571228027
[Epoch 2][Step 37], time=0.06903862953186035, ext_time=0.0041120052337646484, train_time=0.04352712631225586
[Epoch 2][Step 38], time=0.06898140907287598, ext_time=0.004108905792236328, train_time=0.04345130920410156
[Epoch 2][Step 39], time=0.06923675537109375, ext_time=0.004095554351806641, train_time=0.043756961822509766
[Epoch 2][Step 40], time=0.06934022903442383, ext_time=0.004132509231567383, train_time=0.04364299774169922
[Epoch 2][Step 41], time=0.06872367858886719, ext_time=0.004092693328857422, train_time=0.04322409629821777
[Epoch 2][Step 42], time=0.06886959075927734, ext_time=0.004117250442504883, train_time=0.04331827163696289
[Epoch 2][Step 43], time=0.06904911994934082, ext_time=0.004078865051269531, train_time=0.043662071228027344
[Epoch 2][Step 44], time=0.06888413429260254, ext_time=0.004086971282958984, train_time=0.04344892501831055
[Epoch 2][Step 45], time=0.06893706321716309, ext_time=0.004086971282958984, train_time=0.04354119300842285
[Epoch 2][Step 46], time=0.06877279281616211, ext_time=0.004111528396606445, train_time=0.04331779479980469
[Epoch 2][Step 47], time=0.06906747817993164, ext_time=0.004099845886230469, train_time=0.043573856353759766
[Epoch 2][Step 48], time=0.06880378723144531, ext_time=0.004097938537597656, train_time=0.043395280838012695
[Epoch 2][Step 49], time=0.06905913352966309, ext_time=0.004120588302612305, train_time=0.04346323013305664
[Epoch 2][Step 50], time=0.06932258605957031, ext_time=0.004091978073120117, train_time=0.043912649154663086
[Epoch 2][Step 51], time=0.07010436058044434, ext_time=0.004113674163818359, train_time=0.04457259178161621
[Epoch 2][Step 52], time=0.0691077709197998, ext_time=0.004098653793334961, train_time=0.043651580810546875
[Epoch 2][Step 53], time=0.06917405128479004, ext_time=0.004092693328857422, train_time=0.04378795623779297
[Epoch 2][Step 54], time=0.06900787353515625, ext_time=0.0041086673736572266, train_time=0.043524742126464844
[Epoch 2][Step 55], time=0.06920146942138672, ext_time=0.004119157791137695, train_time=0.0436091423034668
[Epoch 2][Step 56], time=0.06904363632202148, ext_time=0.0041463375091552734, train_time=0.0435330867767334
[Epoch 2][Step 57], time=0.06914472579956055, ext_time=0.0041046142578125, train_time=0.04362630844116211
[Epoch 2][Step 58], time=0.06998562812805176, ext_time=0.004114389419555664, train_time=0.044434547424316406
[Epoch 2][Step 59], time=0.06879425048828125, ext_time=0.0040934085845947266, train_time=0.04336714744567871
[Epoch 2][Step 60], time=0.07050299644470215, ext_time=0.004099369049072266, train_time=0.04508709907531738
[Epoch 2][Step 61], time=0.06908202171325684, ext_time=0.004107475280761719, train_time=0.043573856353759766
[Epoch 2][Step 62], time=0.06885981559753418, ext_time=0.004113435745239258, train_time=0.04328799247741699
[Epoch 2][Step 63], time=0.06876087188720703, ext_time=0.004095792770385742, train_time=0.043337345123291016
[Epoch 2][Step 64], time=0.06932830810546875, ext_time=0.00409245491027832, train_time=0.043882131576538086
[Epoch 2][Step 65], time=0.06905436515808105, ext_time=0.004103660583496094, train_time=0.04355287551879883
[Epoch 2][Step 66], time=0.06916522979736328, ext_time=0.004090547561645508, train_time=0.0437469482421875
[Epoch 2][Step 67], time=0.0691230297088623, ext_time=0.004119157791137695, train_time=0.04356050491333008
[Epoch 2][Step 68], time=0.06898999214172363, ext_time=0.004093647003173828, train_time=0.043524742126464844
[Epoch 2][Step 69], time=0.06900477409362793, ext_time=0.004106044769287109, train_time=0.043486595153808594
[Epoch 2][Step 70], time=0.06922388076782227, ext_time=0.0041046142578125, train_time=0.0438077449798584
[Epoch 2][Step 71], time=0.06892514228820801, ext_time=0.004092216491699219, train_time=0.04355931282043457
[Epoch 2][Step 72], time=0.07040691375732422, ext_time=0.004095554351806641, train_time=0.04500627517700195
[Epoch 2][Step 73], time=0.06899785995483398, ext_time=0.004119873046875, train_time=0.043433427810668945
[Epoch 2][Step 74], time=0.07554459571838379, ext_time=0.0040721893310546875, train_time=0.043390750885009766
[Epoch 2][Step 75], time=0.06973481178283691, ext_time=0.0041124820709228516, train_time=0.0441741943359375
[Epoch 2][Step 76], time=0.06886744499206543, ext_time=0.004101991653442383, train_time=0.043387413024902344
[Epoch 2][Step 77], time=0.06924891471862793, ext_time=0.004101753234863281, train_time=0.043442487716674805
[Epoch 2][Step 78], time=0.06875276565551758, ext_time=0.0041005611419677734, train_time=0.04333639144897461
[Epoch 2][Step 79], time=0.06926822662353516, ext_time=0.004095315933227539, train_time=0.043821096420288086
[Epoch 2][Step 80], time=0.06896352767944336, ext_time=0.004118204116821289, train_time=0.04337310791015625
[Epoch 2][Step 81], time=0.06900644302368164, ext_time=0.0040972232818603516, train_time=0.04355192184448242
[Epoch 2][Step 82], time=0.0688176155090332, ext_time=0.0040972232818603516, train_time=0.04339408874511719
[Epoch 2][Step 83], time=0.06883621215820312, ext_time=0.0041005611419677734, train_time=0.04352521896362305
[Epoch 2][Step 84], time=0.06938529014587402, ext_time=0.0040912628173828125, train_time=0.04401803016662598
[Epoch 2][Step 85], time=0.06899666786193848, ext_time=0.004117012023925781, train_time=0.0434720516204834
[Epoch 2][Step 86], time=0.06891345977783203, ext_time=0.00410914421081543, train_time=0.043380022048950195
[Epoch 2][Step 87], time=0.069244384765625, ext_time=0.004122257232666016, train_time=0.043628692626953125
[Epoch 2][Step 88], time=0.06887555122375488, ext_time=0.004117727279663086, train_time=0.04337477684020996
[Epoch 2][Step 89], time=0.06897163391113281, ext_time=0.00412440299987793, train_time=0.04340791702270508
[Epoch 2][Step 90], time=0.0687856674194336, ext_time=0.0041048526763916016, train_time=0.04331064224243164
[Epoch 2][Step 91], time=0.06894493103027344, ext_time=0.004114627838134766, train_time=0.04341912269592285
[Epoch 2][Step 92], time=0.06972408294677734, ext_time=0.00413203239440918, train_time=0.04404807090759277
[Epoch 2][Step 93], time=0.0688481330871582, ext_time=0.0041124820709228516, train_time=0.04332423210144043
[Epoch 2][Step 94], time=0.06888484954833984, ext_time=0.004082441329956055, train_time=0.04347968101501465
[Epoch 2][Step 95], time=0.0687263011932373, ext_time=0.0040798187255859375, train_time=0.043416500091552734
[Epoch 2][Step 96], time=0.06905221939086914, ext_time=0.0041158199310302734, train_time=0.0435483455657959
[Epoch 2][Step 97], time=0.0689401626586914, ext_time=0.004097700119018555, train_time=0.0435023307800293
[Epoch 2][Step 98], time=0.06867361068725586, ext_time=0.004100322723388672, train_time=0.04321026802062988
[Epoch 2][Step 99], time=0.06903910636901855, ext_time=0.004093647003173828, train_time=0.04359865188598633
[Epoch 2][Step 100], time=0.06893229484558105, ext_time=0.004102230072021484, train_time=0.043442487716674805
[Epoch 2][Step 101], time=0.0694737434387207, ext_time=0.004108428955078125, train_time=0.04398036003112793
[Epoch 2][Step 102], time=0.06885743141174316, ext_time=0.004077911376953125, train_time=0.04351496696472168
[Epoch 2][Step 103], time=0.06900620460510254, ext_time=0.00411224365234375, train_time=0.04342007637023926
[Epoch 2][Step 104], time=0.06890130043029785, ext_time=0.004078865051269531, train_time=0.043562889099121094
[Epoch 2][Step 105], time=0.06917214393615723, ext_time=0.004097938537597656, train_time=0.04372382164001465
[Epoch 2][Step 106], time=0.06893181800842285, ext_time=0.004093647003173828, train_time=0.043524980545043945
[Epoch 2][Step 107], time=0.0691981315612793, ext_time=0.004081249237060547, train_time=0.04383969306945801
[Epoch 2][Step 108], time=0.06900954246520996, ext_time=0.004082918167114258, train_time=0.04360175132751465
[Epoch 2][Step 109], time=0.06890034675598145, ext_time=0.004121303558349609, train_time=0.04330754280090332
[Epoch 2][Step 110], time=0.06911516189575195, ext_time=0.004083871841430664, train_time=0.04375886917114258
[Epoch 2][Step 111], time=0.0690467357635498, ext_time=0.004071950912475586, train_time=0.0437467098236084
[Epoch 2][Step 112], time=0.0688941478729248, ext_time=0.004114866256713867, train_time=0.04334378242492676
[Epoch 2][Step 113], time=0.06888198852539062, ext_time=0.0040950775146484375, train_time=0.043477535247802734
[Epoch 2][Step 114], time=0.06911087036132812, ext_time=0.004095315933227539, train_time=0.043692827224731445
[Epoch 2][Step 115], time=0.0688321590423584, ext_time=0.00409388542175293, train_time=0.04337501525878906
[Epoch 2][Step 116], time=0.07647395133972168, ext_time=0.004109621047973633, train_time=0.044220924377441406
[Epoch 2][Step 117], time=0.06892633438110352, ext_time=0.004127025604248047, train_time=0.043376922607421875
[Epoch 2][Step 118], time=0.06874465942382812, ext_time=0.004100799560546875, train_time=0.04326748847961426
[Epoch 2][Step 119], time=0.06914258003234863, ext_time=0.004106044769287109, train_time=0.043596506118774414
[Epoch 2][Step 120], time=0.06892275810241699, ext_time=0.004079103469848633, train_time=0.043543100357055664
[Epoch 2][Step 121], time=0.07094407081604004, ext_time=0.004086494445800781, train_time=0.04553866386413574
[Epoch 2][Step 122], time=0.06980252265930176, ext_time=0.004101276397705078, train_time=0.044284820556640625
[Epoch 2][Step 123], time=0.06889963150024414, ext_time=0.004099369049072266, train_time=0.04344487190246582
[Epoch 2][Step 124], time=0.06893086433410645, ext_time=0.004087209701538086, train_time=0.04351305961608887
[Epoch 2], time=8.876068115234375, loss=0.4204443097114563
[Epoch 3][Step 0], time=0.06905531883239746, ext_time=0.004131317138671875, train_time=0.04341721534729004
[Epoch 3][Step 1], time=0.06881237030029297, ext_time=0.004103183746337891, train_time=0.043298959732055664
[Epoch 3][Step 2], time=0.06885313987731934, ext_time=0.0041124820709228516, train_time=0.0432896614074707
[Epoch 3][Step 3], time=0.06895971298217773, ext_time=0.004088401794433594, train_time=0.04354214668273926
[Epoch 3][Step 4], time=0.06897473335266113, ext_time=0.004116535186767578, train_time=0.04338979721069336
[Epoch 3][Step 5], time=0.06872367858886719, ext_time=0.0040740966796875, train_time=0.04337120056152344
[Epoch 3][Step 6], time=0.06889462471008301, ext_time=0.004103660583496094, train_time=0.04336905479431152
[Epoch 3][Step 7], time=0.06892538070678711, ext_time=0.004098176956176758, train_time=0.043471574783325195
[Epoch 3][Step 8], time=0.06877684593200684, ext_time=0.0040738582611083984, train_time=0.04343461990356445
[Epoch 3][Step 9], time=0.07023453712463379, ext_time=0.004101753234863281, train_time=0.04474329948425293
[Epoch 3][Step 10], time=0.06904339790344238, ext_time=0.004107475280761719, train_time=0.04352116584777832
[Epoch 3][Step 11], time=0.06933474540710449, ext_time=0.004095792770385742, train_time=0.04381513595581055
[Epoch 3][Step 12], time=0.06899380683898926, ext_time=0.004099369049072266, train_time=0.04351162910461426
[Epoch 3][Step 13], time=0.06891345977783203, ext_time=0.0041027069091796875, train_time=0.04346752166748047
[Epoch 3][Step 14], time=0.06915855407714844, ext_time=0.004093170166015625, train_time=0.043703317642211914
[Epoch 3][Step 15], time=0.06879973411560059, ext_time=0.004100799560546875, train_time=0.0433197021484375
[Epoch 3][Step 16], time=0.06887984275817871, ext_time=0.004091024398803711, train_time=0.04345989227294922
[Epoch 3][Step 17], time=0.06920647621154785, ext_time=0.004110574722290039, train_time=0.043724775314331055
[Epoch 3][Step 18], time=0.06975769996643066, ext_time=0.004099130630493164, train_time=0.044351816177368164
[Epoch 3][Step 19], time=0.06904244422912598, ext_time=0.004091978073120117, train_time=0.0436098575592041
[Epoch 3][Step 20], time=0.06886529922485352, ext_time=0.004103899002075195, train_time=0.04343271255493164
[Epoch 3][Step 21], time=0.0692298412322998, ext_time=0.0040814876556396484, train_time=0.04379987716674805
[Epoch 3][Step 22], time=0.06905126571655273, ext_time=0.004068851470947266, train_time=0.043824195861816406
[Epoch 3][Step 23], time=0.06910061836242676, ext_time=0.004101276397705078, train_time=0.043601036071777344
[Epoch 3][Step 24], time=0.06877017021179199, ext_time=0.0041010379791259766, train_time=0.043282508850097656
[Epoch 3][Step 25], time=0.06937265396118164, ext_time=0.004120588302612305, train_time=0.04372906684875488
[Epoch 3][Step 26], time=0.06902003288269043, ext_time=0.004102945327758789, train_time=0.043350934982299805
[Epoch 3][Step 27], time=0.0689537525177002, ext_time=0.004085063934326172, train_time=0.043556928634643555
[Epoch 3][Step 28], time=0.06907868385314941, ext_time=0.004102230072021484, train_time=0.04367852210998535
[Epoch 3][Step 29], time=0.06902933120727539, ext_time=0.004088163375854492, train_time=0.04362630844116211
[Epoch 3][Step 30], time=0.06877517700195312, ext_time=0.004098653793334961, train_time=0.04337477684020996
[Epoch 3][Step 31], time=0.07061052322387695, ext_time=0.004106760025024414, train_time=0.04503989219665527
[Epoch 3][Step 32], time=0.06881141662597656, ext_time=0.004113674163818359, train_time=0.04336738586425781
[Epoch 3][Step 33], time=0.07590436935424805, ext_time=0.004086971282958984, train_time=0.04352545738220215
[Epoch 3][Step 34], time=0.06909036636352539, ext_time=0.0040972232818603516, train_time=0.04363250732421875
[Epoch 3][Step 35], time=0.06921553611755371, ext_time=0.00408625602722168, train_time=0.04371213912963867
[Epoch 3][Step 36], time=0.29000329971313477, ext_time=0.0041277408599853516, train_time=0.26438164710998535
[Epoch 3][Step 37], time=0.0686802864074707, ext_time=0.004137754440307617, train_time=0.0432744026184082
[Epoch 3][Step 38], time=0.06876039505004883, ext_time=0.0040934085845947266, train_time=0.043271541595458984
[Epoch 3][Step 39], time=0.0689849853515625, ext_time=0.004103422164916992, train_time=0.04347515106201172
[Epoch 3][Step 40], time=0.07029938697814941, ext_time=0.004115581512451172, train_time=0.04467654228210449
[Epoch 3][Step 41], time=0.06876444816589355, ext_time=0.004111051559448242, train_time=0.04325604438781738
[Epoch 3][Step 42], time=0.06876730918884277, ext_time=0.0040988922119140625, train_time=0.043354034423828125
[Epoch 3][Step 43], time=0.0690462589263916, ext_time=0.004068613052368164, train_time=0.04377245903015137
[Epoch 3][Step 44], time=0.06900978088378906, ext_time=0.004097700119018555, train_time=0.04355311393737793
[Epoch 3][Step 45], time=0.0689389705657959, ext_time=0.004098176956176758, train_time=0.043469905853271484
[Epoch 3][Step 46], time=0.29190921783447266, ext_time=0.004093647003173828, train_time=0.2665112018585205
[Epoch 3][Step 47], time=0.0699467658996582, ext_time=0.0041043758392333984, train_time=0.04452228546142578
[Epoch 3][Step 48], time=0.07088899612426758, ext_time=0.004081249237060547, train_time=0.045588016510009766
[Epoch 3][Step 49], time=0.06891036033630371, ext_time=0.004100322723388672, train_time=0.04343605041503906
[Epoch 3][Step 50], time=0.0689535140991211, ext_time=0.004095315933227539, train_time=0.04351520538330078
[Epoch 3][Step 51], time=0.06850504875183105, ext_time=0.004081249237060547, train_time=0.04314708709716797
[Epoch 3][Step 52], time=0.07001113891601562, ext_time=0.004096269607543945, train_time=0.044560909271240234
[Epoch 3][Step 53], time=0.06909465789794922, ext_time=0.0041120052337646484, train_time=0.043572425842285156
[Epoch 3][Step 54], time=0.07003164291381836, ext_time=0.0041027069091796875, train_time=0.04456329345703125
[Epoch 3][Step 55], time=0.06904959678649902, ext_time=0.004099845886230469, train_time=0.0435643196105957
[Epoch 3][Step 56], time=0.06879782676696777, ext_time=0.004092216491699219, train_time=0.043409109115600586
[Epoch 3][Step 57], time=0.06910514831542969, ext_time=0.004087924957275391, train_time=0.0437009334564209
[Epoch 3][Step 58], time=0.06882452964782715, ext_time=0.004108428955078125, train_time=0.04332542419433594
[Epoch 3][Step 59], time=0.06866669654846191, ext_time=0.0040912628173828125, train_time=0.043262481689453125
[Epoch 3][Step 60], time=0.06912827491760254, ext_time=0.00410008430480957, train_time=0.04369378089904785
[Epoch 3][Step 61], time=0.06916594505310059, ext_time=0.004112958908081055, train_time=0.04363560676574707
[Epoch 3][Step 62], time=0.06899762153625488, ext_time=0.004088878631591797, train_time=0.043566226959228516
[Epoch 3][Step 63], time=0.06894421577453613, ext_time=0.004110574722290039, train_time=0.04340314865112305
[Epoch 3][Step 64], time=0.06891202926635742, ext_time=0.0040781497955322266, train_time=0.04356670379638672
[Epoch 3][Step 65], time=0.06920385360717773, ext_time=0.004094362258911133, train_time=0.0437169075012207
[Epoch 3][Step 66], time=0.06899547576904297, ext_time=0.0040836334228515625, train_time=0.04361104965209961
[Epoch 3][Step 67], time=0.06909775733947754, ext_time=0.004109382629394531, train_time=0.043527841567993164
[Epoch 3][Step 68], time=0.0687413215637207, ext_time=0.0040853023529052734, train_time=0.04334282875061035
[Epoch 3][Step 69], time=0.06894350051879883, ext_time=0.004103422164916992, train_time=0.04345273971557617
[Epoch 3][Step 70], time=0.0690011978149414, ext_time=0.004071474075317383, train_time=0.043694257736206055
[Epoch 3][Step 71], time=0.07029151916503906, ext_time=0.004097461700439453, train_time=0.04483628273010254
[Epoch 3][Step 72], time=0.06909513473510742, ext_time=0.00410151481628418, train_time=0.043627262115478516
[Epoch 3][Step 73], time=0.06897497177124023, ext_time=0.004094362258911133, train_time=0.04354524612426758
[Epoch 3][Step 74], time=0.06863832473754883, ext_time=0.004096508026123047, train_time=0.0431523323059082
[Epoch 3][Step 75], time=0.07498645782470703, ext_time=0.0040874481201171875, train_time=0.043657541275024414
[Epoch 3][Step 76], time=0.06908035278320312, ext_time=0.004101276397705078, train_time=0.04368758201599121
[Epoch 3][Step 77], time=0.06914472579956055, ext_time=0.004118442535400391, train_time=0.04356527328491211
[Epoch 3][Step 78], time=0.06877493858337402, ext_time=0.0040819644927978516, train_time=0.04342317581176758
[Epoch 3][Step 79], time=0.0689687728881836, ext_time=0.0040929317474365234, train_time=0.04352545738220215
[Epoch 3][Step 80], time=0.06900811195373535, ext_time=0.004107236862182617, train_time=0.04347944259643555
[Epoch 3][Step 81], time=0.06885814666748047, ext_time=0.0041086673736572266, train_time=0.0432891845703125
[Epoch 3][Step 82], time=0.06902933120727539, ext_time=0.00412750244140625, train_time=0.04339146614074707
[Epoch 3][Step 83], time=0.0689842700958252, ext_time=0.004116058349609375, train_time=0.04339957237243652
[Epoch 3][Step 84], time=0.06868767738342285, ext_time=0.004091024398803711, train_time=0.043274879455566406
[Epoch 3][Step 85], time=0.0699930191040039, ext_time=0.0040874481201171875, train_time=0.044672489166259766
[Epoch 3][Step 86], time=0.07129287719726562, ext_time=0.004119157791137695, train_time=0.04565548896789551
[Epoch 3][Step 87], time=0.06902003288269043, ext_time=0.0041162967681884766, train_time=0.04343819618225098
[Epoch 3][Step 88], time=0.06891059875488281, ext_time=0.004096031188964844, train_time=0.0434565544128418
[Epoch 3][Step 89], time=0.068756103515625, ext_time=0.004113674163818359, train_time=0.04325675964355469
[Epoch 3][Step 90], time=0.2748892307281494, ext_time=0.00407719612121582, train_time=0.24953722953796387
[Epoch 3][Step 91], time=0.06877565383911133, ext_time=0.004104137420654297, train_time=0.04329705238342285
[Epoch 3][Step 92], time=0.06913471221923828, ext_time=0.004108428955078125, train_time=0.04365181922912598
[Epoch 3][Step 93], time=0.06952357292175293, ext_time=0.00413203239440918, train_time=0.0435945987701416
[Epoch 3][Step 94], time=0.06913518905639648, ext_time=0.004113197326660156, train_time=0.04362010955810547
[Epoch 3][Step 95], time=0.06873440742492676, ext_time=0.004081249237060547, train_time=0.043386220932006836
[Epoch 3][Step 96], time=0.07313919067382812, ext_time=0.004123210906982422, train_time=0.04757118225097656
[Epoch 3][Step 97], time=0.06906580924987793, ext_time=0.004099845886230469, train_time=0.04358506202697754
[Epoch 3][Step 98], time=0.06912016868591309, ext_time=0.0040972232818603516, train_time=0.04368400573730469
[Epoch 3][Step 99], time=0.06920886039733887, ext_time=0.00411534309387207, train_time=0.0436701774597168
[Epoch 3][Step 100], time=0.06888723373413086, ext_time=0.0041179656982421875, train_time=0.0433192253112793
[Epoch 3][Step 101], time=0.0688326358795166, ext_time=0.004090070724487305, train_time=0.04341769218444824
[Epoch 3][Step 102], time=0.06882119178771973, ext_time=0.004088401794433594, train_time=0.04344964027404785
[Epoch 3][Step 103], time=0.06890654563903809, ext_time=0.004102468490600586, train_time=0.0434262752532959
[Epoch 3][Step 104], time=0.0695652961730957, ext_time=0.00408625602722168, train_time=0.044127702713012695
[Epoch 3][Step 105], time=0.06898307800292969, ext_time=0.004103899002075195, train_time=0.043504953384399414
[Epoch 3][Step 106], time=0.0691063404083252, ext_time=0.004095315933227539, train_time=0.04373025894165039
[Epoch 3][Step 107], time=0.06928253173828125, ext_time=0.004082441329956055, train_time=0.04390740394592285
[Epoch 3][Step 108], time=0.06861400604248047, ext_time=0.004087209701538086, train_time=0.04337120056152344
[Epoch 3][Step 109], time=0.06890749931335449, ext_time=0.004104137420654297, train_time=0.043427228927612305
[Epoch 3][Step 110], time=0.06894540786743164, ext_time=0.004083395004272461, train_time=0.04356241226196289
[Epoch 3][Step 111], time=0.06908321380615234, ext_time=0.004086017608642578, train_time=0.0436859130859375
[Epoch 3][Step 112], time=0.06941747665405273, ext_time=0.0041234493255615234, train_time=0.04378342628479004
[Epoch 3][Step 113], time=0.06898975372314453, ext_time=0.004068136215209961, train_time=0.043692588806152344
[Epoch 3][Step 114], time=0.07039618492126465, ext_time=0.004090070724487305, train_time=0.044951438903808594
[Epoch 3][Step 115], time=0.06883525848388672, ext_time=0.00410771369934082, train_time=0.043354034423828125
[Epoch 3][Step 116], time=0.06897616386413574, ext_time=0.004126787185668945, train_time=0.04337310791015625
[Epoch 3][Step 117], time=0.07566308975219727, ext_time=0.004120349884033203, train_time=0.043372154235839844
[Epoch 3][Step 118], time=0.06882548332214355, ext_time=0.004110813140869141, train_time=0.043320655822753906
[Epoch 3][Step 119], time=0.06909775733947754, ext_time=0.0041005611419677734, train_time=0.04361224174499512
[Epoch 3][Step 120], time=0.0702674388885498, ext_time=0.004071474075317383, train_time=0.0449986457824707
[Epoch 3][Step 121], time=0.069061279296875, ext_time=0.004074811935424805, train_time=0.043723344802856445
[Epoch 3][Step 122], time=0.06881117820739746, ext_time=0.004091978073120117, train_time=0.04337596893310547
[Epoch 3][Step 123], time=0.06925296783447266, ext_time=0.004099845886230469, train_time=0.043854475021362305
[Epoch 3][Step 124], time=0.06894230842590332, ext_time=0.004096508026123047, train_time=0.0434565544128418
[Epoch 3], time=9.32011866569519, loss=0.42143741250038147
    [Step(average) Profiler Level 1 E3 S999]
        L1  sample           0.021446 | send           0.000000
        L1  recv             0.000000 | copy           0.004090 | convert time 0.000000 | train  0.048169
        L1  feature nbytes    3.18 GB | label nbytes 0.00 Bytes
        L1  id nbytes      0.00 Bytes | graph nbytes 0.00 Bytes
        L1  miss nbytes    0.00 Bytes | remote nbytes 0.00 Bytes
        L1  num nodes               0 | num samples           0
        L1  seq duration     0.000000 | refresh duration   0.000000
    [Step(average) Profiler Level 2 E3 S999]
        L2  shuffle     0.000000 | core sample  0.000000 | id remap        0.000000
        L2  graph copy  0.000000 | id copy      0.000000 | cache feat copy 0.004090
        L2  last layer sample time 0.000000 | size 0.000000
    [Step(average) Profiler Level 3 E3 S999]
        L3  khop sample coo  0.000000 | khop sort coo      0.000000 | khop count edge     0.000000 | khop compact edge 0.000000
        L3  walk sample coo  0.000000 | walk topk total    0.000000 | walk topk step1     0.000000 | walk topk step2   0.000000
        L3  walk topk step3  0.000000 | walk topk step4    0.000000 | walk topk step5     0.000000
        L3  walk topk step6  0.000000 | walk topk step7    0.000000
        L3  remap unique     0.000000 | remap populate     0.000000 | remap mapnode       0.000000 | remap mapedge     0.000000
        L3  cache get_index  0.000000 | cache copy_index   0.000000 | cache extract_miss  0.000000
        L3  cache copy_miss  0.000000 | cache combine_miss 0.000000 | cache combine cache 0.004063 | cache combine remote 0.000000
        L3  label extract  0.000000
    [Profiler Level Percentiles E3 S999]
        p50.00_tail_logl2featcopy=0.004090
        p90.00_tail_logl2featcopy=0.004116
        p95.00_tail_logl2featcopy=0.004124
        p99.00_tail_logl2featcopy=0.004157
        p99.90_tail_logl2featcopy=0.027834
[CUDA] cuda: usage: 72.60 GB
worker 2 running with pid=15562
loading train edge idx from disk
loading train edge idx from disk done
tensor([ 367470406, 3158702471, 3196913887,  534369026, 2622541626, 2707306334,
        2288750783,  341639546, 2394912536,   34847343,  697837268, 1665128055,
        3225579545,  808096539,  530910714,  726851972, 1000854521, 1061370191,
         594157634,  526478766,  496425173, 1382980281, 1363464091,  971316959,
        1643305663, 1559556869,  792051811, 2593715952, 2627476216,  865811872,
        1279512108,  281028249, 2848334841, 1142277951, 1624797255, 1682408139,
         511476070,  753655501, 1190696744, 1515340461,  396873136, 3079813016,
         574876927,   31156367,  830710319, 1664434120,  774080817, 2850247945,
         655998496,  888602410,  350570870,  847108703,   69778231,  638128676,
        1443388341, 1479712286, 2858804367,  550628163,  198023098, 2583590303,
        2518492873,    2593795, 2722269746,  659106604, 1369497066,  458403464,
         645516367, 3053389785,  144872323,  792250187, 1401047469, 1545651011,
        1827797263, 1275030316, 2075895474, 2919804301, 2493902937,  112768749,
          11701078,  723465431,  404737965,  786261376,  934911988,  757583227,
        1135493038, 3162165660, 1144120843, 2861906075,  223193336, 1866677628,
         326241255,   64202517, 1840253021,  970607610,  419197513, 3025516425,
         133597469,  978276161, 2348166713,  303649761])
Rank=2, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.005639, per step: 0.000045
presamping
presamping takes 33.46180558204651
worker 3 running with pid=15564
loading train edge idx from disk
loading train edge idx from disk done
tensor([ 367470406, 3158702471, 3196913887,  534369026, 2622541626, 2707306334,
        2288750783,  341639546, 2394912536,   34847343,  697837268, 1665128055,
        3225579545,  808096539,  530910714,  726851972, 1000854521, 1061370191,
         594157634,  526478766,  496425173, 1382980281, 1363464091,  971316959,
        1643305663, 1559556869,  792051811, 2593715952, 2627476216,  865811872,
        1279512108,  281028249, 2848334841, 1142277951, 1624797255, 1682408139,
         511476070,  753655501, 1190696744, 1515340461,  396873136, 3079813016,
         574876927,   31156367,  830710319, 1664434120,  774080817, 2850247945,
         655998496,  888602410,  350570870,  847108703,   69778231,  638128676,
        1443388341, 1479712286, 2858804367,  550628163,  198023098, 2583590303,
        2518492873,    2593795, 2722269746,  659106604, 1369497066,  458403464,
         645516367, 3053389785,  144872323,  792250187, 1401047469, 1545651011,
        1827797263, 1275030316, 2075895474, 2919804301, 2493902937,  112768749,
          11701078,  723465431,  404737965,  786261376,  934911988,  757583227,
        1135493038, 3162165660, 1144120843, 2861906075,  223193336, 1866677628,
         326241255,   64202517, 1840253021,  970607610,  419197513, 3025516425,
         133597469,  978276161, 2348166713,  303649761])
Rank=3, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.005745, per step: 0.000046
presamping
presamping takes 33.83971095085144
worker 1 running with pid=15561
loading train edge idx from disk
loading train edge idx from disk done
tensor([ 367470406, 3158702471, 3196913887,  534369026, 2622541626, 2707306334,
        2288750783,  341639546, 2394912536,   34847343,  697837268, 1665128055,
        3225579545,  808096539,  530910714,  726851972, 1000854521, 1061370191,
         594157634,  526478766,  496425173, 1382980281, 1363464091,  971316959,
        1643305663, 1559556869,  792051811, 2593715952, 2627476216,  865811872,
        1279512108,  281028249, 2848334841, 1142277951, 1624797255, 1682408139,
         511476070,  753655501, 1190696744, 1515340461,  396873136, 3079813016,
         574876927,   31156367,  830710319, 1664434120,  774080817, 2850247945,
         655998496,  888602410,  350570870,  847108703,   69778231,  638128676,
        1443388341, 1479712286, 2858804367,  550628163,  198023098, 2583590303,
        2518492873,    2593795, 2722269746,  659106604, 1369497066,  458403464,
         645516367, 3053389785,  144872323,  792250187, 1401047469, 1545651011,
        1827797263, 1275030316, 2075895474, 2919804301, 2493902937,  112768749,
          11701078,  723465431,  404737965,  786261376,  934911988,  757583227,
        1135493038, 3162165660, 1144120843, 2861906075,  223193336, 1866677628,
         326241255,   64202517, 1840253021,  970607610,  419197513, 3025516425,
         133597469,  978276161, 2348166713,  303649761])
Rank=1, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.005450, per step: 0.000044
presamping
presamping takes 33.650922536849976
worker 4 running with pid=15566
loading train edge idx from disk
loading train edge idx from disk done
tensor([ 367470406, 3158702471, 3196913887,  534369026, 2622541626, 2707306334,
        2288750783,  341639546, 2394912536,   34847343,  697837268, 1665128055,
        3225579545,  808096539,  530910714,  726851972, 1000854521, 1061370191,
         594157634,  526478766,  496425173, 1382980281, 1363464091,  971316959,
        1643305663, 1559556869,  792051811, 2593715952, 2627476216,  865811872,
        1279512108,  281028249, 2848334841, 1142277951, 1624797255, 1682408139,
         511476070,  753655501, 1190696744, 1515340461,  396873136, 3079813016,
         574876927,   31156367,  830710319, 1664434120,  774080817, 2850247945,
         655998496,  888602410,  350570870,  847108703,   69778231,  638128676,
        1443388341, 1479712286, 2858804367,  550628163,  198023098, 2583590303,
        2518492873,    2593795, 2722269746,  659106604, 1369497066,  458403464,
         645516367, 3053389785,  144872323,  792250187, 1401047469, 1545651011,
        1827797263, 1275030316, 2075895474, 2919804301, 2493902937,  112768749,
          11701078,  723465431,  404737965,  786261376,  934911988,  757583227,
        1135493038, 3162165660, 1144120843, 2861906075,  223193336, 1866677628,
         326241255,   64202517, 1840253021,  970607610,  419197513, 3025516425,
         133597469,  978276161, 2348166713,  303649761])
Rank=4, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.006379, per step: 0.000051
presamping
presamping takes 34.19812059402466
worker 7 running with pid=15572
loading train edge idx from disk
loading train edge idx from disk done
tensor([ 367470406, 3158702471, 3196913887,  534369026, 2622541626, 2707306334,
        2288750783,  341639546, 2394912536,   34847343,  697837268, 1665128055,
        3225579545,  808096539,  530910714,  726851972, 1000854521, 1061370191,
         594157634,  526478766,  496425173, 1382980281, 1363464091,  971316959,
        1643305663, 1559556869,  792051811, 2593715952, 2627476216,  865811872,
        1279512108,  281028249, 2848334841, 1142277951, 1624797255, 1682408139,
         511476070,  753655501, 1190696744, 1515340461,  396873136, 3079813016,
         574876927,   31156367,  830710319, 1664434120,  774080817, 2850247945,
         655998496,  888602410,  350570870,  847108703,   69778231,  638128676,
        1443388341, 1479712286, 2858804367,  550628163,  198023098, 2583590303,
        2518492873,    2593795, 2722269746,  659106604, 1369497066,  458403464,
         645516367, 3053389785,  144872323,  792250187, 1401047469, 1545651011,
        1827797263, 1275030316, 2075895474, 2919804301, 2493902937,  112768749,
          11701078,  723465431,  404737965,  786261376,  934911988,  757583227,
        1135493038, 3162165660, 1144120843, 2861906075,  223193336, 1866677628,
         326241255,   64202517, 1840253021,  970607610,  419197513, 3025516425,
         133597469,  978276161, 2348166713,  303649761])
Rank=7, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.005559, per step: 0.000044
presamping
presamping takes 32.506614208221436
worker 6 running with pid=15570
loading train edge idx from disk
loading train edge idx from disk done
tensor([ 367470406, 3158702471, 3196913887,  534369026, 2622541626, 2707306334,
        2288750783,  341639546, 2394912536,   34847343,  697837268, 1665128055,
        3225579545,  808096539,  530910714,  726851972, 1000854521, 1061370191,
         594157634,  526478766,  496425173, 1382980281, 1363464091,  971316959,
        1643305663, 1559556869,  792051811, 2593715952, 2627476216,  865811872,
        1279512108,  281028249, 2848334841, 1142277951, 1624797255, 1682408139,
         511476070,  753655501, 1190696744, 1515340461,  396873136, 3079813016,
         574876927,   31156367,  830710319, 1664434120,  774080817, 2850247945,
         655998496,  888602410,  350570870,  847108703,   69778231,  638128676,
        1443388341, 1479712286, 2858804367,  550628163,  198023098, 2583590303,
        2518492873,    2593795, 2722269746,  659106604, 1369497066,  458403464,
         645516367, 3053389785,  144872323,  792250187, 1401047469, 1545651011,
        1827797263, 1275030316, 2075895474, 2919804301, 2493902937,  112768749,
          11701078,  723465431,  404737965,  786261376,  934911988,  757583227,
        1135493038, 3162165660, 1144120843, 2861906075,  223193336, 1866677628,
         326241255,   64202517, 1840253021,  970607610,  419197513, 3025516425,
         133597469,  978276161, 2348166713,  303649761])
Rank=6, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.005734, per step: 0.000046
presamping
presamping takes 31.980743885040283
worker 5 running with pid=15568
loading train edge idx from disk
loading train edge idx from disk done
tensor([ 367470406, 3158702471, 3196913887,  534369026, 2622541626, 2707306334,
        2288750783,  341639546, 2394912536,   34847343,  697837268, 1665128055,
        3225579545,  808096539,  530910714,  726851972, 1000854521, 1061370191,
         594157634,  526478766,  496425173, 1382980281, 1363464091,  971316959,
        1643305663, 1559556869,  792051811, 2593715952, 2627476216,  865811872,
        1279512108,  281028249, 2848334841, 1142277951, 1624797255, 1682408139,
         511476070,  753655501, 1190696744, 1515340461,  396873136, 3079813016,
         574876927,   31156367,  830710319, 1664434120,  774080817, 2850247945,
         655998496,  888602410,  350570870,  847108703,   69778231,  638128676,
        1443388341, 1479712286, 2858804367,  550628163,  198023098, 2583590303,
        2518492873,    2593795, 2722269746,  659106604, 1369497066,  458403464,
         645516367, 3053389785,  144872323,  792250187, 1401047469, 1545651011,
        1827797263, 1275030316, 2075895474, 2919804301, 2493902937,  112768749,
          11701078,  723465431,  404737965,  786261376,  934911988,  757583227,
        1135493038, 3162165660, 1144120843, 2861906075,  223193336, 1866677628,
         326241255,   64202517, 1840253021,  970607610,  419197513, 3025516425,
         133597469,  978276161, 2348166713,  303649761])
Rank=5, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.005725, per step: 0.000046
presamping
presamping takes 33.97112703323364
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 4         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  372823 KB |    7290 MB |   11986 GB |   11985 GB |
|       from large pool |  362682 KB |    7281 MB |   11971 GB |   11971 GB |
|       from small pool |   10141 KB |      15 MB |      14 GB |      14 GB |
|---------------------------------------------------------------------------|
| Active memory         |  372823 KB |    7290 MB |   11986 GB |   11985 GB |
|       from large pool |  362682 KB |    7281 MB |   11971 GB |   11971 GB |
|       from small pool |   10141 KB |      15 MB |      14 GB |      14 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    9802 MB |   15274 MB |   51906 MB |   42104 MB |
|       from large pool |    9782 MB |   15254 MB |   51876 MB |   42094 MB |
|       from small pool |      20 MB |      20 MB |      30 MB |      10 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1405 MB |   10462 MB |    7322 GB |    7321 GB |
|       from large pool |    1397 MB |   10453 MB |    7307 GB |    7306 GB |
|       from small pool |       8 MB |      10 MB |      15 GB |      15 GB |
|---------------------------------------------------------------------------|
| Allocations           |      71    |      98    |  158162    |  158091    |
|       from large pool |      22    |      43    |   73000    |   72978    |
|       from small pool |      49    |      60    |   85162    |   85113    |
|---------------------------------------------------------------------------|
| Active allocs         |      71    |      98    |  158162    |  158091    |
|       from large pool |      22    |      43    |   73000    |   72978    |
|       from small pool |      49    |      60    |   85162    |   85113    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      24    |      36    |      62    |      38    |
|       from large pool |      14    |      26    |      47    |      33    |
|       from small pool |      10    |      10    |      15    |       5    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      42    |      52    |   56570    |   56528    |
|       from large pool |      18    |      30    |   35902    |   35884    |
|       from small pool |      24    |      30    |   20668    |   20644    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[TRAIN_TIME] train time is 40.408018 seconds
[EPOCH_TIME] 10.102005 seconds, maybe large due to not enough epoch skipped.
[EPOCH_TIME] 9.098256 seconds

