succeed=True
[CUDA] cuda: usage: 6.58 GB
0 :  {link #0 : 1}, {link #1 : 2}, {link #2 : 3}, {link #3 : 4}, {link #4 : 5}, {link #5 : 6}, {link #6 : 7},
1 :  {link #0 : 2}, {link #1 : 3}, {link #2 : 4}, {link #3 : 5}, {link #4 : 6}, {link #5 : 7}, {link #6 : 0},
2 :  {link #0 : 3}, {link #1 : 4}, {link #2 : 5}, {link #3 : 6}, {link #4 : 7}, {link #5 : 0}, {link #6 : 1},
3 :  {link #0 : 4}, {link #1 : 5}, {link #2 : 6}, {link #3 : 7}, {link #4 : 0}, {link #5 : 1}, {link #6 : 2},
4 :  {link #0 : 5}, {link #1 : 6}, {link #2 : 7}, {link #3 : 0}, {link #4 : 1}, {link #5 : 2}, {link #6 : 3},
5 :  {link #0 : 6}, {link #1 : 7}, {link #2 : 0}, {link #3 : 1}, {link #4 : 2}, {link #5 : 3}, {link #6 : 4},
6 :  {link #0 : 7}, {link #1 : 0}, {link #2 : 1}, {link #3 : 2}, {link #4 : 3}, {link #5 : 4}, {link #6 : 5},
7 :  {link #0 : 0}, {link #1 : 1}, {link #2 : 2}, {link #3 : 3}, {link #4 : 4}, {link #5 : 5}, {link #6 : 6},
0 : local 98, cpu 10 {link #0 : g1 8}, {link #1 : g2 8}, {link #2 : g3 8}, {link #3 : g4 8}, {link #4 : g5 8}, {link #5 : g6 8}, {link #6 : g7 8},
1 : local 98, cpu 10 {link #0 : g2 8}, {link #1 : g3 8}, {link #2 : g4 8}, {link #3 : g5 8}, {link #4 : g6 8}, {link #5 : g7 8}, {link #6 : g0 8},
2 : local 98, cpu 10 {link #0 : g3 8}, {link #1 : g4 8}, {link #2 : g5 8}, {link #3 : g6 8}, {link #4 : g7 8}, {link #5 : g0 8}, {link #6 : g1 8},
3 : local 98, cpu 10 {link #0 : g4 8}, {link #1 : g5 8}, {link #2 : g6 8}, {link #3 : g7 8}, {link #4 : g0 8}, {link #5 : g1 8}, {link #6 : g2 8},
4 : local 98, cpu 10 {link #0 : g5 8}, {link #1 : g6 8}, {link #2 : g7 8}, {link #3 : g0 8}, {link #4 : g1 8}, {link #5 : g2 8}, {link #6 : g3 8},
5 : local 98, cpu 10 {link #0 : g6 8}, {link #1 : g7 8}, {link #2 : g0 8}, {link #3 : g1 8}, {link #4 : g2 8}, {link #5 : g3 8}, {link #6 : g4 8},
6 : local 98, cpu 10 {link #0 : g7 8}, {link #1 : g0 8}, {link #2 : g1 8}, {link #3 : g2 8}, {link #4 : g3 8}, {link #5 : g4 8}, {link #6 : g5 8},
7 : local 98, cpu 10 {link #0 : g0 8}, {link #1 : g1 8}, {link #2 : g2 8}, {link #3 : g3 8}, {link #4 : g4 8}, {link #5 : g5 8}, {link #6 : g6 8},
0 :  {link #0 : 1}, {link #1 : 2}, {link #2 : 3}, {link #3 : 4}, {link #4 : 5}, {link #5 : 6}, {link #6 : 7},
1 :  {link #0 : 2}, {link #1 : 3}, {link #2 : 4}, {link #3 : 5}, {link #4 : 6}, {link #5 : 7}, {link #6 : 0},
2 :  {link #0 : 3}, {link #1 : 4}, {link #2 : 5}, {link #3 : 6}, {link #4 : 7}, {link #5 : 0}, {link #6 : 1},
3 :  {link #0 : 4}, {link #1 : 5}, {link #2 : 6}, {link #3 : 7}, {link #4 : 0}, {link #5 : 1}, {link #6 : 2},
4 :  {link #0 : 5}, {link #1 : 6}, {link #2 : 7}, {link #3 : 0}, {link #4 : 1}, {link #5 : 2}, {link #6 : 3},
5 :  {link #0 : 6}, {link #1 : 7}, {link #2 : 0}, {link #3 : 1}, {link #4 : 2}, {link #5 : 3}, {link #6 : 4},
6 :  {link #0 : 7}, {link #1 : 0}, {link #2 : 1}, {link #3 : 2}, {link #4 : 3}, {link #5 : 4}, {link #6 : 5},
7 :  {link #0 : 0}, {link #1 : 1}, {link #2 : 2}, {link #3 : 3}, {link #4 : 4}, {link #5 : 5}, {link #6 : 6},
0 : local 98, cpu 10 {link #0 : g1 8}, {link #1 : g2 8}, {link #2 : g3 8}, {link #3 : g4 8}, {link #4 : g5 8}, {link #5 : g6 8}, {link #6 : g7 8},
1 : local 98, cpu 10 {link #0 : g2 8}, {link #1 : g3 8}, {link #2 : g4 8}, {link #3 : g5 8}, {link #4 : g6 8}, {link #5 : g7 8}, {link #6 : g0 8},
2 : local 98, cpu 10 {link #0 : g3 8}, {link #1 : g4 8}, {link #2 : g5 8}, {link #3 : g6 8}, {link #4 : g7 8}, {link #5 : g0 8}, {link #6 : g1 8},
3 : local 98, cpu 10 {link #0 : g4 8}, {link #1 : g5 8}, {link #2 : g6 8}, {link #3 : g7 8}, {link #4 : g0 8}, {link #5 : g1 8}, {link #6 : g2 8},
4 : local 98, cpu 10 {link #0 : g5 8}, {link #1 : g6 8}, {link #2 : g7 8}, {link #3 : g0 8}, {link #4 : g1 8}, {link #5 : g2 8}, {link #6 : g3 8},
5 : local 98, cpu 10 {link #0 : g6 8}, {link #1 : g7 8}, {link #2 : g0 8}, {link #3 : g1 8}, {link #4 : g2 8}, {link #5 : g3 8}, {link #6 : g4 8},
6 : local 98, cpu 10 {link #0 : g7 8}, {link #1 : g0 8}, {link #2 : g1 8}, {link #3 : g2 8}, {link #4 : g3 8}, {link #5 : g4 8}, {link #6 : g5 8},
7 : local 98, cpu 10 {link #0 : g0 8}, {link #1 : g1 8}, {link #2 : g2 8}, {link #3 : g3 8}, {link #4 : g4 8}, {link #5 : g5 8}, {link #6 : g6 8},
0 :  {link #0 : 1}, {link #1 : 2}, {link #2 : 3}, {link #3 : 4}, {link #4 : 5}, {link #5 : 6}, {link #6 : 7},
1 :  {link #0 : 2}, {link #1 : 3}, {link #2 : 4}, {link #3 : 5}, {link #4 : 6}, {link #5 : 7}, {link #6 : 0},
2 :  {link #0 : 3}, {link #1 : 4}, {link #2 : 5}, {link #3 : 6}, {link #4 : 7}, {link #5 : 0}, {link #6 : 1},
3 :  {link #0 : 4}, {link #1 : 5}, {link #2 : 6}, {link #3 : 7}, {link #4 : 0}, {link #5 : 1}, {link #6 : 2},
4 :  {link #0 : 5}, {link #1 : 6}, {link #2 : 7}, {link #3 : 0}, {link #4 : 1}, {link #5 : 2}, {link #6 : 3},
5 :  {link #0 : 6}, {link #1 : 7}, {link #2 : 0}, {link #3 : 1}, {link #4 : 2}, {link #5 : 3}, {link #6 : 4},
6 :  {link #0 : 7}, {link #1 : 0}, {link #2 : 1}, {link #3 : 2}, {link #4 : 3}, {link #5 : 4}, {link #6 : 5},
7 :  {link #0 : 0}, {link #1 : 1}, {link #2 : 2}, {link #3 : 3}, {link #4 : 4}, {link #5 : 5}, {link #6 : 6},
0 : local 98, cpu 10 {link #0 : g1 8}, {link #1 : g2 8}, {link #2 : g3 8}, {link #3 : g4 8}, {link #4 : g5 8}, {link #5 : g6 8}, {link #6 : g7 8},
1 : local 98, cpu 10 {link #0 : g2 8}, {link #1 : g3 8}, {link #2 : g4 8}, {link #3 : g5 8}, {link #4 : g6 8}, {link #5 : g7 8}, {link #6 : g0 8},
2 : local 98, cpu 10 {link #0 : g3 8}, {link #1 : g4 8}, {link #2 : g5 8}, {link #3 : g6 8}, {link #4 : g7 8}, {link #5 : g0 8}, {link #6 : g1 8},
3 : local 98, cpu 10 {link #0 : g4 8}, {link #1 : g5 8}, {link #2 : g6 8}, {link #3 : g7 8}, {link #4 : g0 8}, {link #5 : g1 8}, {link #6 : g2 8},
4 : local 98, cpu 10 {link #0 : g5 8}, {link #1 : g6 8}, {link #2 : g7 8}, {link #3 : g0 8}, {link #4 : g1 8}, {link #5 : g2 8}, {link #6 : g3 8},
5 : local 98, cpu 10 {link #0 : g6 8}, {link #1 : g7 8}, {link #2 : g0 8}, {link #3 : g1 8}, {link #4 : g2 8}, {link #5 : g3 8}, {link #6 : g4 8},
6 : local 98, cpu 10 {link #0 : g7 8}, {link #1 : g0 8}, {link #2 : g1 8}, {link #3 : g2 8}, {link #4 : g3 8}, {link #5 : g4 8}, {link #6 : g5 8},
7 : local 98, cpu 10 {link #0 : g0 8}, {link #1 : g1 8}, {link #2 : g2 8}, {link #3 : g3 8}, {link #4 : g4 8}, {link #5 : g5 8}, {link #6 : g6 8},
0 :  {link #0 : 1}, {link #1 : 2}, {link #2 : 3}, {link #3 : 4}, {link #4 : 5}, {link #5 : 6}, {link #6 : 7},
1 :  {link #0 : 2}, {link #1 : 3}, {link #2 : 4}, {link #3 : 5}, {link #4 : 6}, {link #5 : 7}, {link #6 : 0},
2 :  {link #0 : 3}, {link #1 : 4}, {link #2 : 5}, {link #3 : 6}, {link #4 : 7}, {link #5 : 0}, {link #6 : 1},
3 :  {link #0 : 4}, {link #1 : 5}, {link #2 : 6}, {link #3 : 7}, {link #4 : 0}, {link #5 : 1}, {link #6 : 2},
4 :  {link #0 : 5}, {link #1 : 6}, {link #2 : 7}, {link #3 : 0}, {link #4 : 1}, {link #5 : 2}, {link #6 : 3},
5 :  {link #0 : 6}, {link #1 : 7}, {link #2 : 0}, {link #3 : 1}, {link #4 : 2}, {link #5 : 3}, {link #6 : 4},
6 :  {link #0 : 7}, {link #1 : 0}, {link #2 : 1}, {link #3 : 2}, {link #4 : 3}, {link #5 : 4}, {link #6 : 5},
7 :  {link #0 : 0}, {link #1 : 1}, {link #2 : 2}, {link #3 : 3}, {link #4 : 4}, {link #5 : 5}, {link #6 : 6},
0 :  {link #0 : 1}, {link #1 : 2}, {link #2 : 3}, {link #3 : 4}, {link #4 : 5}, {link #5 : 6}, {link #6 : 7},
1 :  {link #0 : 2}, {link #1 : 3}, {link #2 : 4}, {link #3 : 5}, {link #4 : 6}, {link #5 : 7}, {link #6 : 0},
2 :  {link #0 : 3}, {link #1 : 4}, {link #2 : 5}, {link #3 : 6}, {link #4 : 7}, {link #5 : 0}, {link #6 : 1},
3 :  {link #0 : 4}, {link #1 : 5}, {link #2 : 6}, {link #3 : 7}, {link #4 : 0}, {link #5 : 1}, {link #6 : 2},
4 :  {link #0 : 5}, {link #1 : 6}, {link #2 : 7}, {link #3 : 0}, {link #4 : 1}, {link #5 : 2}, {link #6 : 3},
5 :  {link #0 : 6}, {link #1 : 7}, {link #2 : 0}, {link #3 : 1}, {link #4 : 2}, {link #5 : 3}, {link #6 : 4},
6 :  {link #0 : 7}, {link #1 : 0}, {link #2 : 1}, {link #3 : 2}, {link #4 : 3}, {link #5 : 4}, {link #6 : 5},
7 :  {link #0 : 0}, {link #1 : 1}, {link #2 : 2}, {link #3 : 3}, {link #4 : 4}, {link #5 : 5}, {link #6 : 6},
0 :  {link #0 : 1}, {link #1 : 2}, {link #2 : 3}, {link #3 : 4}, {link #4 : 5}, {link #5 : 6}, {link #6 : 7},
1 :  {link #0 : 2}, {link #1 : 3}, {link #2 : 4}, {link #3 : 5}, {link #4 : 6}, {link #5 : 7}, {link #6 : 0},
2 :  {link #0 : 3}, {link #1 : 4}, {link #2 : 5}, {link #3 : 6}, {link #4 : 7}, {link #5 : 0}, {link #6 : 1},
3 :  {link #0 : 4}, {link #1 : 5}, {link #2 : 6}, {link #3 : 7}, {link #4 : 0}, {link #5 : 1}, {link #6 : 2},
4 :  {link #0 : 5}, {link #1 : 6}, {link #2 : 7}, {link #3 : 0}, {link #4 : 1}, {link #5 : 2}, {link #6 : 3},
5 :  {link #0 : 6}, {link #1 : 7}, {link #2 : 0}, {link #3 : 1}, {link #4 : 2}, {link #5 : 3}, {link #6 : 4},
6 :  {link #0 : 7}, {link #1 : 0}, {link #2 : 1}, {link #3 : 2}, {link #4 : 3}, {link #5 : 4}, {link #6 : 5},
7 :  {link #0 : 0}, {link #1 : 1}, {link #2 : 2}, {link #3 : 3}, {link #4 : 4}, {link #5 : 5}, {link #6 : 6},
0 : local 98, cpu 10 {link #0 : g1 8}, {link #1 : g2 8}, {link #2 : g3 8}, {link #3 : g4 8}, {link #4 : g5 8}, {link #5 : g6 8}, {link #6 : g7 8},
1 : local 98, cpu 10 {link #0 : g2 8}, {link #1 : g3 8}, {link #2 : g4 8}, {link #3 : g5 8}, {link #4 : g6 8}, {link #5 : g7 8}, {link #6 : g0 8},
2 : local 98, cpu 10 {link #0 : g3 8}, {link #1 : g4 8}, {link #2 : g5 8}, {link #3 : g6 8}, {link #4 : g7 8}, {link #5 : g0 8}, {link #6 : g1 8},
3 : local 98, cpu 10 {link #0 : g4 8}, {link #1 : g5 8}, {link #2 : g6 8}, {link #3 : g7 8}, {link #4 : g0 8}, {link #5 : g1 8}, {link #6 : g2 8},
4 : local 98, cpu 10 {link #0 : g5 8}, {link #1 : g6 8}, {link #2 : g7 8}, {link #3 : g0 8}, {link #4 : g1 8}, {link #5 : g2 8}, {link #6 : g3 8},
5 : local 98, cpu 10 {link #0 : g6 8}, {link #1 : g7 8}, {link #2 : g0 8}, {link #3 : g1 8}, {link #4 : g2 8}, {link #5 : g3 8}, {link #6 : g4 8},
6 : local 98, cpu 10 {link #0 : g7 8}, {link #1 : g0 8}, {link #2 : g1 8}, {link #3 : g2 8}, {link #4 : g3 8}, {link #5 : g4 8}, {link #6 : g5 8},
7 : local 98, cpu 10 {link #0 : g0 8}, {link #1 : g1 8}, {link #2 : g2 8}, {link #3 : g3 8}, {link #4 : g4 8}, {link #5 : g5 8}, {link #6 : g6 8},
0 : local 98, cpu 10 {link #0 : g1 8}, {link #1 : g2 8}, {link #2 : g3 8}, {link #3 : g4 8}, {link #4 : g5 8}, {link #5 : g6 8}, {link #6 : g7 8},
1 : local 98, cpu 10 {link #0 : g2 8}, {link #1 : g3 8}, {link #2 : g4 8}, {link #3 : g5 8}, {link #4 : g6 8}, {link #5 : g7 8}, {link #6 : g0 8},
2 : local 98, cpu 10 {link #0 : g3 8}, {link #1 : g4 8}, {link #2 : g5 8}, {link #3 : g6 8}, {link #4 : g7 8}, {link #5 : g0 8}, {link #6 : g1 8},
3 : local 98, cpu 10 {link #0 : g4 8}, {link #1 : g5 8}, {link #2 : g6 8}, {link #3 : g7 8}, {link #4 : g0 8}, {link #5 : g1 8}, {link #6 : g2 8},
4 : local 98, cpu 10 {link #0 : g5 8}, {link #1 : g6 8}, {link #2 : g7 8}, {link #3 : g0 8}, {link #4 : g1 8}, {link #5 : g2 8}, {link #6 : g3 8},
5 : local 98, cpu 10 {link #0 : g6 8}, {link #1 : g7 8}, {link #2 : g0 8}, {link #3 : g1 8}, {link #4 : g2 8}, {link #5 : g3 8}, {link #6 : g4 8},
6 : local 98, cpu 10 {link #0 : g7 8}, {link #1 : g0 8}, {link #2 : g1 8}, {link #3 : g2 8}, {link #4 : g3 8}, {link #5 : g4 8}, {link #6 : g5 8},
7 : local 98, cpu 10 {link #0 : g0 8}, {link #1 : g1 8}, {link #2 : g2 8}, {link #3 : g3 8}, {link #4 : g4 8}, {link #5 : g5 8}, {link #6 : g6 8},
0 : local 98, cpu 10 {link #0 : g1 8}, {link #1 : g2 8}, {link #2 : g3 8}, {link #3 : g4 8}, {link #4 : g5 8}, {link #5 : g6 8}, {link #6 : g7 8},
1 : local 98, cpu 10 {link #0 : g2 8}, {link #1 : g3 8}, {link #2 : g4 8}, {link #3 : g5 8}, {link #4 : g6 8}, {link #5 : g7 8}, {link #6 : g0 8},
2 : local 98, cpu 10 {link #0 : g3 8}, {link #1 : g4 8}, {link #2 : g5 8}, {link #3 : g6 8}, {link #4 : g7 8}, {link #5 : g0 8}, {link #6 : g1 8},
3 : local 98, cpu 10 {link #0 : g4 8}, {link #1 : g5 8}, {link #2 : g6 8}, {link #3 : g7 8}, {link #4 : g0 8}, {link #5 : g1 8}, {link #6 : g2 8},
4 : local 98, cpu 10 {link #0 : g5 8}, {link #1 : g6 8}, {link #2 : g7 8}, {link #3 : g0 8}, {link #4 : g1 8}, {link #5 : g2 8}, {link #6 : g3 8},
5 : local 98, cpu 10 {link #0 : g6 8}, {link #1 : g7 8}, {link #2 : g0 8}, {link #3 : g1 8}, {link #4 : g2 8}, {link #5 : g3 8}, {link #6 : g4 8},
6 : local 98, cpu 10 {link #0 : g7 8}, {link #1 : g0 8}, {link #2 : g1 8}, {link #3 : g2 8}, {link #4 : g3 8}, {link #5 : g4 8}, {link #6 : g5 8},
7 : local 98, cpu 10 {link #0 : g0 8}, {link #1 : g1 8}, {link #2 : g2 8}, {link #3 : g3 8}, {link #4 : g4 8}, {link #5 : g5 8}, {link #6 : g6 8},
0 :  {link #0 : 1}, {link #1 : 2}, {link #2 : 3}, {link #3 : 4}, {link #4 : 5}, {link #5 : 6}, {link #6 : 7},
1 :  {link #0 : 2}, {link #1 : 3}, {link #2 : 4}, {link #3 : 5}, {link #4 : 6}, {link #5 : 7}, {link #6 : 0},
2 :  {link #0 : 3}, {link #1 : 4}, {link #2 : 5}, {link #3 : 6}, {link #4 : 7}, {link #5 : 0}, {link #6 : 1},
3 :  {link #0 : 4}, {link #1 : 5}, {link #2 : 6}, {link #3 : 7}, {link #4 : 0}, {link #5 : 1}, {link #6 : 2},
4 :  {link #0 : 5}, {link #1 : 6}, {link #2 : 7}, {link #3 : 0}, {link #4 : 1}, {link #5 : 2}, {link #6 : 3},
5 :  {link #0 : 6}, {link #1 : 7}, {link #2 : 0}, {link #3 : 1}, {link #4 : 2}, {link #5 : 3}, {link #6 : 4},
6 :  {link #0 : 7}, {link #1 : 0}, {link #2 : 1}, {link #3 : 2}, {link #4 : 3}, {link #5 : 4}, {link #6 : 5},
7 :  {link #0 : 0}, {link #1 : 1}, {link #2 : 2}, {link #3 : 3}, {link #4 : 4}, {link #5 : 5}, {link #6 : 6},
0 : local 98, cpu 10 {link #0 : g1 8}, {link #1 : g2 8}, {link #2 : g3 8}, {link #3 : g4 8}, {link #4 : g5 8}, {link #5 : g6 8}, {link #6 : g7 8},
1 : local 98, cpu 10 {link #0 : g2 8}, {link #1 : g3 8}, {link #2 : g4 8}, {link #3 : g5 8}, {link #4 : g6 8}, {link #5 : g7 8}, {link #6 : g0 8},
2 : local 98, cpu 10 {link #0 : g3 8}, {link #1 : g4 8}, {link #2 : g5 8}, {link #3 : g6 8}, {link #4 : g7 8}, {link #5 : g0 8}, {link #6 : g1 8},
3 : local 98, cpu 10 {link #0 : g4 8}, {link #1 : g5 8}, {link #2 : g6 8}, {link #3 : g7 8}, {link #4 : g0 8}, {link #5 : g1 8}, {link #6 : g2 8},
4 : local 98, cpu 10 {link #0 : g5 8}, {link #1 : g6 8}, {link #2 : g7 8}, {link #3 : g0 8}, {link #4 : g1 8}, {link #5 : g2 8}, {link #6 : g3 8},
5 : local 98, cpu 10 {link #0 : g6 8}, {link #1 : g7 8}, {link #2 : g0 8}, {link #3 : g1 8}, {link #4 : g2 8}, {link #5 : g3 8}, {link #6 : g4 8},
6 : local 98, cpu 10 {link #0 : g7 8}, {link #1 : g0 8}, {link #2 : g1 8}, {link #3 : g2 8}, {link #4 : g3 8}, {link #5 : g4 8}, {link #6 : g5 8},
7 : local 98, cpu 10 {link #0 : g0 8}, {link #1 : g1 8}, {link #2 : g2 8}, {link #3 : g3 8}, {link #4 : g4 8}, {link #5 : g5 8}, {link #6 : g6 8},
0 :  {link #0 : 1}, {link #1 : 2}, {link #2 : 3}, {link #3 : 4}, {link #4 : 5}, {link #5 : 6}, {link #6 : 7},
1 :  {link #0 : 2}, {link #1 : 3}, {link #2 : 4}, {link #3 : 5}, {link #4 : 6}, {link #5 : 7}, {link #6 : 0},
2 :  {link #0 : 3}, {link #1 : 4}, {link #2 : 5}, {link #3 : 6}, {link #4 : 7}, {link #5 : 0}, {link #6 : 1},
3 :  {link #0 : 4}, {link #1 : 5}, {link #2 : 6}, {link #3 : 7}, {link #4 : 0}, {link #5 : 1}, {link #6 : 2},
4 :  {link #0 : 5}, {link #1 : 6}, {link #2 : 7}, {link #3 : 0}, {link #4 : 1}, {link #5 : 2}, {link #6 : 3},
5 :  {link #0 : 6}, {link #1 : 7}, {link #2 : 0}, {link #3 : 1}, {link #4 : 2}, {link #5 : 3}, {link #6 : 4},
6 :  {link #0 : 7}, {link #1 : 0}, {link #2 : 1}, {link #3 : 2}, {link #4 : 3}, {link #5 : 4}, {link #6 : 5},
7 :  {link #0 : 0}, {link #1 : 1}, {link #2 : 2}, {link #3 : 3}, {link #4 : 4}, {link #5 : 5}, {link #6 : 6},
0 : local 98, cpu 10 {link #0 : g1 8}, {link #1 : g2 8}, {link #2 : g3 8}, {link #3 : g4 8}, {link #4 : g5 8}, {link #5 : g6 8}, {link #6 : g7 8},
1 : local 98, cpu 10 {link #0 : g2 8}, {link #1 : g3 8}, {link #2 : g4 8}, {link #3 : g5 8}, {link #4 : g6 8}, {link #5 : g7 8}, {link #6 : g0 8},
2 : local 98, cpu 10 {link #0 : g3 8}, {link #1 : g4 8}, {link #2 : g5 8}, {link #3 : g6 8}, {link #4 : g7 8}, {link #5 : g0 8}, {link #6 : g1 8},
3 : local 98, cpu 10 {link #0 : g4 8}, {link #1 : g5 8}, {link #2 : g6 8}, {link #3 : g7 8}, {link #4 : g0 8}, {link #5 : g1 8}, {link #6 : g2 8},
4 : local 98, cpu 10 {link #0 : g5 8}, {link #1 : g6 8}, {link #2 : g7 8}, {link #3 : g0 8}, {link #4 : g1 8}, {link #5 : g2 8}, {link #6 : g3 8},
5 : local 98, cpu 10 {link #0 : g6 8}, {link #1 : g7 8}, {link #2 : g0 8}, {link #3 : g1 8}, {link #4 : g2 8}, {link #5 : g3 8}, {link #6 : g4 8},
6 : local 98, cpu 10 {link #0 : g7 8}, {link #1 : g0 8}, {link #2 : g1 8}, {link #3 : g2 8}, {link #4 : g3 8}, {link #5 : g4 8}, {link #6 : g5 8},
7 : local 98, cpu 10 {link #0 : g0 8}, {link #1 : g1 8}, {link #2 : g2 8}, {link #3 : g3 8}, {link #4 : g4 8}, {link #5 : g5 8}, {link #6 : g6 8},
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID
Set parameter TimeLimit to value 200
Set parameter MIPGap to value 0.05
Set parameter LogFile to value "cppsolver.log"
Set parameter Threads to value 56
Academic license - for non-commercial use only - registered to xiaoniu.sxn@sjtu.edu.cn
Gurobi Optimizer version 9.5.1 build v9.5.1rc2 (linux64)
Thread count: 56 physical cores, 112 logical processors, using up to 56 threads
Academic license - for non-commercial use only - registered to xiaoniu.sxn@sjtu.edu.cn
Optimize a model with 602008 rows, 85809 columns and 1478480 nonzeros
Model fingerprint: 0xff311633
Variable types: 9 continuous, 85800 integer (85800 binary)
Coefficient statistics:
  Matrix range     [4e-10, 2e+04]
  Objective range  [1e+00, 1e+00]
  Bounds range     [1e+00, 1e+00]
  RHS range        [1e+00, 5e+04]
Warning: Model contains large matrix coefficient range
         Consider reformulating model or setting NumericFocus parameter
         to avoid numerical issues.
Found heuristic solution: objective 2.000000e+09
Presolve removed 517454 rows and 7 columns
Presolve time: 1.21s
Presolved: 84554 rows, 85802 columns, 413744 nonzeros
Found heuristic solution: objective 199011.65907
Variable types: 1 continuous, 85801 integer (85800 binary)

Deterministic concurrent LP optimizer: primal and dual simplex
Showing first log only...


Use crossover to convert LP symmetric solution to basic solution...
Concurrent spin time: 0.10s

Solved with dual simplex

Root relaxation: objective 4.651486e+03, 41154 iterations, 1.84 seconds (3.61 work units)

    Nodes    |    Current Node    |     Objective Bounds      |     Work
 Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time

     0     0 4651.48570    0 4288 199011.659 4651.48570  97.7%     -   17s
H    0     0                    12353.832022 4651.48570  62.3%     -   17s
     0     0 4651.48572    0 2311 12353.8320 4651.48572  62.3%     -   43s
H    0     0                    7601.1610699 4651.48572  38.8%     -   45s
H    0     0                    7404.8178715 4651.48572  37.2%     -   45s
H    0     0                    4651.4857173 4651.48572  0.00%     -   46s
     0     0 4651.48572    0 2311 4651.48572 4651.48572  0.00%     -   46s

Cutting planes:
  Gomory: 2
  Zero half: 48

Explored 1 nodes (112736 simplex iterations) in 46.09 seconds (81.23 work units)
Thread count was 56 (of 112 available processors)

Solution count 6: 4651.49 7404.82 7601.16 ... 2e+09

Optimal solution found (tolerance 5.00e-02)
Best objective 4.651485717269e+03, best bound 4.651485717269e+03, gap 0.0000%
coll_cache:optimal_local_rate=0.486013,0.481843,0.483284,0.48168,0.481429,0.489629,0.478763,0.479171,
coll_cache:optimal_remote_rate=0.513987,0.518157,0.516716,0.51832,0.518571,0.510371,0.521237,0.520829,
coll_cache:optimal_cpu_rate=7.07047e-11,7.07047e-11,7.07047e-11,7.07047e-11,7.07047e-11,7.07047e-11,7.07047e-11,7.07047e-11,
z=4651.49
test_result:init:feat_nbytes=375030526464
test_result:init:cache_nbytes=49128998400
test_result:init:feat_nbytes=375030526464
test_result:init:cache_nbytes=49128998400
test_result:init:feat_nbytes=375030526464
test_result:init:cache_nbytes=49128998400
test_result:init:feat_nbytes=375030526464
test_result:init:cache_nbytes=49128998400
test_result:init:feat_nbytes=375030526464
test_result:init:cache_nbytes=49128998400
test_result:init:feat_nbytes=375030526464
test_result:init:cache_nbytes=49128998400
test_result:init:feat_nbytes=375030526464
test_result:init:cache_nbytes=49128998400
test_result:init:feat_nbytes=375030526464
test_result:init:cache_nbytes=49128998400
worker 0 running with pid=52685
config:eval_tsp="2023-08-06 18:25:35"
config:num_worker=8
config:num_intra_size=8
config:root_dir=/datasets_gnn/wholegraph
config:graph_name=mag240m-homo
config:epochs=4
config:batchsize=1000
config:skip_epoch=2
config:local_step=250
config:presc_epoch=2
config:neighbors=15,10,5
config:hiddensize=256
config:num_layer=3
config:model=gcn
config:framework=dgl
config:dataloaderworkers=0
config:dropout=0.5
config:weight_decay=0.0005
config:lr=0.003
config:use_nccl=False
config:use_amp=True
config:use_collcache=True
config:cache_percentage=0.13
config:cache_policy=coll_cache_asymm_link
config:omp_thread_num=56
config:unsupervised=True
config:classnum=153
config:global_barrier=<multiprocessing.synchronize.Barrier object at 0x7f6e144779a0>
config:worker_id=0
creating_intra_node_communicator root=0, local_size=8, world_size=8
loading train edge idx from disk
loading train edge idx from disk done
tensor([ 367470406, 3158702471, 3196913887,  311268946, 2622541626, 2707306334,
        2288750783,  341639546, 2394912536, 3266219078,  474737188, 1665128055,
        3225579545,  584996459,  307810634,  726851972, 1000854521, 1061370191,
         371057554,  526478766,  273325093, 1382980281, 1363464091,  971316959,
        1643305663, 1559556869,  792051811, 2593715952, 2627476216,  642711792,
        1279512108,  281028249, 2848334841, 1142277951, 1624797255, 1682408139,
         288375990,  530555421, 1190696744, 1515340461,  396873136, 3079813016,
         574876927,   31156367,  607610239, 1664434120,  774080817, 2850247945,
         655998496,  888602410,  350570870,  624008623,   69778231,  638128676,
        1443388341, 1479712286, 2858804367,  550628163,  198023098, 2583590303,
        2518492873,    2593795, 2722269746,  659106604, 1369497066,  235303384,
         645516367, 3053389785, 3376243999,  792250187, 1401047469, 1545651011,
        1827797263, 1275030316, 2075895474, 2919804301, 2493902937,  112768749,
          11701078,  500365351,  404737965,  786261376,  934911988,  757583227,
        1135493038, 3162165660, 1144120843, 2861906075,      93256, 1866677628,
         103141175, 3295574170, 1840253021,  747507530,  196097433, 3025516425,
         133597469,  755176081, 2348166713,   80549681])
Rank=0, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.009212, per step: 0.000037
epoch=4 total_steps=1000
presamping
presamping takes 17.433218240737915
start training...
[Epoch 0][Step 0], time=1.7699775695800781, ext_time=0.02384638786315918, train_time=1.7393372058868408
[Epoch 0][Step 1], time=0.07533526420593262, ext_time=0.00622248649597168, train_time=0.06365323066711426
[Epoch 0][Step 2], time=0.06714510917663574, ext_time=0.00589442253112793, train_time=0.05620312690734863
[Epoch 0][Step 3], time=0.05441117286682129, ext_time=0.006203651428222656, train_time=0.04314422607421875
[Epoch 0][Step 4], time=0.06177234649658203, ext_time=0.006090641021728516, train_time=0.05071401596069336
[Epoch 0][Step 5], time=0.04913020133972168, ext_time=0.006209135055541992, train_time=0.03783249855041504
[Epoch 0][Step 6], time=0.05409646034240723, ext_time=0.00613713264465332, train_time=0.042951345443725586
[Epoch 0][Step 7], time=0.05521893501281738, ext_time=0.0061740875244140625, train_time=0.044022321701049805
[Epoch 0][Step 8], time=0.05584073066711426, ext_time=0.006110668182373047, train_time=0.04476165771484375
[Epoch 0][Step 9], time=0.05744171142578125, ext_time=0.006148815155029297, train_time=0.04629707336425781
[Epoch 0][Step 10], time=0.05095314979553223, ext_time=0.0061321258544921875, train_time=0.039808034896850586
[Epoch 0][Step 11], time=0.04934883117675781, ext_time=0.006157398223876953, train_time=0.03817033767700195
[Epoch 0][Step 12], time=0.0492100715637207, ext_time=0.006000518798828125, train_time=0.03827357292175293
[Epoch 0][Step 13], time=0.04843854904174805, ext_time=0.006108522415161133, train_time=0.03731226921081543
[Epoch 0][Step 14], time=0.05680489540100098, ext_time=0.006196498870849609, train_time=0.04558157920837402
[Epoch 0][Step 15], time=0.04938936233520508, ext_time=0.006152153015136719, train_time=0.03824639320373535
[Epoch 0][Step 16], time=0.0485386848449707, ext_time=0.0060689449310302734, train_time=0.0375065803527832
[Epoch 0][Step 17], time=0.4469728469848633, ext_time=0.006052494049072266, train_time=0.43599629402160645
[Epoch 0][Step 18], time=0.05347442626953125, ext_time=0.0061206817626953125, train_time=0.042382001876831055
[Epoch 0][Step 19], time=0.049069881439208984, ext_time=0.00609278678894043, train_time=0.03801584243774414
[Epoch 0][Step 20], time=0.049428462982177734, ext_time=0.006100654602050781, train_time=0.03831648826599121
[Epoch 0][Step 21], time=0.04883742332458496, ext_time=0.006194114685058594, train_time=0.03758597373962402
[Epoch 0][Step 22], time=0.04962921142578125, ext_time=0.0061228275299072266, train_time=0.03851509094238281
[Epoch 0][Step 23], time=0.04906129837036133, ext_time=0.006180286407470703, train_time=0.03783679008483887
[Epoch 0][Step 24], time=0.05360150337219238, ext_time=0.0060749053955078125, train_time=0.042582035064697266
[Epoch 0][Step 25], time=0.551131010055542, ext_time=0.006087064743041992, train_time=0.5400378704071045
[Epoch 0][Step 26], time=0.04943656921386719, ext_time=0.0061702728271484375, train_time=0.03826785087585449
[Epoch 0][Step 27], time=0.048242807388305664, ext_time=0.006045818328857422, train_time=0.03723335266113281
[Epoch 0][Step 28], time=0.06274676322937012, ext_time=0.006219387054443359, train_time=0.051435232162475586
[Epoch 0][Step 29], time=0.04988884925842285, ext_time=0.0061643123626708984, train_time=0.03869891166687012
[Epoch 0][Step 30], time=0.0494542121887207, ext_time=0.0060193538665771484, train_time=0.03848767280578613
[Epoch 0][Step 31], time=0.049687862396240234, ext_time=0.006053447723388672, train_time=0.038661956787109375
[Epoch 0][Step 32], time=0.05024003982543945, ext_time=0.0060749053955078125, train_time=0.039215803146362305
[Epoch 0][Step 33], time=0.049347639083862305, ext_time=0.006047725677490234, train_time=0.03832697868347168
[Epoch 0][Step 34], time=0.048662424087524414, ext_time=0.006056070327758789, train_time=0.03770089149475098
[Epoch 0][Step 35], time=0.04937481880187988, ext_time=0.006128787994384766, train_time=0.03830552101135254
[Epoch 0][Step 36], time=0.04862022399902344, ext_time=0.0060732364654541016, train_time=0.0375676155090332
[Epoch 0][Step 37], time=0.048799753189086914, ext_time=0.006058931350708008, train_time=0.037757158279418945
[Epoch 0][Step 38], time=0.048232078552246094, ext_time=0.006036281585693359, train_time=0.037247419357299805
[Epoch 0][Step 39], time=0.3586268424987793, ext_time=0.006083250045776367, train_time=0.34759998321533203
[Epoch 0][Step 40], time=0.04920053482055664, ext_time=0.006142854690551758, train_time=0.03806447982788086
[Epoch 0][Step 41], time=0.05438971519470215, ext_time=0.0061931610107421875, train_time=0.04309868812561035
[Epoch 0][Step 42], time=0.04924798011779785, ext_time=0.006148099899291992, train_time=0.038068294525146484
[Epoch 0][Step 43], time=0.04962468147277832, ext_time=0.006067037582397461, train_time=0.038637399673461914
[Epoch 0][Step 44], time=0.36590123176574707, ext_time=0.006118297576904297, train_time=0.35476183891296387
[Epoch 0][Step 45], time=0.04945564270019531, ext_time=0.006212949752807617, train_time=0.03822517395019531
[Epoch 0][Step 46], time=0.04913973808288574, ext_time=0.006110191345214844, train_time=0.03807353973388672
[Epoch 0][Step 47], time=0.049326419830322266, ext_time=0.006135225296020508, train_time=0.038204193115234375
[Epoch 0][Step 48], time=0.048918724060058594, ext_time=0.0061151981353759766, train_time=0.037781476974487305
[Epoch 0][Step 49], time=0.04921603202819824, ext_time=0.0061032772064208984, train_time=0.0381312370300293
[Epoch 0][Step 50], time=0.04910469055175781, ext_time=0.0060901641845703125, train_time=0.03805828094482422
[Epoch 0][Step 51], time=0.04907703399658203, ext_time=0.006127119064331055, train_time=0.03795003890991211
[Epoch 0][Step 52], time=0.04864621162414551, ext_time=0.006063699722290039, train_time=0.03762531280517578
[Epoch 0][Step 53], time=0.04909682273864746, ext_time=0.0061054229736328125, train_time=0.03795599937438965
[Epoch 0][Step 54], time=0.04902315139770508, ext_time=0.006127834320068359, train_time=0.037889719009399414
[Epoch 0][Step 55], time=0.04899168014526367, ext_time=0.006142854690551758, train_time=0.03775167465209961
[Epoch 0][Step 56], time=0.048671722412109375, ext_time=0.005998134613037109, train_time=0.037737131118774414
[Epoch 0][Step 57], time=0.048723459243774414, ext_time=0.006114006042480469, train_time=0.037631988525390625
[Epoch 0][Step 58], time=0.049056291580200195, ext_time=0.006121397018432617, train_time=0.037955522537231445
[Epoch 0][Step 59], time=0.04954028129577637, ext_time=0.0060918331146240234, train_time=0.0384516716003418
[Epoch 0][Step 60], time=0.049384117126464844, ext_time=0.006213188171386719, train_time=0.03811073303222656
[Epoch 0][Step 61], time=0.048805952072143555, ext_time=0.0060956478118896484, train_time=0.037696123123168945
[Epoch 0][Step 62], time=0.04886341094970703, ext_time=0.006129264831542969, train_time=0.037749528884887695
[Epoch 0][Step 63], time=0.04904890060424805, ext_time=0.0061492919921875, train_time=0.03792428970336914
[Epoch 0][Step 64], time=0.04879021644592285, ext_time=0.006125926971435547, train_time=0.037744998931884766
[Epoch 0][Step 65], time=0.04959511756896973, ext_time=0.006224393844604492, train_time=0.03834104537963867
[Epoch 0][Step 66], time=0.04912686347961426, ext_time=0.006116390228271484, train_time=0.037993431091308594
[Epoch 0][Step 67], time=0.04878401756286621, ext_time=0.00608062744140625, train_time=0.03773331642150879
[Epoch 0][Step 68], time=0.0488588809967041, ext_time=0.006060600280761719, train_time=0.03778862953186035
[Epoch 0][Step 69], time=0.04886221885681152, ext_time=0.0061070919036865234, train_time=0.03780674934387207
[Epoch 0][Step 70], time=0.48966503143310547, ext_time=0.0060710906982421875, train_time=0.4786496162414551
[Epoch 0][Step 71], time=0.048664093017578125, ext_time=0.006086111068725586, train_time=0.037523746490478516
[Epoch 0][Step 72], time=0.04903054237365723, ext_time=0.006111860275268555, train_time=0.03790163993835449
[Epoch 0][Step 73], time=0.0491945743560791, ext_time=0.006138324737548828, train_time=0.038010358810424805
[Epoch 0][Step 74], time=0.04867410659790039, ext_time=0.006077289581298828, train_time=0.0376126766204834
[Epoch 0][Step 75], time=0.04910635948181152, ext_time=0.0060994625091552734, train_time=0.03796100616455078
[Epoch 0][Step 76], time=0.04938936233520508, ext_time=0.006235599517822266, train_time=0.03809952735900879
[Epoch 0][Step 77], time=0.04829287528991699, ext_time=0.006043672561645508, train_time=0.037343740463256836
[Epoch 0][Step 78], time=0.04909777641296387, ext_time=0.00611424446105957, train_time=0.03798961639404297
[Epoch 0][Step 79], time=0.04861927032470703, ext_time=0.0060117244720458984, train_time=0.03768324851989746
[Epoch 0][Step 80], time=0.04922628402709961, ext_time=0.006064414978027344, train_time=0.03820395469665527
[Epoch 0][Step 81], time=0.04888129234313965, ext_time=0.005991220474243164, train_time=0.037958621978759766
[Epoch 0][Step 82], time=0.049308061599731445, ext_time=0.006127357482910156, train_time=0.03810834884643555
[Epoch 0][Step 83], time=0.04894375801086426, ext_time=0.00613713264465332, train_time=0.037779808044433594
[Epoch 0][Step 84], time=0.04888772964477539, ext_time=0.006127834320068359, train_time=0.0377347469329834
[Epoch 0][Step 85], time=0.048757314682006836, ext_time=0.006037712097167969, train_time=0.03776240348815918
[Epoch 0][Step 86], time=0.048564910888671875, ext_time=0.006121397018432617, train_time=0.037471771240234375
[Epoch 0][Step 87], time=0.049030303955078125, ext_time=0.006097078323364258, train_time=0.037976741790771484
[Epoch 0][Step 88], time=0.04886484146118164, ext_time=0.006058216094970703, train_time=0.03786492347717285
[Epoch 0][Step 89], time=0.04906272888183594, ext_time=0.006145477294921875, train_time=0.037900686264038086
[Epoch 0][Step 90], time=0.04895806312561035, ext_time=0.006120443344116211, train_time=0.03783369064331055
[Epoch 0][Step 91], time=0.049095869064331055, ext_time=0.006159543991088867, train_time=0.03791689872741699
[Epoch 0][Step 92], time=0.04894447326660156, ext_time=0.006140947341918945, train_time=0.03787088394165039
[Epoch 0][Step 93], time=0.048872947692871094, ext_time=0.0060939788818359375, train_time=0.037754058837890625
[Epoch 0][Step 94], time=0.053260087966918945, ext_time=0.006039857864379883, train_time=0.0422205924987793
[Epoch 0][Step 95], time=0.04877471923828125, ext_time=0.0061070919036865234, train_time=0.03770852088928223
[Epoch 0][Step 96], time=0.049480438232421875, ext_time=0.006141185760498047, train_time=0.03835463523864746
[Epoch 0][Step 97], time=0.04934859275817871, ext_time=0.00613093376159668, train_time=0.03815317153930664
[Epoch 0][Step 98], time=0.04871702194213867, ext_time=0.0061054229736328125, train_time=0.03762412071228027
[Epoch 0][Step 99], time=0.049391984939575195, ext_time=0.006136178970336914, train_time=0.03826546669006348
[Epoch 0][Step 100], time=0.048793792724609375, ext_time=0.006139993667602539, train_time=0.03763723373413086
[Epoch 0][Step 101], time=0.04903602600097656, ext_time=0.006099224090576172, train_time=0.03796076774597168
[Epoch 0][Step 102], time=0.049515485763549805, ext_time=0.006182193756103516, train_time=0.038339853286743164
[Epoch 0][Step 103], time=0.04937291145324707, ext_time=0.0061647891998291016, train_time=0.038141727447509766
[Epoch 0][Step 104], time=0.049514055252075195, ext_time=0.0061414241790771484, train_time=0.038237810134887695
[Epoch 0][Step 105], time=0.049074649810791016, ext_time=0.006119251251220703, train_time=0.03795647621154785
[Epoch 0][Step 106], time=0.04832339286804199, ext_time=0.006050586700439453, train_time=0.03732657432556152
[Epoch 0][Step 107], time=0.048666954040527344, ext_time=0.006047487258911133, train_time=0.03768777847290039
[Epoch 0][Step 108], time=0.04927968978881836, ext_time=0.006037473678588867, train_time=0.03828597068786621
[Epoch 0][Step 109], time=0.04861307144165039, ext_time=0.006064176559448242, train_time=0.03754568099975586
[Epoch 0][Step 110], time=0.05325675010681152, ext_time=0.006137371063232422, train_time=0.04208683967590332
[Epoch 0][Step 111], time=0.048926591873168945, ext_time=0.0061054229736328125, train_time=0.037828922271728516
[Epoch 0][Step 112], time=0.048859596252441406, ext_time=0.0061626434326171875, train_time=0.0377049446105957
[Epoch 0][Step 113], time=0.04922175407409668, ext_time=0.0061054229736328125, train_time=0.038153886795043945
[Epoch 0][Step 114], time=0.049219369888305664, ext_time=0.006121158599853516, train_time=0.03807640075683594
[Epoch 0][Step 115], time=0.04846930503845215, ext_time=0.006033182144165039, train_time=0.03748130798339844
[Epoch 0][Step 116], time=0.04854130744934082, ext_time=0.006118059158325195, train_time=0.03744649887084961
[Epoch 0][Step 117], time=0.04861760139465332, ext_time=0.006062984466552734, train_time=0.03759765625
[Epoch 0][Step 118], time=0.04919004440307617, ext_time=0.0061969757080078125, train_time=0.03794097900390625
[Epoch 0][Step 119], time=0.04896235466003418, ext_time=0.006134033203125, train_time=0.03780841827392578
[Epoch 0][Step 120], time=0.04974675178527832, ext_time=0.006083250045776367, train_time=0.0386660099029541
[Epoch 0][Step 121], time=0.0488283634185791, ext_time=0.006102800369262695, train_time=0.037726640701293945
[Epoch 0][Step 122], time=0.049317359924316406, ext_time=0.006079912185668945, train_time=0.03826117515563965
[Epoch 0][Step 123], time=0.05620288848876953, ext_time=0.006093263626098633, train_time=0.045142173767089844
[Epoch 0][Step 124], time=0.056449174880981445, ext_time=0.006150484085083008, train_time=0.03925442695617676
[Epoch 0][Step 125], time=0.3936336040496826, ext_time=0.006159305572509766, train_time=0.38249731063842773
[Epoch 0][Step 126], time=0.049185991287231445, ext_time=0.006039857864379883, train_time=0.038214683532714844
[Epoch 0][Step 127], time=0.0494384765625, ext_time=0.006186008453369141, train_time=0.03831005096435547
[Epoch 0][Step 128], time=0.04927635192871094, ext_time=0.006139516830444336, train_time=0.03815102577209473
[Epoch 0][Step 129], time=0.049410104751586914, ext_time=0.0061075687408447266, train_time=0.03828167915344238
[Epoch 0][Step 130], time=0.04908895492553711, ext_time=0.0061664581298828125, train_time=0.037870168685913086
[Epoch 0][Step 131], time=0.04844975471496582, ext_time=0.0061185359954833984, train_time=0.03738832473754883
[Epoch 0][Step 132], time=0.04865074157714844, ext_time=0.0060350894927978516, train_time=0.03767991065979004
[Epoch 0][Step 133], time=0.0498347282409668, ext_time=0.0061566829681396484, train_time=0.038600921630859375
[Epoch 0][Step 134], time=0.049162864685058594, ext_time=0.0060994625091552734, train_time=0.03809762001037598
[Epoch 0][Step 135], time=0.04925799369812012, ext_time=0.006146669387817383, train_time=0.03812694549560547
[Epoch 0][Step 136], time=0.05341076850891113, ext_time=0.005909442901611328, train_time=0.04263877868652344
[Epoch 0][Step 137], time=0.04938793182373047, ext_time=0.006080150604248047, train_time=0.038358449935913086
[Epoch 0][Step 138], time=0.04887104034423828, ext_time=0.006095409393310547, train_time=0.037726402282714844
[Epoch 0][Step 139], time=0.04845094680786133, ext_time=0.005973100662231445, train_time=0.037537336349487305
[Epoch 0][Step 140], time=0.04965019226074219, ext_time=0.006031513214111328, train_time=0.03865504264831543
[Epoch 0][Step 141], time=0.049762725830078125, ext_time=0.006156206130981445, train_time=0.038594722747802734
[Epoch 0][Step 142], time=0.04879426956176758, ext_time=0.0061266422271728516, train_time=0.0377192497253418
[Epoch 0][Step 143], time=0.04910922050476074, ext_time=0.006158113479614258, train_time=0.038028717041015625
[Epoch 0][Step 144], time=0.0486447811126709, ext_time=0.006060123443603516, train_time=0.03753662109375
[Epoch 0][Step 145], time=0.04891014099121094, ext_time=0.006080150604248047, train_time=0.037895917892456055
[Epoch 0][Step 146], time=0.04878520965576172, ext_time=0.006104946136474609, train_time=0.03770732879638672
[Epoch 0][Step 147], time=0.04909539222717285, ext_time=0.006132364273071289, train_time=0.037963151931762695
[Epoch 0][Step 148], time=0.04906463623046875, ext_time=0.00612950325012207, train_time=0.03794527053833008
[Epoch 0][Step 149], time=0.048933982849121094, ext_time=0.0061304569244384766, train_time=0.03779482841491699
[Epoch 0][Step 150], time=0.049683570861816406, ext_time=0.006123781204223633, train_time=0.038567543029785156
[Epoch 0][Step 151], time=0.048619747161865234, ext_time=0.0060999393463134766, train_time=0.037526607513427734
[Epoch 0][Step 152], time=0.04870343208312988, ext_time=0.006022453308105469, train_time=0.03772163391113281
[Epoch 0][Step 153], time=0.04903912544250488, ext_time=0.006112098693847656, train_time=0.03798103332519531
[Epoch 0][Step 154], time=0.04888510704040527, ext_time=0.006102323532104492, train_time=0.03782844543457031
[Epoch 0][Step 155], time=0.04900312423706055, ext_time=0.006065845489501953, train_time=0.03798174858093262
[Epoch 0][Step 156], time=0.048890113830566406, ext_time=0.0061473846435546875, train_time=0.0377192497253418
[Epoch 0][Step 157], time=0.04894137382507324, ext_time=0.006091594696044922, train_time=0.03789472579956055
[Epoch 0][Step 158], time=0.04898643493652344, ext_time=0.00614166259765625, train_time=0.03790426254272461
[Epoch 0][Step 159], time=0.31805419921875, ext_time=0.0060694217681884766, train_time=0.3069920539855957
[Epoch 0][Step 160], time=0.049219369888305664, ext_time=0.006214618682861328, train_time=0.03798317909240723
[Epoch 0][Step 161], time=0.04875683784484863, ext_time=0.006112098693847656, train_time=0.03766131401062012
[Epoch 0][Step 162], time=0.04958844184875488, ext_time=0.006068229675292969, train_time=0.03851914405822754
[Epoch 0][Step 163], time=0.04931640625, ext_time=0.006132602691650391, train_time=0.03818511962890625
[Epoch 0][Step 164], time=0.048777103424072266, ext_time=0.006059408187866211, train_time=0.037787437438964844
[Epoch 0][Step 165], time=0.04896187782287598, ext_time=0.006059885025024414, train_time=0.03789782524108887
[Epoch 0][Step 166], time=0.04936718940734863, ext_time=0.006127119064331055, train_time=0.038257598876953125
[Epoch 0][Step 167], time=0.048810482025146484, ext_time=0.0061321258544921875, train_time=0.0376734733581543
[Epoch 0][Step 168], time=0.04854130744934082, ext_time=0.0060579776763916016, train_time=0.03749203681945801
[Epoch 0][Step 169], time=0.37015748023986816, ext_time=0.006220817565917969, train_time=0.3588120937347412
[Epoch 0][Step 170], time=0.0496983528137207, ext_time=0.006184577941894531, train_time=0.038506507873535156
[Epoch 0][Step 171], time=0.04964947700500488, ext_time=0.006177186965942383, train_time=0.0383145809173584
[Epoch 0][Step 172], time=0.04895663261413574, ext_time=0.006075382232666016, train_time=0.037958383560180664
[Epoch 0][Step 173], time=0.04893970489501953, ext_time=0.006106376647949219, train_time=0.037821054458618164
[Epoch 0][Step 174], time=0.0488278865814209, ext_time=0.006206035614013672, train_time=0.037596940994262695
[Epoch 0][Step 175], time=0.049336910247802734, ext_time=0.006159543991088867, train_time=0.038150787353515625
[Epoch 0][Step 176], time=0.0490109920501709, ext_time=0.0061304569244384766, train_time=0.03793025016784668
[Epoch 0][Step 177], time=0.048883914947509766, ext_time=0.006204843521118164, train_time=0.037683963775634766
[Epoch 0][Step 178], time=0.04832005500793457, ext_time=0.0059926509857177734, train_time=0.037374019622802734
[Epoch 0][Step 179], time=0.04906821250915527, ext_time=0.006063222885131836, train_time=0.03799843788146973
[Epoch 0][Step 180], time=0.04933619499206543, ext_time=0.006170749664306641, train_time=0.03809356689453125
[Epoch 0][Step 181], time=0.049088239669799805, ext_time=0.006106853485107422, train_time=0.03793454170227051
[Epoch 0][Step 182], time=0.048729658126831055, ext_time=0.006108760833740234, train_time=0.037636518478393555
[Epoch 0][Step 183], time=0.04894423484802246, ext_time=0.0061228275299072266, train_time=0.03781533241271973
[Epoch 0][Step 184], time=0.048912763595581055, ext_time=0.006093263626098633, train_time=0.03787803649902344
[Epoch 0][Step 185], time=0.048583984375, ext_time=0.006078243255615234, train_time=0.03755593299865723
[Epoch 0][Step 186], time=0.0491185188293457, ext_time=0.006140708923339844, train_time=0.0379941463470459
[Epoch 0][Step 187], time=0.048758745193481445, ext_time=0.006123542785644531, train_time=0.03761863708496094
[Epoch 0][Step 188], time=0.049089908599853516, ext_time=0.006024360656738281, train_time=0.03808951377868652
[Epoch 0][Step 189], time=0.04903674125671387, ext_time=0.006072998046875, train_time=0.038019657135009766
[Epoch 0][Step 190], time=0.049161434173583984, ext_time=0.006114006042480469, train_time=0.038046836853027344
[Epoch 0][Step 191], time=0.048976898193359375, ext_time=0.006117582321166992, train_time=0.03781318664550781
[Epoch 0][Step 192], time=0.049317121505737305, ext_time=0.006076335906982422, train_time=0.03828144073486328
[Epoch 0][Step 193], time=0.04933023452758789, ext_time=0.0061571598052978516, train_time=0.038161516189575195
[Epoch 0][Step 194], time=0.04924750328063965, ext_time=0.0061376094818115234, train_time=0.03807377815246582
[Epoch 0][Step 195], time=0.048894643783569336, ext_time=0.006039619445800781, train_time=0.03762054443359375
[Epoch 0][Step 196], time=0.04906511306762695, ext_time=0.006161212921142578, train_time=0.03792428970336914
[Epoch 0][Step 197], time=0.04882407188415527, ext_time=0.006105899810791016, train_time=0.03769421577453613
[Epoch 0][Step 198], time=0.04876279830932617, ext_time=0.0061151981353759766, train_time=0.037744760513305664
[Epoch 0][Step 199], time=0.04876446723937988, ext_time=0.006103992462158203, train_time=0.037703514099121094
[Epoch 0][Step 200], time=0.04938673973083496, ext_time=0.0061359405517578125, train_time=0.03825807571411133
[Epoch 0][Step 201], time=0.054662466049194336, ext_time=0.006125211715698242, train_time=0.043557167053222656
[Epoch 0][Step 202], time=0.04934239387512207, ext_time=0.006102323532104492, train_time=0.038350582122802734
[Epoch 0][Step 203], time=0.048887014389038086, ext_time=0.006117820739746094, train_time=0.037758827209472656
[Epoch 0][Step 204], time=0.048812150955200195, ext_time=0.006129264831542969, train_time=0.03770613670349121
[Epoch 0][Step 205], time=0.04906034469604492, ext_time=0.006174325942993164, train_time=0.03790760040283203
[Epoch 0][Step 206], time=0.04912424087524414, ext_time=0.006047964096069336, train_time=0.03814101219177246
[Epoch 0][Step 207], time=0.04953479766845703, ext_time=0.006159782409667969, train_time=0.03838825225830078
[Epoch 0][Step 208], time=0.04846072196960449, ext_time=0.006171703338623047, train_time=0.037328481674194336
[Epoch 0][Step 209], time=0.053116559982299805, ext_time=0.006140947341918945, train_time=0.04206490516662598
[Epoch 0][Step 210], time=0.04905390739440918, ext_time=0.006131649017333984, train_time=0.03789210319519043
[Epoch 0][Step 211], time=0.04944157600402832, ext_time=0.006157636642456055, train_time=0.038297414779663086
[Epoch 0][Step 212], time=0.04938220977783203, ext_time=0.00621342658996582, train_time=0.0381169319152832
[Epoch 0][Step 213], time=0.049101829528808594, ext_time=0.0060863494873046875, train_time=0.037987470626831055
[Epoch 0][Step 214], time=0.04866933822631836, ext_time=0.0061187744140625, train_time=0.03754234313964844
[Epoch 0][Step 215], time=0.048598289489746094, ext_time=0.00610041618347168, train_time=0.037481069564819336
[Epoch 0][Step 216], time=0.05772852897644043, ext_time=0.006143093109130859, train_time=0.0465853214263916
[Epoch 0][Step 217], time=0.048799991607666016, ext_time=0.006139278411865234, train_time=0.037628173828125
[Epoch 0][Step 218], time=0.04810047149658203, ext_time=0.0060040950775146484, train_time=0.03714728355407715
[Epoch 0][Step 219], time=0.04888629913330078, ext_time=0.006128787994384766, train_time=0.037737131118774414
[Epoch 0][Step 220], time=0.0486607551574707, ext_time=0.006083965301513672, train_time=0.037631988525390625
[Epoch 0][Step 221], time=0.04862380027770996, ext_time=0.006062030792236328, train_time=0.03758597373962402
[Epoch 0][Step 222], time=0.0488741397857666, ext_time=0.006147861480712891, train_time=0.03767657279968262
[Epoch 0][Step 223], time=0.04922604560852051, ext_time=0.006104946136474609, train_time=0.03818368911743164
[Epoch 0][Step 224], time=0.04876589775085449, ext_time=0.006043434143066406, train_time=0.0378413200378418
[Epoch 0][Step 225], time=0.04867839813232422, ext_time=0.006058692932128906, train_time=0.03762555122375488
[Epoch 0][Step 226], time=0.04907727241516113, ext_time=0.006046295166015625, train_time=0.03806185722351074
[Epoch 0][Step 227], time=0.048468589782714844, ext_time=0.006063222885131836, train_time=0.03750896453857422
[Epoch 0][Step 228], time=0.048665761947631836, ext_time=0.006091594696044922, train_time=0.03759026527404785
[Epoch 0][Step 229], time=0.04918622970581055, ext_time=0.006134033203125, train_time=0.03801560401916504
[Epoch 0][Step 230], time=0.04890584945678711, ext_time=0.0061609745025634766, train_time=0.03769659996032715
[Epoch 0][Step 231], time=0.048819541931152344, ext_time=0.005976438522338867, train_time=0.03794360160827637
[Epoch 0][Step 232], time=0.04893803596496582, ext_time=0.0061187744140625, train_time=0.037798166275024414
[Epoch 0][Step 233], time=0.04901766777038574, ext_time=0.0060765743255615234, train_time=0.03795266151428223
[Epoch 0][Step 234], time=0.04942607879638672, ext_time=0.006203651428222656, train_time=0.038146257400512695
[Epoch 0][Step 235], time=0.04868316650390625, ext_time=0.006128072738647461, train_time=0.0375673770904541
[Epoch 0][Step 236], time=0.04916739463806152, ext_time=0.006158590316772461, train_time=0.0380403995513916
[Epoch 0][Step 237], time=0.04912233352661133, ext_time=0.006021022796630859, train_time=0.03819775581359863
[Epoch 0][Step 238], time=0.048787832260131836, ext_time=0.006124258041381836, train_time=0.037665605545043945
[Epoch 0][Step 239], time=0.04885363578796387, ext_time=0.006097078323364258, train_time=0.03774380683898926
[Epoch 0][Step 240], time=0.049385786056518555, ext_time=0.006120443344116211, train_time=0.0382847785949707
[Epoch 0][Step 241], time=0.048986196517944336, ext_time=0.006128072738647461, train_time=0.0378267765045166
[Epoch 0][Step 242], time=0.04889106750488281, ext_time=0.0061414241790771484, train_time=0.037783145904541016
[Epoch 0][Step 243], time=0.049233436584472656, ext_time=0.006093263626098633, train_time=0.038156747817993164
[Epoch 0][Step 244], time=0.048630714416503906, ext_time=0.0060825347900390625, train_time=0.03754758834838867
[Epoch 0][Step 245], time=0.04871225357055664, ext_time=0.0061244964599609375, train_time=0.03763294219970703
[Epoch 0][Step 246], time=0.048781394958496094, ext_time=0.006028175354003906, train_time=0.03785300254821777
[Epoch 0][Step 247], time=0.049008846282958984, ext_time=0.006131410598754883, train_time=0.037851810455322266
[Epoch 0][Step 248], time=0.04906630516052246, ext_time=0.006095170974731445, train_time=0.0379033088684082
[Epoch 0][Step 249], time=0.049214839935302734, ext_time=0.00612950325012207, train_time=0.03806042671203613
[Epoch 0], time=17.065638780593872, loss=nan
[Epoch 1][Step 0], time=0.04909253120422363, ext_time=0.006098270416259766, train_time=0.037984371185302734
[Epoch 1][Step 1], time=0.04921579360961914, ext_time=0.006119251251220703, train_time=0.03805398941040039
[Epoch 1][Step 2], time=0.0491330623626709, ext_time=0.006127357482910156, train_time=0.03802227973937988
[Epoch 1][Step 3], time=0.04885458946228027, ext_time=0.006128787994384766, train_time=0.03773641586303711
[Epoch 1][Step 4], time=0.049433231353759766, ext_time=0.006098508834838867, train_time=0.03836321830749512
[Epoch 1][Step 5], time=0.0487213134765625, ext_time=0.006064414978027344, train_time=0.03764939308166504
[Epoch 1][Step 6], time=0.0542902946472168, ext_time=0.006101131439208984, train_time=0.0432436466217041
[Epoch 1][Step 7], time=0.04871201515197754, ext_time=0.006130695343017578, train_time=0.03757739067077637
[Epoch 1][Step 8], time=0.049048423767089844, ext_time=0.006081342697143555, train_time=0.0379641056060791
[Epoch 1][Step 9], time=0.04958772659301758, ext_time=0.006132602691650391, train_time=0.038459062576293945
[Epoch 1][Step 10], time=0.04896354675292969, ext_time=0.00609588623046875, train_time=0.03783559799194336
[Epoch 1][Step 11], time=0.049495697021484375, ext_time=0.006015777587890625, train_time=0.03856468200683594
[Epoch 1][Step 12], time=0.04952645301818848, ext_time=0.006085634231567383, train_time=0.03847908973693848
[Epoch 1][Step 13], time=0.04870176315307617, ext_time=0.006098747253417969, train_time=0.037634849548339844
[Epoch 1][Step 14], time=0.04909849166870117, ext_time=0.006151676177978516, train_time=0.03791332244873047
[Epoch 1][Step 15], time=0.049405813217163086, ext_time=0.006109714508056641, train_time=0.038251638412475586
[Epoch 1][Step 16], time=0.048966407775878906, ext_time=0.006110429763793945, train_time=0.0378262996673584
[Epoch 1][Step 17], time=0.04874777793884277, ext_time=0.006177186965942383, train_time=0.03758859634399414
[Epoch 1][Step 18], time=0.04932832717895508, ext_time=0.006082057952880859, train_time=0.03828620910644531
[Epoch 1][Step 19], time=0.048821210861206055, ext_time=0.0060918331146240234, train_time=0.03773045539855957
[Epoch 1][Step 20], time=0.04903078079223633, ext_time=0.006169319152832031, train_time=0.037904977798461914
[Epoch 1][Step 21], time=0.048906564712524414, ext_time=0.0060999393463134766, train_time=0.03775143623352051
[Epoch 1][Step 22], time=0.048983097076416016, ext_time=0.006099224090576172, train_time=0.03792214393615723
[Epoch 1][Step 23], time=0.04923605918884277, ext_time=0.006150484085083008, train_time=0.03805398941040039
[Epoch 1][Step 24], time=0.04861021041870117, ext_time=0.006054878234863281, train_time=0.03758835792541504
[Epoch 1][Step 25], time=0.04833197593688965, ext_time=0.006084918975830078, train_time=0.03727245330810547
[Epoch 1][Step 26], time=0.049161434173583984, ext_time=0.006165981292724609, train_time=0.03794288635253906
[Epoch 1][Step 27], time=0.04889678955078125, ext_time=0.006177186965942383, train_time=0.0377039909362793
[Epoch 1][Step 28], time=0.43948912620544434, ext_time=0.006152629852294922, train_time=0.4283277988433838
[Epoch 1][Step 29], time=0.049480438232421875, ext_time=0.0061762332916259766, train_time=0.03816652297973633
[Epoch 1][Step 30], time=0.048906564712524414, ext_time=0.006134748458862305, train_time=0.037749528884887695
[Epoch 1][Step 31], time=0.04911661148071289, ext_time=0.006087779998779297, train_time=0.03805971145629883
[Epoch 1][Step 32], time=0.04871392250061035, ext_time=0.006108522415161133, train_time=0.03768491744995117
[Epoch 1][Step 33], time=0.048810482025146484, ext_time=0.006114006042480469, train_time=0.037706613540649414
[Epoch 1][Step 34], time=0.04827070236206055, ext_time=0.0060272216796875, train_time=0.03731417655944824
[Epoch 1][Step 35], time=0.04913973808288574, ext_time=0.0061190128326416016, train_time=0.03806757926940918
[Epoch 1][Step 36], time=0.04880857467651367, ext_time=0.006102323532104492, train_time=0.03771352767944336
[Epoch 1][Step 37], time=0.04902148246765137, ext_time=0.00613856315612793, train_time=0.037902116775512695
[Epoch 1][Step 38], time=0.04872894287109375, ext_time=0.006049394607543945, train_time=0.037763357162475586
[Epoch 1][Step 39], time=0.04837489128112793, ext_time=0.0060770511627197266, train_time=0.037352561950683594
[Epoch 1][Step 40], time=0.04869198799133301, ext_time=0.006083250045776367, train_time=0.03761410713195801
[Epoch 1][Step 41], time=0.049431800842285156, ext_time=0.0061798095703125, train_time=0.038164377212524414
[Epoch 1][Step 42], time=0.04964160919189453, ext_time=0.006166219711303711, train_time=0.0384066104888916
[Epoch 1][Step 43], time=0.04930543899536133, ext_time=0.005978584289550781, train_time=0.038393497467041016
[Epoch 1][Step 44], time=0.05517888069152832, ext_time=0.006159067153930664, train_time=0.038581132888793945
[Epoch 1][Step 45], time=0.048952579498291016, ext_time=0.006026744842529297, train_time=0.03796815872192383
[Epoch 1][Step 46], time=0.04895830154418945, ext_time=0.0061037540435791016, train_time=0.03790998458862305
[Epoch 1][Step 47], time=0.054459333419799805, ext_time=0.006064176559448242, train_time=0.043411970138549805
[Epoch 1][Step 48], time=0.04880523681640625, ext_time=0.006178379058837891, train_time=0.03765559196472168
[Epoch 1][Step 49], time=0.04931449890136719, ext_time=0.006176948547363281, train_time=0.03814411163330078
[Epoch 1][Step 50], time=0.04865455627441406, ext_time=0.006105184555053711, train_time=0.03757667541503906
[Epoch 1][Step 51], time=0.04948925971984863, ext_time=0.006140470504760742, train_time=0.038347721099853516
[Epoch 1][Step 52], time=0.048638105392456055, ext_time=0.006188631057739258, train_time=0.03745603561401367
[Epoch 1][Step 53], time=0.04925227165222168, ext_time=0.006163835525512695, train_time=0.03803443908691406
[Epoch 1][Step 54], time=0.05308890342712402, ext_time=0.005946636199951172, train_time=0.04222583770751953
[Epoch 1][Step 55], time=0.048690080642700195, ext_time=0.0060939788818359375, train_time=0.037639617919921875
[Epoch 1][Step 56], time=0.049187660217285156, ext_time=0.006072044372558594, train_time=0.03813815116882324
[Epoch 1][Step 57], time=0.04881000518798828, ext_time=0.006044149398803711, train_time=0.03786635398864746
[Epoch 1][Step 58], time=0.04939699172973633, ext_time=0.006165742874145508, train_time=0.03824567794799805
[Epoch 1][Step 59], time=0.04921698570251465, ext_time=0.006114959716796875, train_time=0.038065433502197266
[Epoch 1][Step 60], time=0.049382686614990234, ext_time=0.006192922592163086, train_time=0.03812861442565918
[Epoch 1][Step 61], time=0.0491337776184082, ext_time=0.00614476203918457, train_time=0.03801870346069336
[Epoch 1][Step 62], time=0.04930400848388672, ext_time=0.0061244964599609375, train_time=0.038213491439819336
[Epoch 1][Step 63], time=0.0491793155670166, ext_time=0.0061800479888916016, train_time=0.03799915313720703
[Epoch 1][Step 64], time=0.04949498176574707, ext_time=0.00604248046875, train_time=0.03851628303527832
[Epoch 1][Step 65], time=0.04926633834838867, ext_time=0.0061299800872802734, train_time=0.0381321907043457
[Epoch 1][Step 66], time=0.0487363338470459, ext_time=0.0060999393463134766, train_time=0.03766655921936035
[Epoch 1][Step 67], time=0.0487980842590332, ext_time=0.006110191345214844, train_time=0.03766894340515137
[Epoch 1][Step 68], time=0.048768043518066406, ext_time=0.0060596466064453125, train_time=0.03772234916687012
[Epoch 1][Step 69], time=0.0485234260559082, ext_time=0.006082773208618164, train_time=0.037477731704711914
[Epoch 1][Step 70], time=0.04914093017578125, ext_time=0.006140470504760742, train_time=0.03801703453063965
[Epoch 1][Step 71], time=0.04878950119018555, ext_time=0.0060155391693115234, train_time=0.037767648696899414
[Epoch 1][Step 72], time=0.04896259307861328, ext_time=0.006114959716796875, train_time=0.037828922271728516
[Epoch 1][Step 73], time=0.0490107536315918, ext_time=0.0061261653900146484, train_time=0.037871599197387695
[Epoch 1][Step 74], time=0.04854297637939453, ext_time=0.006108522415161133, train_time=0.03745698928833008
[Epoch 1][Step 75], time=0.0495297908782959, ext_time=0.006222963333129883, train_time=0.03823280334472656
[Epoch 1][Step 76], time=0.04931306838989258, ext_time=0.006193876266479492, train_time=0.03807187080383301
[Epoch 1][Step 77], time=0.048665761947631836, ext_time=0.006104707717895508, train_time=0.0375518798828125
[Epoch 1][Step 78], time=0.048764944076538086, ext_time=0.006110429763793945, train_time=0.03767585754394531
[Epoch 1][Step 79], time=0.048592329025268555, ext_time=0.006078243255615234, train_time=0.037595272064208984
[Epoch 1][Step 80], time=0.04886960983276367, ext_time=0.0059778690338134766, train_time=0.038010358810424805
[Epoch 1][Step 81], time=0.049001216888427734, ext_time=0.006096839904785156, train_time=0.03796243667602539
[Epoch 1][Step 82], time=0.049089908599853516, ext_time=0.0061414241790771484, train_time=0.037941932678222656
[Epoch 1][Step 83], time=0.04935646057128906, ext_time=0.006176471710205078, train_time=0.038169145584106445
[Epoch 1][Step 84], time=0.048641204833984375, ext_time=0.006073951721191406, train_time=0.037570953369140625
[Epoch 1][Step 85], time=0.049275875091552734, ext_time=0.006093502044677734, train_time=0.03822207450866699
[Epoch 1][Step 86], time=0.048844099044799805, ext_time=0.006129264831542969, train_time=0.03771781921386719
[Epoch 1][Step 87], time=0.04929924011230469, ext_time=0.006083011627197266, train_time=0.03825211524963379
[Epoch 1][Step 88], time=0.048348188400268555, ext_time=0.0060787200927734375, train_time=0.0373687744140625
[Epoch 1][Step 89], time=0.04866909980773926, ext_time=0.006081581115722656, train_time=0.037628889083862305
[Epoch 1][Step 90], time=0.04903674125671387, ext_time=0.006101131439208984, train_time=0.03795480728149414
[Epoch 1][Step 91], time=0.04912924766540527, ext_time=0.006110191345214844, train_time=0.038037776947021484
[Epoch 1][Step 92], time=0.04889392852783203, ext_time=0.006112337112426758, train_time=0.037770986557006836
[Epoch 1][Step 93], time=0.048493385314941406, ext_time=0.0060808658599853516, train_time=0.03742718696594238
[Epoch 1][Step 94], time=0.048673391342163086, ext_time=0.0061299800872802734, train_time=0.03759932518005371
[Epoch 1][Step 95], time=0.0487971305847168, ext_time=0.006111860275268555, train_time=0.03777146339416504
[Epoch 1][Step 96], time=0.04906916618347168, ext_time=0.006124734878540039, train_time=0.03796219825744629
[Epoch 1][Step 97], time=0.04915118217468262, ext_time=0.006164073944091797, train_time=0.03790926933288574
[Epoch 1][Step 98], time=0.04874229431152344, ext_time=0.006081819534301758, train_time=0.03771090507507324
[Epoch 1][Step 99], time=0.049491167068481445, ext_time=0.006203174591064453, train_time=0.038309335708618164
[Epoch 1][Step 100], time=0.04860568046569824, ext_time=0.006140947341918945, train_time=0.0374910831451416
[Epoch 1][Step 101], time=0.04881882667541504, ext_time=0.006070137023925781, train_time=0.03782176971435547
[Epoch 1][Step 102], time=0.04923558235168457, ext_time=0.006172895431518555, train_time=0.03809785842895508
[Epoch 1][Step 103], time=0.049453020095825195, ext_time=0.0061817169189453125, train_time=0.038187265396118164
[Epoch 1][Step 104], time=0.04909014701843262, ext_time=0.006169557571411133, train_time=0.037889957427978516
[Epoch 1][Step 105], time=0.049063682556152344, ext_time=0.006099224090576172, train_time=0.03800559043884277
[Epoch 1][Step 106], time=0.04863452911376953, ext_time=0.006132841110229492, train_time=0.03751659393310547
[Epoch 1][Step 107], time=0.04894661903381348, ext_time=0.0060138702392578125, train_time=0.03799939155578613
[Epoch 1][Step 108], time=0.049384355545043945, ext_time=0.0060269832611083984, train_time=0.03842663764953613
[Epoch 1][Step 109], time=0.04893612861633301, ext_time=0.0061168670654296875, train_time=0.03786969184875488
[Epoch 1][Step 110], time=0.04896807670593262, ext_time=0.00615692138671875, train_time=0.03779006004333496
[Epoch 1][Step 111], time=0.04978132247924805, ext_time=0.006179332733154297, train_time=0.038590192794799805
[Epoch 1][Step 112], time=0.048999786376953125, ext_time=0.00608372688293457, train_time=0.03793835639953613
[Epoch 1][Step 113], time=0.04925179481506348, ext_time=0.006078481674194336, train_time=0.03824114799499512
[Epoch 1][Step 114], time=0.049115657806396484, ext_time=0.0061495304107666016, train_time=0.037911415100097656
[Epoch 1][Step 115], time=0.048757314682006836, ext_time=0.0061342716217041016, train_time=0.037654876708984375
[Epoch 1][Step 116], time=0.04864382743835449, ext_time=0.006101369857788086, train_time=0.03756904602050781
[Epoch 1][Step 117], time=0.04896712303161621, ext_time=0.006078481674194336, train_time=0.037912845611572266
[Epoch 1][Step 118], time=0.04897356033325195, ext_time=0.006116390228271484, train_time=0.03782963752746582
[Epoch 1][Step 119], time=0.04945778846740723, ext_time=0.006131410598754883, train_time=0.03826189041137695
[Epoch 1][Step 120], time=0.050798654556274414, ext_time=0.006076335906982422, train_time=0.03976607322692871
[Epoch 1][Step 121], time=0.04913592338562012, ext_time=0.006124734878540039, train_time=0.03798055648803711
[Epoch 1][Step 122], time=0.04899907112121582, ext_time=0.006110668182373047, train_time=0.03788876533508301
[Epoch 1][Step 123], time=0.04971742630004883, ext_time=0.006153106689453125, train_time=0.03856992721557617
[Epoch 1][Step 124], time=0.049266815185546875, ext_time=0.006146669387817383, train_time=0.038127899169921875
[Epoch 1][Step 125], time=0.048497676849365234, ext_time=0.006110668182373047, train_time=0.037479400634765625
[Epoch 1][Step 126], time=0.04943966865539551, ext_time=0.006100177764892578, train_time=0.03834819793701172
[Epoch 1][Step 127], time=0.05646681785583496, ext_time=0.00610804557800293, train_time=0.04540586471557617
[Epoch 1][Step 128], time=0.0491335391998291, ext_time=0.006157875061035156, train_time=0.037970542907714844
[Epoch 1][Step 129], time=0.049127817153930664, ext_time=0.006115436553955078, train_time=0.03802371025085449
[Epoch 1][Step 130], time=0.04873061180114746, ext_time=0.0060939788818359375, train_time=0.03764081001281738
[Epoch 1][Step 131], time=0.04859447479248047, ext_time=0.006077766418457031, train_time=0.037537574768066406
[Epoch 1][Step 132], time=0.04863286018371582, ext_time=0.006050586700439453, train_time=0.03762459754943848
[Epoch 1][Step 133], time=0.049329280853271484, ext_time=0.006230592727661133, train_time=0.038022518157958984
[Epoch 1][Step 134], time=0.04933428764343262, ext_time=0.006166219711303711, train_time=0.038176774978637695
[Epoch 1][Step 135], time=0.04913830757141113, ext_time=0.006135463714599609, train_time=0.03796744346618652
[Epoch 1][Step 136], time=0.04906940460205078, ext_time=0.00596165657043457, train_time=0.03824210166931152
[Epoch 1][Step 137], time=0.04864907264709473, ext_time=0.006090402603149414, train_time=0.037635087966918945
[Epoch 1][Step 138], time=0.0491337776184082, ext_time=0.006078958511352539, train_time=0.03802990913391113
[Epoch 1][Step 139], time=0.04872417449951172, ext_time=0.00612950325012207, train_time=0.03762531280517578
[Epoch 1][Step 140], time=0.049530029296875, ext_time=0.0060422420501708984, train_time=0.03855133056640625
[Epoch 1][Step 141], time=0.049715518951416016, ext_time=0.006135225296020508, train_time=0.03855013847351074
[Epoch 1][Step 142], time=0.04842782020568848, ext_time=0.006063699722290039, train_time=0.0374143123626709
[Epoch 1][Step 143], time=0.04841804504394531, ext_time=0.006066083908081055, train_time=0.03738665580749512
[Epoch 1][Step 144], time=0.048593997955322266, ext_time=0.006097078323364258, train_time=0.03751850128173828
[Epoch 1][Step 145], time=0.049155235290527344, ext_time=0.006143331527709961, train_time=0.03801250457763672
[Epoch 1][Step 146], time=0.04918670654296875, ext_time=0.0061798095703125, train_time=0.0379793643951416
[Epoch 1][Step 147], time=0.049141645431518555, ext_time=0.006198883056640625, train_time=0.03791356086730957
[Epoch 1][Step 148], time=0.04896879196166992, ext_time=0.0061359405517578125, train_time=0.03780031204223633
[Epoch 1][Step 149], time=0.04895210266113281, ext_time=0.006102561950683594, train_time=0.03783607482910156
[Epoch 1][Step 150], time=0.04948019981384277, ext_time=0.006012916564941406, train_time=0.03849673271179199
[Epoch 1][Step 151], time=0.04889369010925293, ext_time=0.006151437759399414, train_time=0.037744998931884766
[Epoch 1][Step 152], time=0.04898357391357422, ext_time=0.006067752838134766, train_time=0.03793191909790039
[Epoch 1][Step 153], time=0.048848628997802734, ext_time=0.006083011627197266, train_time=0.03783679008483887
[Epoch 1][Step 154], time=0.04901289939880371, ext_time=0.006048917770385742, train_time=0.038059234619140625
[Epoch 1][Step 155], time=0.46293139457702637, ext_time=0.006098270416259766, train_time=0.4519026279449463
[Epoch 1][Step 156], time=0.04933309555053711, ext_time=0.006211519241333008, train_time=0.0379946231842041
[Epoch 1][Step 157], time=0.048755645751953125, ext_time=0.006122589111328125, train_time=0.03771018981933594
[Epoch 1][Step 158], time=0.04898357391357422, ext_time=0.006017923355102539, train_time=0.037990570068359375
[Epoch 1][Step 159], time=0.04987597465515137, ext_time=0.006040096282958984, train_time=0.03886675834655762
[Epoch 1][Step 160], time=0.04913687705993652, ext_time=0.006138324737548828, train_time=0.037958383560180664
[Epoch 1][Step 161], time=0.04875826835632324, ext_time=0.006070852279663086, train_time=0.037700653076171875
[Epoch 1][Step 162], time=0.04953765869140625, ext_time=0.006230354309082031, train_time=0.03832221031188965
[Epoch 1][Step 163], time=0.04895305633544922, ext_time=0.006125450134277344, train_time=0.037799835205078125
[Epoch 1][Step 164], time=0.04869723320007324, ext_time=0.0060656070709228516, train_time=0.037634849548339844
[Epoch 1][Step 165], time=0.048618316650390625, ext_time=0.006081104278564453, train_time=0.03755593299865723
[Epoch 1][Step 166], time=0.048589468002319336, ext_time=0.006064176559448242, train_time=0.037567138671875
[Epoch 1][Step 167], time=0.04873180389404297, ext_time=0.006106376647949219, train_time=0.03759884834289551
[Epoch 1][Step 168], time=0.049210548400878906, ext_time=0.006094694137573242, train_time=0.038136959075927734
[Epoch 1][Step 169], time=0.053908586502075195, ext_time=0.006252288818359375, train_time=0.04254889488220215
[Epoch 1][Step 170], time=0.04935193061828613, ext_time=0.006085872650146484, train_time=0.03827095031738281
[Epoch 1][Step 171], time=0.04985308647155762, ext_time=0.006091594696044922, train_time=0.03875565528869629
[Epoch 1][Step 172], time=0.048483848571777344, ext_time=0.006023406982421875, train_time=0.03750276565551758
[Epoch 1][Step 173], time=0.04899120330810547, ext_time=0.006160259246826172, train_time=0.037865638732910156
[Epoch 1][Step 174], time=0.048982858657836914, ext_time=0.00610041618347168, train_time=0.0378420352935791
[Epoch 1][Step 175], time=0.04893040657043457, ext_time=0.006146907806396484, train_time=0.03779029846191406
[Epoch 1][Step 176], time=0.04899263381958008, ext_time=0.0061037540435791016, train_time=0.037955522537231445
[Epoch 1][Step 177], time=0.048532724380493164, ext_time=0.006157875061035156, train_time=0.037398338317871094
[Epoch 1][Step 178], time=0.04883599281311035, ext_time=0.0060307979583740234, train_time=0.03788495063781738
[Epoch 1][Step 179], time=0.04942584037780762, ext_time=0.006171464920043945, train_time=0.03825044631958008
[Epoch 1][Step 180], time=0.04906058311462402, ext_time=0.006051301956176758, train_time=0.03790426254272461
[Epoch 1][Step 181], time=0.050028324127197266, ext_time=0.006220579147338867, train_time=0.03873848915100098
[Epoch 1][Step 182], time=0.04856586456298828, ext_time=0.006052970886230469, train_time=0.037505149841308594
[Epoch 1][Step 183], time=0.04894065856933594, ext_time=0.006120443344116211, train_time=0.03780364990234375
[Epoch 1][Step 184], time=0.048980712890625, ext_time=0.006022214889526367, train_time=0.03805398941040039
[Epoch 1][Step 185], time=0.04922294616699219, ext_time=0.006181478500366211, train_time=0.03801441192626953
[Epoch 1][Step 186], time=0.04898977279663086, ext_time=0.006081819534301758, train_time=0.03794503211975098
[Epoch 1][Step 187], time=0.048923492431640625, ext_time=0.006124973297119141, train_time=0.037806034088134766
[Epoch 1][Step 188], time=0.04920768737792969, ext_time=0.006059885025024414, train_time=0.038234710693359375
[Epoch 1][Step 189], time=0.04873967170715332, ext_time=0.006047964096069336, train_time=0.03772783279418945
[Epoch 1][Step 190], time=0.04980182647705078, ext_time=0.006172657012939453, train_time=0.03862500190734863
[Epoch 1][Step 191], time=0.049540042877197266, ext_time=0.006186246871948242, train_time=0.038265228271484375
[Epoch 1][Step 192], time=0.04864048957824707, ext_time=0.006113529205322266, train_time=0.03753471374511719
[Epoch 1][Step 193], time=0.04894733428955078, ext_time=0.006142854690551758, train_time=0.03775954246520996
[Epoch 1][Step 194], time=0.04894542694091797, ext_time=0.006128549575805664, train_time=0.037798166275024414
[Epoch 1][Step 195], time=0.049803733825683594, ext_time=0.006193637847900391, train_time=0.03856205940246582
[Epoch 1][Step 196], time=0.04901695251464844, ext_time=0.006094932556152344, train_time=0.03795170783996582
[Epoch 1][Step 197], time=0.04902005195617676, ext_time=0.006150960922241211, train_time=0.03782320022583008
[Epoch 1][Step 198], time=0.049295902252197266, ext_time=0.006056308746337891, train_time=0.038279056549072266
[Epoch 1][Step 199], time=0.04900813102722168, ext_time=0.006111860275268555, train_time=0.037929534912109375
[Epoch 1][Step 200], time=0.04931640625, ext_time=0.006071567535400391, train_time=0.03827953338623047
[Epoch 1][Step 201], time=0.0490107536315918, ext_time=0.00615239143371582, train_time=0.03785228729248047
[Epoch 1][Step 202], time=0.04937911033630371, ext_time=0.006130695343017578, train_time=0.03828072547912598
[Epoch 1][Step 203], time=0.04914975166320801, ext_time=0.0061130523681640625, train_time=0.038079261779785156
[Epoch 1][Step 204], time=0.04878544807434082, ext_time=0.006087779998779297, train_time=0.03773975372314453
[Epoch 1][Step 205], time=0.04863429069519043, ext_time=0.006052255630493164, train_time=0.03761792182922363
[Epoch 1][Step 206], time=0.04920792579650879, ext_time=0.006055355072021484, train_time=0.03822588920593262
[Epoch 1][Step 207], time=0.04909634590148926, ext_time=0.006119489669799805, train_time=0.03803873062133789
[Epoch 1][Step 208], time=0.04939150810241699, ext_time=0.006143331527709961, train_time=0.038275957107543945
[Epoch 1][Step 209], time=0.04923605918884277, ext_time=0.00605010986328125, train_time=0.03831887245178223
[Epoch 1][Step 210], time=0.0490570068359375, ext_time=0.00609278678894043, train_time=0.0379486083984375
[Epoch 1][Step 211], time=0.04924416542053223, ext_time=0.006102561950683594, train_time=0.03812241554260254
[Epoch 1][Step 212], time=0.04917621612548828, ext_time=0.006144285202026367, train_time=0.03800678253173828
[Epoch 1][Step 213], time=0.04932975769042969, ext_time=0.006144523620605469, train_time=0.038129329681396484
[Epoch 1][Step 214], time=0.05672502517700195, ext_time=0.006043910980224609, train_time=0.037570953369140625
[Epoch 1][Step 215], time=0.04846000671386719, ext_time=0.006100893020629883, train_time=0.03737783432006836
[Epoch 1][Step 216], time=0.04954385757446289, ext_time=0.006197452545166016, train_time=0.03831648826599121
[Epoch 1][Step 217], time=0.04879426956176758, ext_time=0.006158113479614258, train_time=0.03765702247619629
[Epoch 1][Step 218], time=0.048125505447387695, ext_time=0.006054401397705078, train_time=0.03711748123168945
[Epoch 1][Step 219], time=0.048697471618652344, ext_time=0.006157875061035156, train_time=0.037525177001953125
[Epoch 1][Step 220], time=0.04841327667236328, ext_time=0.006081342697143555, train_time=0.037380218505859375
[Epoch 1][Step 221], time=0.04866170883178711, ext_time=0.006113529205322266, train_time=0.03754591941833496
[Epoch 1][Step 222], time=0.04895281791687012, ext_time=0.006158113479614258, train_time=0.0377659797668457
[Epoch 1][Step 223], time=0.05329155921936035, ext_time=0.006102085113525391, train_time=0.042232513427734375
[Epoch 1][Step 224], time=0.04918217658996582, ext_time=0.006000995635986328, train_time=0.038307905197143555
[Epoch 1][Step 225], time=0.04884791374206543, ext_time=0.006094217300415039, train_time=0.037760019302368164
[Epoch 1][Step 226], time=0.048605918884277344, ext_time=0.006067752838134766, train_time=0.03760647773742676
[Epoch 1][Step 227], time=0.04803657531738281, ext_time=0.0060100555419921875, train_time=0.03708982467651367
[Epoch 1][Step 228], time=0.04867672920227051, ext_time=0.0060727596282958984, train_time=0.03766226768493652
[Epoch 1][Step 229], time=0.04890084266662598, ext_time=0.0060846805572509766, train_time=0.03780031204223633
[Epoch 1][Step 230], time=0.04855775833129883, ext_time=0.006056785583496094, train_time=0.03751850128173828
[Epoch 1][Step 231], time=0.049551963806152344, ext_time=0.006041049957275391, train_time=0.03857755661010742
[Epoch 1][Step 232], time=0.048996686935424805, ext_time=0.00610661506652832, train_time=0.03791689872741699
[Epoch 1][Step 233], time=0.048745155334472656, ext_time=0.006125450134277344, train_time=0.03761577606201172
[Epoch 1][Step 234], time=0.04927659034729004, ext_time=0.006113767623901367, train_time=0.03810858726501465
[Epoch 1][Step 235], time=0.04872608184814453, ext_time=0.006033420562744141, train_time=0.03770780563354492
[Epoch 1][Step 236], time=0.049044132232666016, ext_time=0.00608372688293457, train_time=0.03795146942138672
[Epoch 1][Step 237], time=0.04889345169067383, ext_time=0.006066083908081055, train_time=0.03784751892089844
[Epoch 1][Step 238], time=0.04833865165710449, ext_time=0.0060460567474365234, train_time=0.03731489181518555
[Epoch 1][Step 239], time=0.04815244674682617, ext_time=0.006050825119018555, train_time=0.03715085983276367
[Epoch 1][Step 240], time=0.048912763595581055, ext_time=0.006119966506958008, train_time=0.037799835205078125
[Epoch 1][Step 241], time=0.048764944076538086, ext_time=0.0060651302337646484, train_time=0.03770613670349121
[Epoch 1][Step 242], time=0.0488588809967041, ext_time=0.006140470504760742, train_time=0.03774380683898926
[Epoch 1][Step 243], time=0.04890871047973633, ext_time=0.0061457157135009766, train_time=0.03773665428161621
[Epoch 1][Step 244], time=0.04939413070678711, ext_time=0.00620269775390625, train_time=0.0379643440246582
[Epoch 1][Step 245], time=0.04876279830932617, ext_time=0.006129026412963867, train_time=0.037622690200805664
[Epoch 1][Step 246], time=0.04896855354309082, ext_time=0.006019115447998047, train_time=0.03805232048034668
[Epoch 1][Step 247], time=0.04906630516052246, ext_time=0.006157875061035156, train_time=0.03789472579956055
[Epoch 1][Step 248], time=0.048829078674316406, ext_time=0.006061077117919922, train_time=0.037741899490356445
[Epoch 1][Step 249], time=0.04940938949584961, ext_time=0.006142377853393555, train_time=0.0382688045501709
[Epoch 1], time=13.117211103439331, loss=nan
[Epoch 2][Step 0], time=0.048940420150756836, ext_time=0.006063938140869141, train_time=0.037886857986450195
[Epoch 2][Step 1], time=0.04938340187072754, ext_time=0.006143808364868164, train_time=0.03816580772399902
[Epoch 2][Step 2], time=0.04916691780090332, ext_time=0.006151676177978516, train_time=0.037902116775512695
[Epoch 2][Step 3], time=0.0487523078918457, ext_time=0.006070137023925781, train_time=0.03767585754394531
[Epoch 2][Step 4], time=0.049611568450927734, ext_time=0.006102085113525391, train_time=0.038548946380615234
[Epoch 2][Step 5], time=0.048538923263549805, ext_time=0.0061187744140625, train_time=0.03741908073425293
[Epoch 2][Step 6], time=0.0492093563079834, ext_time=0.0060367584228515625, train_time=0.0382380485534668
[Epoch 2][Step 7], time=0.04920363426208496, ext_time=0.006070852279663086, train_time=0.03814244270324707
[Epoch 2][Step 8], time=0.049074411392211914, ext_time=0.006122112274169922, train_time=0.037943363189697266
[Epoch 2][Step 9], time=0.04906749725341797, ext_time=0.006074428558349609, train_time=0.03800773620605469
[Epoch 2][Step 10], time=0.048749446868896484, ext_time=0.006127834320068359, train_time=0.03761863708496094
[Epoch 2][Step 11], time=0.049466609954833984, ext_time=0.006103515625, train_time=0.0383603572845459
[Epoch 2][Step 12], time=0.04913496971130371, ext_time=0.0060803890228271484, train_time=0.03811335563659668
[Epoch 2][Step 13], time=0.04935121536254883, ext_time=0.006049633026123047, train_time=0.03834676742553711
[Epoch 2][Step 14], time=0.048815011978149414, ext_time=0.006118297576904297, train_time=0.03767681121826172
[Epoch 2][Step 15], time=0.04900217056274414, ext_time=0.006140232086181641, train_time=0.03783130645751953
[Epoch 2][Step 16], time=0.04945707321166992, ext_time=0.006222248077392578, train_time=0.03813457489013672
[Epoch 2][Step 17], time=0.04901432991027832, ext_time=0.00612640380859375, train_time=0.037882089614868164
[Epoch 2][Step 18], time=0.049021005630493164, ext_time=0.006082773208618164, train_time=0.03800463676452637
[Epoch 2][Step 19], time=0.04860687255859375, ext_time=0.006095170974731445, train_time=0.03751420974731445
[Epoch 2][Step 20], time=0.04914975166320801, ext_time=0.006113529205322266, train_time=0.03808164596557617
[Epoch 2][Step 21], time=0.04871964454650879, ext_time=0.006148815155029297, train_time=0.03756427764892578
[Epoch 2][Step 22], time=0.04904770851135254, ext_time=0.006145477294921875, train_time=0.03786802291870117
[Epoch 2][Step 23], time=0.04934406280517578, ext_time=0.0061626434326171875, train_time=0.038175344467163086
[Epoch 2][Step 24], time=0.04853963851928711, ext_time=0.006104946136474609, train_time=0.037459611892700195
[Epoch 2][Step 25], time=0.04900479316711426, ext_time=0.006150484085083008, train_time=0.03786134719848633
[Epoch 2][Step 26], time=0.0489962100982666, ext_time=0.006131172180175781, train_time=0.03784894943237305
[Epoch 2][Step 27], time=0.04894661903381348, ext_time=0.006161689758300781, train_time=0.03776431083679199
[Epoch 2][Step 28], time=0.05012321472167969, ext_time=0.006228923797607422, train_time=0.03888106346130371
[Epoch 2][Step 29], time=0.04951167106628418, ext_time=0.0062084197998046875, train_time=0.038225412368774414
[Epoch 2][Step 30], time=0.049304962158203125, ext_time=0.006170511245727539, train_time=0.038102149963378906
[Epoch 2][Step 31], time=0.0488743782043457, ext_time=0.006084442138671875, train_time=0.037815093994140625
[Epoch 2][Step 32], time=0.04895806312561035, ext_time=0.006008625030517578, train_time=0.0380091667175293
[Epoch 2][Step 33], time=0.04871010780334473, ext_time=0.006118059158325195, train_time=0.037612199783325195
[Epoch 2][Step 34], time=0.04860687255859375, ext_time=0.006105661392211914, train_time=0.03754138946533203
[Epoch 2][Step 35], time=0.04892611503601074, ext_time=0.006129026412963867, train_time=0.037779808044433594
[Epoch 2][Step 36], time=0.04887890815734863, ext_time=0.006183624267578125, train_time=0.0376436710357666
[Epoch 2][Step 37], time=0.05673646926879883, ext_time=0.006115436553955078, train_time=0.04561734199523926
[Epoch 2][Step 38], time=0.04845690727233887, ext_time=0.006049156188964844, train_time=0.037459373474121094
[Epoch 2][Step 39], time=0.04869365692138672, ext_time=0.006119728088378906, train_time=0.03764462471008301
[Epoch 2][Step 40], time=0.049284934997558594, ext_time=0.006129026412963867, train_time=0.03809762001037598
[Epoch 2][Step 41], time=0.04916191101074219, ext_time=0.0061228275299072266, train_time=0.03801441192626953
[Epoch 2][Step 42], time=0.04961967468261719, ext_time=0.006166219711303711, train_time=0.0383906364440918
[Epoch 2][Step 43], time=0.04856109619140625, ext_time=0.006040096282958984, train_time=0.037595272064208984
[Epoch 2][Step 44], time=0.0490717887878418, ext_time=0.006117343902587891, train_time=0.037938833236694336
[Epoch 2][Step 45], time=0.049831390380859375, ext_time=0.006140470504760742, train_time=0.0386807918548584
[Epoch 2][Step 46], time=0.04930305480957031, ext_time=0.0061435699462890625, train_time=0.03813600540161133
[Epoch 2][Step 47], time=0.04883384704589844, ext_time=0.006017446517944336, train_time=0.037872314453125
[Epoch 2][Step 48], time=0.048682451248168945, ext_time=0.0061109066009521484, train_time=0.03756523132324219
[Epoch 2][Step 49], time=0.04932069778442383, ext_time=0.006129741668701172, train_time=0.03815031051635742
[Epoch 2][Step 50], time=0.04943060874938965, ext_time=0.0060689449310302734, train_time=0.03841400146484375
[Epoch 2][Step 51], time=0.04951834678649902, ext_time=0.006224393844604492, train_time=0.038254737854003906
[Epoch 2][Step 52], time=0.049016475677490234, ext_time=0.0061151981353759766, train_time=0.03789710998535156
[Epoch 2][Step 53], time=0.049642086029052734, ext_time=0.0061206817626953125, train_time=0.038465023040771484
[Epoch 2][Step 54], time=0.0492098331451416, ext_time=0.006084442138671875, train_time=0.03815126419067383
[Epoch 2][Step 55], time=0.04868006706237793, ext_time=0.006072521209716797, train_time=0.03763461112976074
[Epoch 2][Step 56], time=0.04860353469848633, ext_time=0.006106853485107422, train_time=0.037558555603027344
[Epoch 2][Step 57], time=0.048741817474365234, ext_time=0.006166696548461914, train_time=0.03757739067077637
[Epoch 2][Step 58], time=0.04961037635803223, ext_time=0.006172657012939453, train_time=0.03845071792602539
[Epoch 2][Step 59], time=0.048801422119140625, ext_time=0.006090402603149414, train_time=0.03767967224121094
[Epoch 2][Step 60], time=0.04961991310119629, ext_time=0.0061795711517333984, train_time=0.0383915901184082
[Epoch 2][Step 61], time=0.04880523681640625, ext_time=0.006106853485107422, train_time=0.03769421577453613
[Epoch 2][Step 62], time=0.04900622367858887, ext_time=0.006052494049072266, train_time=0.037957191467285156
[Epoch 2][Step 63], time=0.04880332946777344, ext_time=0.006067514419555664, train_time=0.03774261474609375
[Epoch 2][Step 64], time=0.04924130439758301, ext_time=0.0060503482818603516, train_time=0.03825688362121582
[Epoch 2][Step 65], time=0.04906296730041504, ext_time=0.006166219711303711, train_time=0.03787422180175781
[Epoch 2][Step 66], time=0.04889059066772461, ext_time=0.0061533451080322266, train_time=0.03771233558654785
[Epoch 2][Step 67], time=0.04926013946533203, ext_time=0.006119966506958008, train_time=0.03809475898742676
[Epoch 2][Step 68], time=0.04960942268371582, ext_time=0.00611567497253418, train_time=0.038474321365356445
[Epoch 2][Step 69], time=0.0491328239440918, ext_time=0.00604557991027832, train_time=0.038115739822387695
[Epoch 2][Step 70], time=0.048972129821777344, ext_time=0.006114482879638672, train_time=0.03788304328918457
[Epoch 2][Step 71], time=0.04975104331970215, ext_time=0.006681680679321289, train_time=0.03808307647705078
[Epoch 2][Step 72], time=0.04872465133666992, ext_time=0.006077289581298828, train_time=0.03768301010131836
[Epoch 2][Step 73], time=0.04921245574951172, ext_time=0.006124734878540039, train_time=0.03804898262023926
[Epoch 2][Step 74], time=0.04901862144470215, ext_time=0.006161928176879883, train_time=0.03782153129577637
[Epoch 2][Step 75], time=0.04915785789489746, ext_time=0.00614476203918457, train_time=0.03797030448913574
[Epoch 2][Step 76], time=0.049706220626831055, ext_time=0.006230592727661133, train_time=0.03843832015991211
[Epoch 2][Step 77], time=0.04884815216064453, ext_time=0.0061109066009521484, train_time=0.03774118423461914
[Epoch 2][Step 78], time=0.04891800880432129, ext_time=0.0061283111572265625, train_time=0.037766218185424805
[Epoch 2][Step 79], time=0.04867911338806152, ext_time=0.006070613861083984, train_time=0.03768467903137207
[Epoch 2][Step 80], time=0.048761606216430664, ext_time=0.0060579776763916016, train_time=0.03775334358215332
[Epoch 2][Step 81], time=0.04893231391906738, ext_time=0.006049633026123047, train_time=0.037876129150390625
[Epoch 2][Step 82], time=0.049134254455566406, ext_time=0.006108283996582031, train_time=0.03798103332519531
[Epoch 2][Step 83], time=0.049190521240234375, ext_time=0.006129264831542969, train_time=0.03805398941040039
[Epoch 2][Step 84], time=0.04904675483703613, ext_time=0.00614476203918457, train_time=0.03786134719848633
[Epoch 2][Step 85], time=0.04861187934875488, ext_time=0.006058216094970703, train_time=0.03760051727294922
[Epoch 2][Step 86], time=0.0485382080078125, ext_time=0.006108760833740234, train_time=0.03742694854736328
[Epoch 2][Step 87], time=0.04902338981628418, ext_time=0.0060977935791015625, train_time=0.03796076774597168
[Epoch 2][Step 88], time=0.048685550689697266, ext_time=0.006018877029418945, train_time=0.037757158279418945
[Epoch 2][Step 89], time=0.04899191856384277, ext_time=0.006082773208618164, train_time=0.037940263748168945
[Epoch 2][Step 90], time=0.04934859275817871, ext_time=0.006220102310180664, train_time=0.03812098503112793
[Epoch 2][Step 91], time=0.05003714561462402, ext_time=0.006196260452270508, train_time=0.03874635696411133
[Epoch 2][Step 92], time=0.04898357391357422, ext_time=0.006117343902587891, train_time=0.03791666030883789
[Epoch 2][Step 93], time=0.04905200004577637, ext_time=0.0061032772064208984, train_time=0.03792595863342285
[Epoch 2][Step 94], time=0.048389434814453125, ext_time=0.006114006042480469, train_time=0.03731846809387207
[Epoch 2][Step 95], time=0.04882621765136719, ext_time=0.006033658981323242, train_time=0.0377957820892334
[Epoch 2][Step 96], time=0.048963308334350586, ext_time=0.006011962890625, train_time=0.03798031806945801
[Epoch 2][Step 97], time=0.04926776885986328, ext_time=0.0061566829681396484, train_time=0.038074493408203125
[Epoch 2][Step 98], time=0.049367427825927734, ext_time=0.0061185359954833984, train_time=0.03823661804199219
[Epoch 2][Step 99], time=0.04914259910583496, ext_time=0.006108999252319336, train_time=0.038038015365600586
[Epoch 2][Step 100], time=0.04902005195617676, ext_time=0.00607752799987793, train_time=0.037958621978759766
[Epoch 2][Step 101], time=0.049141645431518555, ext_time=0.006159305572509766, train_time=0.03801250457763672
[Epoch 2][Step 102], time=0.0490872859954834, ext_time=0.006128787994384766, train_time=0.03795433044433594
[Epoch 2][Step 103], time=0.049858808517456055, ext_time=0.0061681270599365234, train_time=0.03859829902648926
[Epoch 2][Step 104], time=0.04982256889343262, ext_time=0.006254911422729492, train_time=0.03851819038391113
[Epoch 2][Step 105], time=0.04896879196166992, ext_time=0.006085634231567383, train_time=0.03792071342468262
[Epoch 2][Step 106], time=0.04863405227661133, ext_time=0.0061113834381103516, train_time=0.03754425048828125
[Epoch 2][Step 107], time=0.04878664016723633, ext_time=0.006073474884033203, train_time=0.03773927688598633
[Epoch 2][Step 108], time=0.048996925354003906, ext_time=0.006072044372558594, train_time=0.037981510162353516
[Epoch 2][Step 109], time=0.04877209663391113, ext_time=0.00606083869934082, train_time=0.037790536880493164
[Epoch 2][Step 110], time=0.04904580116271973, ext_time=0.006122112274169922, train_time=0.037882089614868164
[Epoch 2][Step 111], time=0.049080610275268555, ext_time=0.006085395812988281, train_time=0.03797268867492676
[Epoch 2][Step 112], time=0.0492854118347168, ext_time=0.006140470504760742, train_time=0.03808736801147461
[Epoch 2][Step 113], time=0.04872441291809082, ext_time=0.006062984466552734, train_time=0.0377354621887207
[Epoch 2][Step 114], time=0.049312591552734375, ext_time=0.006163358688354492, train_time=0.03810620307922363
[Epoch 2][Step 115], time=0.04863452911376953, ext_time=0.006100177764892578, train_time=0.03755450248718262
[Epoch 2][Step 116], time=0.04897952079772949, ext_time=0.006098270416259766, train_time=0.037912607192993164
[Epoch 2][Step 117], time=0.048888206481933594, ext_time=0.0061397552490234375, train_time=0.03777766227722168
[Epoch 2][Step 118], time=0.04905080795288086, ext_time=0.006116390228271484, train_time=0.03787708282470703
[Epoch 2][Step 119], time=0.04883098602294922, ext_time=0.006113767623901367, train_time=0.03767991065979004
[Epoch 2][Step 120], time=0.04998064041137695, ext_time=0.006167411804199219, train_time=0.03881549835205078
[Epoch 2][Step 121], time=0.04945230484008789, ext_time=0.006118297576904297, train_time=0.038338422775268555
[Epoch 2][Step 122], time=0.04980134963989258, ext_time=0.006117820739746094, train_time=0.03869342803955078
[Epoch 2][Step 123], time=0.04957222938537598, ext_time=0.006154298782348633, train_time=0.038439273834228516
[Epoch 2][Step 124], time=0.049256086349487305, ext_time=0.006136894226074219, train_time=0.03811192512512207
[Epoch 2][Step 125], time=0.04838919639587402, ext_time=0.0060842037200927734, train_time=0.037342071533203125
[Epoch 2][Step 126], time=0.04938960075378418, ext_time=0.006108999252319336, train_time=0.03835010528564453
[Epoch 2][Step 127], time=0.04982280731201172, ext_time=0.006094455718994141, train_time=0.03878307342529297
[Epoch 2][Step 128], time=0.04933357238769531, ext_time=0.0061566829681396484, train_time=0.03813767433166504
[Epoch 2][Step 129], time=0.04955935478210449, ext_time=0.006148099899291992, train_time=0.038433074951171875
[Epoch 2][Step 130], time=0.04929018020629883, ext_time=0.00605463981628418, train_time=0.038194894790649414
[Epoch 2][Step 131], time=0.04843759536743164, ext_time=0.006060600280761719, train_time=0.037438392639160156
[Epoch 2][Step 132], time=0.048560142517089844, ext_time=0.006166934967041016, train_time=0.03740668296813965
[Epoch 2][Step 133], time=0.04990124702453613, ext_time=0.006186723709106445, train_time=0.03860902786254883
[Epoch 2][Step 134], time=0.05536961555480957, ext_time=0.006192445755004883, train_time=0.0378420352935791
[Epoch 2][Step 135], time=0.049173593521118164, ext_time=0.006174325942993164, train_time=0.03801870346069336
[Epoch 2][Step 136], time=0.04906773567199707, ext_time=0.005968570709228516, train_time=0.038225412368774414
[Epoch 2][Step 137], time=0.04876446723937988, ext_time=0.006088733673095703, train_time=0.03772568702697754
[Epoch 2][Step 138], time=0.04913163185119629, ext_time=0.006151437759399414, train_time=0.037932395935058594
[Epoch 2][Step 139], time=0.04875636100769043, ext_time=0.006064653396606445, train_time=0.037690162658691406
[Epoch 2][Step 140], time=0.04976797103881836, ext_time=0.006102800369262695, train_time=0.038726806640625
[Epoch 2][Step 141], time=0.049781084060668945, ext_time=0.006272792816162109, train_time=0.03843188285827637
[Epoch 2][Step 142], time=0.04931497573852539, ext_time=0.00616002082824707, train_time=0.038152456283569336
[Epoch 2][Step 143], time=0.04884600639343262, ext_time=0.006077766418457031, train_time=0.03777432441711426
[Epoch 2][Step 144], time=0.04888582229614258, ext_time=0.006119251251220703, train_time=0.037731170654296875
[Epoch 2][Step 145], time=0.04911923408508301, ext_time=0.006134510040283203, train_time=0.0380098819732666
[Epoch 2][Step 146], time=0.04889845848083496, ext_time=0.0061528682708740234, train_time=0.037758827209472656
[Epoch 2][Step 147], time=0.04939675331115723, ext_time=0.006155729293823242, train_time=0.0381925106048584
[Epoch 2][Step 148], time=0.04887819290161133, ext_time=0.0060482025146484375, train_time=0.03784894943237305
[Epoch 2][Step 149], time=0.048553466796875, ext_time=0.006062507629394531, train_time=0.037507057189941406
[Epoch 2][Step 150], time=0.04931640625, ext_time=0.006096363067626953, train_time=0.03821253776550293
[Epoch 2][Step 151], time=0.04932045936584473, ext_time=0.00614166259765625, train_time=0.03813576698303223
[Epoch 2][Step 152], time=0.048813819885253906, ext_time=0.0060651302337646484, train_time=0.03774261474609375
[Epoch 2][Step 153], time=0.04897713661193848, ext_time=0.006119966506958008, train_time=0.0379030704498291
[Epoch 2][Step 154], time=0.048462629318237305, ext_time=0.006117582321166992, train_time=0.03739643096923828
[Epoch 2][Step 155], time=0.04937267303466797, ext_time=0.006179332733154297, train_time=0.03816795349121094
[Epoch 2][Step 156], time=0.0484161376953125, ext_time=0.006138801574707031, train_time=0.037308454513549805
[Epoch 2][Step 157], time=0.04914236068725586, ext_time=0.0061571598052978516, train_time=0.03801274299621582
[Epoch 2][Step 158], time=0.04873776435852051, ext_time=0.006095170974731445, train_time=0.03766942024230957
[Epoch 2][Step 159], time=0.04940676689147949, ext_time=0.006018638610839844, train_time=0.03841066360473633
[Epoch 2][Step 160], time=0.04886794090270996, ext_time=0.006096363067626953, train_time=0.03779292106628418
[Epoch 2][Step 161], time=0.04868268966674805, ext_time=0.006140232086181641, train_time=0.037552595138549805
[Epoch 2][Step 162], time=0.04941821098327637, ext_time=0.006150722503662109, train_time=0.038231611251831055
[Epoch 2][Step 163], time=0.04920530319213867, ext_time=0.006052732467651367, train_time=0.03815627098083496
[Epoch 2][Step 164], time=0.0487675666809082, ext_time=0.006122589111328125, train_time=0.03768110275268555
[Epoch 2][Step 165], time=0.04934954643249512, ext_time=0.00606536865234375, train_time=0.03832244873046875
[Epoch 2][Step 166], time=0.04874062538146973, ext_time=0.006116151809692383, train_time=0.03764963150024414
[Epoch 2][Step 167], time=0.04933309555053711, ext_time=0.006155967712402344, train_time=0.038164615631103516
[Epoch 2][Step 168], time=0.049771785736083984, ext_time=0.00611567497253418, train_time=0.03862953186035156
[Epoch 2][Step 169], time=0.049997806549072266, ext_time=0.006183624267578125, train_time=0.03870058059692383
[Epoch 2][Step 170], time=0.04952669143676758, ext_time=0.006206512451171875, train_time=0.03829193115234375
[Epoch 2][Step 171], time=0.048673152923583984, ext_time=0.006051063537597656, train_time=0.03765535354614258
[Epoch 2][Step 172], time=0.04842805862426758, ext_time=0.0060694217681884766, train_time=0.03737497329711914
[Epoch 2][Step 173], time=0.04916048049926758, ext_time=0.006093263626098633, train_time=0.03806805610656738
[Epoch 2][Step 174], time=0.04878425598144531, ext_time=0.006123542785644531, train_time=0.037644147872924805
[Epoch 2][Step 175], time=0.04875922203063965, ext_time=0.006136178970336914, train_time=0.03762960433959961
[Epoch 2][Step 176], time=0.04864668846130371, ext_time=0.006107330322265625, train_time=0.03759002685546875
[Epoch 2][Step 177], time=0.04859161376953125, ext_time=0.006087541580200195, train_time=0.03751873970031738
[Epoch 2][Step 178], time=0.048070669174194336, ext_time=0.006046295166015625, train_time=0.037096261978149414
[Epoch 2][Step 179], time=0.050219058990478516, ext_time=0.006230831146240234, train_time=0.038834571838378906
[Epoch 2][Step 180], time=0.04944109916687012, ext_time=0.0060803890228271484, train_time=0.038370370864868164
[Epoch 2][Step 181], time=0.04983782768249512, ext_time=0.006173849105834961, train_time=0.038588523864746094
[Epoch 2][Step 182], time=0.049147844314575195, ext_time=0.0061566829681396484, train_time=0.03797459602355957
[Epoch 2][Step 183], time=0.04963254928588867, ext_time=0.006188869476318359, train_time=0.03839397430419922
[Epoch 2][Step 184], time=0.04863381385803223, ext_time=0.006052494049072266, train_time=0.03764986991882324
[Epoch 2][Step 185], time=0.04899740219116211, ext_time=0.006196498870849609, train_time=0.037811994552612305
[Epoch 2][Step 186], time=0.049404144287109375, ext_time=0.006174802780151367, train_time=0.03817629814147949
[Epoch 2][Step 187], time=0.049241065979003906, ext_time=0.006161689758300781, train_time=0.03807377815246582
[Epoch 2][Step 188], time=0.04914593696594238, ext_time=0.0060863494873046875, train_time=0.03809523582458496
[Epoch 2][Step 189], time=0.048665523529052734, ext_time=0.0060617923736572266, train_time=0.03761029243469238
[Epoch 2][Step 190], time=0.049443960189819336, ext_time=0.006083965301513672, train_time=0.03836870193481445
[Epoch 2][Step 191], time=0.0489964485168457, ext_time=0.0061419010162353516, train_time=0.037819862365722656
[Epoch 2][Step 192], time=0.04905581474304199, ext_time=0.006107330322265625, train_time=0.037987709045410156
[Epoch 2][Step 193], time=0.04890871047973633, ext_time=0.006070137023925781, train_time=0.037815093994140625
[Epoch 2][Step 194], time=0.049067020416259766, ext_time=0.006158113479614258, train_time=0.03787684440612793
[Epoch 2][Step 195], time=0.04918956756591797, ext_time=0.006131649017333984, train_time=0.03801608085632324
[Epoch 2][Step 196], time=0.04864096641540527, ext_time=0.006073713302612305, train_time=0.03760075569152832
[Epoch 2][Step 197], time=0.048629045486450195, ext_time=0.0060770511627197266, train_time=0.03756141662597656
[Epoch 2][Step 198], time=0.049092769622802734, ext_time=0.00637507438659668, train_time=0.03779721260070801
[Epoch 2][Step 199], time=0.0491030216217041, ext_time=0.006162166595458984, train_time=0.03793931007385254
[Epoch 2][Step 200], time=0.04887080192565918, ext_time=0.006123542785644531, train_time=0.037750244140625
[Epoch 2][Step 201], time=0.048911094665527344, ext_time=0.006075859069824219, train_time=0.03784823417663574
[Epoch 2][Step 202], time=0.049407243728637695, ext_time=0.006081342697143555, train_time=0.03836989402770996
[Epoch 2][Step 203], time=0.0489659309387207, ext_time=0.0061016082763671875, train_time=0.037886619567871094
[Epoch 2][Step 204], time=0.048692941665649414, ext_time=0.0060842037200927734, train_time=0.03763580322265625
[Epoch 2][Step 205], time=0.04921770095825195, ext_time=0.006117343902587891, train_time=0.0381159782409668
[Epoch 2][Step 206], time=0.049120187759399414, ext_time=0.006009101867675781, train_time=0.0381779670715332
[Epoch 2][Step 207], time=0.048764705657958984, ext_time=0.006130218505859375, train_time=0.037619829177856445
[Epoch 2][Step 208], time=0.049048423767089844, ext_time=0.0061740875244140625, train_time=0.037883758544921875
[Epoch 2][Step 209], time=0.04916095733642578, ext_time=0.00608372688293457, train_time=0.03813958168029785
[Epoch 2][Step 210], time=0.049970388412475586, ext_time=0.0061817169189453125, train_time=0.03870081901550293
[Epoch 2][Step 211], time=0.04927515983581543, ext_time=0.006112813949584961, train_time=0.038176536560058594
[Epoch 2][Step 212], time=0.04886054992675781, ext_time=0.006123781204223633, train_time=0.03774380683898926
[Epoch 2][Step 213], time=0.04926609992980957, ext_time=0.006108522415161133, train_time=0.03812980651855469
[Epoch 2][Step 214], time=0.04883003234863281, ext_time=0.0061647891998291016, train_time=0.03768634796142578
[Epoch 2][Step 215], time=0.049043893814086914, ext_time=0.00622868537902832, train_time=0.037819623947143555
[Epoch 2][Step 216], time=0.04973649978637695, ext_time=0.0061187744140625, train_time=0.03864145278930664
[Epoch 2][Step 217], time=0.04921698570251465, ext_time=0.006119489669799805, train_time=0.03807568550109863
[Epoch 2][Step 218], time=0.04865717887878418, ext_time=0.0060710906982421875, train_time=0.037642717361450195
[Epoch 2][Step 219], time=0.04915976524353027, ext_time=0.006133556365966797, train_time=0.03797173500061035
[Epoch 2][Step 220], time=0.04858851432800293, ext_time=0.0060405731201171875, train_time=0.037630319595336914
[Epoch 2][Step 221], time=0.048783302307128906, ext_time=0.0061070919036865234, train_time=0.03770565986633301
[Epoch 2][Step 222], time=0.04893970489501953, ext_time=0.00613856315612793, train_time=0.03778433799743652
[Epoch 2][Step 223], time=0.04941868782043457, ext_time=0.006021022796630859, train_time=0.03851461410522461
[Epoch 2][Step 224], time=0.04898548126220703, ext_time=0.006085634231567383, train_time=0.03797578811645508
[Epoch 2][Step 225], time=0.04925417900085449, ext_time=0.0061190128326416016, train_time=0.0381319522857666
[Epoch 2][Step 226], time=0.048838138580322266, ext_time=0.006107807159423828, train_time=0.03772878646850586
[Epoch 2][Step 227], time=0.048528194427490234, ext_time=0.006044149398803711, train_time=0.03759050369262695
[Epoch 2][Step 228], time=0.04881739616394043, ext_time=0.0060482025146484375, train_time=0.03778576850891113
[Epoch 2][Step 229], time=0.049550533294677734, ext_time=0.006193399429321289, train_time=0.03830361366271973
[Epoch 2][Step 230], time=0.04918980598449707, ext_time=0.006146430969238281, train_time=0.03802776336669922
[Epoch 2][Step 231], time=0.04890775680541992, ext_time=0.006112098693847656, train_time=0.03778696060180664
[Epoch 2][Step 232], time=0.04879045486450195, ext_time=0.0060884952545166016, train_time=0.03766608238220215
[Epoch 2][Step 233], time=0.049141883850097656, ext_time=0.006109952926635742, train_time=0.03798413276672363
[Epoch 2][Step 234], time=0.04971885681152344, ext_time=0.006152153015136719, train_time=0.03855085372924805
[Epoch 2][Step 235], time=0.0492708683013916, ext_time=0.006193876266479492, train_time=0.03807973861694336
[Epoch 2][Step 236], time=0.04928421974182129, ext_time=0.006064176559448242, train_time=0.03821420669555664
[Epoch 2][Step 237], time=0.049031734466552734, ext_time=0.006091594696044922, train_time=0.037923574447631836
[Epoch 2][Step 238], time=0.04890775680541992, ext_time=0.006133079528808594, train_time=0.037767648696899414
[Epoch 2][Step 239], time=0.048528194427490234, ext_time=0.006149768829345703, train_time=0.03740334510803223
[Epoch 2][Step 240], time=0.04867982864379883, ext_time=0.006052255630493164, train_time=0.03766655921936035
[Epoch 2][Step 241], time=0.04849958419799805, ext_time=0.0061206817626953125, train_time=0.037396907806396484
[Epoch 2][Step 242], time=0.04888606071472168, ext_time=0.006074666976928711, train_time=0.037801265716552734
[Epoch 2][Step 243], time=0.048891544342041016, ext_time=0.0061800479888916016, train_time=0.037700653076171875
[Epoch 2][Step 244], time=0.04884076118469238, ext_time=0.006201744079589844, train_time=0.0376436710357666
[Epoch 2][Step 245], time=0.048938751220703125, ext_time=0.006070137023925781, train_time=0.0378873348236084
[Epoch 2][Step 246], time=0.04883766174316406, ext_time=0.006070852279663086, train_time=0.037809133529663086
[Epoch 2][Step 247], time=0.04906344413757324, ext_time=0.006123065948486328, train_time=0.0379331111907959
[Epoch 2][Step 248], time=0.04899287223815918, ext_time=0.006064653396606445, train_time=0.03788447380065918
[Epoch 2][Step 249], time=0.04964447021484375, ext_time=0.006195545196533203, train_time=0.03838658332824707
[Epoch 2], time=12.298096895217896, loss=nan
[Epoch 3][Step 0], time=0.04929924011230469, ext_time=0.0060939788818359375, train_time=0.03820514678955078
[Epoch 3][Step 1], time=0.050098419189453125, ext_time=0.006205320358276367, train_time=0.03880000114440918
[Epoch 3][Step 2], time=0.0490264892578125, ext_time=0.0061647891998291016, train_time=0.03783273696899414
[Epoch 3][Step 3], time=0.04880714416503906, ext_time=0.006137847900390625, train_time=0.03769207000732422
[Epoch 3][Step 4], time=0.04945683479309082, ext_time=0.006136894226074219, train_time=0.038329362869262695
[Epoch 3][Step 5], time=0.04877877235412598, ext_time=0.006096839904785156, train_time=0.03768610954284668
[Epoch 3][Step 6], time=0.04935932159423828, ext_time=0.006165742874145508, train_time=0.03816843032836914
[Epoch 3][Step 7], time=0.04918265342712402, ext_time=0.006121635437011719, train_time=0.038030385971069336
[Epoch 3][Step 8], time=0.04933571815490723, ext_time=0.006056070327758789, train_time=0.038286447525024414
[Epoch 3][Step 9], time=0.04954719543457031, ext_time=0.006140470504760742, train_time=0.03842306137084961
[Epoch 3][Step 10], time=0.04927539825439453, ext_time=0.006136894226074219, train_time=0.0381162166595459
[Epoch 3][Step 11], time=0.04941153526306152, ext_time=0.006227970123291016, train_time=0.03820919990539551
[Epoch 3][Step 12], time=0.04889178276062012, ext_time=0.0060882568359375, train_time=0.037880659103393555
[Epoch 3][Step 13], time=0.048666954040527344, ext_time=0.006155490875244141, train_time=0.037523508071899414
[Epoch 3][Step 14], time=0.04909849166870117, ext_time=0.006211757659912109, train_time=0.0378727912902832
[Epoch 3][Step 15], time=0.04888439178466797, ext_time=0.006112813949584961, train_time=0.037776947021484375
[Epoch 3][Step 16], time=0.04874420166015625, ext_time=0.006092071533203125, train_time=0.03766751289367676
[Epoch 3][Step 17], time=0.05072641372680664, ext_time=0.007179975509643555, train_time=0.03849625587463379
[Epoch 3][Step 18], time=0.04919910430908203, ext_time=0.006121635437011719, train_time=0.03805065155029297
[Epoch 3][Step 19], time=0.048813819885253906, ext_time=0.006137847900390625, train_time=0.03767061233520508
[Epoch 3][Step 20], time=0.04909801483154297, ext_time=0.006091594696044922, train_time=0.03803610801696777
[Epoch 3][Step 21], time=0.048697710037231445, ext_time=0.006089925765991211, train_time=0.03759574890136719
[Epoch 3][Step 22], time=0.04913043975830078, ext_time=0.006109714508056641, train_time=0.03798103332519531
[Epoch 3][Step 23], time=0.04955935478210449, ext_time=0.006150722503662109, train_time=0.038342952728271484
[Epoch 3][Step 24], time=0.048645734786987305, ext_time=0.006110191345214844, train_time=0.03760027885437012
[Epoch 3][Step 25], time=0.0487363338470459, ext_time=0.006158351898193359, train_time=0.03756093978881836
[Epoch 3][Step 26], time=0.04997873306274414, ext_time=0.006192922592163086, train_time=0.03872823715209961
[Epoch 3][Step 27], time=0.048630475997924805, ext_time=0.006058454513549805, train_time=0.037564992904663086
[Epoch 3][Step 28], time=0.37758898735046387, ext_time=0.006126880645751953, train_time=0.3664429187774658
[Epoch 3][Step 29], time=0.04951786994934082, ext_time=0.006209850311279297, train_time=0.03823661804199219
[Epoch 3][Step 30], time=0.04897499084472656, ext_time=0.006066322326660156, train_time=0.03791022300720215
[Epoch 3][Step 31], time=0.04957103729248047, ext_time=0.006083965301513672, train_time=0.038515329360961914
[Epoch 3][Step 32], time=0.04838824272155762, ext_time=0.006089210510253906, train_time=0.037364959716796875
[Epoch 3][Step 33], time=0.0490267276763916, ext_time=0.006124019622802734, train_time=0.03788280487060547
[Epoch 3][Step 34], time=0.04854011535644531, ext_time=0.0060138702392578125, train_time=0.03757286071777344
[Epoch 3][Step 35], time=0.048840999603271484, ext_time=0.006145954132080078, train_time=0.03771209716796875
[Epoch 3][Step 36], time=0.0494837760925293, ext_time=0.0062711238861083984, train_time=0.038175344467163086
[Epoch 3][Step 37], time=0.0491175651550293, ext_time=0.006151914596557617, train_time=0.0379636287689209
[Epoch 3][Step 38], time=0.048310041427612305, ext_time=0.0060198307037353516, train_time=0.03734993934631348
[Epoch 3][Step 39], time=0.04880881309509277, ext_time=0.006093502044677734, train_time=0.037789106369018555
[Epoch 3][Step 40], time=0.04952096939086914, ext_time=0.006172895431518555, train_time=0.038266897201538086
[Epoch 3][Step 41], time=0.04965686798095703, ext_time=0.006196737289428711, train_time=0.0384061336517334
[Epoch 3][Step 42], time=0.04991269111633301, ext_time=0.006181478500366211, train_time=0.03862333297729492
[Epoch 3][Step 43], time=0.04872250556945801, ext_time=0.00604557991027832, train_time=0.03772163391113281
[Epoch 3][Step 44], time=0.04949355125427246, ext_time=0.006135702133178711, train_time=0.03838920593261719
[Epoch 3][Step 45], time=0.049161672592163086, ext_time=0.006155252456665039, train_time=0.03794145584106445
[Epoch 3][Step 46], time=0.049021244049072266, ext_time=0.006166696548461914, train_time=0.037877559661865234
[Epoch 3][Step 47], time=0.04956388473510742, ext_time=0.006164073944091797, train_time=0.0384519100189209
[Epoch 3][Step 48], time=0.04969930648803711, ext_time=0.006163358688354492, train_time=0.03847098350524902
[Epoch 3][Step 49], time=0.04912734031677246, ext_time=0.0060422420501708984, train_time=0.038123130798339844
[Epoch 3][Step 50], time=0.048679351806640625, ext_time=0.00613856315612793, train_time=0.03753042221069336
[Epoch 3][Step 51], time=0.04937243461608887, ext_time=0.006124019622802734, train_time=0.03819537162780762
[Epoch 3][Step 52], time=0.04914212226867676, ext_time=0.00612640380859375, train_time=0.0381016731262207
[Epoch 3][Step 53], time=0.04994988441467285, ext_time=0.006175041198730469, train_time=0.03868603706359863
[Epoch 3][Step 54], time=0.05690598487854004, ext_time=0.006015300750732422, train_time=0.038091421127319336
[Epoch 3][Step 55], time=0.04843711853027344, ext_time=0.0060846805572509766, train_time=0.03739118576049805
[Epoch 3][Step 56], time=0.048987388610839844, ext_time=0.006081104278564453, train_time=0.03794407844543457
[Epoch 3][Step 57], time=0.048299312591552734, ext_time=0.005991935729980469, train_time=0.03738522529602051
[Epoch 3][Step 58], time=0.04910016059875488, ext_time=0.0061244964599609375, train_time=0.0379791259765625
[Epoch 3][Step 59], time=0.04926776885986328, ext_time=0.006193637847900391, train_time=0.038045644760131836
[Epoch 3][Step 60], time=0.04967021942138672, ext_time=0.006184577941894531, train_time=0.03842043876647949
[Epoch 3][Step 61], time=0.049010276794433594, ext_time=0.0061511993408203125, train_time=0.03785228729248047
[Epoch 3][Step 62], time=0.04899120330810547, ext_time=0.006094217300415039, train_time=0.03788256645202637
[Epoch 3][Step 63], time=0.04907083511352539, ext_time=0.006181478500366211, train_time=0.03791618347167969
[Epoch 3][Step 64], time=0.04906606674194336, ext_time=0.006024837493896484, train_time=0.03810691833496094
[Epoch 3][Step 65], time=0.049562692642211914, ext_time=0.0061931610107421875, train_time=0.03835344314575195
[Epoch 3][Step 66], time=0.04888772964477539, ext_time=0.0061151981353759766, train_time=0.0377500057220459
[Epoch 3][Step 67], time=0.048516035079956055, ext_time=0.006039619445800781, train_time=0.037493228912353516
[Epoch 3][Step 68], time=0.048726558685302734, ext_time=0.006134986877441406, train_time=0.03756856918334961
[Epoch 3][Step 69], time=0.04837846755981445, ext_time=0.006087064743041992, train_time=0.037279367446899414
[Epoch 3][Step 70], time=0.04899716377258301, ext_time=0.006180763244628906, train_time=0.037839651107788086
[Epoch 3][Step 71], time=0.04899787902832031, ext_time=0.006061553955078125, train_time=0.0379335880279541
[Epoch 3][Step 72], time=0.04866623878479004, ext_time=0.006124258041381836, train_time=0.0375361442565918
[Epoch 3][Step 73], time=0.04932522773742676, ext_time=0.0061817169189453125, train_time=0.03812694549560547
[Epoch 3][Step 74], time=0.04900050163269043, ext_time=0.00609898567199707, train_time=0.03790163993835449
[Epoch 3][Step 75], time=0.04904794692993164, ext_time=0.006110429763793945, train_time=0.03789234161376953
[Epoch 3][Step 76], time=0.0495452880859375, ext_time=0.006181478500366211, train_time=0.038307905197143555
[Epoch 3][Step 77], time=0.0492861270904541, ext_time=0.006173610687255859, train_time=0.038053035736083984
[Epoch 3][Step 78], time=0.3014538288116455, ext_time=0.006102800369262695, train_time=0.2903769016265869
[Epoch 3][Step 79], time=0.04852628707885742, ext_time=0.0060651302337646484, train_time=0.03744697570800781
[Epoch 3][Step 80], time=0.04870963096618652, ext_time=0.006125926971435547, train_time=0.03759264945983887
[Epoch 3][Step 81], time=0.04903244972229004, ext_time=0.0059604644775390625, train_time=0.03816080093383789
[Epoch 3][Step 82], time=0.04916501045227051, ext_time=0.006150484085083008, train_time=0.03797101974487305
[Epoch 3][Step 83], time=0.049208879470825195, ext_time=0.0061969757080078125, train_time=0.03799080848693848
[Epoch 3][Step 84], time=0.04861736297607422, ext_time=0.0061151981353759766, train_time=0.037528276443481445
[Epoch 3][Step 85], time=0.04887843132019043, ext_time=0.006050825119018555, train_time=0.03781771659851074
[Epoch 3][Step 86], time=0.048692941665649414, ext_time=0.006108999252319336, train_time=0.03762674331665039
[Epoch 3][Step 87], time=0.04876303672790527, ext_time=0.006119728088378906, train_time=0.037706851959228516
[Epoch 3][Step 88], time=0.04866433143615723, ext_time=0.006046772003173828, train_time=0.03761100769042969
[Epoch 3][Step 89], time=0.04961991310119629, ext_time=0.006154537200927734, train_time=0.03840208053588867
[Epoch 3][Step 90], time=0.04879331588745117, ext_time=0.006110429763793945, train_time=0.03766298294067383
[Epoch 3][Step 91], time=0.049833059310913086, ext_time=0.006191730499267578, train_time=0.03856992721557617
[Epoch 3][Step 92], time=0.04964327812194824, ext_time=0.006077766418457031, train_time=0.038626670837402344
[Epoch 3][Step 93], time=0.04895949363708496, ext_time=0.006096601486206055, train_time=0.03777742385864258
[Epoch 3][Step 94], time=0.04837203025817871, ext_time=0.006110429763793945, train_time=0.03728032112121582
[Epoch 3][Step 95], time=0.048993825912475586, ext_time=0.006117582321166992, train_time=0.03788304328918457
[Epoch 3][Step 96], time=0.04910564422607422, ext_time=0.006182670593261719, train_time=0.03792309761047363
[Epoch 3][Step 97], time=0.04985761642456055, ext_time=0.0061795711517333984, train_time=0.038572072982788086
[Epoch 3][Step 98], time=0.04844093322753906, ext_time=0.006057024002075195, train_time=0.037435293197631836
[Epoch 3][Step 99], time=0.0491032600402832, ext_time=0.0061588287353515625, train_time=0.03794217109680176
[Epoch 3][Step 100], time=0.04875779151916504, ext_time=0.006131649017333984, train_time=0.03764677047729492
[Epoch 3][Step 101], time=0.04902172088623047, ext_time=0.006060361862182617, train_time=0.037972211837768555
[Epoch 3][Step 102], time=0.049185991287231445, ext_time=0.006060361862182617, train_time=0.037982940673828125
[Epoch 3][Step 103], time=0.0493772029876709, ext_time=0.0061511993408203125, train_time=0.03817152976989746
[Epoch 3][Step 104], time=0.04929375648498535, ext_time=0.006112337112426758, train_time=0.038146257400512695
[Epoch 3][Step 105], time=0.04960942268371582, ext_time=0.006178379058837891, train_time=0.038378000259399414
[Epoch 3][Step 106], time=0.04848170280456543, ext_time=0.006055593490600586, train_time=0.037447214126586914
[Epoch 3][Step 107], time=0.04928469657897949, ext_time=0.006162405014038086, train_time=0.03811049461364746
[Epoch 3][Step 108], time=0.0490875244140625, ext_time=0.006091594696044922, train_time=0.038028717041015625
[Epoch 3][Step 109], time=0.04871797561645508, ext_time=0.006081104278564453, train_time=0.03766298294067383
[Epoch 3][Step 110], time=0.048796892166137695, ext_time=0.0061779022216796875, train_time=0.03764224052429199
[Epoch 3][Step 111], time=0.04979419708251953, ext_time=0.00619816780090332, train_time=0.03853964805603027
[Epoch 3][Step 112], time=0.049050331115722656, ext_time=0.006081104278564453, train_time=0.038034677505493164
[Epoch 3][Step 113], time=0.04903221130371094, ext_time=0.006062746047973633, train_time=0.03805351257324219
[Epoch 3][Step 114], time=0.0492854118347168, ext_time=0.006201744079589844, train_time=0.0380702018737793
[Epoch 3][Step 115], time=0.049271583557128906, ext_time=0.006197690963745117, train_time=0.03807377815246582
[Epoch 3][Step 116], time=0.049246788024902344, ext_time=0.00605010986328125, train_time=0.03824186325073242
[Epoch 3][Step 117], time=0.04871559143066406, ext_time=0.00607609748840332, train_time=0.037642717361450195
[Epoch 3][Step 118], time=0.04968380928039551, ext_time=0.006220579147338867, train_time=0.0383908748626709
[Epoch 3][Step 119], time=0.04890036582946777, ext_time=0.006140947341918945, train_time=0.037713050842285156
[Epoch 3][Step 120], time=0.04981422424316406, ext_time=0.006131649017333984, train_time=0.038659095764160156
[Epoch 3][Step 121], time=0.049560546875, ext_time=0.006150722503662109, train_time=0.03831815719604492
[Epoch 3][Step 122], time=0.049411773681640625, ext_time=0.00611424446105957, train_time=0.038316965103149414
[Epoch 3][Step 123], time=0.0493619441986084, ext_time=0.00612950325012207, train_time=0.03831171989440918
[Epoch 3][Step 124], time=0.04878115653991699, ext_time=0.006119251251220703, train_time=0.03764653205871582
[Epoch 3][Step 125], time=0.04889416694641113, ext_time=0.0061643123626708984, train_time=0.03776717185974121
[Epoch 3][Step 126], time=0.049411773681640625, ext_time=0.006051301956176758, train_time=0.0384523868560791
[Epoch 3][Step 127], time=0.04935503005981445, ext_time=0.0059969425201416016, train_time=0.038448333740234375
[Epoch 3][Step 128], time=0.049053192138671875, ext_time=0.006135225296020508, train_time=0.037882328033447266
[Epoch 3][Step 129], time=0.0489811897277832, ext_time=0.006117820739746094, train_time=0.03787970542907715
[Epoch 3][Step 130], time=0.04927396774291992, ext_time=0.006136655807495117, train_time=0.038133859634399414
[Epoch 3][Step 131], time=0.04867196083068848, ext_time=0.00612330436706543, train_time=0.037544965744018555
[Epoch 3][Step 132], time=0.04909801483154297, ext_time=0.006021738052368164, train_time=0.038141727447509766
[Epoch 3][Step 133], time=0.049089908599853516, ext_time=0.006120920181274414, train_time=0.03797149658203125
[Epoch 3][Step 134], time=0.049416542053222656, ext_time=0.006121397018432617, train_time=0.03823089599609375
[Epoch 3][Step 135], time=0.04883146286010742, ext_time=0.006109476089477539, train_time=0.037728071212768555
[Epoch 3][Step 136], time=0.04933738708496094, ext_time=0.006060361862182617, train_time=0.03837251663208008
[Epoch 3][Step 137], time=0.048334360122680664, ext_time=0.0060231685638427734, train_time=0.03736591339111328
[Epoch 3][Step 138], time=0.04934859275817871, ext_time=0.006098747253417969, train_time=0.038175106048583984
[Epoch 3][Step 139], time=0.048614501953125, ext_time=0.006167888641357422, train_time=0.03746986389160156
[Epoch 3][Step 140], time=0.05011439323425293, ext_time=0.00612330436706543, train_time=0.0390620231628418
[Epoch 3][Step 141], time=0.04944205284118652, ext_time=0.006158590316772461, train_time=0.038234710693359375
[Epoch 3][Step 142], time=0.049004316329956055, ext_time=0.0060999393463134766, train_time=0.03790998458862305
[Epoch 3][Step 143], time=0.04851055145263672, ext_time=0.006104230880737305, train_time=0.0374453067779541
[Epoch 3][Step 144], time=0.04921245574951172, ext_time=0.0061702728271484375, train_time=0.037980079650878906
[Epoch 3][Step 145], time=0.04924345016479492, ext_time=0.006137371063232422, train_time=0.03811931610107422
[Epoch 3][Step 146], time=0.0489044189453125, ext_time=0.006087779998779297, train_time=0.037790536880493164
[Epoch 3][Step 147], time=0.049053192138671875, ext_time=0.006209611892700195, train_time=0.03785109519958496
[Epoch 3][Step 148], time=0.049182891845703125, ext_time=0.0061609745025634766, train_time=0.038004159927368164
[Epoch 3][Step 149], time=0.04875612258911133, ext_time=0.006045341491699219, train_time=0.03774237632751465
[Epoch 3][Step 150], time=0.04980587959289551, ext_time=0.006087064743041992, train_time=0.038694143295288086
[Epoch 3][Step 151], time=0.049019813537597656, ext_time=0.006122112274169922, train_time=0.03789353370666504
[Epoch 3][Step 152], time=0.0490572452545166, ext_time=0.0061054229736328125, train_time=0.0379176139831543
[Epoch 3][Step 153], time=0.04865312576293945, ext_time=0.006107330322265625, train_time=0.03759884834289551
[Epoch 3][Step 154], time=0.049454689025878906, ext_time=0.0066149234771728516, train_time=0.03784036636352539
[Epoch 3][Step 155], time=0.048685312271118164, ext_time=0.006120920181274414, train_time=0.03758573532104492
[Epoch 3][Step 156], time=0.0490574836730957, ext_time=0.0061762332916259766, train_time=0.037863731384277344
[Epoch 3][Step 157], time=0.04872608184814453, ext_time=0.006051301956176758, train_time=0.037702322006225586
[Epoch 3][Step 158], time=0.04996657371520996, ext_time=0.006058931350708008, train_time=0.03898763656616211
[Epoch 3][Step 159], time=0.049447059631347656, ext_time=0.0060710906982421875, train_time=0.038382530212402344
[Epoch 3][Step 160], time=0.04957318305969238, ext_time=0.00616908073425293, train_time=0.038342952728271484
[Epoch 3][Step 161], time=0.04860258102416992, ext_time=0.006100654602050781, train_time=0.03751993179321289
[Epoch 3][Step 162], time=0.049204111099243164, ext_time=0.0061473846435546875, train_time=0.038034677505493164
[Epoch 3][Step 163], time=0.04903697967529297, ext_time=0.006130695343017578, train_time=0.037904977798461914
[Epoch 3][Step 164], time=0.049097537994384766, ext_time=0.006062507629394531, train_time=0.03804135322570801
[Epoch 3][Step 165], time=0.04826807975769043, ext_time=0.006072044372558594, train_time=0.03720688819885254
[Epoch 3][Step 166], time=0.0493466854095459, ext_time=0.006124258041381836, train_time=0.0382080078125
[Epoch 3][Step 167], time=0.04932856559753418, ext_time=0.0061130523681640625, train_time=0.03818702697753906
[Epoch 3][Step 168], time=0.04911971092224121, ext_time=0.006070375442504883, train_time=0.03805899620056152
[Epoch 3][Step 169], time=0.05730104446411133, ext_time=0.0062274932861328125, train_time=0.04593610763549805
[Epoch 3][Step 170], time=0.04932212829589844, ext_time=0.0060710906982421875, train_time=0.03819084167480469
[Epoch 3][Step 171], time=0.049018144607543945, ext_time=0.006065845489501953, train_time=0.03794097900390625
[Epoch 3][Step 172], time=0.04853391647338867, ext_time=0.006022453308105469, train_time=0.03761458396911621
[Epoch 3][Step 173], time=0.04939675331115723, ext_time=0.0061647891998291016, train_time=0.038182735443115234
[Epoch 3][Step 174], time=0.04909157752990723, ext_time=0.006059885025024414, train_time=0.038050174713134766
[Epoch 3][Step 175], time=0.04877638816833496, ext_time=0.006093263626098633, train_time=0.03769516944885254
[Epoch 3][Step 176], time=0.04862809181213379, ext_time=0.006085395812988281, train_time=0.037587881088256836
[Epoch 3][Step 177], time=0.04890036582946777, ext_time=0.00610661506652832, train_time=0.0378422737121582
[Epoch 3][Step 178], time=0.04838156700134277, ext_time=0.006131172180175781, train_time=0.03727364540100098
[Epoch 3][Step 179], time=0.04912304878234863, ext_time=0.006142854690551758, train_time=0.03796243667602539
[Epoch 3][Step 180], time=0.05138087272644043, ext_time=0.006180763244628906, train_time=0.04015970230102539
[Epoch 3][Step 181], time=0.04958772659301758, ext_time=0.006113767623901367, train_time=0.038424015045166016
[Epoch 3][Step 182], time=0.04840421676635742, ext_time=0.006054401397705078, train_time=0.03740644454956055
[Epoch 3][Step 183], time=0.04917502403259277, ext_time=0.006175518035888672, train_time=0.03797483444213867
[Epoch 3][Step 184], time=0.048810482025146484, ext_time=0.006086826324462891, train_time=0.037755489349365234
[Epoch 3][Step 185], time=0.048818349838256836, ext_time=0.00616908073425293, train_time=0.03760862350463867
[Epoch 3][Step 186], time=0.049088239669799805, ext_time=0.006160736083984375, train_time=0.03789496421813965
[Epoch 3][Step 187], time=0.04866361618041992, ext_time=0.006109952926635742, train_time=0.037584543228149414
[Epoch 3][Step 188], time=0.04942154884338379, ext_time=0.0060122013092041016, train_time=0.03845524787902832
[Epoch 3][Step 189], time=0.04903221130371094, ext_time=0.006103038787841797, train_time=0.03792452812194824
[Epoch 3][Step 190], time=0.049312591552734375, ext_time=0.0061528682708740234, train_time=0.03815174102783203
[Epoch 3][Step 191], time=0.04875326156616211, ext_time=0.00611424446105957, train_time=0.03760504722595215
[Epoch 3][Step 192], time=0.048742055892944336, ext_time=0.006153583526611328, train_time=0.03756451606750488
[Epoch 3][Step 193], time=0.04949307441711426, ext_time=0.006181001663208008, train_time=0.03825831413269043
[Epoch 3][Step 194], time=0.049132347106933594, ext_time=0.00613713264465332, train_time=0.037958383560180664
[Epoch 3][Step 195], time=0.04896807670593262, ext_time=0.006142377853393555, train_time=0.037810325622558594
[Epoch 3][Step 196], time=0.04888105392456055, ext_time=0.0060367584228515625, train_time=0.03784656524658203
[Epoch 3][Step 197], time=0.04908943176269531, ext_time=0.006091594696044922, train_time=0.03803706169128418
[Epoch 3][Step 198], time=0.3602132797241211, ext_time=0.006014108657836914, train_time=0.3492462635040283
[Epoch 3][Step 199], time=0.04943203926086426, ext_time=0.0062122344970703125, train_time=0.03827095031738281
[Epoch 3][Step 200], time=0.04898357391357422, ext_time=0.0060956478118896484, train_time=0.03787803649902344
[Epoch 3][Step 201], time=0.04921078681945801, ext_time=0.006139516830444336, train_time=0.03809952735900879
[Epoch 3][Step 202], time=0.04929780960083008, ext_time=0.006009101867675781, train_time=0.03817343711853027
[Epoch 3][Step 203], time=0.04876303672790527, ext_time=0.006062507629394531, train_time=0.037671566009521484
[Epoch 3][Step 204], time=0.04868960380554199, ext_time=0.006037235260009766, train_time=0.03767824172973633
[Epoch 3][Step 205], time=0.04884767532348633, ext_time=0.006051063537597656, train_time=0.03784775733947754
[Epoch 3][Step 206], time=0.049575090408325195, ext_time=0.0059604644775390625, train_time=0.038712263107299805
[Epoch 3][Step 207], time=0.04926800727844238, ext_time=0.0060977935791015625, train_time=0.03816819190979004
[Epoch 3][Step 208], time=0.049291133880615234, ext_time=0.006092071533203125, train_time=0.038170576095581055
[Epoch 3][Step 209], time=0.0491642951965332, ext_time=0.006067991256713867, train_time=0.03819131851196289
[Epoch 3][Step 210], time=0.04849362373352051, ext_time=0.006142854690551758, train_time=0.037370920181274414
[Epoch 3][Step 211], time=0.04928874969482422, ext_time=0.0061914920806884766, train_time=0.03805184364318848
[Epoch 3][Step 212], time=0.04926729202270508, ext_time=0.006151676177978516, train_time=0.03810620307922363
[Epoch 3][Step 213], time=0.04916024208068848, ext_time=0.006104707717895508, train_time=0.03803849220275879
[Epoch 3][Step 214], time=0.04888129234313965, ext_time=0.006132364273071289, train_time=0.03768801689147949
[Epoch 3][Step 215], time=0.04933762550354004, ext_time=0.006122589111328125, train_time=0.03816986083984375
[Epoch 3][Step 216], time=0.04939770698547363, ext_time=0.006096839904785156, train_time=0.038282155990600586
[Epoch 3][Step 217], time=0.049041032791137695, ext_time=0.00617671012878418, train_time=0.03784918785095215
[Epoch 3][Step 218], time=0.04833173751831055, ext_time=0.006069660186767578, train_time=0.03729987144470215
[Epoch 3][Step 219], time=0.04889178276062012, ext_time=0.006228208541870117, train_time=0.0376439094543457
[Epoch 3][Step 220], time=0.048821449279785156, ext_time=0.006043195724487305, train_time=0.03782844543457031
[Epoch 3][Step 221], time=0.048712968826293945, ext_time=0.006146669387817383, train_time=0.037540435791015625
[Epoch 3][Step 222], time=0.04857945442199707, ext_time=0.00608515739440918, train_time=0.0375058650970459
[Epoch 3][Step 223], time=0.049021005630493164, ext_time=0.006073951721191406, train_time=0.03799867630004883
[Epoch 3][Step 224], time=0.05468463897705078, ext_time=0.0060002803802490234, train_time=0.038698673248291016
[Epoch 3][Step 225], time=0.04964709281921387, ext_time=0.006181955337524414, train_time=0.03840804100036621
[Epoch 3][Step 226], time=0.048635244369506836, ext_time=0.006072998046875, train_time=0.037592411041259766
[Epoch 3][Step 227], time=0.047943830490112305, ext_time=0.006047725677490234, train_time=0.0369565486907959
[Epoch 3][Step 228], time=0.048613786697387695, ext_time=0.00609898567199707, train_time=0.03751778602600098
[Epoch 3][Step 229], time=0.04935026168823242, ext_time=0.00616145133972168, train_time=0.03811836242675781
[Epoch 3][Step 230], time=0.04911923408508301, ext_time=0.006090402603149414, train_time=0.03799867630004883
[Epoch 3][Step 231], time=0.04883289337158203, ext_time=0.006159305572509766, train_time=0.037695884704589844
[Epoch 3][Step 232], time=0.04893016815185547, ext_time=0.006061077117919922, train_time=0.037878990173339844
[Epoch 3][Step 233], time=0.04888415336608887, ext_time=0.006085395812988281, train_time=0.03777194023132324
[Epoch 3][Step 234], time=0.04946017265319824, ext_time=0.006148338317871094, train_time=0.03827524185180664
[Epoch 3][Step 235], time=0.04906797409057617, ext_time=0.006133556365966797, train_time=0.037920475006103516
[Epoch 3][Step 236], time=0.04923081398010254, ext_time=0.006188392639160156, train_time=0.03800702095031738
[Epoch 3][Step 237], time=0.0493159294128418, ext_time=0.006089687347412109, train_time=0.03826618194580078
[Epoch 3][Step 238], time=0.04867815971374512, ext_time=0.006057024002075195, train_time=0.037633657455444336
[Epoch 3][Step 239], time=0.04796147346496582, ext_time=0.0059926509857177734, train_time=0.0370182991027832
[Epoch 3][Step 240], time=0.048983097076416016, ext_time=0.006143808364868164, train_time=0.03781843185424805
[Epoch 3][Step 241], time=0.048970937728881836, ext_time=0.006100177764892578, train_time=0.03785228729248047
[Epoch 3][Step 242], time=0.04903054237365723, ext_time=0.0061075687408447266, train_time=0.037912607192993164
[Epoch 3][Step 243], time=0.048635244369506836, ext_time=0.006112813949584961, train_time=0.037546634674072266
[Epoch 3][Step 244], time=0.04841804504394531, ext_time=0.0060694217681884766, train_time=0.03735685348510742
[Epoch 3][Step 245], time=0.04901766777038574, ext_time=0.006091117858886719, train_time=0.037919044494628906
[Epoch 3][Step 246], time=0.04848742485046387, ext_time=0.0060384273529052734, train_time=0.03753161430358887
[Epoch 3][Step 247], time=0.04920506477355957, ext_time=0.00612640380859375, train_time=0.03804945945739746
[Epoch 3][Step 248], time=0.048479557037353516, ext_time=0.0061070919036865234, train_time=0.03737330436706543
[Epoch 3][Step 249], time=0.04997992515563965, ext_time=0.006165981292724609, train_time=0.03871870040893555
[Epoch 3], time=13.198006391525269, loss=nan
    [Step(average) Profiler Level 1 E3 S1999]
        L1  sample           0.004985 | send           0.000000
        L1  recv             0.000000 | copy           0.006137 | convert time 0.000000 | train  0.040314
        L1  feature nbytes    2.23 GB | label nbytes 0.00 Bytes
        L1  id nbytes      0.00 Bytes | graph nbytes 0.00 Bytes
        L1  miss nbytes       9.21 MB | remote nbytes    1.15 GB
        L1  num nodes               0 | num samples           0
        L1  seq duration     0.000000 | refresh duration   0.000000
    [Step(average) Profiler Level 2 E3 S1999]
        L2  shuffle     0.000000 | core sample  0.000000 | id remap        0.000000
        L2  graph copy  0.000000 | id copy      0.000000 | cache feat copy 0.006137
        L2  last layer sample time 0.000000 | size 0.000000
    [Step(average) Profiler Level 3 E3 S1999]
        L3  khop sample coo  0.000000 | khop sort coo      0.000000 | khop count edge     0.000000 | khop compact edge 0.000000
        L3  walk sample coo  0.000000 | walk topk total    0.000000 | walk topk step1     0.000000 | walk topk step2   0.000000
        L3  walk topk step3  0.000000 | walk topk step4    0.000000 | walk topk step5     0.000000
        L3  walk topk step6  0.000000 | walk topk step7    0.000000
        L3  remap unique     0.000000 | remap populate     0.000000 | remap mapnode       0.000000 | remap mapedge     0.000000
        L3  cache get_index  0.000504 | cache copy_index   0.000000 | cache extract_miss  0.000000
        L3  cache copy_miss  0.000000 | cache combine_miss 0.000715 | cache combine cache 0.000135 | cache combine remote 0.005464
        L3  label extract  0.000000
    [Profiler Level Percentiles E3 S1999]
        p50.00_tail_logl2featcopy=0.006124
        p90.00_tail_logl2featcopy=0.006273
        p95.00_tail_logl2featcopy=0.006363
        p99.00_tail_logl2featcopy=0.006541
        p99.90_tail_logl2featcopy=0.023696
[CUDA] cuda: usage: 77.06 GB
worker 7 running with pid=52698
loading train edge idx from disk
loading train edge idx from disk done
tensor([ 367470406, 3158702471, 3196913887,  311268946, 2622541626, 2707306334,
        2288750783,  341639546, 2394912536, 3266219078,  474737188, 1665128055,
        3225579545,  584996459,  307810634,  726851972, 1000854521, 1061370191,
         371057554,  526478766,  273325093, 1382980281, 1363464091,  971316959,
        1643305663, 1559556869,  792051811, 2593715952, 2627476216,  642711792,
        1279512108,  281028249, 2848334841, 1142277951, 1624797255, 1682408139,
         288375990,  530555421, 1190696744, 1515340461,  396873136, 3079813016,
         574876927,   31156367,  607610239, 1664434120,  774080817, 2850247945,
         655998496,  888602410,  350570870,  624008623,   69778231,  638128676,
        1443388341, 1479712286, 2858804367,  550628163,  198023098, 2583590303,
        2518492873,    2593795, 2722269746,  659106604, 1369497066,  235303384,
         645516367, 3053389785, 3376243999,  792250187, 1401047469, 1545651011,
        1827797263, 1275030316, 2075895474, 2919804301, 2493902937,  112768749,
          11701078,  500365351,  404737965,  786261376,  934911988,  757583227,
        1135493038, 3162165660, 1144120843, 2861906075,      93256, 1866677628,
         103141175, 3295574170, 1840253021,  747507530,  196097433, 3025516425,
         133597469,  755176081, 2348166713,   80549681])
Rank=7, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.009005, per step: 0.000036
presamping
presamping takes 16.779637813568115
worker 4 running with pid=52692
loading train edge idx from disk
loading train edge idx from disk done
tensor([ 367470406, 3158702471, 3196913887,  311268946, 2622541626, 2707306334,
        2288750783,  341639546, 2394912536, 3266219078,  474737188, 1665128055,
        3225579545,  584996459,  307810634,  726851972, 1000854521, 1061370191,
         371057554,  526478766,  273325093, 1382980281, 1363464091,  971316959,
        1643305663, 1559556869,  792051811, 2593715952, 2627476216,  642711792,
        1279512108,  281028249, 2848334841, 1142277951, 1624797255, 1682408139,
         288375990,  530555421, 1190696744, 1515340461,  396873136, 3079813016,
         574876927,   31156367,  607610239, 1664434120,  774080817, 2850247945,
         655998496,  888602410,  350570870,  624008623,   69778231,  638128676,
        1443388341, 1479712286, 2858804367,  550628163,  198023098, 2583590303,
        2518492873,    2593795, 2722269746,  659106604, 1369497066,  235303384,
         645516367, 3053389785, 3376243999,  792250187, 1401047469, 1545651011,
        1827797263, 1275030316, 2075895474, 2919804301, 2493902937,  112768749,
          11701078,  500365351,  404737965,  786261376,  934911988,  757583227,
        1135493038, 3162165660, 1144120843, 2861906075,      93256, 1866677628,
         103141175, 3295574170, 1840253021,  747507530,  196097433, 3025516425,
         133597469,  755176081, 2348166713,   80549681])
Rank=4, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.008794, per step: 0.000035
presamping
presamping takes 19.74584650993347
worker 5 running with pid=52694
loading train edge idx from disk
loading train edge idx from disk done
tensor([ 367470406, 3158702471, 3196913887,  311268946, 2622541626, 2707306334,
        2288750783,  341639546, 2394912536, 3266219078,  474737188, 1665128055,
        3225579545,  584996459,  307810634,  726851972, 1000854521, 1061370191,
         371057554,  526478766,  273325093, 1382980281, 1363464091,  971316959,
        1643305663, 1559556869,  792051811, 2593715952, 2627476216,  642711792,
        1279512108,  281028249, 2848334841, 1142277951, 1624797255, 1682408139,
         288375990,  530555421, 1190696744, 1515340461,  396873136, 3079813016,
         574876927,   31156367,  607610239, 1664434120,  774080817, 2850247945,
         655998496,  888602410,  350570870,  624008623,   69778231,  638128676,
        1443388341, 1479712286, 2858804367,  550628163,  198023098, 2583590303,
        2518492873,    2593795, 2722269746,  659106604, 1369497066,  235303384,
         645516367, 3053389785, 3376243999,  792250187, 1401047469, 1545651011,
        1827797263, 1275030316, 2075895474, 2919804301, 2493902937,  112768749,
          11701078,  500365351,  404737965,  786261376,  934911988,  757583227,
        1135493038, 3162165660, 1144120843, 2861906075,      93256, 1866677628,
         103141175, 3295574170, 1840253021,  747507530,  196097433, 3025516425,
         133597469,  755176081, 2348166713,   80549681])
Rank=5, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.009311, per step: 0.000037
presamping
presamping takes 19.537404537200928
worker 1 running with pid=52687
loading train edge idx from disk
loading train edge idx from disk done
tensor([ 367470406, 3158702471, 3196913887,  311268946, 2622541626, 2707306334,
        2288750783,  341639546, 2394912536, 3266219078,  474737188, 1665128055,
        3225579545,  584996459,  307810634,  726851972, 1000854521, 1061370191,
         371057554,  526478766,  273325093, 1382980281, 1363464091,  971316959,
        1643305663, 1559556869,  792051811, 2593715952, 2627476216,  642711792,
        1279512108,  281028249, 2848334841, 1142277951, 1624797255, 1682408139,
         288375990,  530555421, 1190696744, 1515340461,  396873136, 3079813016,
         574876927,   31156367,  607610239, 1664434120,  774080817, 2850247945,
         655998496,  888602410,  350570870,  624008623,   69778231,  638128676,
        1443388341, 1479712286, 2858804367,  550628163,  198023098, 2583590303,
        2518492873,    2593795, 2722269746,  659106604, 1369497066,  235303384,
         645516367, 3053389785, 3376243999,  792250187, 1401047469, 1545651011,
        1827797263, 1275030316, 2075895474, 2919804301, 2493902937,  112768749,
          11701078,  500365351,  404737965,  786261376,  934911988,  757583227,
        1135493038, 3162165660, 1144120843, 2861906075,      93256, 1866677628,
         103141175, 3295574170, 1840253021,  747507530,  196097433, 3025516425,
         133597469,  755176081, 2348166713,   80549681])
Rank=1, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.008926, per step: 0.000036
presamping
presamping takes 18.21855092048645
worker 6 running with pid=52696
loading train edge idx from disk
loading train edge idx from disk done
tensor([ 367470406, 3158702471, 3196913887,  311268946, 2622541626, 2707306334,
        2288750783,  341639546, 2394912536, 3266219078,  474737188, 1665128055,
        3225579545,  584996459,  307810634,  726851972, 1000854521, 1061370191,
         371057554,  526478766,  273325093, 1382980281, 1363464091,  971316959,
        1643305663, 1559556869,  792051811, 2593715952, 2627476216,  642711792,
        1279512108,  281028249, 2848334841, 1142277951, 1624797255, 1682408139,
         288375990,  530555421, 1190696744, 1515340461,  396873136, 3079813016,
         574876927,   31156367,  607610239, 1664434120,  774080817, 2850247945,
         655998496,  888602410,  350570870,  624008623,   69778231,  638128676,
        1443388341, 1479712286, 2858804367,  550628163,  198023098, 2583590303,
        2518492873,    2593795, 2722269746,  659106604, 1369497066,  235303384,
         645516367, 3053389785, 3376243999,  792250187, 1401047469, 1545651011,
        1827797263, 1275030316, 2075895474, 2919804301, 2493902937,  112768749,
          11701078,  500365351,  404737965,  786261376,  934911988,  757583227,
        1135493038, 3162165660, 1144120843, 2861906075,      93256, 1866677628,
         103141175, 3295574170, 1840253021,  747507530,  196097433, 3025516425,
         133597469,  755176081, 2348166713,   80549681])
Rank=6, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.009715, per step: 0.000039
presamping
presamping takes 19.76603674888611
worker 2 running with pid=52688
loading train edge idx from disk
loading train edge idx from disk done
tensor([ 367470406, 3158702471, 3196913887,  311268946, 2622541626, 2707306334,
        2288750783,  341639546, 2394912536, 3266219078,  474737188, 1665128055,
        3225579545,  584996459,  307810634,  726851972, 1000854521, 1061370191,
         371057554,  526478766,  273325093, 1382980281, 1363464091,  971316959,
        1643305663, 1559556869,  792051811, 2593715952, 2627476216,  642711792,
        1279512108,  281028249, 2848334841, 1142277951, 1624797255, 1682408139,
         288375990,  530555421, 1190696744, 1515340461,  396873136, 3079813016,
         574876927,   31156367,  607610239, 1664434120,  774080817, 2850247945,
         655998496,  888602410,  350570870,  624008623,   69778231,  638128676,
        1443388341, 1479712286, 2858804367,  550628163,  198023098, 2583590303,
        2518492873,    2593795, 2722269746,  659106604, 1369497066,  235303384,
         645516367, 3053389785, 3376243999,  792250187, 1401047469, 1545651011,
        1827797263, 1275030316, 2075895474, 2919804301, 2493902937,  112768749,
          11701078,  500365351,  404737965,  786261376,  934911988,  757583227,
        1135493038, 3162165660, 1144120843, 2861906075,      93256, 1866677628,
         103141175, 3295574170, 1840253021,  747507530,  196097433, 3025516425,
         133597469,  755176081, 2348166713,   80549681])
Rank=2, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.009160, per step: 0.000037
presamping
presamping takes 17.511115074157715
worker 3 running with pid=52690
loading train edge idx from disk
loading train edge idx from disk done
tensor([ 367470406, 3158702471, 3196913887,  311268946, 2622541626, 2707306334,
        2288750783,  341639546, 2394912536, 3266219078,  474737188, 1665128055,
        3225579545,  584996459,  307810634,  726851972, 1000854521, 1061370191,
         371057554,  526478766,  273325093, 1382980281, 1363464091,  971316959,
        1643305663, 1559556869,  792051811, 2593715952, 2627476216,  642711792,
        1279512108,  281028249, 2848334841, 1142277951, 1624797255, 1682408139,
         288375990,  530555421, 1190696744, 1515340461,  396873136, 3079813016,
         574876927,   31156367,  607610239, 1664434120,  774080817, 2850247945,
         655998496,  888602410,  350570870,  624008623,   69778231,  638128676,
        1443388341, 1479712286, 2858804367,  550628163,  198023098, 2583590303,
        2518492873,    2593795, 2722269746,  659106604, 1369497066,  235303384,
         645516367, 3053389785, 3376243999,  792250187, 1401047469, 1545651011,
        1827797263, 1275030316, 2075895474, 2919804301, 2493902937,  112768749,
          11701078,  500365351,  404737965,  786261376,  934911988,  757583227,
        1135493038, 3162165660, 1144120843, 2861906075,      93256, 1866677628,
         103141175, 3295574170, 1840253021,  747507530,  196097433, 3025516425,
         133597469,  755176081, 2348166713,   80549681])
Rank=3, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.009226, per step: 0.000037
presamping
presamping takes 17.70997428894043
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 1         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  113561 KB |    8116 MB |   12997 GB |   12997 GB |
|       from large pool |  109308 KB |    8112 MB |   12984 GB |   12984 GB |
|       from small pool |    4252 KB |       5 MB |      13 GB |      13 GB |
|---------------------------------------------------------------------------|
| Active memory         |  113561 KB |    8116 MB |   12997 GB |   12997 GB |
|       from large pool |  109308 KB |    8112 MB |   12984 GB |   12984 GB |
|       from small pool |    4252 KB |       5 MB |      13 GB |      13 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   21520 MB |   22036 MB |   42602 MB |   21082 MB |
|       from large pool |   21512 MB |   22028 MB |   42592 MB |   21080 MB |
|       from small pool |       8 MB |       8 MB |      10 MB |       2 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |    3203 MB |    7800 MB |    7444 GB |    7441 GB |
|       from large pool |    3201 MB |    7798 MB |    7428 GB |    7425 GB |
|       from small pool |       1 MB |       4 MB |      15 GB |      15 GB |
|---------------------------------------------------------------------------|
| Allocations           |      57    |      94    |  303291    |  303234    |
|       from large pool |      24    |      51    |  139017    |  138993    |
|       from small pool |      33    |      46    |  164274    |  164241    |
|---------------------------------------------------------------------------|
| Active allocs         |      57    |      94    |  303291    |  303234    |
|       from large pool |      24    |      51    |  139017    |  138993    |
|       from small pool |      33    |      46    |  164274    |  164241    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      24    |      24    |      30    |       6    |
|       from large pool |      20    |      20    |      25    |       5    |
|       from small pool |       4    |       4    |       5    |       1    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      33    |      43    |  114635    |  114602    |
|       from large pool |      18    |      27    |   73457    |   73439    |
|       from small pool |      15    |      23    |   41178    |   41163    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[TRAIN_TIME] train time is 55.681102 seconds
[EPOCH_TIME] 13.920275 seconds, maybe large due to not enough epoch skipped.
[EPOCH_TIME] 12.748215 seconds

